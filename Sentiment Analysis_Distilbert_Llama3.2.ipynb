{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/paulineng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/paulineng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/paulineng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/paulineng/Desktop/03 Text Analytics and Applications/Group Project\"\n",
    "df = pd.read_csv(f\"{base_dir}/Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for null and duplicate reviews. 17485 duplicated reviews were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 568454\n",
      "Missing Text: 0\n",
      "Duplicates (by 'Text' only): 174875\n"
     ]
    }
   ],
   "source": [
    "#Check for null and duplicates in 'Text' column\n",
    "def check_duplicate_null (df, text_column='Text'):\n",
    "    total_rows = len(df)\n",
    "    missing_count = df[text_column].isna().sum()\n",
    "    duplicate_count = df.duplicated(subset=text_column).sum()\n",
    "    \n",
    "    print(f\"Total rows: {total_rows}\")\n",
    "    print(f\"Missing {text_column}: {missing_count}\")\n",
    "    print(f\"Duplicates (by '{text_column}' only): {duplicate_count}\")\n",
    "\n",
    "check_duplicate_null(df, text_column='Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393579 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[393579 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop duplicates\n",
    "df.drop_duplicates(subset='Text', keep='first', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 393579\n",
      "Missing Text: 0\n",
      "Duplicates (by 'Text' only): 0\n"
     ]
    }
   ],
   "source": [
    "#After dropping duplicates, confirm no duplicate or missing text\n",
    "check_duplicate_null(df, text_column='Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews outside the 1–5 range: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for valid rating scores 1 to 5\n",
    "out_of_range = df[(df['Score'] < 1) | (df['Score'] > 5)]\n",
    "print(\"Number of reviews outside the 1–5 range:\", len(out_of_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['review_length_raw'] = df['Text'].apply(lambda x: len(str(x).split()))\n",
    "bins = [0, 10, 50, 100, 200, 400, 500, df['review_length_raw'].max() + 1]\n",
    "labels = [\"<10\", \"10-50\", \"50-100\", \"100-200\", \"200-400\", \"400-500\", \">500\"]\n",
    "df['length_category'] = pd.cut(df['review_length_raw'], bins=bins, labels=labels, right=False)\n",
    "category_counts = df['length_category'].value_counts().sort_index()\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(\n",
    "    category_counts.index.astype(str),\n",
    "    category_counts.values,\n",
    "    color=\"steelblue\",\n",
    "    edgecolor='none'\n",
    ")\n",
    "plt.title('Figure 1: Distribution of Review Length', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Review Length', fontweight='bold')\n",
    "plt.ylabel('Number of Review', fontweight='bold')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        height,\n",
    "        f\"{int(height)}\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontweight='bold'\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for extremely short reviews (<10 words) and extremly long reviews (>500 reviews). There are 63 reviews with <10 words and 1529 reviews with >500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews < 10 words: 63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14893               Smoothest green tea yet....good all day\n",
       "15560                     Same price as Dr. Foster & Smith.\n",
       "44455          Yummy, if you like noodles I recomend these.\n",
       "49025     <span class=\"tiny\"> Length:: 1:02 Mins<br /><b...\n",
       "65997     <span class=\"tiny\"> Length:: 0:42 Mins<br /><b...\n",
       "                                ...                        \n",
       "495800    <span class=\"tiny\"> Length:: 0:17 Mins<br /><b...\n",
       "552341                     Great!  Make it all of the time.\n",
       "558985    My office staff has been delighted with every ...\n",
       "566927    Rather mild but pleasant tasting coffee...typi...\n",
       "568415                     as it should be for $6 a bottle.\n",
       "Name: Text, Length: 63, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Review with <10 words\n",
    "short_threshold = 10\n",
    "very_short_df = df[df['Text'].apply(lambda x: len(str(x).split())) < short_threshold]\n",
    "print(\"Number of reviews < 10 words:\", len(very_short_df))\n",
    "\n",
    "very_short_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews >500 words: 1529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "528                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I once loved these chips and they were the only chips i would buy.  I discovered them when I was in England back in 2000 and quickly became a fan.  About a year ago I picked up a bag that was on sale at my local supermarket.  I was finding it odd that they were on sale so much but took advantage of it.  After opening the bag I found the chips were not even close to the Kettle chips I was used to.  They were all uniform whitish yellow in color, flavor was way off, the lovely extra crisp brown chips were gone completely and I was very disappointed.  So I e-mailed Kettle with the following:  \"What Happened? I bought this bag of chips the other day and they have a very different taste; It tastes \"cheaper\". I don't know how else to put it... I also noticed that the chips seemed to be less cooked as I did not see any of the browner colored chips that have the most flavor. I am hoping that nothing has changed with the ingredients or process used to produce this product. Did I just get a weird batch? I have been buying only Kettle Chips for about 10 years now so I am wondering.\"  I did receive a reply: \"Thanks for letting us know about your experience with your Kettle Brand® Chips. It sounds like you may have received a bag that should not have slipped by our inspections, and we apologize.Our potatoes do vary seasonally which could account for a variation in color-but our chips should still taste great!Thanks for providing us with the \"best before\" code from the bag.  This really helps when passing on your comments to our staff.<br />We are sending some coupons to replace your purchase with any of our Kettle Brand® flavors or nut butters, believing you will have a great experience with your next purchase! In case you buy this product again, we suggest avoiding the same best before date (if you still have it) in the rare instance another bag from the same case slipped by our inspections at the same time.<br />Thanks again for letting us know about this and expect the coupons to arrive within 3 weeks.  Please let me know if I can be of any more help.\"  Well the next bag was good.  Since that time I have picked up 3 bags of chips all were like the \"bad\" bag so I am pretty sure that they have changed there product to reduce cost.  I did some research and found out that Kettle was bought out by a private equity company.  So the same cookie cutter management processes are probably being employed at Kettle.  Acquire company with high quality brand recognition, sell product to mass merchants, lower quality/cost of product to increase margin and finally sell company just before the customer base starts to realize that the brand is no longer a quality brand.  increased profits make the company more valuable on paper so they make a nice profit for the investors. Customer and employees lose out of course as does an unsuspecting buyer of the exploited brand.  Stay away from Kettle chips they are no longer the same...\n",
       "539       I was getting VERY worried, when I read some of the other reviews here.  Specifically, the \"One Star\" reviews, to which I always go, to see if the faults these other reviewers find with any merchandise would prevent me from buying it.<br /><br />WOW!  They sure seemed to hate the KETTLE CHIPS, BACKYARD BARBECUE 9-OUNCE BAGS, (PACK OF 12), that I had bought as 1 ounce bags, liked A LOT, decided to subscribe....and then, for good measure, got 2 orders of the 9 ounce bags.<br /><br />Yes...I love potato chips....especially these KETTLE CHIPS, BACKYARD BARBECUE FLAVOUR....but others seemed to really HATE them...or at least, hate how they had changed.<br />But then I realized they were talking about OTHER FLAVOURS!  Amazon, in it's deep wisdom, has obviously seen fit to put ALL comments concerning ALL flavours of KETTLE, (and other brands of?????) potato chips, TOGETHER!<br /><br />Of course, this DOES have SOME advantages, because most potato-chip lovers, (like me!), enjoy eating several flavour, and brand varieties.  So, comparisons can be made easily.  Also, as we're all potato-chip lovers, but each person has his or her very favourite flavour that they are reviewing, we are, here a sort of \"United Nations of Potato Chip Lovers\"....all different, but all united in our love of Potato Chips!  (The rest of the world can REALLY benefit from the example of our tightly-knit, but ever...er,...expanding...group here, I think! : )  But -- not at first realizing that these<br />different flavour reviews were all together, did cause me a little confusion and dismay.... at least to begin with.... (Amazon should have mentioned that this is the \"Kettle Potato Chip Review Forum\"! : )<br /><br />I am happy to report that KETTLE CHIPS, BACKYARD BARBEQUE FLAVOUR, are totally delicious!  (At least they are in the one-ounce bags...hopefully the same product in the 9 ounce bags will taste the same!)  These are definitely chips for ADULTS, however -- and/or children whose stronger-than-adult taste buds can withstand the very strong flavour of these chips.  They are NOT the strongest flavour I have ever had...that was from a jalapeno pepper chip which was far too strong for even me!<br />These Backyard Barbeque chips by Kettle, however, have just the right amount of sweetness, (with honey powder, onion and sugar), to take the edge of the stonger flavours<br />(paprika, chili pepper, cayenne pepper, and natural smoke flavour), of which there is less, (they come further down in the list of ingredients than the sweeteners.)<br /><br />The complete list of ingredients of these KETTLE BACKYARD BARBECUE CHIPS, (in the 1-ounce bags, and hopefully, in the 9 ounce bags as well), is as follows:<br /><br />Potatoes<br />Vegetable Oil, (Safflower and Sunflower Oil),<br />Honey Powder, (Dried cane sugar, honey),<br />Rice Powder<br />Sugar<br />Salt<br />Onion Powder<br />Tomato Powder<br />Paprika<br />Torula Yeast<br />Garlic Powder<br />Chili Pepper<br />Citric Acid<br />Cayenne Pepper<br />Paprika Oleoresin, (Colour)<br />Natural Smoke Flavour<br /><br />Naturally cooked, natural ingredients.  The combination is a true taste treat!<br /><br />Of course, as with all ptato chips, moderation is the key.<br />Potatoes contain a LOT of potassium....which gives energy and othr good things....but too much of which can damage kindneys.  The vegetable oil is great -- but too much oil, (as well as too much starch, from the potatoes), can hurt the eyes.  Natural smoke flavour is SO yummy....but it, (as well as sugar), has -- in very large amounts -- been linked to cancer production<br /><br />As far as the starch from the potatoes and oil go, this<br />can be ameliorated, (a bit), by drinking TEA...which is good for the eyes.  But as far as the potassium, (energy - good, too much -- bad for the kidneys), and the sugar and natural smoke flavour, (too much leading to cancer production) -- the only thing is to do what is good in everything.....M O D E R A T I O N...!<br /><br />Twice or three times a month, I allow myself to go on what I call a \"Potato Chip Diet\".  I eat only one large bag, (or the equivalent in small ones), of potato chips all day.  I supplement this with tea, coffee, and lemonade, as well as several servings of Carnation Instant Breakfast Essentials, (I like the Dark Chocolate flavour)  This adds up to fewer calories than I would normally eat, if I had my normal three meals a day plus snacks.  It also teaches me to eat s-l-o-w-l-y, because that one big bag, (or many little bags), never lasts as long as I'd like.  Anyway, with excercise and sensible eating, the rest of the month, (and keeping my scale nearby, and weighing myself at least twice a day, every day), I've taken off ten pounds in the last three months! : )<br /><br />These BACKYARD BARBEQUE flavour potato chips from KETTLE,<br />are totally scrumptious.  Except for those jalapino chips, (which tasted good, but were far too spicy for my own taste buds), I have yet to meet a potato chip I didn't like to eat.  These Kettle BACKYARD BARBEQUE flavour potato chips, with their combination of potatoes, sweetness, and spices, have truly become one of my top five favourites....if not the VERY first favourite, of all!<br /><br />Flavoured potato PERFECTION!\n",
       "1052                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           They claim this product is \"unadulterated\", which would make you think \"oh! sweet! it's going to be the BEST, because nobody else's coconut oil says it's \"unadulterated\".  I checked out their website, and for those of you who don't know... you want to go for COLD PRESSED oils. If they're not cold pressed, it means they've been processed with major machinery and subjected to high heats, which as anything goes, can and usually does, kill any good minerals and vitamins. Their site posts information on their extraction process. As of today, this is what it states:<br /><br />\"\"Manila Coco oil extraction method is through a proprietary, state-of-the-art mechanical expeller (Manila VirginFlo), thermo-stable to hold off the lowest moisture possible (0.1%) to avoid rancidity and keep shelf life consistent up to 3 years under normal conditions. Our oils are 1st and 2nd stage press-induced, without chemical solvents, no bleaching, no deodorizing, no hydrogenation, no fermentation enzymes - to keep its natural light sweet coconut aroma and taste. This method sustains its unique character even when subjected to high (up to 170 degrees Celsius) heat temperatures.\"\"<br /><br />Mechanical Expeller is their form of extraction. And they also say it sustains unique character... blah blah blah... when subjected to high heat temperatures. Therefore, in my personal opinion, it is not as \"unadulterated\" as their information on their products on Amazon make them sound. I will be steering clear of their products.<br /><br />I'm sorry if my review offends some, but if you're going to pay good money for something, you should know about it. I would use different brands before sticking yourself with this one. I was looking for larger quantities, which is why I looked at this product, however I will be sticking with Nutiva. As their coconut oil is cold pressed soon after the coconuts are cut open. The information below is direct from their website.<br /><br />\"\"What makes Nutiva's virgin coconut oil so special? Much of the magic lies in the way the oil is processed. Within several hours of the coconuts being chopped, the meat is cold-pressed, unlike other varieties of coconut oil which can be left for more than 10 hours before pressing. Nutiva's approach preserves as much of the oil's natural color, flavor and aroma, giving you the best results for any use.\"\"<br /><br />If you don't care about how it's processed, it is still going to be much healthier than your average grocery store found vegetable and canola oils. If you want to read some scary things, look up the dark information on how those are processed. YUCK! Talk about horrifying.<br /><br />Thank you for your time.<br />-Amy<br /><br />PS. I used to be one of those \"organic? what kind of fruitcake are you? Think you're more special than anybody else?\" people. But I have learned so much in the past year and a half, dealing with my son's allergies and intollerances. There's more to it than \"oh it's more expensive, so it's just making me feel special because I can afford it.\" No. There's WAY more to it than that. I urge everybody to talk to people about organic foods. It's a way of life, a healthier way of life. We all deserve to live healthier. If you live healthier, even though it costs more, in the long term you're saving money because you are healthier. So that means less doctor visits, less expensive (and nasty harmful) medications, etc.\n",
       "1320                                                                                                  As another reviewer stated, many of the reviews for this product are actually for a DIFFERENT raw cacao powder- from alive and aware, ecuadorian criollo raw cacao powder. That is what I ordered about 3 months ago and it was AWESOME! I am almost out and when I went to reorder my amazon account directed me to this product, from SAQUIN??, which is NOT what I ordered, and it is more expensive- the same base price but i got it with FREE shipping, not 15 bucks so that is a big price increase.  I know it was still from alive and aware mid-february, but recently something changed.<br />I am really confused/irritated how my review for \"alive and aware raw cacao\" got switched to a different brand from a different seller?!?! i mean, can't they just say \"out of stock\" or \"currently unavailable\" like they do with other stuff. why would they switch reviews around?<br />Seems very underhanded to transfer reviews from a different product to a newer one, especially since as the other reviewer stated they are NOT comparable and this stuff from SAQUIN is terrible compared to what we were getting from alive and aware. also the price increase is pretty shocking! i guess it is the market, and raw cacao is in higher demand. Too bad that was such an awesome price for really awesome cacao.<br />I did recently order alive and aware's raw criollo cacao nibs and i highly recommend those. they are as the description states, from alive and aware, not another brand.<br />Frankly I am beginning to wonder about some of the \"brands\" and \"vendors\" that ship from Amazon. I know they have warehouses in different parts of the country, but it is a little suspicious and I just wish there was more transparency about what comes from Amazon and what comes from a different company. seems like halal everyday, alive and aware, etc, are almost interchangable since amazon took the liberty to take reviews from alive and aware and post them to halaleveryday/saquin. are these really different companies, under the auspices of amazon, or is it amazon by a different name only? like the other reviewer said, he ordered something that said \"alive and aware\" in the description and when it came it was from saquin/halal everyday.  who knows. i just want some more transparency so i can have more trust when ordering from amazon.<br /><br />For now, i am going to seek out another source, not through amazon, that stands behind their cacao. it is very important to me, for health benefits and the ecological/social impacts of where it is harvested, to know that i am getting top-notch, certified organic, raw cacao. if amazon is going to be so wishy-washy and sneaky, I'm going elsewhere. (wagging finger at amazon!)<br /><br />I think for now I will leave the following review for alive and aware in case they do bring it back.<br /><br />Heavens to Besty, this stuff ROCKS!! It is such a good value too, maybe the best out there as I have def shopped around.  I have tried a few different brands of raw organic cacao powder, and this is certainly top-notch.  Kudos to Alive and Aware for offering it at such a reasonable price!!<br />I am not a raw foodie per say, but I try to follow a neo-paleo protocol which includes super foods such as raw cacao.  Properly prepared, with just enough natural sweetener, I think this is a truly guilt-free pleasure.  It is LOADED with antioxidants, as you probably know.  So go ahead, get the big bag.  You can then share it with friends and family and turn them on to this super groovy super food \"of the Gods\" (theobroma) as they say :)<br />My favorite way to consume it is actually as not so hot cocoa- I just whisk it into gently heated fresh (raw) whole milk or cream (so it's not too hot and to preserve as much nutrients as possible, I know it's not 100% raw  but hey this is how I love it!), add just enough sweetener (I like sorghum molasses, a scant t-spoon), a bit of maca powder, a dash of real salt, and after that's thoroughly whisked I top it off with a spoonful of EVO COCONUT OIL- YUMM!!! I have converted everyone, even the kids I babysit (who used to prefer swiss miss). Or I make a concentrated warm cocoa beverage sans maca and coconut oil and then stir it into my raw milk for a half gallon of raw chocolate milk, lightly sweetened.  You better believe it goes fast!!  I love my family to get their good old fashioned grass fed animal fats with bioavailable vitamins A, D and the X- factor (read Weston A Price) and loads of antioxidants from the cacao to boot.  Plus cacao activates the seratonin receptors and sorry I am bit fuzzy but you know it makes you feel good and happy!!<br />Also process it with EVO Coconut Oil and sweetener such as sorghum or honey or maple syrup in your cuisinart for heavenly truffles- refrigerate for proper texture due to coconut oil.  I often toss in soaked,dried nuts and dried unsulfured fruit and shredded coconut for healthy truffle energy bars. just process in batches so it's kind of homogenous. Like those lara bars but cheaper and no packaging and even organic or raw.<br />Go for it! Buy this huge bag, share the goodness and you'll be healthier and happier for it. I guarantee!!  PEACE be with You!\n",
       "1497                                                                                                                          MY QUESTION FOLLOWED BY THEIR REPLY - VERY GOOD CUSTOMER SERVICE!!<br /><br />Hey guys,<br />So we are trying to feed a new born as much breast milk as we can, however there is not enough to meet his nutritional needs.<br />So a formula is in order as a supplement. With that, we are interested in your toddler formula, and it appears that since this meets the FDA Infant Formula Guidelines, that it should be safe, (and opinions on the Internet seem to feel the same way). However, our doctor says that it should not be used because of the higher amounts of calcium and phosphorous. He was also concerned about using the DHA/ARA supplement with concerns about the egg white process and that the proteins in egg whites are not good for an infant. Any thoughts on this? Thanks!<br /><br />THEIR ANSWER<br /><br />Dear Dave,<br /><br />Thank you for contacting Nature's One®.  Firstly, you are correct in that our Baby's Only Organic® formulas meet the nutritional requirements of the FDA's Infant Formula Act. No dilution is needed for babies under 12 months of age. Please follow label mixing instructions.<br /><br />Regarding the calcium and phosphorous content in Baby's Only Organic® formulas, calcium is an essential nutrient needed for bone health. The American Academy of Pediatrics Expert Panel for Nutrient Levels in Infant Formula has provided recommendations on the amount of calcium with the minimum per 100 Calories being 50 milligrams and the maximum being 140 milligrams per 100 Calories. Phosphorus is another important mineral for bone health. The Expert Panel has also recommended that the calcium to phosphorus ratio in an infant formula be no less than 1.1 or more than 2.0. Baby's Only Organic® falls within these ranges with our calcium at 135 milligrams per 100 Calories and a calcium to phosphorus ratio of 1.5.<br />Reference: Committee on Nutrition, Pediatric Nutrition Handbook, The American Academy of Pediatrics, 2009, pages 1245-1246.<br /><br />The balance between calcium and phosphorus is most important for bone development. The calcium to phosphorus ratio in both Baby's Only Organic® formula and Enfamil NextStep is 1:5. Thus, Baby's Only Organic® formulas provide an appropriate ratio of calcium and phosphorus for toddlers and an appropriate overall quantity of calcium and phosphorus.<br /><br />Regarding our Baby's Only Essentials® DHA/ARA supplement, The DHA utilized in our Baby's Only Essentials® DHA & ARA supplement is sourced from egg yolk phospholipids. You are probably aware that most often an egg allergy is caused by the egg white rather than the yolk. Additionally, it is the protein component of foods that usually elicit an allergic reaction. Because we use the phospholipids (not protein) from the egg yolk, there is only a very minute chance that an allergic response will ensue.<br /><br />If your child has a history of allergies, we highly recommend that you consult your child's healthcare provider.<br /><br />DHA is also found naturally in other foods, including oily fish like trout, sardines, tuna and salmon and the yolk of eggs. Dietary ARA is available from animal meats, dairy foods, eggs, peanuts and nori seaweed. As your child increases the variety of foods in her diet, you can include some of these foods in her diet. Other natural sources of DHA would include fish oil or fish oil supplements. Unfortunately, it is difficult to insure that these are free from mercury or other environmental toxins. But, also remember that these fatty acids can be formed from dietary linoleic and linolenic acids (nuts, seeds, grains legumes, vegetables and their cold-pressed oils). By including good sources of high quality fats in the diet, your child will easily be able to meet her specific needs<br /><br />Most egg allergies are a result of ingestion of egg white; egg yolk allergies are rare.<br /><br />Proteins are the component of foods that cause allergic reactions. Egg allergy is usually due to the proteins in the egg white. These protein allergens are: ovomucoid, ovalbumin, ovotransferrin; lysozyme, and ovomucin.<br /><br />However, there can be a rare situation of egg yolk allergy. The literature to date usually associates egg yolk allergy to a reaction triggered by inhaled bird allergen, referred to as Bird-egg syndrome. This is a very rare syndrome.<br /><br />Egg allergy can also be seasonal. Oak pollen, short and western ragweed and the goosefoot family of weeds may cross react with eggs when these pollens are in season.<br /><br />The estimated point prevalence of egg allergy in children is 1.6% by 2.5 years of age. (1) Again, egg white is usually the cause of an egg allergy. Most children outgrow an allergy to eggs by 5 years of age.<br /><br /> (1) Eggesbo M, Botten G, Halvorsen R, Magnus P, \"The prevalence of allergy to egg: a population-based study in young children,\" Allergy 56; 5:403<br /><br />I hope this information is helpful to you. Thank you for your interest in Baby's Only Organic® formulas. Please let me know if you have additional questions.<br /><br />Sincerely,<br /><br />Lori<br />Nature's One Inc.<br />[...]<br />[...]<br />Toll Free [...]\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "566812                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Was at a market (World Cost Plus?)and came across this. There was another brand too, Melinda's or Meranda's...something, yeah. I decided to go with this one as the other had carrots and mango puree and other stuff (blah). I'm sure this is too make it not so hot but I figured this might cover up it's natural taste too.<br /><br />So I stopped at Taco Bell on the way home. Figured start with something mild and got a ranchero chicken soft taco. Put one drop of this stuff and smeared it around. Not bad. Complimented it nicely. Second was a meximelt. One drop only again. This time it seemed they merged together and boosted each others spices. By the time I was done I had a nice long heat going and some sweats which lasted untill I got home.<br /><br />You know when you take a shot of hard liquor on an empty stomach? That burn? Imagine that burn slooooowly moving through your system. Yeah, it' like that. I'm sure it will kill any parasites living in your intestinal tract. Might even remove any bubble gum you swallowed as a kid.<br /><br />Next day, tried it again, this time on a burger. Threw some ranch on it and tried 2 drops this time. Got to my second burger and knew if I did 2 drops again that I might be in trouble, so went with only 1 drop.<br /><br />1 or 2 drops per item seems to be the right amount. Pouring this stuff on like it was Tapatio WILL without a doubt lead to problems!! But I will be taking this to work for all those Tapatio junkies and others who just eat raw chilis straight up. Hehe, let's see if they think they're still macho now, huh?!! This stuff is deceiving! Seems fine at first, but man o man, that heat will catch up and bite you! I have bought the habanero version of Tabasco and didn't care for it. That was mainly vinegar with way too much of a black pepper type taste. It is hot, but I ended up throwing that away. This however, I definetly will be buying more of!!! It may overpower your food if you use too much of it, but for most part it merges with your food and creates a new flavor. Those who said it tasted bad or metallic must have had a bad batch.<br /><br />By the way, me, i'm not....well wasn't a big chili person untill recently. I used that mild sauce (aka \"weak sauce\") up untill a few years ago. So I haven't trained myself into eating stuff as hot as this. Pretty much an average guy with a growing interest for new things : )<br /><br />update: finally did try that Melinda's version of Naja. Did not care for it at all! It had a very quick bite to it and too much of that pepper extract taste (even though it isn't loaded with extract). Sadly the Melinda's is sitting the fridge, barely touched.....but my Dave's is almost done.\n",
       "567117                                                                                                                                                                                                                                                                                                         I never was much of a chocolate person. I grew up preferring Strawberry, then Vanilla, and, lastly, chocolate.<br /><br />Then when I was 35, my husband took me with him on a business trip to Switzerland. What a treat that was! Lining the main boulevards were small confectionery shops filled with cocholates the likes of which I had never, ever laid eyes upon. A tiny box of chocolates that would be about 5 inches square and hold 12 pieces of candy cost around $30. But I had no idea that Chocolate could taste so exquistely good or look so beautiful. Little candies with 3 layers of chocolate in various flavors topped with small green candy looking twigs, or hearts, or diamond shapes.<br />Truffles made with plain chocolate or all different types of liquors. If I could have afforded it, I would have eaten myself into the size of a blimp. And the sales people were so delightful, always reminding me that this box was made Today and was meant to be eaten TODAY or it would get stale. I thought about our boxes of chocolate that sit on the shelves for weeks or months and winced. Thankfully, lots of walking was required to see the sights and I was able to eat what I could afford and still not gain! It was like Heaven.<br /><br />But then, back to the States we came. Hersheys just didn't cut it anymore. So I began taste testing what I could find locally always recalling the vendors' words \"that chocolate was made today and is to be eatenn today.\" I tried Truffles, I tried mixed boxes whose photos made them LOOK LIKE the insides of the tiny little boxes in Switzerland. But nothing measured up.<br /><br />One day, I was in a local store and sighted these Guylian Belgian Chocolate Sea Shells. It was my turn to bring treats to a group I go to on Thursdays. The chocolates were on sale and I had noted that the Belgian chocolates I had tried did seem fresher than the others, and tasted better than other brands shipped in Stateside. So I bought two boxes and trooped off to my meeting.<br /><br />As Soon as I had put the chocolate out, I checked to make sure that no one else had brought chocolate as a treat. Nope. Then I took one and ambled away to give them a taste. I wanted to make certain I hadn't bought something awful. So with my back turned to the group, I tried out a piece. I popped the whole thing in my mouth and went through my usualy routine for checking chocolate. I let the piece of candy just lay on my tongue for about 25 seconds until it had softened up and then began lightly and politely sucking on the chocolate. Oh my. It was fresh and had a delightful sweet chocolate taste very similar to the Swiss Chocolate I so loved. In fact, this was just a bit creamier. With little time to spare, I went ahead and bit into the piece expecting solid chocolate. But no, there was a soft inner core of ever sweeter, softer, creamier, fresher, chocolate in the center. I was Delightfully Surprised. Hating to hurry, I went ahead and chewed the piece up so that I could join the group.<br /><br />But my what an experience. I found myself going back to the counter several times during the afternoon, to get another piece of that chocolate I had brought. I urged the others to try it and each one was also very impressed with this chocolate. Where DID you get these? Were they terribly expensive? How long do they keep? Can I put them in my candy jar or will they melt? The SeaShells were an overwhelming success. I shared that I got them at the local pharmacy on the corner, that they were currently on sale, best to eat them as soon as possible, but they will keep in the freezer without problem for a year, and, yes you should be able to keep them in the candy jar as it was then winter here in Arizona, but I would not put them in a jar during the summer. I have found that even with air conditioning, delicate chocolate does not hold up well out of its box when it is hot. Somehow the candies sense the outside heat and their insides get really old and stale and melt. Ugh. Best to keep them in the fridge in the summer. If you buy them on sale as a gift, stick them in the freezer to preserve them like new.<br /><br />I am amazed at how good these are and I do pick them up on sale and pop them in the freezer for gifts, and keep them hidden in the fridge as a treat for myself. They are indeed, the best \"other country, Stateside Product\" I have found. Whatever theis company does is amazing because these tender candies stay fresh and edible for those of us here. So, I highly Recommend them as they are my favorites. I would NOT order them in the summer or when it starts to get warmish at all as they will probably melt in transit unless they are shipped in dry ice, which I do not know. But I only have them shipped in the dead of winter because it can get so warm here at any time.<br /><br />So, If you are a candy eater, and love foreighn chocolates, then get some of these. They are a wonderful treat. I hope you like them as well as I do.!\n",
       "567118                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             When these delightful GUYLIAN BELGIAN CHOCOLATE SEA SHELLS, were on sale at my local department store, many years ago, my mom bought them -- because they were on sale.  But after TASTING these yummy morsels, we knew that these were the BEST chocolate ANYWHERE -- on sale, or not!<br /><br />A few years later, my sister came to visit.  We bought some more Gulian Belgian Chocolate Sea Shells. (don't remember if they were on sale then or not), in honour of her visit.  She took ONE bite of one....and summed up what my mom and I had thought ever since WE had first tasted them:<br /><br />  \"...I can't believe how good they are!\"<br /><br />.......................................................<br /><br />THE REAL REASONS WHY THESE CHOCOLATES ARE S_O GOOD Dept.<br /><br />Many years after her visit, I was watching The History Channel, and they mentioned Belgian chocolate, and showing how it was made.  I remember the voice-over saying that Belgian chocolate is even better than French chocolate -- and giving the reasons for this.<br />1) Belgian chocolates are made from the freshest of the most fresh ingredients.  2) Belgian chocolates are made by people who take IMMENSE PRIDE in their profession, and want to make sure everything is JUST right!<br /><br />.....................................................<br /><br />FALSE ECONOMY.....DON'T GET STUCK LIKE I DID!! Dept.<br /><br />I recently made the mistake of trying to find a \"Belgian Chocolate Bargain\" on Amazon.  Believe it or not, it was an 11-pound BLOCK of Dark Belgian chocolate.  WORST culinary mistake I ever bought, (I won't mention my home-made kitchen disasters here.) The greater the cocoa content, the harder the chocolate, you see.  I don't know if it was mentioned or not....but I probably would have bought this anyway, so delighted am I with BELGIAN chocolate.  I wound up with something SO huge, and SO hard, that I was lucky a friend of mine's husband was able to break it into twelve smaller blocks -- with his home-workshop SAW!  He didn't dare break it into slices, because this could have BROKEN his saw!  So I am left with 12 blocks of approximately 1 1/2\" x 2\" x 3\", that I will probaby have to grate, then powder in my blender.  IF, that is, I don't get disgusted enough to throw the whole thing out.  Sadly, these hard BLOCKS of Belgian chocolate are no longer fresh....or that tasty, either..........<br /><br />...................................................<br /><br />THE ( YUMMY! ) BOTTOM LINE:<br /><br />So, for a treat, DON'T look for a super-bargain....even in Belgian Chocolates.  Save money by fore-swearing pizza for a few months, or other such economies.  GUYLIAN BELGIAN CHOCOLATE SEA-SHELLS, (here in the 8.82 ounce \"REGULAR economy\" pack), offers bite-size morsels of true confectionary ART!  They are better than ANY chocolate you have ever tasted -- unless you have tasted Guylian Belgian Chocolate Sea-Shells before!  Give them to anyone you appreciate and admire....including yourself.  And you, (or whomever you give them to), will surely echo my sister's words:<br /><br />  \".....I can't believe how good they are!\"\n",
       "567532                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I bought this product around the beginning to middle of May 2011 &, at that time, it showed a picture of the box from the company Cultures for Health LLC.  It also had (& still has) their name on it as \"by Cultures of Health LLC\" but then further down is says \"Ships from and sold by Lifetime Kefir.\"  I just want to clarify for everyone out there, who like me thought I was buying from a specific COMPANY that sells milk kefir, that this is not sold through Cultures for Health & it is not sponsored or affiliated with them in any way.  I contacted Cultures for Health today and the customer service lady said that they are not affiliated with this \"Lifetime Kefir\". I also received my kefir grains in a plastic baggie & wrapped in about 5 more plastic baggies, all smooshed up flat, and looking nothing like the cauliflower looking kefir grains you see pictures of.  Needless to say I was a little freaked out.  I decided to just try it out & see if the kefir grew and 'worked'.  -----  THAT BEING SAID ..... the kefir grew wonderfully! and has tripled or quadrupled in a months time.  I also sent the seller a question after working with and growing my kefir for about 2 or 3 days and he gave me a quick, polite, fairly thorough answer. Customer service seemed just good ... and quick.  I started with making about 1c of kefir and it was fizzy, clumpy/watery, weird.  I didn't know what I was supposed to be looking for but I guess this is normal and I just kept working with it each day changing the milk out and making new kefir.  It took about 1-2 weeks before it was producing well and I was making good kefir (not fizzy, but creamy now).  I was slowly figuring out how to work with the product.  I now make a quart jar of kefir daily.  I switch out the grains/kefir each morning and am left with about 3-4 cups of kefir each day.  All-in-all, I think the product is good. *****UPDATE 7/13/11******:  Since the initial review here, I have contacted the seller about some things & have had wonderful, very polite, and very quick customer service.  There is nothing bad to say at all about the customer service with this seller, in my opinion.  He seems to go out of the way to make sure the buyer is fully satisfied with the product.  And the product seems great.  My grains have grown tremendously and I have probably 1 to 1 1/2 CUPS of kefir GRAINS now.  That is all from about 1T of smooshy, yellow looking 'stuff' (kefir grains) that I initially got from the seller.  It took a couple weeks for them to start working \"normally\" and looking more \"normal\" but just give them some time and they seem to come through and make great kefir.  The only reason for less than 5 stars is simply because I feel like there still is a little misleading advertising in the product.  It appears this seller (Lifetime Kefir) has a few different kefir grain ads/products on amazon & the one that I bought from ([...]) shows that it is \"by: Cultures for Health, LLC\" and \"shipped and sold by Lifetime Kefir\".  I thought I was buying the grains from Culture for Health through a middle-man, so to speak.  When actually it is not a Cultures for Health product at all.  Maybe no big deal to others, but it was for me.  It ended up being a great product in the end though.\n",
       "568249                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           First of all, I have no ties with Truvia. In fact, I decided to replace my Truvia recently with Stevia in the Raw which is why I'm now typing this. In my grocery store the Stevia in the Raw was cheaper. I'd always felt Truvia expensive, so I was all over that.<br /><br />While I personally do not believe the phrase \"You get what you pay for\" since sometimes a consumer is only paying for more marketing in a more expensive product...in this case, it's true.<br /><br />I do like sugar in the raw and I do buy it. It's way better than regular sugar being bleached and processed through bone char (for reals).<br /><br />But, first of all, this isn't \"in the raw\". That would mean it's pure Stevia. It also contains Dextrose. Dextrose is a very cheap additive that's sweet that's made from corn. It's high carb. Great if you just finished a tough workout and need carbs. Not great if you call yourself Stevia in the RAW<br /><br />Having formerly worked in food chemical sales, I know that Dextrose is Glucose. This is not an artificial additive, however diabetes is caused by high levels of glucose in the blood. I therefore find it quite scary that this is labeled \"raw\" when diabetics may use it or someone wishing to avoid sugar would use it.  Now granted, Truvia has a fruit sweetener in it as well, because stevia is actually SO sweet that you'd have hardly anything in a pack otherwise because it takes very little stevia to sweeten something, but it's not calling itself \"raw\" either.<br /><br />But let's bypass that and take our sugar/stevia packs and move on. Is the rest the same?<br /><br />Huh-uh.<br /><br />You get 50 packs of Stevia in the Raw in a box.<br />You get 40 packs of Truvia in a box.<br /><br />Superb huh?<br /><br />Likely, because Stevia in the Raw was a tiny bit less expensive, you will do as I did and think \"Woo Hoo! I get more for less!\" Aw, those marketing dogs saw me coming a mile away.<br /><br />Not so fast.<br /><br />I kept making my coffee and hating the taste of it. Bitter.  I began adding 2 packs of Stevia in the Raw. Still not sweet. I had just bought a new coffee and I was thinking it must be stronger of something. Then I found a pack of Truvia I had in the drawer and realized how much MORE was in the pack simply by picking up the pack. I added that one pack to my coffee and it tasted, finally, sweet again.<br /><br />So that got me thinking...<br /><br />I go to the Stevia in the Raw box and look at the net weight of those 50 packets.<br />It is 1.75 ounces.<br />I then, when shopping again, pick up a box of Truvia (and buy it of course because I'm tired of coffee tasting unsweetened.) and for 40 packets it's 4.9 ounces!!!!<br /><br />WOA! I've just been had. I have to use about 3-4 of those Stevia in the Raw packets to equal the taste of one Truvia packet because there is next to nothing inside the packet..just as I suspected. They gave me more packets with less inside each one. So I have to waste paper, and time opening packet after packet just for one cup o' joe.<br /><br />And quite frankly, I don't like deceptive marketing and it's going on all over every 1.75 ounce box of Stevia in the Raw.<br /><br />But, wait...one more thing...<br /><br />Because Stevia in the Raw has sugar in it in glucose form, is it really 0 calories for the same amount? or just a low amount in one packet but by the time you use 4, how many calories may have snuck in....because 0.5 calories can add up too.  Not that I care about 4 calories or 2 calories, but in comparing the two products, and how little is in a packet of Stevia in the Raw...<br /><br />It wouldn't surprise me.<br /><br />Truvia, by the way, has Erythritol in it. This is one of the best all-natural zero calorie sweeteners you can buy. The Brand Z Sweet is erythritol. It's great for diabetics and dieters because it's the one that will NOT spike your blood sugar but is still all-natural. Stevia is so lightweight it needs a counterpart. Erythritol is a stevia cousin. Dextrose is a cheap filler that isn't.\n",
       "Name: Text, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Review with > 500 words\n",
    "long_threshold = 500\n",
    "long_df = df[df['Text'].apply(lambda x: len(str(x).split())) > long_threshold]\n",
    "print(\"Number of reviews >500 words:\", len(long_df))\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "long_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>review_length_raw</th>\n",
       "      <th>length_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.</td>\n",
       "      <td>48</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "      <td>31</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.</td>\n",
       "      <td>94</td>\n",
       "      <td>50-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.</td>\n",
       "      <td>41</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "      <td>27</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if not better than resturants I have eaten at..My husband loved it..will find other recipes to use this in..</td>\n",
       "      <td>26</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolate notes are especially weak. Milk thickens it but the flavor still disappoints. This was worth a try but I'll never buy again. I will use what's left, which will be gone in no time thanks to the small cans.</td>\n",
       "      <td>46</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 of those in one training session.  I tried to train our dog with \"Ceaser dog treats\",  it just made our puppy hyper.  If you compare the ingredients, you will know why.  Little stars has just basic food ingredients without any preservatives and food coloring.  Sweet potato flavor also did not make my hand smell like dog food.</td>\n",
       "      <td>66</td>\n",
       "      <td>50-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rewarding your dog for being good while grooming.  Lower in calories and loved by all the doggies.  Sweet potatoes seem to be their favorite Wet Noses treat!</td>\n",
       "      <td>35</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised, I use it on cereal, with raw vinegar, and as a general sweetner.</td>\n",
       "      <td>21</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391987 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Text  \\\n",
       "0                                                                                                                                                                                                                                                             I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.   \n",
       "1                                                                                                                                                                                                                                                                                                                                      Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".   \n",
       "2       This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.   \n",
       "3                                                                                                                                                                                                                                                                                                         If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                        Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "568449                                                                                                                                                                                                                                                                                                                                                                          Great for sesame chicken..this is a good if not better than resturants I have eaten at..My husband loved it..will find other recipes to use this in..   \n",
       "568450                                                                                                                                                                                                                                                                   I'm disappointed with the flavor. The chocolate notes are especially weak. Milk thickens it but the flavor still disappoints. This was worth a try but I'll never buy again. I will use what's left, which will be gone in no time thanks to the small cans.   \n",
       "568451                                                                                                                                           These stars are small, so you can give 10-15 of those in one training session.  I tried to train our dog with \"Ceaser dog treats\",  it just made our puppy hyper.  If you compare the ingredients, you will know why.  Little stars has just basic food ingredients without any preservatives and food coloring.  Sweet potato flavor also did not make my hand smell like dog food.   \n",
       "568452                                                                                                                                                                                                                                                                                                                       These are the BEST treats for training and rewarding your dog for being good while grooming.  Lower in calories and loved by all the doggies.  Sweet potatoes seem to be their favorite Wet Noses treat!   \n",
       "568453                                                                                                                                                                                                                                                                                                                                                                                                                I am very satisfied ,product is as advertised, I use it on cereal, with raw vinegar, and as a general sweetner.   \n",
       "\n",
       "        review_length_raw length_category  \n",
       "0                      48           10-50  \n",
       "1                      31           10-50  \n",
       "2                      94          50-100  \n",
       "3                      41           10-50  \n",
       "4                      27           10-50  \n",
       "...                   ...             ...  \n",
       "568449                 26           10-50  \n",
       "568450                 46           10-50  \n",
       "568451                 66          50-100  \n",
       "568452                 35           10-50  \n",
       "568453                 21           10-50  \n",
       "\n",
       "[391987 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop review with <10 and >500 words\n",
    "short_threshold = 10\n",
    "long_threshold = 500\n",
    "\n",
    "df_filtered = df[\n",
    "    (df['Text'].apply(lambda x: len(str(x).split())) >= short_threshold) &\n",
    "    (df['Text'].apply(lambda x: len(str(x).split())) <= long_threshold)\n",
    "]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_counts = df_filtered['Score'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(score_counts.index, score_counts.values, color='teal')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        str(int(height)),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=10,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.title('Figure 2: Distribution of Review Rating (1 to 5 Star)', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Rating', fontweight='bold')\n",
    "plt.ylabel('Number of Reviews', fontweight='bold')\n",
    "plt.xticks(score_counts.index)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove 3-star reviews\n",
    "df_filtered = df_filtered[df_filtered['Score'] != 3]\n",
    "\n",
    "def map_score_to_sentiment(score):\n",
    "    if score in [1, 2]:\n",
    "        return 0\n",
    "    elif score in [4, 5]:\n",
    "        return 1\n",
    "\n",
    "df_filtered['Sentiment'] = df_filtered['Score'].apply(map_score_to_sentiment)\n",
    "sentiment_counts = df_filtered['Sentiment'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(5, 5)) \n",
    "bars = plt.bar(\n",
    "    sentiment_counts.index,\n",
    "    sentiment_counts.values,\n",
    "    color='#E68A00',\n",
    "    width=0.4  \n",
    ")\n",
    "\n",
    "plt.xticks([0, 1], [\"Negative\", \"Positive\"]) \n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        height,\n",
    "        str(int(height)),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=10,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.title('Figure 4: Number of Positive and Negative \\nReviews Before Stratified Sampling', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Sentiment', fontweight='bold')\n",
    "plt.ylabel('Number of Reviews', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure balanced dataset and we have as much data in our analysis as possible, all negative reviews are kept and randomly sample equal number of positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "0    56817\n",
      "1    56817\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_positive = df_filtered[df_filtered['Sentiment'] == 1]\n",
    "df_negative = df_filtered[df_filtered['Sentiment'] == 0]\n",
    "\n",
    "neg = len(df_negative)\n",
    "df_pos_downsampled = df_positive.sample(n=neg, random_state=42)\n",
    "df_balanced = pd.concat([df_pos_downsampled, df_negative], axis=0)\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_balanced['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as separate csv for further analysis\n",
    "df_balanced.to_csv(f\"{base_dir}/balanced_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.read_csv(f\"{base_dir}/balanced_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into 80% train and 20% test set\n",
    "train_df, test_df = train_test_split(df_balanced, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(\"train_sen.csv\", index=False)\n",
    "test_df.to_csv(\"test_sen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90907 entries, 0 to 90906\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      90907 non-null  int64 \n",
      " 1   ProductId               90907 non-null  object\n",
      " 2   UserId                  90907 non-null  object\n",
      " 3   ProfileName             90904 non-null  object\n",
      " 4   HelpfulnessNumerator    90907 non-null  int64 \n",
      " 5   HelpfulnessDenominator  90907 non-null  int64 \n",
      " 6   Score                   90907 non-null  int64 \n",
      " 7   Time                    90907 non-null  int64 \n",
      " 8   Summary                 90907 non-null  object\n",
      " 9   Text                    90907 non-null  object\n",
      " 10  review_length_raw       90907 non-null  int64 \n",
      " 11  length_category         90907 non-null  object\n",
      " 12  Sentiment               90907 non-null  int64 \n",
      "dtypes: int64(7), object(6)\n",
      "memory usage: 9.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22727 entries, 0 to 22726\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      22727 non-null  int64 \n",
      " 1   ProductId               22727 non-null  object\n",
      " 2   UserId                  22727 non-null  object\n",
      " 3   ProfileName             22726 non-null  object\n",
      " 4   HelpfulnessNumerator    22727 non-null  int64 \n",
      " 5   HelpfulnessDenominator  22727 non-null  int64 \n",
      " 6   Score                   22727 non-null  int64 \n",
      " 7   Time                    22727 non-null  int64 \n",
      " 8   Summary                 22726 non-null  object\n",
      " 9   Text                    22727 non-null  object\n",
      " 10  review_length_raw       22727 non-null  int64 \n",
      " 11  length_category         22727 non-null  object\n",
      " 12  Sentiment               22727 non-null  int64 \n",
      "dtypes: int64(7), object(6)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"{base_dir}/train_sen.csv\")\n",
    "test_df  = pd.read_csv(f\"{base_dir}/test_sen.csv\")\n",
    "\n",
    "train_df.info()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/text/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch running on: mps\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "mps_available = getattr(torch.backends.mps, 'is_available', lambda: False)()\n",
    "\n",
    "if cuda_available:\n",
    "    device = \"cuda\"\n",
    "elif mps_available:\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"PyTorch running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "train_df = pd.read_csv(f\"{base_dir}/train_sen.csv\")\n",
    "test_df  = pd.read_csv(f\"{base_dir}/test_sen.csv\")\n",
    "\n",
    "train_texts  = train_df[\"Text\"].tolist()\n",
    "train_labels = train_df[\"Sentiment\"].tolist()\n",
    "\n",
    "test_texts  = test_df[\"Text\"].tolist()\n",
    "test_labels = test_df[\"Sentiment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings   = tokenizer(test_texts,   truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "test_dataset   = SentimentDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_accuracy  = evaluate.load(\"accuracy\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall    = evaluate.load(\"recall\")\n",
    "metric_f1        = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc  = metric_accuracy.compute(predictions=predictions, references=labels)\n",
    "    prec = metric_precision.compute(predictions=predictions, references=labels)\n",
    "    rec  = metric_recall.compute(predictions=predictions, references=labels)\n",
    "    f1   = metric_f1.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\":  acc[\"accuracy\"],\n",
    "        \"Precision\": prec[\"precision\"],\n",
    "        \"Recall\":    rec[\"recall\"],\n",
    "        \"F1\":        f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/text/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_distilbert',\n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    save_strategy=\"epoch\",           \n",
    "    load_best_model_at_end=True,     \n",
    "    metric_for_best_model=\"F1\",      \n",
    "    greater_is_better=True,          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34092' max='34092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34092/34092 7:25:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>0.180237</td>\n",
       "      <td>0.943943</td>\n",
       "      <td>0.952084</td>\n",
       "      <td>0.935586</td>\n",
       "      <td>0.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.225768</td>\n",
       "      <td>0.948871</td>\n",
       "      <td>0.949072</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.949156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.252786</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.953631</td>\n",
       "      <td>0.950376</td>\n",
       "      <td>0.952001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34092, training_loss=0.14710813947480902, metrics={'train_runtime': 26726.3306, 'train_samples_per_second': 10.204, 'train_steps_per_second': 1.276, 'total_flos': 3.612664142886298e+16, 'train_loss': 0.14710813947480902, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25278615951538086, 'eval_Accuracy': 0.951819421833062, 'eval_Precision': 0.9536313339773426, 'eval_Recall': 0.9503763346753019, 'eval_F1': 0.9520010520317362, 'eval_runtime': 700.7336, 'eval_samples_per_second': 32.433, 'eval_steps_per_second': 4.054, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_output = trainer.predict(test_dataset)  \n",
    "\n",
    "logits = pred_output.predictions\n",
    "y_true = pred_output.label_ids\n",
    "\n",
    "y_pred = np.argmax(logits, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    0.9533    0.9516     11301\n",
      "           1     0.9536    0.9504    0.9520     11426\n",
      "\n",
      "    accuracy                         0.9518     22727\n",
      "   macro avg     0.9518    0.9518    0.9518     22727\n",
      "weighted avg     0.9518    0.9518    0.9518     22727\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10773   528]\n",
      " [  567 10859]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "class_names = ['Negative', 'Positive']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=0)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add distilbert test predictions as a new column and save updated df into a csv file\n",
    "test_df[\"distilbert_prediction\"] = y_pred\n",
    "test_df.to_csv(\"test_with_distilbert_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Llama 3.2 (3B) documentation: https://github.com/ollama/ollama/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/paulineng/Desktop/03 Text Analytics and Applications/Group Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{base_dir}/train_sen.csv\") \n",
    "test_df  = pd.read_csv(f\"{base_dir}/test_sen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 63429:\n",
      "Review: Great buy for the money. Almonds are large and whole. I am planning to order more almonds plus other nuts from this company.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 62567:\n",
      "Review: I was very disappointed with my order. The first thing, I did not receive the complete order. When I called , they said they could not help me. I only received only one Barrel of Pretzels. Second the one Barrel i did received looked just awful.<br />I do not even want to open it. I am a Pretzel Lover, and Utz is one of my Favorites. I do not know what happened, but I will never buy this item again through Amazon. I am even concerned about ordering any Food item through Amazon.<br />I have ordered many items through Amazon and I never had a problem until now. It was just disappointed that Amazon did not help me...\n",
      "Sentiment: 0\n",
      "\n",
      "Example 48820:\n",
      "Review: Very Convenient, can take with you to work, on trips,<a href=\"http://www.amazon.com/gp/product/B00284TNL8\">International Delight Amaretto Liquid Creamer, 288-Count Single-Serve Packages</a> etc.  Excellent prodduct.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 71876:\n",
      "Review: As much as our dogs enjoyed Lickety Stik, the cloying stench of \"savory chicken\" repulsed the rest of the family. The odor wafted off the stick and filled the room like a musky air freshener. We called it \"Icky Stik\" or \"Stinky Stik\" as the experience was so nauseating that no one volunteered to reopen the stick, despite pleas from our dogs.<br /><br />We tested the PetSafe Lickety Stik as part of the Amazon Vine program, which is to say the product arrived free. The company sent us the Savory Chicken flavor and we tested it with our Cockapoo and Miniature Schnauzer, both adult females. Neither dog had trouble figuring out how to advance the roller ball so they could taste the liquid. One warning: if you get this stuff on your hands you'll play heck trying to wash it off.<br /><br />A collective shudder ran through the family as we wondered: if Savory Chicken smells this bad, can you imagine inhaling a deep whiff of \"Braised Liver\" or \"Smoky Bacon\"? Worse yet, the company touts the product's portability and recommends carrying it in your purse. That's a bit risk since this stuff in the bottle is hardly perfume.<br /><br />The company says Lickety Stick consists of all-natural ingredients. Here's the list from the bottle: Natural Chicken Flavors, Cultured Milk Lecithin, Mixed Tocopherois (Natural Preservative - A Source of Vitamin E), Ascorbyl Palmtate (Source of Vitamin C), Rosemary Extract, Green Tea Extract.<br /><br />In summary, with so many better options available for dog treats, we cannot recommend Lickety Stick because of its foul smell, sticky ingredients and the serious risk to your purse should the bottle leak.<br /><br />Rating: One star.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 85656:\n",
      "Review: This tea is delicious! I've noticed my skin is starting to look a lot better since I have been drinking it. I have a cup almost every day. I will be purchasing more when I run out!\n",
      "Sentiment: 1\n",
      "\n",
      "Example 29628:\n",
      "Review: I am unhappy with the purchase on the grounds of deceptive labeling.  This tea is NOT matcha, but rather a matcha blend that is mostly sencha.  I should have read the product description more carefully, but was duped by the product listing title. Amazon should change listing to Rishi Tea...Matcha blend\n",
      "Sentiment: 0\n",
      "\n",
      "Example 21254:\n",
      "Review: I would give this company zero stars if I could. I purchased these flowers for my grandmother's birthday, but she never received them. When I contacted the company's cutomer service, I was told that the flowers were delivered, but no one was home, so they were left at the front door of the house (company doesn't have a receipt signature policy). I was also told that I cannot receive a refund or a delivery with signature. As far as I know any reputable company would leave a note to pick up their item from the local USPS if no one is home and would not leave it at the door. Hopefully Better Business Bureau resolves this issue.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 41480:\n",
      "Review: I got these for a reason.<br /><br />My eight year old Elizabeth and I make our Christmas cookies (at least one kind) evey year and they need decorations; now we have alot!<br /><br />ELIZABETH'S COOKIES<br /><br />1 box low salt Ritz crackers<br />1 jar name-brand peanut butter<br />1 pkg chocolate or white almond bark<br />Semi sweet chocolate chips, or white chocolate chips<br /><br />\"Butter\" 2 crackers together, and set on waxed paper.  Keep doing this until you have 1 sleeve of the pkg done (pkg has 4 sleeves of crackers in it)<br /><br />Melt 5 squares of almond bark and 1/4 pkg of the chips you choose  in Microwave-bowl just till they melt, stir to smooth.<br /><br />Dip the cracker that are done with the peanut butter into the mixture and remove to waxed paper (Use a fork to dip the crackers). Be sure to cover all of the cracker(s).  Keep doing this until all crackers are done, melting more almond bark and chips as you need them.<br /><br />As cookies are cooling, put fancy decorations on top, such as these from Marshall's Creek!  We store our hardened cookies in plastic ice cream pals (with the lids on), on our screened-in porch. It is our Christmas-Treat area, and many stop on their way into the house for a treat!  I have to check the containers at night to be sure they are all closed!<br /><br />Linda Muir - Recipe Columnist Wisconsin State Farmer - Cook Book Writer<br /><br />We like chocolate almond bark with milk chocolate chips, and white almond bark with white chips the best.<br /><br />Do this at Valentine's and use the Red Sugars!<br /><br />Linda Muir - Recipe Columnist Wisconsin State Farmer - Cookbook Writer\n",
      "Sentiment: 1\n",
      "\n",
      "Example 49503:\n",
      "Review: I drink my coffee black, no sugar as it really lets the flavored coffee taste richer, at its peak of intensity. This coffee had ZIP flavor! Save your $$ & buy some Barnie's! At least I bought this on sale. I would not recommend it at all, even as a plain coffee it was not very pleasant tasting! If you want a gOOD flavored coffee try Boyer's, they sell it here on Amazon!\n",
      "Sentiment: 0\n",
      "\n",
      "Example 47630:\n",
      "Review: The item was delivered here in great condition. My 5 month old American Eskimo likes the tug a jug even without any treats or kibble inside. But after a few uses a small piece of the bottom lid chipped off. My puppy didn't even play roughly with it. It could have been dangerous if he ate it. Luckily I was there.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 48751:\n",
      "Review: This \"34\" pack is really only 13 kinds of coffee, with multiple of the gross kinds (who wants SIX Island Coconut coffees?!) and it comes in a PAPER BAG!  Don't waste your money!\n",
      "Sentiment: 0\n",
      "\n",
      "Example 40605:\n",
      "Review: Ordered for my elderly parents in another state on a special Christmas promotion,  then visited and was able to see and taste the products.  Disappointing and embarrassing!  The steaks were small, thin, and tasteless.  The filling of the stuffed sole, while being made with crab supposedly, was pasty and bland.  The twice baked stuffed potatoes were tasty and appealing (though only the top half was filled, the rest just baked potato) but what you really want when you buy a steak package, is good steak!  The advertised \"gifts\" were not even kept by my recipients,  so poor were the quality of the knives.  In all, a waste of money.  Even at half price, not worth it!\n",
      "Sentiment: 0\n",
      "\n",
      "Example 43494:\n",
      "Review: I wanted so badly to love these peanuts.  The texture is absolutely perfect.  However, the salt quickly sneaks up on your.  They are over salted to the point eating them becomes physically painful.  Huge failure that could easily be turned into a success.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 89017:\n",
      "Review: Removes all the air from wine bottles, but also 2 liter soda bottles.  Such a wonderful idea and it really works well.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 55945:\n",
      "Review: These are really, really good!<br />The pros:<br />-They taste just like the Betty Crocker box-mix-brownies you remember from your gluten days, the ones your kids might remember, too.  And they're a snap to mix up and bake.<br />-You don't have to add chocolate chips, nuts, cream cheese, or frosting on top to make them taste good. But you can if you want to!<br />-They're readily available at your local store, or here for a better price!  Mainstream and GF, yay!<br />-They have that dense, chewy, fudgy texture most of us love in a brownie.  These aren't cakey or crumbly.<br /><br />The cons:<br />-The mix only makes an 8x8 inch pan.  Bob's Red Mill GF brownie mix makes a 9x13 inch pan for roughly the same price, which might be better if you have a large family or are taking them to a party.<br />-These don't make a good brownie sundae with ice cream (they'll get hard) and they aren't good for crumbling up to layer in a trifle or parfait (they'll get hard and icky).  I'd recommend the Bob's Red Mill GF brownie mix again for that, or just a scratch recipe.<br /><br />A great find for someone who's got a celiac kid at home with a sweet tooth or maybe a just a celiac \"kid at heart!\"\n",
      "Sentiment: 1\n",
      "\n",
      "Example 85651:\n",
      "Review: I picked up one of these packets locally to try it for the first time.  Like most seasoning packets, it is going to carry a fairly significant amount of salt (10% of your RDA, according to the U.S. Nutrition Facts information), but that's about it as far as dangers from this packet are concerned.  The labeling (all in German) claims this packet makes 4 portions--but they're very generous portions; our family of 3 had more than enough to satisfy everyone, and enough left over for lunch the next day.<br /><br />Basic directions (again, in German) are printed on the back, to wit: cut a pound of meat (beef, pork or poultry) into cubes and brown in hot oil.  Add about 1 1/2 c. water, bring to a boil, add contents of the packet and return to boil.  Cover, turn to low and cook 60-90 minutes, or until meat is tender.  (Or cook in a 400 degree F oven.)  Serve with potatoes.<br /><br />Each packet also offers another recipe; ours had \"Budapest-style\" goulash on the back.  Here's how that one goes: cut about a pound of pork stew meat into cubes and brown them in oil.  Add a generous 1 1/2 c. water and the contents of the goulash spice packet.  Bring to a boil, cover, turn to low and cook for about an hour.<br /><br />In a separate pan, cook about 2 ounces bacon until crisp.  Drain off nearly all the fat, then add two chopped onions and two chopped bell peppers (red and/or green) to the pan.  Saute for 10 minutes, or until the onions start to take on some color.  Add these to the main pan along with 2 or 3 tomatoes, peeled, seeded and diced (or use whole canned tomatoes, cut up), and cook another 10 minutes.<br /><br />We served this goulash over rice.  The original called for it to be served with potato dumplings, which would also be excellent.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 31527:\n",
      "Review: Unfortunately these flavorings, like most, do not have a natural taste. Perhaps my taste buds are more discerning than some, but I just can't find flavorings that taste good. The price was not bad for the set for someone who will actually use it.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 12633:\n",
      "Review: This box looks impressive, but it's very misleading. Items are really small. That's a 2 oz jar of olives, 4 oz. of Wisconsin processed cheese food (more like Velveeta than a true cheese), a 1.75 oz sweet hot mustard, 3 oz. of pretzels---and the big item is a 9 oz. summer sausage. The box was filled with LOTS of styrofoam peanuts and a little crinkled colored paper. For $39.99 on sale, it wasn't the really nice gift package I thought I was buying.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 9405:\n",
      "Review: then you will like these. I was a fan of cinnamon Altoids for years then I tried Newman's and was hooked. Altoids logo is \"curiously strong\", well sometimes their logo should be \"ridiculously strong\"!  I don't even eat Altoids anymore, these are my new favorite!!\n",
      "Sentiment: 1\n",
      "\n",
      "Example 45464:\n",
      "Review: I read the reviews, but thought that all I needed was a visual marker, so that I could train my dog to go there.  I read so many bad reviews, that I decided not to buy it online, however, I thought the people who said \"the dog will pee anywhere but near the post\" were exaggerating.<br /><br />So there I found myself, in Petco.  I asked for a toy hydrant (just a visual clue for training).  They said all they had was the pee post.  At that point, I figured it was the pee post, or nothing.  So I thought I'd take a chance.<br /><br />As you can tell by the 1 star review, I felt compelled to post my own review on amazon to save others who might eventually cave-in like I did.  Stay strong.  The other reviewers are not lying.<br /><br />I opened the package and was immediately overcome by the smell of pee.  You certainly do not have to be a dog, nor do you have to be near to smell that thing.  \"Whoopee, this should work for sure.\"  After all, dogs hate the smell of other dog's pee, they feel compelled to pee over it.  My dog refuses to go near it to even smell the post.  They must have used pee (pheromones) from a super-aggressive dog, because my dog is conceding the yard to the post and now choses to pee elsewhere.<br /><br />I am thinking about washing the post in bleach and seeing if it has better results.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 17240:\n",
      "Review: I have tried several delicious gluten-free cookie mixes and this was by far the worst. I knew something was funny about this mix when I was adding the ingredients. The dough smelled exactly like Play-doh. The dough was extremely sticky and wouldn't come off my hands when I tried to mix the dough manually. After baking, the cookies were grainy and had a chemical-y taste. They were stiff and not gooey, like I prefer. I would not recommend this brand - if you are looking for a delicious, soft, GF chocolate chip cookie mix, try King Arthur brand cookie mix and add your own chocolate chips. I will not be buying this brand ever again.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 33311:\n",
      "Review: Very disappointed will not be buying again. The package says to use up to 3 pods for a strong cup of coffee.  One pod is like drinking water, two is better but using 2-3 pods surely isn't a value and the taste isn't worth the price.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 87763:\n",
      "Review: Regarding Barry Farm Foods, I couldn't tell by the description that these carob chips contain soy. They are not returnable. I think it would be helpful to list all ingredients as on the actual label for those of us with lots of diet restrictions.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 33153:\n",
      "Review: My kids love the Vanilla snackimals and I think they taste great too.  It's nice to find a small bagged snack that doesn't contain GM ingredients and tastes good.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 89473:\n",
      "Review: I generally like this brand's flavored coffees. The Turtle Sunday flavor that I bought this time does not suit my taste. However, the quality cannot be beat.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 81851:\n",
      "Review: This is a very pretty container, and my granddaughter loved the blue color when mixed with water-- but--- it tastes more like coconut than chocolate-- should be labeled hot coconut drink.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 28533:\n",
      "Review: I don't generally even like pumpkin products but this spread is amazing!  Perfect and easy to throw together for any party.  My guests couldn't get enough\n",
      "Sentiment: 1\n",
      "\n",
      "Example 46548:\n",
      "Review: I have purchased these gummi candies in the past and not had a problem, but these strawberries tasted terrible and I ended throwing them out.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 70907:\n",
      "Review: I'd previously bought a package of the Impra cherry tea, which I liked, and thought this would be a good way to try some of their other flavors too.  Eh....  the cherry is definitely my favorite, and the peach is quite good, but the other flavors seemed fairly undistinguished to me.  I am kind of regretting that this came in a package of 5 boxes, when 1 would have been enough for my purposes.  Won't order again, anyway.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 16678:\n",
      "Review: My boyfriend and I both drink this, sometimes before exercising and other times just for the taste! It is satisfying and thick, richer than instant hot cocoa for comparison. I sometimes also use it in smoothies - it's delicious when used with strawberries! Strawberry chocolate smoothie.. mmm. I also wish this was part of Subscribe & Save.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 49234:\n",
      "Review: I love spicy food, and I add hot sauce to almost everything I eat, but this hot sauce a completely disappointment.<br /><br />The name itself is b...s..., I have tasted more spicy hot sauce than this.<br /><br />Just for anyone interested, the main ingredients as indicated on the bottle are: red habaneros, hot pepper extract, red chiles. However, all I tasted was black pepper, not even a hint of habaneros. It's 2nd worst hot sauce for me (Tabasco is #1 because it is a SOUR sauce, nothing hot about it), because it reminded me of the cheap instant noodle soup bowl (black pepper beef flavor noodle soup) that I used to eat when I was a child.<br /><br />No taste, no flavor, and no aroma. No tonge numbing, no throat burning, and no stomach twisting. Just plain dull heat and cheap taste.<br /><br />Well, money well wasted. By the way, I used 6 drops on my one bowl of steam rice, and the heat didn't even last 5 minutes.<br /><br />The bottome line is:<br />This is NOT a hot sauce for spicy food lover. A good hot sauce makes food tasty with aroma and flavor, this one doesn't.<br /><br />It's like I can make the sweetest cake for you by loading it with tons of sugars, is it sweet? Of course, but is it a good tasty cake? You tell me.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 16413:\n",
      "Review: My husband does not like whole wheat anything but he liked this pizza dough. It was very simple to make and spread on our pizza stone. We put Rossi Pizza sauce and mozzarella cheese on and it was great!\n",
      "Sentiment: 1\n",
      "\n",
      "Example 36791:\n",
      "Review: I've tried a few Jasmine teas and a few Jasmine green teas....And this one really does reach the top two! You don't lose the Jasmine flavor as you do in some other teas around here, and I like to suck on the tea bag because its not too strong and it has wonderful flavor. If you're looking for something a bit more naturally sweet I would suggest Bigelow Jasmine Green tea.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 15337:\n",
      "Review: THESE POTATO FRIES ARE AS HARD AS ROCKS.I KNOW THAT THE SUPERMARKET HAS POTATO FRIES AND THEY ARE SOFT CHEWABLES. THESE POTATO FRIES ARE STALE. DO NOT BUY!!\n",
      "Sentiment: 0\n",
      "\n",
      "Example 56594:\n",
      "Review: This is my second order of Jack Link's Beef Jerky, Peppered, Mega Pack from Amazon due to lower price than other stores and I hit the jackpot.  You can see the pictures I upload for this product.  It has mold all over, which even can be seen from outside the bag.  Unfortunately I did not see it and put one in my mouth.  Few seconds afterward, the taste was so strange and my friend, who was about to eat, stop me from swallowing.  Try for yourself, but please be careful.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 22881:\n",
      "Review: This stuff tastes great -- almost as good as the sugar stuff, but without the calories. I usually take 3 key limes, two tablespoons of coconut syrup, and pour a sprite zero on top for a coconut limeade.<br /><br />FYI I have seen this stuff at World Market.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 16736:\n",
      "Review: As I'm always looking for a DEAL on Cranaple by OS there is no DEAL here at $9.54 a bottle. When my local store has it around $3.58 a 64.oz bottle Thanks but No Thanks\n",
      "Sentiment: 0\n",
      "\n",
      "Example 55638:\n",
      "Review: We had been giving our dog the Liver Biscotti, and as I wrote in my review, those seemed to be difficult for her to chew.  So, I decided to try these Charley Bear treats.  She loves these!  They seem to be just the right crunchiness for her and they don't add too many calories to her diet.  She loved them so much, I ordered two other flavors as well.  These are the perfect size, too.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 31944:\n",
      "Review: It's easy to make, a warm cereal for someone who does not tolerate oat or wheat. I whip an egg in it & add fruit & honey. Makes a wholesome breakfast.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 11150:\n",
      "Review: This grapeseed oil is great!  I heartily recommend it as a nutritious alternative to olive oil -- the taste is much lighter. ;o) This brand is packaged in a metal, light-proof container, so the nutrients aren't destroyed by light.  I have purchased it locally and decided to save the trip to the store by buying it at Amazon for about the same price.<br /><br />  The three-pack wasn't wrapped together, but was three separate cans.  They appeared to have several dents caused by rolling around in the insufficient packaging.  That might have been acceptable (well, not really), but the cans also had dirt all over the tops of them.  The dirt and dents made them look like something from the dollar-store discount bin!  Initially I received an email from Amazon stating that they were non-returnable as grocery items, but in the end they did pay for return shipping and reimbursement of the order.  I would rate the product 5 stars, but knocked it down to 4 on the review due to the shipping and dirt (more than just a little 'dust') on the product.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 55058:\n",
      "Review: I stopped using dairy about a year ago. The hardest thing was trying to find a \"creamer\" for my coffee. I was using almond milk, but it just wasn't adding the creamy goodness of half and half. The first time I tried this product, it had been sent to me by mistake when I ordered the unsweetened version. What a great mistake! I am SO pleased to find a product that is healthy, dairy-free, and tastes great in my coffee! I have not had the problems someone mentioned about separating, etc. Don' let the \"sweetened without sugar\" aspect scare you. It's very lightly sweetened with one of the healthier sugar alternatives [erythritol].\n",
      "Sentiment: 1\n",
      "\n",
      "Example 13415:\n",
      "Review: I have a senseo coffee maker and senseo pods were suddenly unavailable, I bought the coffee duck used starbucks fine grind and that worked ok, but messy.  Clean the darn thing each time, make sure you don't lose the lid but. . .it was better than perking a whole pot.  Then I discovered Wolfgang puck.  Awesome.  I use one pod in the one cup holder, twice to make a full delicious mug of dark rich coffee.  Senseo has since become available and like a fool, I ordered it at $12 more than my last shipment. . . DUH!  That will be my last order for senseo, seems like it was the plan, be unavailable and then jack up the price.  Not with Wolfgang around. Its fills the bill . . . And my mug perfectly.\n",
      "Sentiment: 1\n",
      "\n",
      "Example 81797:\n",
      "Review: Apple Jacks is a family favorite and it is very wonderful to have it show up at my door automatically AND at a very reasonable cost!\n",
      "Sentiment: 1\n",
      "\n",
      "Example 60555:\n",
      "Review: I was hoping for a more smooth and pronounced french vanilla flavor. The product did not deliver. It's an okay coffee,just not vanilla.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 65879:\n",
      "Review: The coffee itself is alright, but every cup I've brewed (about 10 so far) have had grounds in it. I wouldn't buy this again.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 35928:\n",
      "Review: Excellent product and such a handy way to buy it!  Amazon to the rescur, again!\n",
      "Sentiment: 1\n",
      "\n",
      "Example 23771:\n",
      "Review: I was so disapointed, I got my shipment today, drank around 3 cans.  I felt a little funny so I read the label.  This particular coconut water had as much sugar as orange juice.<br /><br />sigh - have to give these away, I'm diabetic.  Ordered a no sugar version.<br /><br />Coconut water (juice)is cut from the jelly coconut.  Different sort of coconut then the hairy coconut you get coconut milk from.  I know hairy is not scientific.  I do love Coconut Water.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 24375:\n",
      "Review: On their site, they say \"PayPal accepted upon request\". If you request to pay with PayPal, it takes them 4 days to acknowledge it. And this is the only site I've ever seen that accepts PayPal \"by request\". Very primitive marketing.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 15061:\n",
      "Review: Disgusting!<br /><br />Dumping the packet into water, it started to foam and fizz.  I'm thinking: \"Maybe I should have read the ingredients.\"  Drinking something from Bill Nye's chem-shop isn't disgusting, its just not natural.  Well, I took a sip and seconds later I dumped that concoction down the drain where it belongs.<br /><br />If you want energy, BomDia makes some great tasting natural energy Acai Berry drinks, my favorite being 'Conquer.'  If you like cheap energy, stick with the time tested Chocolate.\n",
      "Sentiment: 0\n",
      "\n",
      "Example 68817:\n",
      "Review: Very fast shipping! Product was exactly as described. Im new to jolokias and these have me hooked. I received them monday and today (wednesday) they are all gone! grind them up in a blender and sprinkle them over your food and hold on! i will definitely be buying more of these very soon!\n",
      "Sentiment: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query review and sentiment data from train dataset. Selected reviews will be included in the prompt.\n",
    "\n",
    "few_shot_examples = train_df.sample(n=50, random_state=42)\n",
    "\n",
    "examples_str = \"\"\n",
    "for i, row in few_shot_examples.iterrows():\n",
    "    examples_str += f\"Example {i}:\\nReview: {row['Text']}\\nSentiment: {row['Sentiment']}\\n\\n\"\n",
    "\n",
    "print(examples_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For test dataset, filter only the 'Text' and 'Sentiment' columns and save as a separate csv file\n",
    "test_df = pd.read_csv(f\"{base_dir}/test_sen.csv\")\n",
    "filtered_test_df = test_df[['Text', 'Sentiment']]\n",
    "filtered_test_df.to_csv(f\"{base_dir}/filtered_test_sen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Ollama server that host llama3.2\n",
    "def start_ollama_server():\n",
    "        print(\"Starting Ollama server (default port 11434)...\")\n",
    "\n",
    "    command = [\"ollama\", \"serve\"]\n",
    "    server_process = subprocess.Popen(\n",
    "        command,\n",
    "        stdout=subprocess.PIPE,         #for monitoring server output\n",
    "        stderr=subprocess.STDOUT,       #for monitoring server output\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    logs_list = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        if time.time() - start_time > 10:\n",
    "            break  \n",
    "\n",
    "        line = server_process.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line_stripped = line.strip()\n",
    "        logs_list.append(line_stripped)\n",
    "\n",
    "        if \"Listening on\" in line_stripped:\n",
    "            break\n",
    "\n",
    "    return server_process, logs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama_rest_api(prompt_text):\n",
    "    endpoints = [\n",
    "        \"http://127.0.0.1:11434/api/generate\",\n",
    "        \"http://127.0.0.1:11434/generate\"\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3.2\",\n",
    "        \"prompt\": prompt_text\n",
    "    }\n",
    "\n",
    "    for url in endpoints:\n",
    "        print(f\"\\nTrying endpoint: {url}\")\n",
    "        try:\n",
    "            resp = requests.post(url, json=payload, timeout=30)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"Connection error. Is the server up?\")\n",
    "            continue\n",
    "\n",
    "        print(\"Status Code:\", resp.status_code)\n",
    "        if resp.status_code == 200:\n",
    "            final_answer = parse_streaming_json(resp.text)\n",
    "            return final_answer\n",
    "        else:\n",
    "            print(\"Raw Response Text:\", resp.text)\n",
    "\n",
    "    return \"Could not get a 200 response from any known endpoint.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managing JSON output \n",
    "def parse_streaming_json(raw_text):\n",
    "    lines = raw_text.strip().splitlines()\n",
    "    final_answer = \"\"\n",
    "    for line in lines:\n",
    "        try:\n",
    "            chunk = json.loads(line)\n",
    "            partial_text = chunk.get(\"response\", \"\")\n",
    "            final_answer += partial_text\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return final_answer.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends review to Ollama server and get a sentiment classification (0 or 1) from Llama3.2\n",
    "def classify_sentiment(review_text, model_name=\"llama3.2\", timeout=60, max_retries=2): \n",
    "    endpoints = [\n",
    "        \"http://127.0.0.1:11434/api/generate\",\n",
    "        \"http://127.0.0.1:11434/generate\"\n",
    "    ]\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "You are a sentiment classifier for Amazon Fine Food reviews.\n",
    "Output exactly '0' (no quotes) if the review is negative, or '1' if the review is positive.\n",
    "No explanation, no extra words, just the single digit '0' or '1' (without quotes).\n",
    "For the review below, determine the overall sentiment by weighing all positive and negative aspects. If the majority of the review is positive, return 1; if it's negative, return 0. Even if the review contains some negative points, if the overall tone is positive, output 1.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Review: Great buy for the money. Almonds are large and whole. I am planning to order more almonds plus other nuts from this company.\n",
    "Sentiment: 1\n",
    "\n",
    "Review: I was very disappointed with my order. The first thing, I did not receive the complete order. When I called, they said they could not help me. I only received one Barrel of Pretzels. Second, the one Barrel I did receive looked just awful. I do not even want to open it. I am a Pretzel Lover, and Utz is one of my Favorites. I do not know what happened, but I will never buy this item again through Amazon. I am even concerned about ordering any food item through Amazon. I have ordered many items through Amazon and I never had a problem until now.\n",
    "Sentiment: 0\n",
    "\n",
    "Review: Very Convenient, can take with you to work, on trips, etc. Excellent product.\n",
    "Sentiment: 1\n",
    "\n",
    "Review: As much as our dogs enjoyed Lickety Stik, the cloying stench of \"savory chicken\" repulsed the rest of the family. The odor wafted off the stick and filled the room like a musky air freshener. We called it \"Icky Stik\" or \"Stinky Stik\" as the experience was so nauseating that no one volunteered to reopen the stick, despite pleas from our dogs.\n",
    "Sentiment: 0\n",
    "\n",
    "Review: This tea is delicious! I've noticed my skin is starting to look a lot better since I have been drinking it. I have a cup almost every day. I will be purchasing more when I run out!\n",
    "Sentiment: 1\n",
    "\n",
    "Review: I am unhappy with the purchase on the grounds of deceptive labeling. This tea is NOT matcha, but rather a matcha blend that is mostly sencha. I should have read the product description more carefully, but was duped by the product listing title. Amazon should change the listing to Rishi Tea... Matcha blend.\n",
    "Sentiment: 0\n",
    "\n",
    "Review: I would give this company zero stars if I could. I purchased these flowers for my grandmother's birthday, but she never received them. When I contacted the company's customer service, I was told that the flowers were delivered, but no one was home, so they were left at the front door. I was also told that I cannot receive a refund or a delivery with signature. Hopefully, the Better Business Bureau resolves this issue.\n",
    "Sentiment: 0\n",
    "\n",
    "Review: I got these for a reason. My eight year old Elizabeth and I make our Christmas cookies (at least one kind) every year and they need decorations; now we have a lot!\n",
    "Sentiment: 1\n",
    "\n",
    "Review: The item was delivered in great condition and my dog enjoyed the tug toy, but after a few uses a small piece chipped off and it could have been dangerous if ingested.\n",
    "Sentiment: 0\n",
    "\n",
    "Review: I wanted so badly to love these peanuts. The texture is absolutely perfect; however, the salt quickly sneaks up on you and makes them painful to eat.\n",
    "Sentiment: 0\n",
    "\n",
    "Review: These brownies are really, really good and remind me of homemade box-mix brownies. However, they only make an 8x8 pan and the consistency isn’t ideal for a sundae or layered dessert.\n",
    "Sentiment: 1\n",
    "\n",
    "Review: I generally like this brand's flavored coffees; however, the Turtle Sunday flavor I bought did not suit my taste, even though the overall quality cannot be beat.\n",
    "Sentiment: 1\n",
    "\n",
    "Now classify the following review:\n",
    "\n",
    "Review: \"{review_text}\"\n",
    "\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    for url in endpoints:\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                resp = requests.post(url, json=payload, timeout=timeout)\n",
    "                if resp.status_code == 200:\n",
    "                    answer_text = parse_streaming_json(resp.text).strip()\n",
    "                    if answer_text.startswith(\"1\"):\n",
    "                        return 1\n",
    "                    else:\n",
    "                        return 0\n",
    "                else:\n",
    "                    print(f\"Raw Response from {url}: {resp.status_code} {resp.text}\")\n",
    "                    break\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                print(f\"Server not reachable on {url}, attempt {attempt+1}/{max_retries}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)  \n",
    "                else:\n",
    "                    print(\"Max retries reached, defaulting to 0.\")\n",
    "                    return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 => Predicted: 1\n",
      "Row 1 => Predicted: 1\n",
      "Row 2 => Predicted: 1\n",
      "Row 3 => Predicted: 1\n",
      "Row 4 => Predicted: 1\n",
      "Row 5 => Predicted: 1\n",
      "Row 6 => Predicted: 0\n",
      "Row 7 => Predicted: 0\n",
      "Row 8 => Predicted: 1\n",
      "Row 9 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 0 to 9...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10 => Predicted: 0\n",
      "Row 11 => Predicted: 0\n",
      "Row 12 => Predicted: 1\n",
      "Row 13 => Predicted: 0\n",
      "Row 14 => Predicted: 1\n",
      "Row 15 => Predicted: 0\n",
      "Row 16 => Predicted: 0\n",
      "Row 17 => Predicted: 0\n",
      "Row 18 => Predicted: 1\n",
      "Row 19 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10 to 19...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20 => Predicted: 1\n",
      "Row 21 => Predicted: 0\n",
      "Row 22 => Predicted: 0\n",
      "Row 23 => Predicted: 0\n",
      "Row 24 => Predicted: 0\n",
      "Row 25 => Predicted: 0\n",
      "Row 26 => Predicted: 0\n",
      "Row 27 => Predicted: 1\n",
      "Row 28 => Predicted: 0\n",
      "Row 29 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20 to 29...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 30 => Predicted: 0\n",
      "Row 31 => Predicted: 0\n",
      "Row 32 => Predicted: 0\n",
      "Row 33 => Predicted: 0\n",
      "Row 34 => Predicted: 1\n",
      "Row 35 => Predicted: 0\n",
      "Row 36 => Predicted: 1\n",
      "Row 37 => Predicted: 1\n",
      "Row 38 => Predicted: 1\n",
      "Row 39 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 30 to 39...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 40 => Predicted: 1\n",
      "Row 41 => Predicted: 0\n",
      "Row 42 => Predicted: 1\n",
      "Row 43 => Predicted: 1\n",
      "Row 44 => Predicted: 0\n",
      "Row 45 => Predicted: 0\n",
      "Row 46 => Predicted: 0\n",
      "Row 47 => Predicted: 0\n",
      "Row 48 => Predicted: 0\n",
      "Row 49 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 40 to 49...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 50 => Predicted: 0\n",
      "Row 51 => Predicted: 1\n",
      "Row 52 => Predicted: 1\n",
      "Row 53 => Predicted: 0\n",
      "Row 54 => Predicted: 1\n",
      "Row 55 => Predicted: 1\n",
      "Row 56 => Predicted: 1\n",
      "Row 57 => Predicted: 0\n",
      "Row 58 => Predicted: 0\n",
      "Row 59 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 50 to 59...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 60 => Predicted: 0\n",
      "Row 61 => Predicted: 1\n",
      "Row 62 => Predicted: 0\n",
      "Row 63 => Predicted: 0\n",
      "Row 64 => Predicted: 0\n",
      "Row 65 => Predicted: 1\n",
      "Row 66 => Predicted: 1\n",
      "Row 67 => Predicted: 0\n",
      "Row 68 => Predicted: 0\n",
      "Row 69 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 60 to 69...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 70 => Predicted: 0\n",
      "Row 71 => Predicted: 1\n",
      "Row 72 => Predicted: 0\n",
      "Row 73 => Predicted: 1\n",
      "Row 74 => Predicted: 1\n",
      "Row 75 => Predicted: 0\n",
      "Row 76 => Predicted: 0\n",
      "Row 77 => Predicted: 1\n",
      "Row 78 => Predicted: 1\n",
      "Row 79 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 70 to 79...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 80 => Predicted: 1\n",
      "Row 81 => Predicted: 0\n",
      "Row 82 => Predicted: 1\n",
      "Row 83 => Predicted: 1\n",
      "Row 84 => Predicted: 0\n",
      "Row 85 => Predicted: 0\n",
      "Row 86 => Predicted: 0\n",
      "Row 87 => Predicted: 0\n",
      "Row 88 => Predicted: 1\n",
      "Row 89 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 80 to 89...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 90 => Predicted: 1\n",
      "Row 91 => Predicted: 1\n",
      "Row 92 => Predicted: 0\n",
      "Row 93 => Predicted: 0\n",
      "Row 94 => Predicted: 1\n",
      "Row 95 => Predicted: 0\n",
      "Row 96 => Predicted: 1\n",
      "Row 97 => Predicted: 1\n",
      "Row 98 => Predicted: 0\n",
      "Row 99 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 90 to 99...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 100 => Predicted: 0\n",
      "Row 101 => Predicted: 1\n",
      "Row 102 => Predicted: 1\n",
      "Row 103 => Predicted: 0\n",
      "Row 104 => Predicted: 0\n",
      "Row 105 => Predicted: 0\n",
      "Row 106 => Predicted: 0\n",
      "Row 107 => Predicted: 0\n",
      "Row 108 => Predicted: 0\n",
      "Row 109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 100 to 109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 110 => Predicted: 0\n",
      "Row 111 => Predicted: 0\n",
      "Row 112 => Predicted: 1\n",
      "Row 113 => Predicted: 1\n",
      "Row 114 => Predicted: 0\n",
      "Row 115 => Predicted: 1\n",
      "Row 116 => Predicted: 1\n",
      "Row 117 => Predicted: 0\n",
      "Row 118 => Predicted: 1\n",
      "Row 119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 110 to 119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 120 => Predicted: 1\n",
      "Row 121 => Predicted: 0\n",
      "Row 122 => Predicted: 0\n",
      "Row 123 => Predicted: 1\n",
      "Row 124 => Predicted: 1\n",
      "Row 125 => Predicted: 1\n",
      "Row 126 => Predicted: 1\n",
      "Row 127 => Predicted: 1\n",
      "Row 128 => Predicted: 1\n",
      "Row 129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 120 to 129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 130 => Predicted: 0\n",
      "Row 131 => Predicted: 1\n",
      "Row 132 => Predicted: 1\n",
      "Row 133 => Predicted: 0\n",
      "Row 134 => Predicted: 0\n",
      "Row 135 => Predicted: 0\n",
      "Row 136 => Predicted: 1\n",
      "Row 137 => Predicted: 1\n",
      "Row 138 => Predicted: 0\n",
      "Row 139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 130 to 139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 140 => Predicted: 1\n",
      "Row 141 => Predicted: 0\n",
      "Row 142 => Predicted: 1\n",
      "Row 143 => Predicted: 0\n",
      "Row 144 => Predicted: 1\n",
      "Row 145 => Predicted: 0\n",
      "Row 146 => Predicted: 1\n",
      "Row 147 => Predicted: 1\n",
      "Row 148 => Predicted: 0\n",
      "Row 149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 140 to 149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 150 => Predicted: 1\n",
      "Row 151 => Predicted: 0\n",
      "Row 152 => Predicted: 1\n",
      "Row 153 => Predicted: 0\n",
      "Row 154 => Predicted: 1\n",
      "Row 155 => Predicted: 0\n",
      "Row 156 => Predicted: 0\n",
      "Row 157 => Predicted: 0\n",
      "Row 158 => Predicted: 1\n",
      "Row 159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 150 to 159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 160 => Predicted: 0\n",
      "Row 161 => Predicted: 0\n",
      "Row 162 => Predicted: 0\n",
      "Row 163 => Predicted: 1\n",
      "Row 164 => Predicted: 1\n",
      "Row 165 => Predicted: 0\n",
      "Row 166 => Predicted: 0\n",
      "Row 167 => Predicted: 1\n",
      "Row 168 => Predicted: 0\n",
      "Row 169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 160 to 169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 170 => Predicted: 1\n",
      "Row 171 => Predicted: 1\n",
      "Row 172 => Predicted: 1\n",
      "Row 173 => Predicted: 0\n",
      "Row 174 => Predicted: 1\n",
      "Row 175 => Predicted: 0\n",
      "Row 176 => Predicted: 0\n",
      "Row 177 => Predicted: 0\n",
      "Row 178 => Predicted: 0\n",
      "Row 179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 170 to 179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 180 => Predicted: 0\n",
      "Row 181 => Predicted: 1\n",
      "Row 182 => Predicted: 0\n",
      "Row 183 => Predicted: 1\n",
      "Row 184 => Predicted: 1\n",
      "Row 185 => Predicted: 1\n",
      "Row 186 => Predicted: 1\n",
      "Row 187 => Predicted: 0\n",
      "Row 188 => Predicted: 1\n",
      "Row 189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 180 to 189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 190 => Predicted: 1\n",
      "Row 191 => Predicted: 0\n",
      "Row 192 => Predicted: 0\n",
      "Row 193 => Predicted: 1\n",
      "Row 194 => Predicted: 0\n",
      "Row 195 => Predicted: 0\n",
      "Row 196 => Predicted: 1\n",
      "Row 197 => Predicted: 1\n",
      "Row 198 => Predicted: 1\n",
      "Row 199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 190 to 199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 200 => Predicted: 0\n",
      "Row 201 => Predicted: 0\n",
      "Row 202 => Predicted: 1\n",
      "Row 203 => Predicted: 0\n",
      "Row 204 => Predicted: 1\n",
      "Row 205 => Predicted: 0\n",
      "Row 206 => Predicted: 0\n",
      "Row 207 => Predicted: 1\n",
      "Row 208 => Predicted: 0\n",
      "Row 209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 200 to 209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 210 => Predicted: 1\n",
      "Row 211 => Predicted: 0\n",
      "Row 212 => Predicted: 1\n",
      "Row 213 => Predicted: 0\n",
      "Row 214 => Predicted: 0\n",
      "Row 215 => Predicted: 1\n",
      "Row 216 => Predicted: 0\n",
      "Row 217 => Predicted: 1\n",
      "Row 218 => Predicted: 1\n",
      "Row 219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 210 to 219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 220 => Predicted: 0\n",
      "Row 221 => Predicted: 0\n",
      "Row 222 => Predicted: 0\n",
      "Row 223 => Predicted: 1\n",
      "Row 224 => Predicted: 0\n",
      "Row 225 => Predicted: 1\n",
      "Row 226 => Predicted: 1\n",
      "Row 227 => Predicted: 1\n",
      "Row 228 => Predicted: 0\n",
      "Row 229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 220 to 229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 230 => Predicted: 0\n",
      "Row 231 => Predicted: 1\n",
      "Row 232 => Predicted: 1\n",
      "Row 233 => Predicted: 1\n",
      "Row 234 => Predicted: 0\n",
      "Row 235 => Predicted: 0\n",
      "Row 236 => Predicted: 1\n",
      "Row 237 => Predicted: 0\n",
      "Row 238 => Predicted: 0\n",
      "Row 239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 230 to 239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 240 => Predicted: 1\n",
      "Row 241 => Predicted: 1\n",
      "Row 242 => Predicted: 1\n",
      "Row 243 => Predicted: 1\n",
      "Row 244 => Predicted: 0\n",
      "Row 245 => Predicted: 0\n",
      "Row 246 => Predicted: 1\n",
      "Row 247 => Predicted: 1\n",
      "Row 248 => Predicted: 1\n",
      "Row 249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 240 to 249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 250 => Predicted: 1\n",
      "Row 251 => Predicted: 1\n",
      "Row 252 => Predicted: 1\n",
      "Row 253 => Predicted: 1\n",
      "Row 254 => Predicted: 1\n",
      "Row 255 => Predicted: 0\n",
      "Row 256 => Predicted: 1\n",
      "Row 257 => Predicted: 0\n",
      "Row 258 => Predicted: 1\n",
      "Row 259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 250 to 259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 260 => Predicted: 1\n",
      "Row 261 => Predicted: 0\n",
      "Row 262 => Predicted: 0\n",
      "Row 263 => Predicted: 0\n",
      "Row 264 => Predicted: 1\n",
      "Row 265 => Predicted: 0\n",
      "Row 266 => Predicted: 0\n",
      "Row 267 => Predicted: 0\n",
      "Row 268 => Predicted: 1\n",
      "Row 269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 260 to 269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 270 => Predicted: 1\n",
      "Row 271 => Predicted: 0\n",
      "Row 272 => Predicted: 1\n",
      "Row 273 => Predicted: 1\n",
      "Row 274 => Predicted: 1\n",
      "Row 275 => Predicted: 1\n",
      "Row 276 => Predicted: 1\n",
      "Row 277 => Predicted: 0\n",
      "Row 278 => Predicted: 1\n",
      "Row 279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 270 to 279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 280 => Predicted: 1\n",
      "Row 281 => Predicted: 0\n",
      "Row 282 => Predicted: 1\n",
      "Row 283 => Predicted: 1\n",
      "Row 284 => Predicted: 1\n",
      "Row 285 => Predicted: 0\n",
      "Row 286 => Predicted: 1\n",
      "Row 287 => Predicted: 1\n",
      "Row 288 => Predicted: 1\n",
      "Row 289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 280 to 289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 290 => Predicted: 0\n",
      "Row 291 => Predicted: 1\n",
      "Row 292 => Predicted: 0\n",
      "Row 293 => Predicted: 1\n",
      "Row 294 => Predicted: 0\n",
      "Row 295 => Predicted: 1\n",
      "Row 296 => Predicted: 1\n",
      "Row 297 => Predicted: 1\n",
      "Row 298 => Predicted: 1\n",
      "Row 299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 290 to 299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 300 => Predicted: 1\n",
      "Row 301 => Predicted: 0\n",
      "Row 302 => Predicted: 1\n",
      "Row 303 => Predicted: 1\n",
      "Row 304 => Predicted: 1\n",
      "Row 305 => Predicted: 0\n",
      "Row 306 => Predicted: 1\n",
      "Row 307 => Predicted: 0\n",
      "Row 308 => Predicted: 1\n",
      "Row 309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 300 to 309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 310 => Predicted: 1\n",
      "Row 311 => Predicted: 0\n",
      "Row 312 => Predicted: 1\n",
      "Row 313 => Predicted: 0\n",
      "Row 314 => Predicted: 0\n",
      "Row 315 => Predicted: 1\n",
      "Row 316 => Predicted: 0\n",
      "Row 317 => Predicted: 0\n",
      "Row 318 => Predicted: 1\n",
      "Row 319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 310 to 319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 320 => Predicted: 0\n",
      "Row 321 => Predicted: 0\n",
      "Row 322 => Predicted: 1\n",
      "Row 323 => Predicted: 1\n",
      "Row 324 => Predicted: 0\n",
      "Row 325 => Predicted: 0\n",
      "Row 326 => Predicted: 0\n",
      "Row 327 => Predicted: 1\n",
      "Row 328 => Predicted: 0\n",
      "Row 329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 320 to 329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 330 => Predicted: 0\n",
      "Row 331 => Predicted: 0\n",
      "Row 332 => Predicted: 0\n",
      "Row 333 => Predicted: 1\n",
      "Row 334 => Predicted: 1\n",
      "Row 335 => Predicted: 0\n",
      "Row 336 => Predicted: 1\n",
      "Row 337 => Predicted: 0\n",
      "Row 338 => Predicted: 0\n",
      "Row 339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 330 to 339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 340 => Predicted: 1\n",
      "Row 341 => Predicted: 0\n",
      "Row 342 => Predicted: 0\n",
      "Row 343 => Predicted: 1\n",
      "Row 344 => Predicted: 1\n",
      "Row 345 => Predicted: 0\n",
      "Row 346 => Predicted: 1\n",
      "Row 347 => Predicted: 1\n",
      "Row 348 => Predicted: 0\n",
      "Row 349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 340 to 349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 350 => Predicted: 0\n",
      "Row 351 => Predicted: 0\n",
      "Row 352 => Predicted: 0\n",
      "Row 353 => Predicted: 1\n",
      "Row 354 => Predicted: 1\n",
      "Row 355 => Predicted: 1\n",
      "Row 356 => Predicted: 0\n",
      "Row 357 => Predicted: 1\n",
      "Row 358 => Predicted: 1\n",
      "Row 359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 350 to 359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 360 => Predicted: 0\n",
      "Row 361 => Predicted: 1\n",
      "Row 362 => Predicted: 0\n",
      "Row 363 => Predicted: 1\n",
      "Row 364 => Predicted: 1\n",
      "Row 365 => Predicted: 0\n",
      "Row 366 => Predicted: 0\n",
      "Row 367 => Predicted: 0\n",
      "Row 368 => Predicted: 0\n",
      "Row 369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 360 to 369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 370 => Predicted: 0\n",
      "Row 371 => Predicted: 0\n",
      "Row 372 => Predicted: 1\n",
      "Row 373 => Predicted: 1\n",
      "Row 374 => Predicted: 0\n",
      "Row 375 => Predicted: 0\n",
      "Row 376 => Predicted: 1\n",
      "Row 377 => Predicted: 0\n",
      "Row 378 => Predicted: 1\n",
      "Row 379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 370 to 379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 380 => Predicted: 0\n",
      "Row 381 => Predicted: 0\n",
      "Row 382 => Predicted: 0\n",
      "Row 383 => Predicted: 0\n",
      "Row 384 => Predicted: 0\n",
      "Row 385 => Predicted: 0\n",
      "Row 386 => Predicted: 0\n",
      "Row 387 => Predicted: 0\n",
      "Row 388 => Predicted: 1\n",
      "Row 389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 380 to 389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 390 => Predicted: 1\n",
      "Row 391 => Predicted: 0\n",
      "Row 392 => Predicted: 0\n",
      "Row 393 => Predicted: 1\n",
      "Row 394 => Predicted: 1\n",
      "Row 395 => Predicted: 0\n",
      "Row 396 => Predicted: 0\n",
      "Row 397 => Predicted: 0\n",
      "Row 398 => Predicted: 1\n",
      "Row 399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 390 to 399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 400 => Predicted: 1\n",
      "Row 401 => Predicted: 1\n",
      "Row 402 => Predicted: 0\n",
      "Row 403 => Predicted: 0\n",
      "Row 404 => Predicted: 1\n",
      "Row 405 => Predicted: 1\n",
      "Row 406 => Predicted: 1\n",
      "Row 407 => Predicted: 0\n",
      "Row 408 => Predicted: 1\n",
      "Row 409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 400 to 409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 410 => Predicted: 1\n",
      "Row 411 => Predicted: 0\n",
      "Row 412 => Predicted: 0\n",
      "Row 413 => Predicted: 0\n",
      "Row 414 => Predicted: 0\n",
      "Row 415 => Predicted: 1\n",
      "Row 416 => Predicted: 1\n",
      "Row 417 => Predicted: 1\n",
      "Row 418 => Predicted: 0\n",
      "Row 419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 410 to 419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 420 => Predicted: 0\n",
      "Row 421 => Predicted: 0\n",
      "Row 422 => Predicted: 1\n",
      "Row 423 => Predicted: 0\n",
      "Row 424 => Predicted: 0\n",
      "Row 425 => Predicted: 1\n",
      "Row 426 => Predicted: 0\n",
      "Row 427 => Predicted: 1\n",
      "Row 428 => Predicted: 0\n",
      "Row 429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 420 to 429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 430 => Predicted: 1\n",
      "Row 431 => Predicted: 0\n",
      "Row 432 => Predicted: 0\n",
      "Row 433 => Predicted: 1\n",
      "Row 434 => Predicted: 1\n",
      "Row 435 => Predicted: 1\n",
      "Row 436 => Predicted: 0\n",
      "Row 437 => Predicted: 0\n",
      "Row 438 => Predicted: 1\n",
      "Row 439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 430 to 439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 440 => Predicted: 0\n",
      "Row 441 => Predicted: 0\n",
      "Row 442 => Predicted: 0\n",
      "Row 443 => Predicted: 1\n",
      "Row 444 => Predicted: 0\n",
      "Row 445 => Predicted: 1\n",
      "Row 446 => Predicted: 1\n",
      "Row 447 => Predicted: 1\n",
      "Row 448 => Predicted: 0\n",
      "Row 449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 440 to 449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 450 => Predicted: 1\n",
      "Row 451 => Predicted: 0\n",
      "Row 452 => Predicted: 0\n",
      "Row 453 => Predicted: 1\n",
      "Row 454 => Predicted: 1\n",
      "Row 455 => Predicted: 1\n",
      "Row 456 => Predicted: 0\n",
      "Row 457 => Predicted: 1\n",
      "Row 458 => Predicted: 1\n",
      "Row 459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 450 to 459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 460 => Predicted: 0\n",
      "Row 461 => Predicted: 1\n",
      "Row 462 => Predicted: 0\n",
      "Row 463 => Predicted: 1\n",
      "Row 464 => Predicted: 0\n",
      "Row 465 => Predicted: 0\n",
      "Row 466 => Predicted: 1\n",
      "Row 467 => Predicted: 0\n",
      "Row 468 => Predicted: 0\n",
      "Row 469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 460 to 469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 470 => Predicted: 1\n",
      "Row 471 => Predicted: 0\n",
      "Row 472 => Predicted: 0\n",
      "Row 473 => Predicted: 0\n",
      "Row 474 => Predicted: 1\n",
      "Row 475 => Predicted: 0\n",
      "Row 476 => Predicted: 0\n",
      "Row 477 => Predicted: 1\n",
      "Row 478 => Predicted: 0\n",
      "Row 479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 470 to 479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 480 => Predicted: 0\n",
      "Row 481 => Predicted: 0\n",
      "Row 482 => Predicted: 1\n",
      "Row 483 => Predicted: 1\n",
      "Row 484 => Predicted: 0\n",
      "Row 485 => Predicted: 0\n",
      "Row 486 => Predicted: 0\n",
      "Row 487 => Predicted: 1\n",
      "Row 488 => Predicted: 0\n",
      "Row 489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 480 to 489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 490 => Predicted: 1\n",
      "Row 491 => Predicted: 0\n",
      "Row 492 => Predicted: 0\n",
      "Row 493 => Predicted: 0\n",
      "Row 494 => Predicted: 0\n",
      "Row 495 => Predicted: 0\n",
      "Row 496 => Predicted: 1\n",
      "Row 497 => Predicted: 1\n",
      "Row 498 => Predicted: 1\n",
      "Row 499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 490 to 499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 500 => Predicted: 0\n",
      "Row 501 => Predicted: 1\n",
      "Row 502 => Predicted: 0\n",
      "Row 503 => Predicted: 0\n",
      "Row 504 => Predicted: 1\n",
      "Row 505 => Predicted: 1\n",
      "Row 506 => Predicted: 1\n",
      "Row 507 => Predicted: 0\n",
      "Row 508 => Predicted: 1\n",
      "Row 509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 500 to 509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 510 => Predicted: 0\n",
      "Row 511 => Predicted: 0\n",
      "Row 512 => Predicted: 1\n",
      "Row 513 => Predicted: 1\n",
      "Row 514 => Predicted: 1\n",
      "Row 515 => Predicted: 1\n",
      "Row 516 => Predicted: 0\n",
      "Row 517 => Predicted: 1\n",
      "Row 518 => Predicted: 1\n",
      "Row 519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 510 to 519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 520 => Predicted: 1\n",
      "Row 521 => Predicted: 0\n",
      "Row 522 => Predicted: 0\n",
      "Row 523 => Predicted: 0\n",
      "Row 524 => Predicted: 0\n",
      "Row 525 => Predicted: 1\n",
      "Row 526 => Predicted: 0\n",
      "Row 527 => Predicted: 1\n",
      "Row 528 => Predicted: 1\n",
      "Row 529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 520 to 529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 530 => Predicted: 0\n",
      "Row 531 => Predicted: 1\n",
      "Row 532 => Predicted: 0\n",
      "Row 533 => Predicted: 1\n",
      "Row 534 => Predicted: 0\n",
      "Row 535 => Predicted: 1\n",
      "Row 536 => Predicted: 0\n",
      "Row 537 => Predicted: 0\n",
      "Row 538 => Predicted: 0\n",
      "Row 539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 530 to 539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 540 => Predicted: 1\n",
      "Row 541 => Predicted: 0\n",
      "Row 542 => Predicted: 1\n",
      "Row 543 => Predicted: 0\n",
      "Row 544 => Predicted: 1\n",
      "Row 545 => Predicted: 0\n",
      "Row 546 => Predicted: 0\n",
      "Row 547 => Predicted: 0\n",
      "Row 548 => Predicted: 0\n",
      "Row 549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 540 to 549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 550 => Predicted: 0\n",
      "Row 551 => Predicted: 0\n",
      "Row 552 => Predicted: 0\n",
      "Row 553 => Predicted: 0\n",
      "Row 554 => Predicted: 0\n",
      "Row 555 => Predicted: 0\n",
      "Row 556 => Predicted: 0\n",
      "Row 557 => Predicted: 1\n",
      "Row 558 => Predicted: 0\n",
      "Row 559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 550 to 559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 560 => Predicted: 1\n",
      "Row 561 => Predicted: 0\n",
      "Row 562 => Predicted: 0\n",
      "Row 563 => Predicted: 0\n",
      "Row 564 => Predicted: 1\n",
      "Row 565 => Predicted: 1\n",
      "Row 566 => Predicted: 1\n",
      "Row 567 => Predicted: 1\n",
      "Row 568 => Predicted: 1\n",
      "Row 569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 560 to 569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 570 => Predicted: 0\n",
      "Row 571 => Predicted: 0\n",
      "Row 572 => Predicted: 0\n",
      "Row 573 => Predicted: 1\n",
      "Row 574 => Predicted: 1\n",
      "Row 575 => Predicted: 1\n",
      "Row 576 => Predicted: 1\n",
      "Row 577 => Predicted: 1\n",
      "Row 578 => Predicted: 0\n",
      "Row 579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 570 to 579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 580 => Predicted: 0\n",
      "Row 581 => Predicted: 1\n",
      "Row 582 => Predicted: 1\n",
      "Row 583 => Predicted: 0\n",
      "Row 584 => Predicted: 0\n",
      "Row 585 => Predicted: 0\n",
      "Row 586 => Predicted: 0\n",
      "Row 587 => Predicted: 0\n",
      "Row 588 => Predicted: 1\n",
      "Row 589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 580 to 589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 590 => Predicted: 1\n",
      "Row 591 => Predicted: 1\n",
      "Row 592 => Predicted: 0\n",
      "Row 593 => Predicted: 1\n",
      "Row 594 => Predicted: 0\n",
      "Row 595 => Predicted: 1\n",
      "Row 596 => Predicted: 1\n",
      "Row 597 => Predicted: 1\n",
      "Row 598 => Predicted: 0\n",
      "Row 599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 590 to 599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 600 => Predicted: 1\n",
      "Row 601 => Predicted: 1\n",
      "Row 602 => Predicted: 0\n",
      "Row 603 => Predicted: 0\n",
      "Row 604 => Predicted: 1\n",
      "Row 605 => Predicted: 1\n",
      "Row 606 => Predicted: 0\n",
      "Row 607 => Predicted: 0\n",
      "Row 608 => Predicted: 0\n",
      "Row 609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 600 to 609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 610 => Predicted: 0\n",
      "Row 611 => Predicted: 1\n",
      "Row 612 => Predicted: 0\n",
      "Row 613 => Predicted: 0\n",
      "Row 614 => Predicted: 0\n",
      "Row 615 => Predicted: 1\n",
      "Row 616 => Predicted: 0\n",
      "Row 617 => Predicted: 1\n",
      "Row 618 => Predicted: 1\n",
      "Row 619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 610 to 619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 620 => Predicted: 1\n",
      "Row 621 => Predicted: 0\n",
      "Row 622 => Predicted: 0\n",
      "Row 623 => Predicted: 1\n",
      "Row 624 => Predicted: 1\n",
      "Row 625 => Predicted: 0\n",
      "Row 626 => Predicted: 0\n",
      "Row 627 => Predicted: 0\n",
      "Row 628 => Predicted: 1\n",
      "Row 629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 620 to 629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 630 => Predicted: 0\n",
      "Row 631 => Predicted: 0\n",
      "Row 632 => Predicted: 0\n",
      "Row 633 => Predicted: 0\n",
      "Row 634 => Predicted: 0\n",
      "Row 635 => Predicted: 0\n",
      "Row 636 => Predicted: 1\n",
      "Row 637 => Predicted: 0\n",
      "Row 638 => Predicted: 1\n",
      "Row 639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 630 to 639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 640 => Predicted: 1\n",
      "Row 641 => Predicted: 1\n",
      "Row 642 => Predicted: 1\n",
      "Row 643 => Predicted: 1\n",
      "Row 644 => Predicted: 0\n",
      "Row 645 => Predicted: 1\n",
      "Row 646 => Predicted: 1\n",
      "Row 647 => Predicted: 1\n",
      "Row 648 => Predicted: 0\n",
      "Row 649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 640 to 649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 650 => Predicted: 1\n",
      "Row 651 => Predicted: 1\n",
      "Row 652 => Predicted: 1\n",
      "Row 653 => Predicted: 0\n",
      "Row 654 => Predicted: 1\n",
      "Row 655 => Predicted: 0\n",
      "Row 656 => Predicted: 0\n",
      "Row 657 => Predicted: 0\n",
      "Row 658 => Predicted: 1\n",
      "Row 659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 650 to 659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 660 => Predicted: 0\n",
      "Row 661 => Predicted: 1\n",
      "Row 662 => Predicted: 0\n",
      "Row 663 => Predicted: 0\n",
      "Row 664 => Predicted: 0\n",
      "Row 665 => Predicted: 1\n",
      "Row 666 => Predicted: 0\n",
      "Row 667 => Predicted: 1\n",
      "Row 668 => Predicted: 1\n",
      "Row 669 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 660 to 669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 670 => Predicted: 1\n",
      "Row 671 => Predicted: 0\n",
      "Row 672 => Predicted: 1\n",
      "Row 673 => Predicted: 1\n",
      "Row 674 => Predicted: 0\n",
      "Row 675 => Predicted: 1\n",
      "Row 676 => Predicted: 1\n",
      "Row 677 => Predicted: 1\n",
      "Row 678 => Predicted: 1\n",
      "Row 679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 670 to 679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 680 => Predicted: 0\n",
      "Row 681 => Predicted: 1\n",
      "Row 682 => Predicted: 1\n",
      "Row 683 => Predicted: 1\n",
      "Row 684 => Predicted: 1\n",
      "Row 685 => Predicted: 1\n",
      "Row 686 => Predicted: 0\n",
      "Row 687 => Predicted: 1\n",
      "Row 688 => Predicted: 1\n",
      "Row 689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 680 to 689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 690 => Predicted: 0\n",
      "Row 691 => Predicted: 1\n",
      "Row 692 => Predicted: 1\n",
      "Row 693 => Predicted: 1\n",
      "Row 694 => Predicted: 0\n",
      "Row 695 => Predicted: 0\n",
      "Row 696 => Predicted: 1\n",
      "Row 697 => Predicted: 1\n",
      "Row 698 => Predicted: 0\n",
      "Row 699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 690 to 699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 700 => Predicted: 1\n",
      "Row 701 => Predicted: 1\n",
      "Row 702 => Predicted: 0\n",
      "Row 703 => Predicted: 1\n",
      "Row 704 => Predicted: 0\n",
      "Row 705 => Predicted: 1\n",
      "Row 706 => Predicted: 0\n",
      "Row 707 => Predicted: 0\n",
      "Row 708 => Predicted: 1\n",
      "Row 709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 700 to 709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 710 => Predicted: 1\n",
      "Row 711 => Predicted: 0\n",
      "Row 712 => Predicted: 0\n",
      "Row 713 => Predicted: 0\n",
      "Row 714 => Predicted: 1\n",
      "Row 715 => Predicted: 0\n",
      "Row 716 => Predicted: 1\n",
      "Row 717 => Predicted: 0\n",
      "Row 718 => Predicted: 1\n",
      "Row 719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 710 to 719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 720 => Predicted: 1\n",
      "Row 721 => Predicted: 0\n",
      "Row 722 => Predicted: 1\n",
      "Row 723 => Predicted: 1\n",
      "Row 724 => Predicted: 0\n",
      "Row 725 => Predicted: 1\n",
      "Row 726 => Predicted: 0\n",
      "Row 727 => Predicted: 0\n",
      "Row 728 => Predicted: 0\n",
      "Row 729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 720 to 729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 730 => Predicted: 0\n",
      "Row 731 => Predicted: 1\n",
      "Row 732 => Predicted: 1\n",
      "Row 733 => Predicted: 1\n",
      "Row 734 => Predicted: 1\n",
      "Row 735 => Predicted: 0\n",
      "Row 736 => Predicted: 0\n",
      "Row 737 => Predicted: 1\n",
      "Row 738 => Predicted: 1\n",
      "Row 739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 730 to 739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 740 => Predicted: 1\n",
      "Row 741 => Predicted: 1\n",
      "Row 742 => Predicted: 1\n",
      "Row 743 => Predicted: 0\n",
      "Row 744 => Predicted: 0\n",
      "Row 745 => Predicted: 0\n",
      "Row 746 => Predicted: 1\n",
      "Row 747 => Predicted: 1\n",
      "Row 748 => Predicted: 1\n",
      "Row 749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 740 to 749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 750 => Predicted: 1\n",
      "Row 751 => Predicted: 1\n",
      "Row 752 => Predicted: 0\n",
      "Row 753 => Predicted: 0\n",
      "Row 754 => Predicted: 0\n",
      "Row 755 => Predicted: 0\n",
      "Row 756 => Predicted: 0\n",
      "Row 757 => Predicted: 0\n",
      "Row 758 => Predicted: 1\n",
      "Row 759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 750 to 759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 760 => Predicted: 1\n",
      "Row 761 => Predicted: 1\n",
      "Row 762 => Predicted: 1\n",
      "Row 763 => Predicted: 1\n",
      "Row 764 => Predicted: 1\n",
      "Row 765 => Predicted: 0\n",
      "Row 766 => Predicted: 1\n",
      "Row 767 => Predicted: 0\n",
      "Row 768 => Predicted: 0\n",
      "Row 769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 760 to 769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 770 => Predicted: 0\n",
      "Row 771 => Predicted: 0\n",
      "Row 772 => Predicted: 0\n",
      "Row 773 => Predicted: 0\n",
      "Row 774 => Predicted: 1\n",
      "Row 775 => Predicted: 1\n",
      "Row 776 => Predicted: 0\n",
      "Row 777 => Predicted: 0\n",
      "Row 778 => Predicted: 0\n",
      "Row 779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 770 to 779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 780 => Predicted: 0\n",
      "Row 781 => Predicted: 0\n",
      "Row 782 => Predicted: 1\n",
      "Row 783 => Predicted: 0\n",
      "Row 784 => Predicted: 0\n",
      "Row 785 => Predicted: 0\n",
      "Row 786 => Predicted: 1\n",
      "Row 787 => Predicted: 0\n",
      "Row 788 => Predicted: 0\n",
      "Row 789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 780 to 789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 790 => Predicted: 1\n",
      "Row 791 => Predicted: 1\n",
      "Row 792 => Predicted: 1\n",
      "Row 793 => Predicted: 0\n",
      "Row 794 => Predicted: 1\n",
      "Row 795 => Predicted: 1\n",
      "Row 796 => Predicted: 1\n",
      "Row 797 => Predicted: 1\n",
      "Row 798 => Predicted: 1\n",
      "Row 799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 790 to 799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 800 => Predicted: 1\n",
      "Row 801 => Predicted: 0\n",
      "Row 802 => Predicted: 0\n",
      "Row 803 => Predicted: 1\n",
      "Row 804 => Predicted: 0\n",
      "Row 805 => Predicted: 0\n",
      "Row 806 => Predicted: 1\n",
      "Row 807 => Predicted: 1\n",
      "Row 808 => Predicted: 0\n",
      "Row 809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 800 to 809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 810 => Predicted: 1\n",
      "Row 811 => Predicted: 0\n",
      "Row 812 => Predicted: 0\n",
      "Row 813 => Predicted: 1\n",
      "Row 814 => Predicted: 0\n",
      "Row 815 => Predicted: 0\n",
      "Row 816 => Predicted: 0\n",
      "Row 817 => Predicted: 1\n",
      "Row 818 => Predicted: 1\n",
      "Row 819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 810 to 819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 820 => Predicted: 1\n",
      "Row 821 => Predicted: 0\n",
      "Row 822 => Predicted: 1\n",
      "Row 823 => Predicted: 0\n",
      "Row 824 => Predicted: 0\n",
      "Row 825 => Predicted: 1\n",
      "Row 826 => Predicted: 1\n",
      "Row 827 => Predicted: 1\n",
      "Row 828 => Predicted: 1\n",
      "Row 829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 820 to 829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 830 => Predicted: 1\n",
      "Row 831 => Predicted: 0\n",
      "Row 832 => Predicted: 1\n",
      "Row 833 => Predicted: 1\n",
      "Row 834 => Predicted: 1\n",
      "Row 835 => Predicted: 0\n",
      "Row 836 => Predicted: 0\n",
      "Row 837 => Predicted: 0\n",
      "Row 838 => Predicted: 1\n",
      "Row 839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 830 to 839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 840 => Predicted: 1\n",
      "Row 841 => Predicted: 1\n",
      "Row 842 => Predicted: 0\n",
      "Row 843 => Predicted: 0\n",
      "Row 844 => Predicted: 1\n",
      "Row 845 => Predicted: 0\n",
      "Row 846 => Predicted: 0\n",
      "Row 847 => Predicted: 0\n",
      "Row 848 => Predicted: 0\n",
      "Row 849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 840 to 849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 850 => Predicted: 0\n",
      "Row 851 => Predicted: 0\n",
      "Row 852 => Predicted: 1\n",
      "Row 853 => Predicted: 1\n",
      "Row 854 => Predicted: 1\n",
      "Row 855 => Predicted: 1\n",
      "Row 856 => Predicted: 1\n",
      "Row 857 => Predicted: 0\n",
      "Row 858 => Predicted: 1\n",
      "Row 859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 850 to 859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 860 => Predicted: 0\n",
      "Row 861 => Predicted: 1\n",
      "Row 862 => Predicted: 0\n",
      "Row 863 => Predicted: 1\n",
      "Row 864 => Predicted: 0\n",
      "Row 865 => Predicted: 1\n",
      "Row 866 => Predicted: 1\n",
      "Row 867 => Predicted: 1\n",
      "Row 868 => Predicted: 0\n",
      "Row 869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 860 to 869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 870 => Predicted: 1\n",
      "Row 871 => Predicted: 0\n",
      "Row 872 => Predicted: 0\n",
      "Row 873 => Predicted: 0\n",
      "Row 874 => Predicted: 1\n",
      "Row 875 => Predicted: 0\n",
      "Row 876 => Predicted: 0\n",
      "Row 877 => Predicted: 1\n",
      "Row 878 => Predicted: 0\n",
      "Row 879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 870 to 879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 880 => Predicted: 0\n",
      "Row 881 => Predicted: 1\n",
      "Row 882 => Predicted: 0\n",
      "Row 883 => Predicted: 0\n",
      "Row 884 => Predicted: 1\n",
      "Row 885 => Predicted: 0\n",
      "Row 886 => Predicted: 1\n",
      "Row 887 => Predicted: 1\n",
      "Row 888 => Predicted: 1\n",
      "Row 889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 880 to 889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 890 => Predicted: 0\n",
      "Row 891 => Predicted: 1\n",
      "Row 892 => Predicted: 1\n",
      "Row 893 => Predicted: 0\n",
      "Row 894 => Predicted: 0\n",
      "Row 895 => Predicted: 1\n",
      "Row 896 => Predicted: 1\n",
      "Row 897 => Predicted: 1\n",
      "Row 898 => Predicted: 1\n",
      "Row 899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 890 to 899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 900 => Predicted: 1\n",
      "Row 901 => Predicted: 1\n",
      "Row 902 => Predicted: 1\n",
      "Row 903 => Predicted: 0\n",
      "Row 904 => Predicted: 1\n",
      "Row 905 => Predicted: 1\n",
      "Row 906 => Predicted: 1\n",
      "Row 907 => Predicted: 1\n",
      "Row 908 => Predicted: 1\n",
      "Row 909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 900 to 909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 910 => Predicted: 0\n",
      "Row 911 => Predicted: 0\n",
      "Row 912 => Predicted: 0\n",
      "Row 913 => Predicted: 0\n",
      "Row 914 => Predicted: 0\n",
      "Row 915 => Predicted: 1\n",
      "Row 916 => Predicted: 1\n",
      "Row 917 => Predicted: 0\n",
      "Row 918 => Predicted: 0\n",
      "Row 919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 910 to 919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 920 => Predicted: 1\n",
      "Row 921 => Predicted: 1\n",
      "Row 922 => Predicted: 1\n",
      "Row 923 => Predicted: 0\n",
      "Row 924 => Predicted: 1\n",
      "Row 925 => Predicted: 0\n",
      "Row 926 => Predicted: 1\n",
      "Row 927 => Predicted: 0\n",
      "Row 928 => Predicted: 1\n",
      "Row 929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 920 to 929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 930 => Predicted: 1\n",
      "Row 931 => Predicted: 0\n",
      "Row 932 => Predicted: 0\n",
      "Row 933 => Predicted: 1\n",
      "Row 934 => Predicted: 1\n",
      "Row 935 => Predicted: 0\n",
      "Row 936 => Predicted: 1\n",
      "Row 937 => Predicted: 0\n",
      "Row 938 => Predicted: 0\n",
      "Row 939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 930 to 939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 940 => Predicted: 0\n",
      "Row 941 => Predicted: 0\n",
      "Row 942 => Predicted: 0\n",
      "Row 943 => Predicted: 0\n",
      "Row 944 => Predicted: 1\n",
      "Row 945 => Predicted: 1\n",
      "Row 946 => Predicted: 0\n",
      "Row 947 => Predicted: 1\n",
      "Row 948 => Predicted: 1\n",
      "Row 949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 940 to 949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 950 => Predicted: 0\n",
      "Row 951 => Predicted: 1\n",
      "Row 952 => Predicted: 1\n",
      "Row 953 => Predicted: 0\n",
      "Row 954 => Predicted: 1\n",
      "Row 955 => Predicted: 1\n",
      "Row 956 => Predicted: 1\n",
      "Row 957 => Predicted: 1\n",
      "Row 958 => Predicted: 1\n",
      "Row 959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 950 to 959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 960 => Predicted: 1\n",
      "Row 961 => Predicted: 1\n",
      "Row 962 => Predicted: 0\n",
      "Row 963 => Predicted: 0\n",
      "Row 964 => Predicted: 1\n",
      "Row 965 => Predicted: 0\n",
      "Row 966 => Predicted: 1\n",
      "Row 967 => Predicted: 0\n",
      "Row 968 => Predicted: 0\n",
      "Row 969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 960 to 969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 970 => Predicted: 1\n",
      "Row 971 => Predicted: 0\n",
      "Row 972 => Predicted: 1\n",
      "Row 973 => Predicted: 0\n",
      "Row 974 => Predicted: 0\n",
      "Row 975 => Predicted: 0\n",
      "Row 976 => Predicted: 0\n",
      "Row 977 => Predicted: 0\n",
      "Row 978 => Predicted: 0\n",
      "Row 979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 970 to 979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 980 => Predicted: 1\n",
      "Row 981 => Predicted: 0\n",
      "Row 982 => Predicted: 1\n",
      "Row 983 => Predicted: 1\n",
      "Row 984 => Predicted: 1\n",
      "Row 985 => Predicted: 1\n",
      "Row 986 => Predicted: 1\n",
      "Row 987 => Predicted: 1\n",
      "Row 988 => Predicted: 0\n",
      "Row 989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 980 to 989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 990 => Predicted: 0\n",
      "Row 991 => Predicted: 0\n",
      "Row 992 => Predicted: 0\n",
      "Row 993 => Predicted: 0\n",
      "Row 994 => Predicted: 0\n",
      "Row 995 => Predicted: 0\n",
      "Row 996 => Predicted: 1\n",
      "Row 997 => Predicted: 0\n",
      "Row 998 => Predicted: 1\n",
      "Row 999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 990 to 999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1000 => Predicted: 0\n",
      "Row 1001 => Predicted: 0\n",
      "Row 1002 => Predicted: 0\n",
      "Row 1003 => Predicted: 1\n",
      "Row 1004 => Predicted: 1\n",
      "Row 1005 => Predicted: 0\n",
      "Row 1006 => Predicted: 1\n",
      "Row 1007 => Predicted: 1\n",
      "Row 1008 => Predicted: 0\n",
      "Row 1009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1000 to 1009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1010 => Predicted: 1\n",
      "Row 1011 => Predicted: 0\n",
      "Row 1012 => Predicted: 0\n",
      "Row 1013 => Predicted: 1\n",
      "Row 1014 => Predicted: 1\n",
      "Row 1015 => Predicted: 0\n",
      "Row 1016 => Predicted: 0\n",
      "Row 1017 => Predicted: 0\n",
      "Row 1018 => Predicted: 0\n",
      "Row 1019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1010 to 1019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1020 => Predicted: 1\n",
      "Row 1021 => Predicted: 0\n",
      "Row 1022 => Predicted: 1\n",
      "Row 1023 => Predicted: 0\n",
      "Row 1024 => Predicted: 1\n",
      "Row 1025 => Predicted: 0\n",
      "Row 1026 => Predicted: 0\n",
      "Row 1027 => Predicted: 1\n",
      "Row 1028 => Predicted: 1\n",
      "Row 1029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1020 to 1029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1030 => Predicted: 1\n",
      "Row 1031 => Predicted: 0\n",
      "Row 1032 => Predicted: 1\n",
      "Row 1033 => Predicted: 1\n",
      "Row 1034 => Predicted: 1\n",
      "Row 1035 => Predicted: 0\n",
      "Row 1036 => Predicted: 1\n",
      "Row 1037 => Predicted: 1\n",
      "Row 1038 => Predicted: 1\n",
      "Row 1039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1030 to 1039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1040 => Predicted: 1\n",
      "Row 1041 => Predicted: 0\n",
      "Row 1042 => Predicted: 0\n",
      "Row 1043 => Predicted: 1\n",
      "Row 1044 => Predicted: 1\n",
      "Row 1045 => Predicted: 1\n",
      "Row 1046 => Predicted: 1\n",
      "Row 1047 => Predicted: 1\n",
      "Row 1048 => Predicted: 0\n",
      "Row 1049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1040 to 1049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1050 => Predicted: 0\n",
      "Row 1051 => Predicted: 1\n",
      "Row 1052 => Predicted: 1\n",
      "Row 1053 => Predicted: 1\n",
      "Row 1054 => Predicted: 1\n",
      "Row 1055 => Predicted: 0\n",
      "Row 1056 => Predicted: 0\n",
      "Row 1057 => Predicted: 1\n",
      "Row 1058 => Predicted: 0\n",
      "Row 1059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1050 to 1059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1060 => Predicted: 0\n",
      "Row 1061 => Predicted: 0\n",
      "Row 1062 => Predicted: 0\n",
      "Row 1063 => Predicted: 1\n",
      "Row 1064 => Predicted: 0\n",
      "Row 1065 => Predicted: 1\n",
      "Row 1066 => Predicted: 0\n",
      "Row 1067 => Predicted: 0\n",
      "Row 1068 => Predicted: 1\n",
      "Row 1069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1060 to 1069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1070 => Predicted: 1\n",
      "Row 1071 => Predicted: 0\n",
      "Row 1072 => Predicted: 0\n",
      "Row 1073 => Predicted: 1\n",
      "Row 1074 => Predicted: 0\n",
      "Row 1075 => Predicted: 0\n",
      "Row 1076 => Predicted: 1\n",
      "Row 1077 => Predicted: 1\n",
      "Row 1078 => Predicted: 0\n",
      "Row 1079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1070 to 1079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1080 => Predicted: 1\n",
      "Row 1081 => Predicted: 1\n",
      "Row 1082 => Predicted: 1\n",
      "Row 1083 => Predicted: 1\n",
      "Row 1084 => Predicted: 0\n",
      "Row 1085 => Predicted: 0\n",
      "Row 1086 => Predicted: 1\n",
      "Row 1087 => Predicted: 1\n",
      "Row 1088 => Predicted: 1\n",
      "Row 1089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1080 to 1089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1090 => Predicted: 0\n",
      "Row 1091 => Predicted: 0\n",
      "Row 1092 => Predicted: 0\n",
      "Row 1093 => Predicted: 1\n",
      "Row 1094 => Predicted: 1\n",
      "Row 1095 => Predicted: 1\n",
      "Row 1096 => Predicted: 1\n",
      "Row 1097 => Predicted: 1\n",
      "Row 1098 => Predicted: 0\n",
      "Row 1099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1090 to 1099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1100 => Predicted: 1\n",
      "Row 1101 => Predicted: 0\n",
      "Row 1102 => Predicted: 1\n",
      "Row 1103 => Predicted: 1\n",
      "Row 1104 => Predicted: 1\n",
      "Row 1105 => Predicted: 1\n",
      "Row 1106 => Predicted: 0\n",
      "Row 1107 => Predicted: 1\n",
      "Row 1108 => Predicted: 1\n",
      "Row 1109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1100 to 1109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1110 => Predicted: 1\n",
      "Row 1111 => Predicted: 1\n",
      "Row 1112 => Predicted: 1\n",
      "Row 1113 => Predicted: 0\n",
      "Row 1114 => Predicted: 0\n",
      "Row 1115 => Predicted: 0\n",
      "Row 1116 => Predicted: 1\n",
      "Row 1117 => Predicted: 0\n",
      "Row 1118 => Predicted: 0\n",
      "Row 1119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1110 to 1119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1120 => Predicted: 1\n",
      "Row 1121 => Predicted: 1\n",
      "Row 1122 => Predicted: 0\n",
      "Row 1123 => Predicted: 0\n",
      "Row 1124 => Predicted: 1\n",
      "Row 1125 => Predicted: 1\n",
      "Row 1126 => Predicted: 1\n",
      "Row 1127 => Predicted: 1\n",
      "Row 1128 => Predicted: 1\n",
      "Row 1129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1120 to 1129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1130 => Predicted: 1\n",
      "Row 1131 => Predicted: 1\n",
      "Row 1132 => Predicted: 0\n",
      "Row 1133 => Predicted: 0\n",
      "Row 1134 => Predicted: 0\n",
      "Row 1135 => Predicted: 0\n",
      "Row 1136 => Predicted: 0\n",
      "Row 1137 => Predicted: 0\n",
      "Row 1138 => Predicted: 0\n",
      "Row 1139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1130 to 1139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1140 => Predicted: 0\n",
      "Row 1141 => Predicted: 1\n",
      "Row 1142 => Predicted: 1\n",
      "Row 1143 => Predicted: 1\n",
      "Row 1144 => Predicted: 0\n",
      "Row 1145 => Predicted: 0\n",
      "Row 1146 => Predicted: 1\n",
      "Row 1147 => Predicted: 0\n",
      "Row 1148 => Predicted: 1\n",
      "Row 1149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1140 to 1149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1150 => Predicted: 1\n",
      "Row 1151 => Predicted: 1\n",
      "Row 1152 => Predicted: 1\n",
      "Row 1153 => Predicted: 1\n",
      "Row 1154 => Predicted: 1\n",
      "Row 1155 => Predicted: 0\n",
      "Row 1156 => Predicted: 0\n",
      "Row 1157 => Predicted: 1\n",
      "Row 1158 => Predicted: 0\n",
      "Row 1159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1150 to 1159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1160 => Predicted: 1\n",
      "Row 1161 => Predicted: 1\n",
      "Row 1162 => Predicted: 0\n",
      "Row 1163 => Predicted: 0\n",
      "Row 1164 => Predicted: 1\n",
      "Row 1165 => Predicted: 0\n",
      "Row 1166 => Predicted: 0\n",
      "Row 1167 => Predicted: 0\n",
      "Row 1168 => Predicted: 0\n",
      "Row 1169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1160 to 1169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1170 => Predicted: 1\n",
      "Row 1171 => Predicted: 0\n",
      "Row 1172 => Predicted: 0\n",
      "Row 1173 => Predicted: 0\n",
      "Row 1174 => Predicted: 0\n",
      "Row 1175 => Predicted: 0\n",
      "Row 1176 => Predicted: 0\n",
      "Row 1177 => Predicted: 1\n",
      "Row 1178 => Predicted: 1\n",
      "Row 1179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1170 to 1179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1180 => Predicted: 1\n",
      "Row 1181 => Predicted: 0\n",
      "Row 1182 => Predicted: 1\n",
      "Row 1183 => Predicted: 0\n",
      "Row 1184 => Predicted: 1\n",
      "Row 1185 => Predicted: 1\n",
      "Row 1186 => Predicted: 0\n",
      "Row 1187 => Predicted: 1\n",
      "Row 1188 => Predicted: 1\n",
      "Row 1189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1180 to 1189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1190 => Predicted: 1\n",
      "Row 1191 => Predicted: 1\n",
      "Row 1192 => Predicted: 0\n",
      "Row 1193 => Predicted: 1\n",
      "Row 1194 => Predicted: 0\n",
      "Row 1195 => Predicted: 0\n",
      "Row 1196 => Predicted: 0\n",
      "Row 1197 => Predicted: 1\n",
      "Row 1198 => Predicted: 1\n",
      "Row 1199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1190 to 1199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1200 => Predicted: 1\n",
      "Row 1201 => Predicted: 0\n",
      "Row 1202 => Predicted: 0\n",
      "Row 1203 => Predicted: 1\n",
      "Row 1204 => Predicted: 0\n",
      "Row 1205 => Predicted: 1\n",
      "Row 1206 => Predicted: 0\n",
      "Row 1207 => Predicted: 0\n",
      "Row 1208 => Predicted: 1\n",
      "Row 1209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1200 to 1209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1210 => Predicted: 1\n",
      "Row 1211 => Predicted: 0\n",
      "Row 1212 => Predicted: 1\n",
      "Row 1213 => Predicted: 0\n",
      "Row 1214 => Predicted: 0\n",
      "Row 1215 => Predicted: 1\n",
      "Row 1216 => Predicted: 1\n",
      "Row 1217 => Predicted: 0\n",
      "Row 1218 => Predicted: 0\n",
      "Row 1219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1210 to 1219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1220 => Predicted: 0\n",
      "Row 1221 => Predicted: 1\n",
      "Row 1222 => Predicted: 1\n",
      "Row 1223 => Predicted: 0\n",
      "Row 1224 => Predicted: 1\n",
      "Row 1225 => Predicted: 1\n",
      "Row 1226 => Predicted: 0\n",
      "Row 1227 => Predicted: 1\n",
      "Row 1228 => Predicted: 1\n",
      "Row 1229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1220 to 1229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1230 => Predicted: 0\n",
      "Row 1231 => Predicted: 0\n",
      "Row 1232 => Predicted: 0\n",
      "Row 1233 => Predicted: 0\n",
      "Row 1234 => Predicted: 0\n",
      "Row 1235 => Predicted: 0\n",
      "Row 1236 => Predicted: 1\n",
      "Row 1237 => Predicted: 1\n",
      "Row 1238 => Predicted: 1\n",
      "Row 1239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1230 to 1239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1240 => Predicted: 1\n",
      "Row 1241 => Predicted: 0\n",
      "Row 1242 => Predicted: 1\n",
      "Row 1243 => Predicted: 0\n",
      "Row 1244 => Predicted: 1\n",
      "Row 1245 => Predicted: 0\n",
      "Row 1246 => Predicted: 1\n",
      "Row 1247 => Predicted: 0\n",
      "Row 1248 => Predicted: 1\n",
      "Row 1249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1240 to 1249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1250 => Predicted: 1\n",
      "Row 1251 => Predicted: 1\n",
      "Row 1252 => Predicted: 1\n",
      "Row 1253 => Predicted: 0\n",
      "Row 1254 => Predicted: 0\n",
      "Row 1255 => Predicted: 0\n",
      "Row 1256 => Predicted: 0\n",
      "Row 1257 => Predicted: 0\n",
      "Row 1258 => Predicted: 0\n",
      "Row 1259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1250 to 1259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1260 => Predicted: 1\n",
      "Row 1261 => Predicted: 0\n",
      "Row 1262 => Predicted: 0\n",
      "Row 1263 => Predicted: 0\n",
      "Row 1264 => Predicted: 0\n",
      "Row 1265 => Predicted: 0\n",
      "Row 1266 => Predicted: 1\n",
      "Row 1267 => Predicted: 1\n",
      "Row 1268 => Predicted: 0\n",
      "Row 1269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1260 to 1269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1270 => Predicted: 0\n",
      "Row 1271 => Predicted: 1\n",
      "Row 1272 => Predicted: 1\n",
      "Row 1273 => Predicted: 0\n",
      "Row 1274 => Predicted: 1\n",
      "Row 1275 => Predicted: 0\n",
      "Row 1276 => Predicted: 1\n",
      "Row 1277 => Predicted: 0\n",
      "Row 1278 => Predicted: 1\n",
      "Row 1279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1270 to 1279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1280 => Predicted: 1\n",
      "Row 1281 => Predicted: 1\n",
      "Row 1282 => Predicted: 1\n",
      "Row 1283 => Predicted: 1\n",
      "Row 1284 => Predicted: 0\n",
      "Row 1285 => Predicted: 0\n",
      "Row 1286 => Predicted: 1\n",
      "Row 1287 => Predicted: 0\n",
      "Row 1288 => Predicted: 0\n",
      "Row 1289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1280 to 1289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1290 => Predicted: 0\n",
      "Row 1291 => Predicted: 1\n",
      "Row 1292 => Predicted: 0\n",
      "Row 1293 => Predicted: 1\n",
      "Row 1294 => Predicted: 0\n",
      "Row 1295 => Predicted: 0\n",
      "Row 1296 => Predicted: 1\n",
      "Row 1297 => Predicted: 1\n",
      "Row 1298 => Predicted: 1\n",
      "Row 1299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1290 to 1299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1300 => Predicted: 0\n",
      "Row 1301 => Predicted: 1\n",
      "Row 1302 => Predicted: 1\n",
      "Row 1303 => Predicted: 1\n",
      "Row 1304 => Predicted: 1\n",
      "Row 1305 => Predicted: 0\n",
      "Row 1306 => Predicted: 0\n",
      "Row 1307 => Predicted: 0\n",
      "Row 1308 => Predicted: 1\n",
      "Row 1309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1300 to 1309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1310 => Predicted: 1\n",
      "Row 1311 => Predicted: 1\n",
      "Row 1312 => Predicted: 1\n",
      "Row 1313 => Predicted: 0\n",
      "Row 1314 => Predicted: 1\n",
      "Row 1315 => Predicted: 0\n",
      "Row 1316 => Predicted: 1\n",
      "Row 1317 => Predicted: 0\n",
      "Row 1318 => Predicted: 1\n",
      "Row 1319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1310 to 1319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1320 => Predicted: 0\n",
      "Row 1321 => Predicted: 1\n",
      "Row 1322 => Predicted: 1\n",
      "Row 1323 => Predicted: 0\n",
      "Row 1324 => Predicted: 0\n",
      "Row 1325 => Predicted: 0\n",
      "Row 1326 => Predicted: 0\n",
      "Row 1327 => Predicted: 0\n",
      "Row 1328 => Predicted: 0\n",
      "Row 1329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1320 to 1329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1330 => Predicted: 0\n",
      "Row 1331 => Predicted: 0\n",
      "Row 1332 => Predicted: 0\n",
      "Row 1333 => Predicted: 1\n",
      "Row 1334 => Predicted: 1\n",
      "Row 1335 => Predicted: 0\n",
      "Row 1336 => Predicted: 0\n",
      "Row 1337 => Predicted: 1\n",
      "Row 1338 => Predicted: 1\n",
      "Row 1339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1330 to 1339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1340 => Predicted: 0\n",
      "Row 1341 => Predicted: 0\n",
      "Row 1342 => Predicted: 1\n",
      "Row 1343 => Predicted: 1\n",
      "Row 1344 => Predicted: 0\n",
      "Row 1345 => Predicted: 0\n",
      "Row 1346 => Predicted: 0\n",
      "Row 1347 => Predicted: 0\n",
      "Row 1348 => Predicted: 0\n",
      "Row 1349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1340 to 1349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1350 => Predicted: 1\n",
      "Row 1351 => Predicted: 0\n",
      "Row 1352 => Predicted: 1\n",
      "Row 1353 => Predicted: 1\n",
      "Row 1354 => Predicted: 1\n",
      "Row 1355 => Predicted: 1\n",
      "Row 1356 => Predicted: 1\n",
      "Row 1357 => Predicted: 1\n",
      "Row 1358 => Predicted: 1\n",
      "Row 1359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1350 to 1359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1360 => Predicted: 1\n",
      "Row 1361 => Predicted: 0\n",
      "Row 1362 => Predicted: 1\n",
      "Row 1363 => Predicted: 1\n",
      "Row 1364 => Predicted: 0\n",
      "Row 1365 => Predicted: 1\n",
      "Row 1366 => Predicted: 0\n",
      "Row 1367 => Predicted: 0\n",
      "Row 1368 => Predicted: 0\n",
      "Row 1369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1360 to 1369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1370 => Predicted: 1\n",
      "Row 1371 => Predicted: 1\n",
      "Row 1372 => Predicted: 1\n",
      "Row 1373 => Predicted: 0\n",
      "Row 1374 => Predicted: 1\n",
      "Row 1375 => Predicted: 1\n",
      "Row 1376 => Predicted: 1\n",
      "Row 1377 => Predicted: 0\n",
      "Row 1378 => Predicted: 1\n",
      "Row 1379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1370 to 1379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1380 => Predicted: 1\n",
      "Row 1381 => Predicted: 0\n",
      "Row 1382 => Predicted: 1\n",
      "Row 1383 => Predicted: 0\n",
      "Row 1384 => Predicted: 1\n",
      "Row 1385 => Predicted: 1\n",
      "Row 1386 => Predicted: 1\n",
      "Row 1387 => Predicted: 1\n",
      "Row 1388 => Predicted: 1\n",
      "Row 1389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1380 to 1389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1390 => Predicted: 1\n",
      "Row 1391 => Predicted: 0\n",
      "Row 1392 => Predicted: 0\n",
      "Row 1393 => Predicted: 0\n",
      "Row 1394 => Predicted: 0\n",
      "Row 1395 => Predicted: 0\n",
      "Row 1396 => Predicted: 1\n",
      "Row 1397 => Predicted: 1\n",
      "Row 1398 => Predicted: 0\n",
      "Row 1399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1390 to 1399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1400 => Predicted: 0\n",
      "Row 1401 => Predicted: 1\n",
      "Row 1402 => Predicted: 0\n",
      "Row 1403 => Predicted: 1\n",
      "Row 1404 => Predicted: 1\n",
      "Row 1405 => Predicted: 1\n",
      "Row 1406 => Predicted: 0\n",
      "Row 1407 => Predicted: 1\n",
      "Row 1408 => Predicted: 0\n",
      "Row 1409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1400 to 1409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1410 => Predicted: 0\n",
      "Row 1411 => Predicted: 1\n",
      "Row 1412 => Predicted: 1\n",
      "Row 1413 => Predicted: 0\n",
      "Row 1414 => Predicted: 0\n",
      "Row 1415 => Predicted: 1\n",
      "Row 1416 => Predicted: 0\n",
      "Row 1417 => Predicted: 1\n",
      "Row 1418 => Predicted: 0\n",
      "Row 1419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1410 to 1419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1420 => Predicted: 0\n",
      "Row 1421 => Predicted: 0\n",
      "Row 1422 => Predicted: 0\n",
      "Row 1423 => Predicted: 0\n",
      "Row 1424 => Predicted: 0\n",
      "Row 1425 => Predicted: 1\n",
      "Row 1426 => Predicted: 0\n",
      "Row 1427 => Predicted: 0\n",
      "Row 1428 => Predicted: 1\n",
      "Row 1429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1420 to 1429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1430 => Predicted: 1\n",
      "Row 1431 => Predicted: 0\n",
      "Row 1432 => Predicted: 0\n",
      "Row 1433 => Predicted: 0\n",
      "Row 1434 => Predicted: 0\n",
      "Row 1435 => Predicted: 1\n",
      "Row 1436 => Predicted: 1\n",
      "Row 1437 => Predicted: 1\n",
      "Row 1438 => Predicted: 1\n",
      "Row 1439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1430 to 1439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1440 => Predicted: 1\n",
      "Row 1441 => Predicted: 0\n",
      "Row 1442 => Predicted: 0\n",
      "Row 1443 => Predicted: 0\n",
      "Row 1444 => Predicted: 1\n",
      "Row 1445 => Predicted: 0\n",
      "Row 1446 => Predicted: 0\n",
      "Row 1447 => Predicted: 0\n",
      "Row 1448 => Predicted: 1\n",
      "Row 1449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1440 to 1449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1450 => Predicted: 0\n",
      "Row 1451 => Predicted: 1\n",
      "Row 1452 => Predicted: 1\n",
      "Row 1453 => Predicted: 0\n",
      "Row 1454 => Predicted: 1\n",
      "Row 1455 => Predicted: 1\n",
      "Row 1456 => Predicted: 1\n",
      "Row 1457 => Predicted: 1\n",
      "Row 1458 => Predicted: 0\n",
      "Row 1459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1450 to 1459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1460 => Predicted: 1\n",
      "Row 1461 => Predicted: 0\n",
      "Row 1462 => Predicted: 1\n",
      "Row 1463 => Predicted: 1\n",
      "Row 1464 => Predicted: 0\n",
      "Row 1465 => Predicted: 0\n",
      "Row 1466 => Predicted: 0\n",
      "Row 1467 => Predicted: 0\n",
      "Row 1468 => Predicted: 0\n",
      "Row 1469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1460 to 1469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1470 => Predicted: 1\n",
      "Row 1471 => Predicted: 0\n",
      "Row 1472 => Predicted: 0\n",
      "Row 1473 => Predicted: 0\n",
      "Row 1474 => Predicted: 0\n",
      "Row 1475 => Predicted: 1\n",
      "Row 1476 => Predicted: 0\n",
      "Row 1477 => Predicted: 1\n",
      "Row 1478 => Predicted: 0\n",
      "Row 1479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1470 to 1479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1480 => Predicted: 0\n",
      "Row 1481 => Predicted: 0\n",
      "Row 1482 => Predicted: 0\n",
      "Row 1483 => Predicted: 1\n",
      "Row 1484 => Predicted: 0\n",
      "Row 1485 => Predicted: 0\n",
      "Row 1486 => Predicted: 1\n",
      "Row 1487 => Predicted: 1\n",
      "Row 1488 => Predicted: 0\n",
      "Row 1489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1480 to 1489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1490 => Predicted: 0\n",
      "Row 1491 => Predicted: 0\n",
      "Row 1492 => Predicted: 0\n",
      "Row 1493 => Predicted: 0\n",
      "Row 1494 => Predicted: 0\n",
      "Row 1495 => Predicted: 0\n",
      "Row 1496 => Predicted: 0\n",
      "Row 1497 => Predicted: 1\n",
      "Row 1498 => Predicted: 0\n",
      "Row 1499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1490 to 1499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1500 => Predicted: 0\n",
      "Row 1501 => Predicted: 0\n",
      "Row 1502 => Predicted: 1\n",
      "Row 1503 => Predicted: 1\n",
      "Row 1504 => Predicted: 1\n",
      "Row 1505 => Predicted: 0\n",
      "Row 1506 => Predicted: 1\n",
      "Row 1507 => Predicted: 1\n",
      "Row 1508 => Predicted: 1\n",
      "Row 1509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1500 to 1509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1510 => Predicted: 1\n",
      "Row 1511 => Predicted: 1\n",
      "Row 1512 => Predicted: 0\n",
      "Row 1513 => Predicted: 1\n",
      "Row 1514 => Predicted: 0\n",
      "Row 1515 => Predicted: 1\n",
      "Row 1516 => Predicted: 1\n",
      "Row 1517 => Predicted: 1\n",
      "Row 1518 => Predicted: 1\n",
      "Row 1519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1510 to 1519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1520 => Predicted: 1\n",
      "Row 1521 => Predicted: 0\n",
      "Row 1522 => Predicted: 0\n",
      "Row 1523 => Predicted: 1\n",
      "Row 1524 => Predicted: 0\n",
      "Row 1525 => Predicted: 1\n",
      "Row 1526 => Predicted: 1\n",
      "Row 1527 => Predicted: 0\n",
      "Row 1528 => Predicted: 0\n",
      "Row 1529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1520 to 1529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1530 => Predicted: 0\n",
      "Row 1531 => Predicted: 1\n",
      "Row 1532 => Predicted: 0\n",
      "Row 1533 => Predicted: 0\n",
      "Row 1534 => Predicted: 1\n",
      "Row 1535 => Predicted: 0\n",
      "Row 1536 => Predicted: 1\n",
      "Row 1537 => Predicted: 0\n",
      "Row 1538 => Predicted: 0\n",
      "Row 1539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1530 to 1539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1540 => Predicted: 1\n",
      "Row 1541 => Predicted: 0\n",
      "Row 1542 => Predicted: 0\n",
      "Row 1543 => Predicted: 0\n",
      "Row 1544 => Predicted: 0\n",
      "Row 1545 => Predicted: 1\n",
      "Row 1546 => Predicted: 0\n",
      "Row 1547 => Predicted: 0\n",
      "Row 1548 => Predicted: 1\n",
      "Row 1549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1540 to 1549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1550 => Predicted: 0\n",
      "Row 1551 => Predicted: 0\n",
      "Row 1552 => Predicted: 1\n",
      "Row 1553 => Predicted: 1\n",
      "Row 1554 => Predicted: 0\n",
      "Row 1555 => Predicted: 1\n",
      "Row 1556 => Predicted: 1\n",
      "Row 1557 => Predicted: 0\n",
      "Row 1558 => Predicted: 1\n",
      "Row 1559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1550 to 1559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1560 => Predicted: 1\n",
      "Row 1561 => Predicted: 1\n",
      "Row 1562 => Predicted: 0\n",
      "Row 1563 => Predicted: 0\n",
      "Row 1564 => Predicted: 0\n",
      "Row 1565 => Predicted: 1\n",
      "Row 1566 => Predicted: 0\n",
      "Row 1567 => Predicted: 0\n",
      "Row 1568 => Predicted: 1\n",
      "Row 1569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1560 to 1569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1570 => Predicted: 1\n",
      "Row 1571 => Predicted: 0\n",
      "Row 1572 => Predicted: 0\n",
      "Row 1573 => Predicted: 0\n",
      "Row 1574 => Predicted: 0\n",
      "Row 1575 => Predicted: 1\n",
      "Row 1576 => Predicted: 1\n",
      "Row 1577 => Predicted: 1\n",
      "Row 1578 => Predicted: 1\n",
      "Row 1579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1570 to 1579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1580 => Predicted: 0\n",
      "Row 1581 => Predicted: 0\n",
      "Row 1582 => Predicted: 1\n",
      "Row 1583 => Predicted: 1\n",
      "Row 1584 => Predicted: 1\n",
      "Row 1585 => Predicted: 1\n",
      "Row 1586 => Predicted: 1\n",
      "Row 1587 => Predicted: 1\n",
      "Row 1588 => Predicted: 0\n",
      "Row 1589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1580 to 1589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1590 => Predicted: 0\n",
      "Row 1591 => Predicted: 1\n",
      "Row 1592 => Predicted: 1\n",
      "Row 1593 => Predicted: 1\n",
      "Row 1594 => Predicted: 1\n",
      "Row 1595 => Predicted: 0\n",
      "Row 1596 => Predicted: 1\n",
      "Row 1597 => Predicted: 1\n",
      "Row 1598 => Predicted: 1\n",
      "Row 1599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1590 to 1599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1600 => Predicted: 1\n",
      "Row 1601 => Predicted: 1\n",
      "Row 1602 => Predicted: 1\n",
      "Row 1603 => Predicted: 1\n",
      "Row 1604 => Predicted: 0\n",
      "Row 1605 => Predicted: 0\n",
      "Row 1606 => Predicted: 1\n",
      "Row 1607 => Predicted: 1\n",
      "Row 1608 => Predicted: 0\n",
      "Row 1609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1600 to 1609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1610 => Predicted: 1\n",
      "Row 1611 => Predicted: 0\n",
      "Row 1612 => Predicted: 0\n",
      "Row 1613 => Predicted: 1\n",
      "Row 1614 => Predicted: 0\n",
      "Row 1615 => Predicted: 1\n",
      "Row 1616 => Predicted: 0\n",
      "Row 1617 => Predicted: 0\n",
      "Row 1618 => Predicted: 0\n",
      "Row 1619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1610 to 1619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1620 => Predicted: 1\n",
      "Row 1621 => Predicted: 0\n",
      "Row 1622 => Predicted: 1\n",
      "Row 1623 => Predicted: 0\n",
      "Row 1624 => Predicted: 0\n",
      "Row 1625 => Predicted: 0\n",
      "Row 1626 => Predicted: 0\n",
      "Row 1627 => Predicted: 1\n",
      "Row 1628 => Predicted: 0\n",
      "Row 1629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1620 to 1629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1630 => Predicted: 1\n",
      "Row 1631 => Predicted: 0\n",
      "Row 1632 => Predicted: 1\n",
      "Row 1633 => Predicted: 0\n",
      "Row 1634 => Predicted: 0\n",
      "Row 1635 => Predicted: 0\n",
      "Row 1636 => Predicted: 1\n",
      "Row 1637 => Predicted: 1\n",
      "Row 1638 => Predicted: 1\n",
      "Row 1639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1630 to 1639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1640 => Predicted: 1\n",
      "Row 1641 => Predicted: 1\n",
      "Row 1642 => Predicted: 0\n",
      "Row 1643 => Predicted: 0\n",
      "Row 1644 => Predicted: 0\n",
      "Row 1645 => Predicted: 1\n",
      "Row 1646 => Predicted: 0\n",
      "Row 1647 => Predicted: 0\n",
      "Row 1648 => Predicted: 1\n",
      "Row 1649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1640 to 1649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1650 => Predicted: 1\n",
      "Row 1651 => Predicted: 0\n",
      "Row 1652 => Predicted: 1\n",
      "Row 1653 => Predicted: 0\n",
      "Row 1654 => Predicted: 1\n",
      "Row 1655 => Predicted: 0\n",
      "Row 1656 => Predicted: 0\n",
      "Row 1657 => Predicted: 1\n",
      "Row 1658 => Predicted: 0\n",
      "Row 1659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1650 to 1659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1660 => Predicted: 0\n",
      "Row 1661 => Predicted: 1\n",
      "Row 1662 => Predicted: 0\n",
      "Row 1663 => Predicted: 1\n",
      "Row 1664 => Predicted: 0\n",
      "Row 1665 => Predicted: 1\n",
      "Row 1666 => Predicted: 0\n",
      "Row 1667 => Predicted: 1\n",
      "Row 1668 => Predicted: 0\n",
      "Row 1669 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1660 to 1669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1670 => Predicted: 1\n",
      "Row 1671 => Predicted: 0\n",
      "Row 1672 => Predicted: 1\n",
      "Row 1673 => Predicted: 0\n",
      "Row 1674 => Predicted: 0\n",
      "Row 1675 => Predicted: 0\n",
      "Row 1676 => Predicted: 1\n",
      "Row 1677 => Predicted: 0\n",
      "Row 1678 => Predicted: 0\n",
      "Row 1679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1670 to 1679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1680 => Predicted: 1\n",
      "Row 1681 => Predicted: 1\n",
      "Row 1682 => Predicted: 1\n",
      "Row 1683 => Predicted: 1\n",
      "Row 1684 => Predicted: 1\n",
      "Row 1685 => Predicted: 0\n",
      "Row 1686 => Predicted: 0\n",
      "Row 1687 => Predicted: 1\n",
      "Row 1688 => Predicted: 1\n",
      "Row 1689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1680 to 1689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1690 => Predicted: 1\n",
      "Row 1691 => Predicted: 0\n",
      "Row 1692 => Predicted: 1\n",
      "Row 1693 => Predicted: 1\n",
      "Row 1694 => Predicted: 1\n",
      "Row 1695 => Predicted: 0\n",
      "Row 1696 => Predicted: 0\n",
      "Row 1697 => Predicted: 0\n",
      "Row 1698 => Predicted: 1\n",
      "Row 1699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1690 to 1699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1700 => Predicted: 1\n",
      "Row 1701 => Predicted: 0\n",
      "Row 1702 => Predicted: 0\n",
      "Row 1703 => Predicted: 1\n",
      "Row 1704 => Predicted: 1\n",
      "Row 1705 => Predicted: 0\n",
      "Row 1706 => Predicted: 1\n",
      "Row 1707 => Predicted: 1\n",
      "Row 1708 => Predicted: 0\n",
      "Row 1709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1700 to 1709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1710 => Predicted: 1\n",
      "Row 1711 => Predicted: 1\n",
      "Row 1712 => Predicted: 0\n",
      "Row 1713 => Predicted: 1\n",
      "Row 1714 => Predicted: 0\n",
      "Row 1715 => Predicted: 1\n",
      "Row 1716 => Predicted: 0\n",
      "Row 1717 => Predicted: 0\n",
      "Row 1718 => Predicted: 1\n",
      "Row 1719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1710 to 1719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1720 => Predicted: 1\n",
      "Row 1721 => Predicted: 0\n",
      "Row 1722 => Predicted: 0\n",
      "Row 1723 => Predicted: 1\n",
      "Row 1724 => Predicted: 1\n",
      "Row 1725 => Predicted: 1\n",
      "Row 1726 => Predicted: 0\n",
      "Row 1727 => Predicted: 0\n",
      "Row 1728 => Predicted: 0\n",
      "Row 1729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1720 to 1729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1730 => Predicted: 1\n",
      "Row 1731 => Predicted: 1\n",
      "Row 1732 => Predicted: 0\n",
      "Row 1733 => Predicted: 1\n",
      "Row 1734 => Predicted: 1\n",
      "Row 1735 => Predicted: 0\n",
      "Row 1736 => Predicted: 0\n",
      "Row 1737 => Predicted: 1\n",
      "Row 1738 => Predicted: 0\n",
      "Row 1739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1730 to 1739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1740 => Predicted: 1\n",
      "Row 1741 => Predicted: 1\n",
      "Row 1742 => Predicted: 1\n",
      "Row 1743 => Predicted: 1\n",
      "Row 1744 => Predicted: 1\n",
      "Row 1745 => Predicted: 0\n",
      "Row 1746 => Predicted: 1\n",
      "Row 1747 => Predicted: 0\n",
      "Row 1748 => Predicted: 0\n",
      "Row 1749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1740 to 1749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1750 => Predicted: 0\n",
      "Row 1751 => Predicted: 1\n",
      "Row 1752 => Predicted: 1\n",
      "Row 1753 => Predicted: 0\n",
      "Row 1754 => Predicted: 1\n",
      "Row 1755 => Predicted: 0\n",
      "Row 1756 => Predicted: 1\n",
      "Row 1757 => Predicted: 0\n",
      "Row 1758 => Predicted: 1\n",
      "Row 1759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1750 to 1759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1760 => Predicted: 1\n",
      "Row 1761 => Predicted: 0\n",
      "Row 1762 => Predicted: 1\n",
      "Row 1763 => Predicted: 0\n",
      "Row 1764 => Predicted: 1\n",
      "Row 1765 => Predicted: 0\n",
      "Row 1766 => Predicted: 0\n",
      "Row 1767 => Predicted: 1\n",
      "Row 1768 => Predicted: 0\n",
      "Row 1769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1760 to 1769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1770 => Predicted: 1\n",
      "Row 1771 => Predicted: 1\n",
      "Row 1772 => Predicted: 1\n",
      "Row 1773 => Predicted: 1\n",
      "Row 1774 => Predicted: 1\n",
      "Row 1775 => Predicted: 0\n",
      "Row 1776 => Predicted: 0\n",
      "Row 1777 => Predicted: 1\n",
      "Row 1778 => Predicted: 1\n",
      "Row 1779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1770 to 1779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1780 => Predicted: 1\n",
      "Row 1781 => Predicted: 0\n",
      "Row 1782 => Predicted: 1\n",
      "Row 1783 => Predicted: 0\n",
      "Row 1784 => Predicted: 1\n",
      "Row 1785 => Predicted: 1\n",
      "Row 1786 => Predicted: 1\n",
      "Row 1787 => Predicted: 1\n",
      "Row 1788 => Predicted: 0\n",
      "Row 1789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1780 to 1789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1790 => Predicted: 0\n",
      "Row 1791 => Predicted: 1\n",
      "Row 1792 => Predicted: 0\n",
      "Row 1793 => Predicted: 0\n",
      "Row 1794 => Predicted: 0\n",
      "Row 1795 => Predicted: 0\n",
      "Row 1796 => Predicted: 0\n",
      "Row 1797 => Predicted: 1\n",
      "Row 1798 => Predicted: 0\n",
      "Row 1799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1790 to 1799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1800 => Predicted: 0\n",
      "Row 1801 => Predicted: 0\n",
      "Row 1802 => Predicted: 1\n",
      "Row 1803 => Predicted: 1\n",
      "Row 1804 => Predicted: 0\n",
      "Row 1805 => Predicted: 0\n",
      "Row 1806 => Predicted: 0\n",
      "Row 1807 => Predicted: 0\n",
      "Row 1808 => Predicted: 1\n",
      "Row 1809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1800 to 1809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1810 => Predicted: 1\n",
      "Row 1811 => Predicted: 1\n",
      "Row 1812 => Predicted: 1\n",
      "Row 1813 => Predicted: 0\n",
      "Row 1814 => Predicted: 1\n",
      "Row 1815 => Predicted: 1\n",
      "Row 1816 => Predicted: 1\n",
      "Row 1817 => Predicted: 0\n",
      "Row 1818 => Predicted: 0\n",
      "Row 1819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1810 to 1819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1820 => Predicted: 0\n",
      "Row 1821 => Predicted: 0\n",
      "Row 1822 => Predicted: 0\n",
      "Row 1823 => Predicted: 0\n",
      "Row 1824 => Predicted: 0\n",
      "Row 1825 => Predicted: 0\n",
      "Row 1826 => Predicted: 0\n",
      "Row 1827 => Predicted: 0\n",
      "Row 1828 => Predicted: 1\n",
      "Row 1829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1820 to 1829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1830 => Predicted: 1\n",
      "Row 1831 => Predicted: 0\n",
      "Row 1832 => Predicted: 0\n",
      "Row 1833 => Predicted: 0\n",
      "Row 1834 => Predicted: 0\n",
      "Row 1835 => Predicted: 0\n",
      "Row 1836 => Predicted: 0\n",
      "Row 1837 => Predicted: 0\n",
      "Row 1838 => Predicted: 0\n",
      "Row 1839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1830 to 1839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1840 => Predicted: 0\n",
      "Row 1841 => Predicted: 1\n",
      "Row 1842 => Predicted: 1\n",
      "Row 1843 => Predicted: 0\n",
      "Row 1844 => Predicted: 0\n",
      "Row 1845 => Predicted: 1\n",
      "Row 1846 => Predicted: 0\n",
      "Row 1847 => Predicted: 1\n",
      "Row 1848 => Predicted: 1\n",
      "Row 1849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1840 to 1849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1850 => Predicted: 0\n",
      "Row 1851 => Predicted: 0\n",
      "Row 1852 => Predicted: 1\n",
      "Row 1853 => Predicted: 1\n",
      "Row 1854 => Predicted: 1\n",
      "Row 1855 => Predicted: 0\n",
      "Row 1856 => Predicted: 1\n",
      "Row 1857 => Predicted: 1\n",
      "Row 1858 => Predicted: 1\n",
      "Row 1859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1850 to 1859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1860 => Predicted: 1\n",
      "Row 1861 => Predicted: 1\n",
      "Row 1862 => Predicted: 1\n",
      "Row 1863 => Predicted: 0\n",
      "Row 1864 => Predicted: 0\n",
      "Row 1865 => Predicted: 1\n",
      "Row 1866 => Predicted: 1\n",
      "Row 1867 => Predicted: 0\n",
      "Row 1868 => Predicted: 0\n",
      "Row 1869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1860 to 1869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1870 => Predicted: 0\n",
      "Row 1871 => Predicted: 0\n",
      "Row 1872 => Predicted: 1\n",
      "Row 1873 => Predicted: 0\n",
      "Row 1874 => Predicted: 1\n",
      "Row 1875 => Predicted: 0\n",
      "Row 1876 => Predicted: 1\n",
      "Row 1877 => Predicted: 1\n",
      "Row 1878 => Predicted: 1\n",
      "Row 1879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1870 to 1879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1880 => Predicted: 1\n",
      "Row 1881 => Predicted: 0\n",
      "Row 1882 => Predicted: 0\n",
      "Row 1883 => Predicted: 0\n",
      "Row 1884 => Predicted: 1\n",
      "Row 1885 => Predicted: 1\n",
      "Row 1886 => Predicted: 1\n",
      "Row 1887 => Predicted: 1\n",
      "Row 1888 => Predicted: 0\n",
      "Row 1889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1880 to 1889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1890 => Predicted: 1\n",
      "Row 1891 => Predicted: 0\n",
      "Row 1892 => Predicted: 0\n",
      "Row 1893 => Predicted: 1\n",
      "Row 1894 => Predicted: 1\n",
      "Row 1895 => Predicted: 1\n",
      "Row 1896 => Predicted: 1\n",
      "Row 1897 => Predicted: 1\n",
      "Row 1898 => Predicted: 0\n",
      "Row 1899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1890 to 1899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1900 => Predicted: 0\n",
      "Row 1901 => Predicted: 0\n",
      "Row 1902 => Predicted: 1\n",
      "Row 1903 => Predicted: 0\n",
      "Row 1904 => Predicted: 0\n",
      "Row 1905 => Predicted: 0\n",
      "Row 1906 => Predicted: 0\n",
      "Row 1907 => Predicted: 1\n",
      "Row 1908 => Predicted: 1\n",
      "Row 1909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1900 to 1909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1910 => Predicted: 1\n",
      "Row 1911 => Predicted: 0\n",
      "Row 1912 => Predicted: 0\n",
      "Row 1913 => Predicted: 0\n",
      "Row 1914 => Predicted: 1\n",
      "Row 1915 => Predicted: 1\n",
      "Row 1916 => Predicted: 1\n",
      "Row 1917 => Predicted: 0\n",
      "Row 1918 => Predicted: 0\n",
      "Row 1919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1910 to 1919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1920 => Predicted: 0\n",
      "Row 1921 => Predicted: 1\n",
      "Row 1922 => Predicted: 1\n",
      "Row 1923 => Predicted: 0\n",
      "Row 1924 => Predicted: 1\n",
      "Row 1925 => Predicted: 1\n",
      "Row 1926 => Predicted: 0\n",
      "Row 1927 => Predicted: 0\n",
      "Row 1928 => Predicted: 1\n",
      "Row 1929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1920 to 1929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1930 => Predicted: 0\n",
      "Row 1931 => Predicted: 1\n",
      "Row 1932 => Predicted: 1\n",
      "Row 1933 => Predicted: 0\n",
      "Row 1934 => Predicted: 0\n",
      "Row 1935 => Predicted: 0\n",
      "Row 1936 => Predicted: 1\n",
      "Row 1937 => Predicted: 1\n",
      "Row 1938 => Predicted: 1\n",
      "Row 1939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1930 to 1939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1940 => Predicted: 1\n",
      "Row 1941 => Predicted: 1\n",
      "Row 1942 => Predicted: 0\n",
      "Row 1943 => Predicted: 1\n",
      "Row 1944 => Predicted: 1\n",
      "Row 1945 => Predicted: 0\n",
      "Row 1946 => Predicted: 0\n",
      "Row 1947 => Predicted: 0\n",
      "Row 1948 => Predicted: 1\n",
      "Row 1949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1940 to 1949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1950 => Predicted: 1\n",
      "Row 1951 => Predicted: 1\n",
      "Row 1952 => Predicted: 1\n",
      "Row 1953 => Predicted: 1\n",
      "Row 1954 => Predicted: 1\n",
      "Row 1955 => Predicted: 1\n",
      "Row 1956 => Predicted: 0\n",
      "Row 1957 => Predicted: 1\n",
      "Row 1958 => Predicted: 0\n",
      "Row 1959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1950 to 1959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1960 => Predicted: 1\n",
      "Row 1961 => Predicted: 1\n",
      "Row 1962 => Predicted: 1\n",
      "Row 1963 => Predicted: 0\n",
      "Row 1964 => Predicted: 0\n",
      "Row 1965 => Predicted: 1\n",
      "Row 1966 => Predicted: 1\n",
      "Row 1967 => Predicted: 1\n",
      "Row 1968 => Predicted: 1\n",
      "Row 1969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1960 to 1969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1970 => Predicted: 1\n",
      "Row 1971 => Predicted: 0\n",
      "Row 1972 => Predicted: 0\n",
      "Row 1973 => Predicted: 1\n",
      "Row 1974 => Predicted: 1\n",
      "Row 1975 => Predicted: 1\n",
      "Row 1976 => Predicted: 1\n",
      "Row 1977 => Predicted: 1\n",
      "Row 1978 => Predicted: 1\n",
      "Row 1979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1970 to 1979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1980 => Predicted: 1\n",
      "Row 1981 => Predicted: 0\n",
      "Row 1982 => Predicted: 0\n",
      "Row 1983 => Predicted: 1\n",
      "Row 1984 => Predicted: 0\n",
      "Row 1985 => Predicted: 1\n",
      "Row 1986 => Predicted: 0\n",
      "Row 1987 => Predicted: 1\n",
      "Row 1988 => Predicted: 1\n",
      "Row 1989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 1980 to 1989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1990 => Predicted: 1\n",
      "Row 1991 => Predicted: 0\n",
      "Row 1992 => Predicted: 0\n",
      "Row 1993 => Predicted: 0\n",
      "Row 1994 => Predicted: 0\n",
      "Row 1995 => Predicted: 1\n",
      "Row 1996 => Predicted: 0\n",
      "Row 1997 => Predicted: 0\n",
      "Row 1998 => Predicted: 0\n",
      "Row 1999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 1990 to 1999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2000 => Predicted: 1\n",
      "Row 2001 => Predicted: 1\n",
      "Row 2002 => Predicted: 0\n",
      "Row 2003 => Predicted: 0\n",
      "Row 2004 => Predicted: 0\n",
      "Row 2005 => Predicted: 0\n",
      "Row 2006 => Predicted: 1\n",
      "Row 2007 => Predicted: 1\n",
      "Row 2008 => Predicted: 0\n",
      "Row 2009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2000 to 2009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2010 => Predicted: 0\n",
      "Row 2011 => Predicted: 0\n",
      "Row 2012 => Predicted: 0\n",
      "Row 2013 => Predicted: 1\n",
      "Row 2014 => Predicted: 1\n",
      "Row 2015 => Predicted: 0\n",
      "Row 2016 => Predicted: 0\n",
      "Row 2017 => Predicted: 1\n",
      "Row 2018 => Predicted: 1\n",
      "Row 2019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2010 to 2019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2020 => Predicted: 0\n",
      "Row 2021 => Predicted: 0\n",
      "Row 2022 => Predicted: 0\n",
      "Row 2023 => Predicted: 0\n",
      "Row 2024 => Predicted: 0\n",
      "Row 2025 => Predicted: 0\n",
      "Row 2026 => Predicted: 1\n",
      "Row 2027 => Predicted: 1\n",
      "Row 2028 => Predicted: 1\n",
      "Row 2029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2020 to 2029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2030 => Predicted: 0\n",
      "Row 2031 => Predicted: 1\n",
      "Row 2032 => Predicted: 0\n",
      "Row 2033 => Predicted: 1\n",
      "Row 2034 => Predicted: 0\n",
      "Row 2035 => Predicted: 0\n",
      "Row 2036 => Predicted: 0\n",
      "Row 2037 => Predicted: 0\n",
      "Row 2038 => Predicted: 0\n",
      "Row 2039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2030 to 2039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2040 => Predicted: 0\n",
      "Row 2041 => Predicted: 1\n",
      "Row 2042 => Predicted: 0\n",
      "Row 2043 => Predicted: 1\n",
      "Row 2044 => Predicted: 1\n",
      "Row 2045 => Predicted: 0\n",
      "Row 2046 => Predicted: 0\n",
      "Row 2047 => Predicted: 1\n",
      "Row 2048 => Predicted: 1\n",
      "Row 2049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2040 to 2049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2050 => Predicted: 1\n",
      "Row 2051 => Predicted: 0\n",
      "Row 2052 => Predicted: 1\n",
      "Row 2053 => Predicted: 1\n",
      "Row 2054 => Predicted: 1\n",
      "Row 2055 => Predicted: 0\n",
      "Row 2056 => Predicted: 0\n",
      "Row 2057 => Predicted: 0\n",
      "Row 2058 => Predicted: 1\n",
      "Row 2059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2050 to 2059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2060 => Predicted: 0\n",
      "Row 2061 => Predicted: 1\n",
      "Row 2062 => Predicted: 1\n",
      "Row 2063 => Predicted: 0\n",
      "Row 2064 => Predicted: 0\n",
      "Row 2065 => Predicted: 1\n",
      "Row 2066 => Predicted: 1\n",
      "Row 2067 => Predicted: 1\n",
      "Row 2068 => Predicted: 0\n",
      "Row 2069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2060 to 2069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2070 => Predicted: 0\n",
      "Row 2071 => Predicted: 1\n",
      "Row 2072 => Predicted: 1\n",
      "Row 2073 => Predicted: 1\n",
      "Row 2074 => Predicted: 1\n",
      "Row 2075 => Predicted: 0\n",
      "Row 2076 => Predicted: 1\n",
      "Row 2077 => Predicted: 1\n",
      "Row 2078 => Predicted: 1\n",
      "Row 2079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2070 to 2079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2080 => Predicted: 0\n",
      "Row 2081 => Predicted: 0\n",
      "Row 2082 => Predicted: 0\n",
      "Row 2083 => Predicted: 1\n",
      "Row 2084 => Predicted: 1\n",
      "Row 2085 => Predicted: 1\n",
      "Row 2086 => Predicted: 0\n",
      "Row 2087 => Predicted: 1\n",
      "Row 2088 => Predicted: 1\n",
      "Row 2089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2080 to 2089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2090 => Predicted: 1\n",
      "Row 2091 => Predicted: 1\n",
      "Row 2092 => Predicted: 0\n",
      "Row 2093 => Predicted: 0\n",
      "Row 2094 => Predicted: 0\n",
      "Row 2095 => Predicted: 1\n",
      "Row 2096 => Predicted: 0\n",
      "Row 2097 => Predicted: 0\n",
      "Row 2098 => Predicted: 1\n",
      "Row 2099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2090 to 2099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2100 => Predicted: 0\n",
      "Row 2101 => Predicted: 0\n",
      "Row 2102 => Predicted: 0\n",
      "Row 2103 => Predicted: 1\n",
      "Row 2104 => Predicted: 0\n",
      "Row 2105 => Predicted: 0\n",
      "Row 2106 => Predicted: 1\n",
      "Row 2107 => Predicted: 0\n",
      "Row 2108 => Predicted: 1\n",
      "Row 2109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2100 to 2109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2110 => Predicted: 1\n",
      "Row 2111 => Predicted: 0\n",
      "Row 2112 => Predicted: 0\n",
      "Row 2113 => Predicted: 1\n",
      "Row 2114 => Predicted: 1\n",
      "Row 2115 => Predicted: 0\n",
      "Row 2116 => Predicted: 1\n",
      "Row 2117 => Predicted: 1\n",
      "Row 2118 => Predicted: 1\n",
      "Row 2119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2110 to 2119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2120 => Predicted: 0\n",
      "Row 2121 => Predicted: 0\n",
      "Row 2122 => Predicted: 1\n",
      "Row 2123 => Predicted: 0\n",
      "Row 2124 => Predicted: 0\n",
      "Row 2125 => Predicted: 0\n",
      "Row 2126 => Predicted: 1\n",
      "Row 2127 => Predicted: 1\n",
      "Row 2128 => Predicted: 1\n",
      "Row 2129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2120 to 2129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2130 => Predicted: 1\n",
      "Row 2131 => Predicted: 1\n",
      "Row 2132 => Predicted: 0\n",
      "Row 2133 => Predicted: 1\n",
      "Row 2134 => Predicted: 0\n",
      "Row 2135 => Predicted: 0\n",
      "Row 2136 => Predicted: 0\n",
      "Row 2137 => Predicted: 1\n",
      "Row 2138 => Predicted: 0\n",
      "Row 2139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2130 to 2139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2140 => Predicted: 1\n",
      "Row 2141 => Predicted: 1\n",
      "Row 2142 => Predicted: 1\n",
      "Row 2143 => Predicted: 0\n",
      "Row 2144 => Predicted: 1\n",
      "Row 2145 => Predicted: 1\n",
      "Row 2146 => Predicted: 1\n",
      "Row 2147 => Predicted: 1\n",
      "Row 2148 => Predicted: 1\n",
      "Row 2149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2140 to 2149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2150 => Predicted: 1\n",
      "Row 2151 => Predicted: 0\n",
      "Row 2152 => Predicted: 1\n",
      "Row 2153 => Predicted: 1\n",
      "Row 2154 => Predicted: 1\n",
      "Row 2155 => Predicted: 0\n",
      "Row 2156 => Predicted: 0\n",
      "Row 2157 => Predicted: 1\n",
      "Row 2158 => Predicted: 0\n",
      "Row 2159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2150 to 2159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2160 => Predicted: 0\n",
      "Row 2161 => Predicted: 1\n",
      "Row 2162 => Predicted: 0\n",
      "Row 2163 => Predicted: 1\n",
      "Row 2164 => Predicted: 0\n",
      "Row 2165 => Predicted: 1\n",
      "Row 2166 => Predicted: 1\n",
      "Row 2167 => Predicted: 0\n",
      "Row 2168 => Predicted: 1\n",
      "Row 2169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2160 to 2169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2170 => Predicted: 0\n",
      "Row 2171 => Predicted: 1\n",
      "Row 2172 => Predicted: 0\n",
      "Row 2173 => Predicted: 1\n",
      "Row 2174 => Predicted: 0\n",
      "Row 2175 => Predicted: 1\n",
      "Row 2176 => Predicted: 1\n",
      "Row 2177 => Predicted: 1\n",
      "Row 2178 => Predicted: 1\n",
      "Row 2179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2170 to 2179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2180 => Predicted: 1\n",
      "Row 2181 => Predicted: 1\n",
      "Row 2182 => Predicted: 1\n",
      "Row 2183 => Predicted: 1\n",
      "Row 2184 => Predicted: 1\n",
      "Row 2185 => Predicted: 0\n",
      "Row 2186 => Predicted: 1\n",
      "Row 2187 => Predicted: 0\n",
      "Row 2188 => Predicted: 1\n",
      "Row 2189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2180 to 2189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2190 => Predicted: 1\n",
      "Row 2191 => Predicted: 1\n",
      "Row 2192 => Predicted: 1\n",
      "Row 2193 => Predicted: 0\n",
      "Row 2194 => Predicted: 1\n",
      "Row 2195 => Predicted: 0\n",
      "Row 2196 => Predicted: 0\n",
      "Row 2197 => Predicted: 1\n",
      "Row 2198 => Predicted: 0\n",
      "Row 2199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2190 to 2199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2200 => Predicted: 1\n",
      "Row 2201 => Predicted: 1\n",
      "Row 2202 => Predicted: 0\n",
      "Row 2203 => Predicted: 1\n",
      "Row 2204 => Predicted: 0\n",
      "Row 2205 => Predicted: 1\n",
      "Row 2206 => Predicted: 0\n",
      "Row 2207 => Predicted: 0\n",
      "Row 2208 => Predicted: 0\n",
      "Row 2209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2200 to 2209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2210 => Predicted: 0\n",
      "Row 2211 => Predicted: 1\n",
      "Row 2212 => Predicted: 0\n",
      "Row 2213 => Predicted: 1\n",
      "Row 2214 => Predicted: 1\n",
      "Row 2215 => Predicted: 1\n",
      "Row 2216 => Predicted: 0\n",
      "Row 2217 => Predicted: 0\n",
      "Row 2218 => Predicted: 0\n",
      "Row 2219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2210 to 2219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2220 => Predicted: 0\n",
      "Row 2221 => Predicted: 1\n",
      "Row 2222 => Predicted: 1\n",
      "Row 2223 => Predicted: 0\n",
      "Row 2224 => Predicted: 0\n",
      "Row 2225 => Predicted: 1\n",
      "Row 2226 => Predicted: 1\n",
      "Row 2227 => Predicted: 0\n",
      "Row 2228 => Predicted: 0\n",
      "Row 2229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2220 to 2229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2230 => Predicted: 0\n",
      "Row 2231 => Predicted: 1\n",
      "Row 2232 => Predicted: 0\n",
      "Row 2233 => Predicted: 1\n",
      "Row 2234 => Predicted: 1\n",
      "Row 2235 => Predicted: 0\n",
      "Row 2236 => Predicted: 0\n",
      "Row 2237 => Predicted: 0\n",
      "Row 2238 => Predicted: 0\n",
      "Row 2239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2230 to 2239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2240 => Predicted: 0\n",
      "Row 2241 => Predicted: 0\n",
      "Row 2242 => Predicted: 0\n",
      "Row 2243 => Predicted: 1\n",
      "Row 2244 => Predicted: 0\n",
      "Row 2245 => Predicted: 0\n",
      "Row 2246 => Predicted: 0\n",
      "Row 2247 => Predicted: 0\n",
      "Row 2248 => Predicted: 0\n",
      "Row 2249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2240 to 2249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2250 => Predicted: 1\n",
      "Row 2251 => Predicted: 1\n",
      "Row 2252 => Predicted: 1\n",
      "Row 2253 => Predicted: 1\n",
      "Row 2254 => Predicted: 1\n",
      "Row 2255 => Predicted: 1\n",
      "Row 2256 => Predicted: 1\n",
      "Row 2257 => Predicted: 1\n",
      "Row 2258 => Predicted: 0\n",
      "Row 2259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2250 to 2259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2260 => Predicted: 1\n",
      "Row 2261 => Predicted: 1\n",
      "Row 2262 => Predicted: 1\n",
      "Row 2263 => Predicted: 1\n",
      "Row 2264 => Predicted: 1\n",
      "Row 2265 => Predicted: 1\n",
      "Row 2266 => Predicted: 1\n",
      "Row 2267 => Predicted: 0\n",
      "Row 2268 => Predicted: 1\n",
      "Row 2269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2260 to 2269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2270 => Predicted: 0\n",
      "Row 2271 => Predicted: 1\n",
      "Row 2272 => Predicted: 1\n",
      "Row 2273 => Predicted: 0\n",
      "Row 2274 => Predicted: 0\n",
      "Row 2275 => Predicted: 0\n",
      "Row 2276 => Predicted: 0\n",
      "Row 2277 => Predicted: 0\n",
      "Row 2278 => Predicted: 0\n",
      "Row 2279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2270 to 2279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2280 => Predicted: 1\n",
      "Row 2281 => Predicted: 1\n",
      "Row 2282 => Predicted: 0\n",
      "Row 2283 => Predicted: 1\n",
      "Row 2284 => Predicted: 1\n",
      "Row 2285 => Predicted: 0\n",
      "Row 2286 => Predicted: 0\n",
      "Row 2287 => Predicted: 0\n",
      "Row 2288 => Predicted: 0\n",
      "Row 2289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2280 to 2289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2290 => Predicted: 0\n",
      "Row 2291 => Predicted: 0\n",
      "Row 2292 => Predicted: 1\n",
      "Row 2293 => Predicted: 0\n",
      "Row 2294 => Predicted: 0\n",
      "Row 2295 => Predicted: 1\n",
      "Row 2296 => Predicted: 0\n",
      "Row 2297 => Predicted: 0\n",
      "Row 2298 => Predicted: 1\n",
      "Row 2299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2290 to 2299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2300 => Predicted: 0\n",
      "Row 2301 => Predicted: 0\n",
      "Row 2302 => Predicted: 1\n",
      "Row 2303 => Predicted: 0\n",
      "Row 2304 => Predicted: 1\n",
      "Row 2305 => Predicted: 0\n",
      "Row 2306 => Predicted: 0\n",
      "Row 2307 => Predicted: 0\n",
      "Row 2308 => Predicted: 1\n",
      "Row 2309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2300 to 2309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2310 => Predicted: 0\n",
      "Row 2311 => Predicted: 0\n",
      "Row 2312 => Predicted: 1\n",
      "Row 2313 => Predicted: 0\n",
      "Row 2314 => Predicted: 1\n",
      "Row 2315 => Predicted: 1\n",
      "Row 2316 => Predicted: 1\n",
      "Row 2317 => Predicted: 1\n",
      "Row 2318 => Predicted: 0\n",
      "Row 2319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2310 to 2319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2320 => Predicted: 0\n",
      "Row 2321 => Predicted: 1\n",
      "Row 2322 => Predicted: 0\n",
      "Row 2323 => Predicted: 0\n",
      "Row 2324 => Predicted: 1\n",
      "Row 2325 => Predicted: 0\n",
      "Row 2326 => Predicted: 1\n",
      "Row 2327 => Predicted: 0\n",
      "Row 2328 => Predicted: 1\n",
      "Row 2329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2320 to 2329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2330 => Predicted: 1\n",
      "Row 2331 => Predicted: 0\n",
      "Row 2332 => Predicted: 1\n",
      "Row 2333 => Predicted: 0\n",
      "Row 2334 => Predicted: 1\n",
      "Row 2335 => Predicted: 0\n",
      "Row 2336 => Predicted: 0\n",
      "Row 2337 => Predicted: 0\n",
      "Row 2338 => Predicted: 0\n",
      "Row 2339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2330 to 2339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2340 => Predicted: 1\n",
      "Row 2341 => Predicted: 0\n",
      "Row 2342 => Predicted: 0\n",
      "Row 2343 => Predicted: 1\n",
      "Row 2344 => Predicted: 0\n",
      "Row 2345 => Predicted: 1\n",
      "Row 2346 => Predicted: 0\n",
      "Row 2347 => Predicted: 0\n",
      "Row 2348 => Predicted: 0\n",
      "Row 2349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2340 to 2349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2350 => Predicted: 0\n",
      "Row 2351 => Predicted: 0\n",
      "Row 2352 => Predicted: 1\n",
      "Row 2353 => Predicted: 0\n",
      "Row 2354 => Predicted: 1\n",
      "Row 2355 => Predicted: 1\n",
      "Row 2356 => Predicted: 0\n",
      "Row 2357 => Predicted: 1\n",
      "Row 2358 => Predicted: 1\n",
      "Row 2359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2350 to 2359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2360 => Predicted: 1\n",
      "Row 2361 => Predicted: 1\n",
      "Row 2362 => Predicted: 1\n",
      "Row 2363 => Predicted: 0\n",
      "Row 2364 => Predicted: 0\n",
      "Row 2365 => Predicted: 1\n",
      "Row 2366 => Predicted: 1\n",
      "Row 2367 => Predicted: 0\n",
      "Row 2368 => Predicted: 0\n",
      "Row 2369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2360 to 2369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2370 => Predicted: 1\n",
      "Row 2371 => Predicted: 1\n",
      "Row 2372 => Predicted: 1\n",
      "Row 2373 => Predicted: 0\n",
      "Row 2374 => Predicted: 1\n",
      "Row 2375 => Predicted: 0\n",
      "Row 2376 => Predicted: 0\n",
      "Row 2377 => Predicted: 1\n",
      "Row 2378 => Predicted: 1\n",
      "Row 2379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2370 to 2379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2380 => Predicted: 1\n",
      "Row 2381 => Predicted: 1\n",
      "Row 2382 => Predicted: 1\n",
      "Row 2383 => Predicted: 1\n",
      "Row 2384 => Predicted: 0\n",
      "Row 2385 => Predicted: 0\n",
      "Row 2386 => Predicted: 0\n",
      "Row 2387 => Predicted: 1\n",
      "Row 2388 => Predicted: 1\n",
      "Row 2389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2380 to 2389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2390 => Predicted: 0\n",
      "Row 2391 => Predicted: 1\n",
      "Row 2392 => Predicted: 0\n",
      "Row 2393 => Predicted: 0\n",
      "Row 2394 => Predicted: 0\n",
      "Row 2395 => Predicted: 0\n",
      "Row 2396 => Predicted: 0\n",
      "Row 2397 => Predicted: 0\n",
      "Row 2398 => Predicted: 1\n",
      "Row 2399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2390 to 2399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2400 => Predicted: 1\n",
      "Row 2401 => Predicted: 1\n",
      "Row 2402 => Predicted: 1\n",
      "Row 2403 => Predicted: 0\n",
      "Row 2404 => Predicted: 1\n",
      "Row 2405 => Predicted: 1\n",
      "Row 2406 => Predicted: 0\n",
      "Row 2407 => Predicted: 0\n",
      "Row 2408 => Predicted: 0\n",
      "Row 2409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2400 to 2409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2410 => Predicted: 1\n",
      "Row 2411 => Predicted: 0\n",
      "Row 2412 => Predicted: 0\n",
      "Row 2413 => Predicted: 1\n",
      "Row 2414 => Predicted: 0\n",
      "Row 2415 => Predicted: 0\n",
      "Row 2416 => Predicted: 0\n",
      "Row 2417 => Predicted: 1\n",
      "Row 2418 => Predicted: 1\n",
      "Row 2419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2410 to 2419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2420 => Predicted: 1\n",
      "Row 2421 => Predicted: 1\n",
      "Row 2422 => Predicted: 0\n",
      "Row 2423 => Predicted: 0\n",
      "Row 2424 => Predicted: 0\n",
      "Row 2425 => Predicted: 1\n",
      "Row 2426 => Predicted: 0\n",
      "Row 2427 => Predicted: 1\n",
      "Row 2428 => Predicted: 1\n",
      "Row 2429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2420 to 2429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2430 => Predicted: 1\n",
      "Row 2431 => Predicted: 0\n",
      "Row 2432 => Predicted: 0\n",
      "Row 2433 => Predicted: 1\n",
      "Row 2434 => Predicted: 1\n",
      "Row 2435 => Predicted: 0\n",
      "Row 2436 => Predicted: 1\n",
      "Row 2437 => Predicted: 1\n",
      "Row 2438 => Predicted: 1\n",
      "Row 2439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2430 to 2439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2440 => Predicted: 1\n",
      "Row 2441 => Predicted: 0\n",
      "Row 2442 => Predicted: 1\n",
      "Row 2443 => Predicted: 1\n",
      "Row 2444 => Predicted: 1\n",
      "Row 2445 => Predicted: 1\n",
      "Row 2446 => Predicted: 1\n",
      "Row 2447 => Predicted: 1\n",
      "Row 2448 => Predicted: 0\n",
      "Row 2449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2440 to 2449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2450 => Predicted: 1\n",
      "Row 2451 => Predicted: 1\n",
      "Row 2452 => Predicted: 1\n",
      "Row 2453 => Predicted: 0\n",
      "Row 2454 => Predicted: 1\n",
      "Row 2455 => Predicted: 0\n",
      "Row 2456 => Predicted: 1\n",
      "Row 2457 => Predicted: 1\n",
      "Row 2458 => Predicted: 1\n",
      "Row 2459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2450 to 2459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2460 => Predicted: 1\n",
      "Row 2461 => Predicted: 0\n",
      "Row 2462 => Predicted: 0\n",
      "Row 2463 => Predicted: 0\n",
      "Row 2464 => Predicted: 1\n",
      "Row 2465 => Predicted: 0\n",
      "Row 2466 => Predicted: 0\n",
      "Row 2467 => Predicted: 1\n",
      "Row 2468 => Predicted: 0\n",
      "Row 2469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2460 to 2469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2470 => Predicted: 1\n",
      "Row 2471 => Predicted: 1\n",
      "Row 2472 => Predicted: 0\n",
      "Row 2473 => Predicted: 1\n",
      "Row 2474 => Predicted: 1\n",
      "Row 2475 => Predicted: 1\n",
      "Row 2476 => Predicted: 0\n",
      "Row 2477 => Predicted: 1\n",
      "Row 2478 => Predicted: 0\n",
      "Row 2479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2470 to 2479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2480 => Predicted: 0\n",
      "Row 2481 => Predicted: 0\n",
      "Row 2482 => Predicted: 0\n",
      "Row 2483 => Predicted: 1\n",
      "Row 2484 => Predicted: 0\n",
      "Row 2485 => Predicted: 1\n",
      "Row 2486 => Predicted: 1\n",
      "Row 2487 => Predicted: 0\n",
      "Row 2488 => Predicted: 1\n",
      "Row 2489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2480 to 2489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2490 => Predicted: 1\n",
      "Row 2491 => Predicted: 1\n",
      "Row 2492 => Predicted: 1\n",
      "Row 2493 => Predicted: 1\n",
      "Row 2494 => Predicted: 0\n",
      "Row 2495 => Predicted: 0\n",
      "Row 2496 => Predicted: 1\n",
      "Row 2497 => Predicted: 0\n",
      "Row 2498 => Predicted: 0\n",
      "Row 2499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2490 to 2499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2500 => Predicted: 1\n",
      "Row 2501 => Predicted: 1\n",
      "Row 2502 => Predicted: 1\n",
      "Row 2503 => Predicted: 1\n",
      "Row 2504 => Predicted: 0\n",
      "Row 2505 => Predicted: 0\n",
      "Row 2506 => Predicted: 0\n",
      "Row 2507 => Predicted: 0\n",
      "Row 2508 => Predicted: 0\n",
      "Row 2509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2500 to 2509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2510 => Predicted: 1\n",
      "Row 2511 => Predicted: 1\n",
      "Row 2512 => Predicted: 1\n",
      "Row 2513 => Predicted: 0\n",
      "Row 2514 => Predicted: 0\n",
      "Row 2515 => Predicted: 1\n",
      "Row 2516 => Predicted: 1\n",
      "Row 2517 => Predicted: 1\n",
      "Row 2518 => Predicted: 1\n",
      "Row 2519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2510 to 2519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2520 => Predicted: 0\n",
      "Row 2521 => Predicted: 0\n",
      "Row 2522 => Predicted: 1\n",
      "Row 2523 => Predicted: 0\n",
      "Row 2524 => Predicted: 0\n",
      "Row 2525 => Predicted: 1\n",
      "Row 2526 => Predicted: 0\n",
      "Row 2527 => Predicted: 1\n",
      "Row 2528 => Predicted: 0\n",
      "Row 2529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2520 to 2529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2530 => Predicted: 0\n",
      "Row 2531 => Predicted: 1\n",
      "Row 2532 => Predicted: 0\n",
      "Row 2533 => Predicted: 0\n",
      "Row 2534 => Predicted: 0\n",
      "Row 2535 => Predicted: 1\n",
      "Row 2536 => Predicted: 0\n",
      "Row 2537 => Predicted: 1\n",
      "Row 2538 => Predicted: 0\n",
      "Row 2539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2530 to 2539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2540 => Predicted: 0\n",
      "Row 2541 => Predicted: 0\n",
      "Row 2542 => Predicted: 0\n",
      "Row 2543 => Predicted: 1\n",
      "Row 2544 => Predicted: 0\n",
      "Row 2545 => Predicted: 0\n",
      "Row 2546 => Predicted: 0\n",
      "Row 2547 => Predicted: 0\n",
      "Row 2548 => Predicted: 0\n",
      "Row 2549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2540 to 2549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2550 => Predicted: 1\n",
      "Row 2551 => Predicted: 1\n",
      "Row 2552 => Predicted: 0\n",
      "Row 2553 => Predicted: 0\n",
      "Row 2554 => Predicted: 1\n",
      "Row 2555 => Predicted: 0\n",
      "Row 2556 => Predicted: 0\n",
      "Row 2557 => Predicted: 1\n",
      "Row 2558 => Predicted: 1\n",
      "Row 2559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2550 to 2559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2560 => Predicted: 1\n",
      "Row 2561 => Predicted: 1\n",
      "Row 2562 => Predicted: 0\n",
      "Row 2563 => Predicted: 1\n",
      "Row 2564 => Predicted: 1\n",
      "Row 2565 => Predicted: 0\n",
      "Row 2566 => Predicted: 0\n",
      "Row 2567 => Predicted: 1\n",
      "Row 2568 => Predicted: 1\n",
      "Row 2569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2560 to 2569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2570 => Predicted: 0\n",
      "Row 2571 => Predicted: 0\n",
      "Row 2572 => Predicted: 1\n",
      "Row 2573 => Predicted: 0\n",
      "Row 2574 => Predicted: 0\n",
      "Row 2575 => Predicted: 1\n",
      "Row 2576 => Predicted: 1\n",
      "Row 2577 => Predicted: 0\n",
      "Row 2578 => Predicted: 1\n",
      "Row 2579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2570 to 2579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2580 => Predicted: 1\n",
      "Row 2581 => Predicted: 0\n",
      "Row 2582 => Predicted: 0\n",
      "Row 2583 => Predicted: 1\n",
      "Row 2584 => Predicted: 0\n",
      "Row 2585 => Predicted: 0\n",
      "Row 2586 => Predicted: 1\n",
      "Row 2587 => Predicted: 1\n",
      "Row 2588 => Predicted: 0\n",
      "Row 2589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2580 to 2589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2590 => Predicted: 0\n",
      "Row 2591 => Predicted: 1\n",
      "Row 2592 => Predicted: 0\n",
      "Row 2593 => Predicted: 1\n",
      "Row 2594 => Predicted: 1\n",
      "Row 2595 => Predicted: 1\n",
      "Row 2596 => Predicted: 1\n",
      "Row 2597 => Predicted: 1\n",
      "Row 2598 => Predicted: 0\n",
      "Row 2599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2590 to 2599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2600 => Predicted: 1\n",
      "Row 2601 => Predicted: 0\n",
      "Row 2602 => Predicted: 0\n",
      "Row 2603 => Predicted: 1\n",
      "Row 2604 => Predicted: 0\n",
      "Row 2605 => Predicted: 1\n",
      "Row 2606 => Predicted: 0\n",
      "Row 2607 => Predicted: 0\n",
      "Row 2608 => Predicted: 0\n",
      "Row 2609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2600 to 2609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2610 => Predicted: 1\n",
      "Row 2611 => Predicted: 1\n",
      "Row 2612 => Predicted: 1\n",
      "Row 2613 => Predicted: 0\n",
      "Row 2614 => Predicted: 0\n",
      "Row 2615 => Predicted: 0\n",
      "Row 2616 => Predicted: 0\n",
      "Row 2617 => Predicted: 0\n",
      "Row 2618 => Predicted: 1\n",
      "Row 2619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2610 to 2619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2620 => Predicted: 1\n",
      "Row 2621 => Predicted: 1\n",
      "Row 2622 => Predicted: 0\n",
      "Row 2623 => Predicted: 1\n",
      "Row 2624 => Predicted: 1\n",
      "Row 2625 => Predicted: 1\n",
      "Row 2626 => Predicted: 1\n",
      "Row 2627 => Predicted: 1\n",
      "Row 2628 => Predicted: 0\n",
      "Row 2629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2620 to 2629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2630 => Predicted: 0\n",
      "Row 2631 => Predicted: 1\n",
      "Row 2632 => Predicted: 1\n",
      "Row 2633 => Predicted: 0\n",
      "Row 2634 => Predicted: 1\n",
      "Row 2635 => Predicted: 0\n",
      "Row 2636 => Predicted: 0\n",
      "Row 2637 => Predicted: 1\n",
      "Row 2638 => Predicted: 0\n",
      "Row 2639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2630 to 2639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2640 => Predicted: 1\n",
      "Row 2641 => Predicted: 0\n",
      "Row 2642 => Predicted: 1\n",
      "Row 2643 => Predicted: 1\n",
      "Row 2644 => Predicted: 1\n",
      "Row 2645 => Predicted: 0\n",
      "Row 2646 => Predicted: 1\n",
      "Row 2647 => Predicted: 1\n",
      "Row 2648 => Predicted: 1\n",
      "Row 2649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2640 to 2649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2650 => Predicted: 1\n",
      "Row 2651 => Predicted: 0\n",
      "Row 2652 => Predicted: 1\n",
      "Row 2653 => Predicted: 1\n",
      "Row 2654 => Predicted: 0\n",
      "Row 2655 => Predicted: 1\n",
      "Row 2656 => Predicted: 1\n",
      "Row 2657 => Predicted: 0\n",
      "Row 2658 => Predicted: 0\n",
      "Row 2659 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2650 to 2659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2660 => Predicted: 0\n",
      "Row 2661 => Predicted: 1\n",
      "Row 2662 => Predicted: 1\n",
      "Row 2663 => Predicted: 1\n",
      "Row 2664 => Predicted: 0\n",
      "Row 2665 => Predicted: 1\n",
      "Row 2666 => Predicted: 0\n",
      "Row 2667 => Predicted: 1\n",
      "Row 2668 => Predicted: 1\n",
      "Row 2669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2660 to 2669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2670 => Predicted: 1\n",
      "Row 2671 => Predicted: 0\n",
      "Row 2672 => Predicted: 0\n",
      "Row 2673 => Predicted: 0\n",
      "Row 2674 => Predicted: 0\n",
      "Row 2675 => Predicted: 1\n",
      "Row 2676 => Predicted: 0\n",
      "Row 2677 => Predicted: 0\n",
      "Row 2678 => Predicted: 0\n",
      "Row 2679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2670 to 2679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2680 => Predicted: 0\n",
      "Row 2681 => Predicted: 0\n",
      "Row 2682 => Predicted: 1\n",
      "Row 2683 => Predicted: 1\n",
      "Row 2684 => Predicted: 1\n",
      "Row 2685 => Predicted: 1\n",
      "Row 2686 => Predicted: 1\n",
      "Row 2687 => Predicted: 0\n",
      "Row 2688 => Predicted: 1\n",
      "Row 2689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2680 to 2689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2690 => Predicted: 0\n",
      "Row 2691 => Predicted: 1\n",
      "Row 2692 => Predicted: 1\n",
      "Row 2693 => Predicted: 0\n",
      "Row 2694 => Predicted: 0\n",
      "Row 2695 => Predicted: 1\n",
      "Row 2696 => Predicted: 1\n",
      "Row 2697 => Predicted: 1\n",
      "Row 2698 => Predicted: 1\n",
      "Row 2699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2690 to 2699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2700 => Predicted: 0\n",
      "Row 2701 => Predicted: 1\n",
      "Row 2702 => Predicted: 1\n",
      "Row 2703 => Predicted: 0\n",
      "Row 2704 => Predicted: 1\n",
      "Row 2705 => Predicted: 0\n",
      "Row 2706 => Predicted: 0\n",
      "Row 2707 => Predicted: 0\n",
      "Row 2708 => Predicted: 0\n",
      "Row 2709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2700 to 2709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2710 => Predicted: 0\n",
      "Row 2711 => Predicted: 1\n",
      "Row 2712 => Predicted: 0\n",
      "Row 2713 => Predicted: 0\n",
      "Row 2714 => Predicted: 0\n",
      "Row 2715 => Predicted: 0\n",
      "Row 2716 => Predicted: 1\n",
      "Row 2717 => Predicted: 0\n",
      "Row 2718 => Predicted: 1\n",
      "Row 2719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2710 to 2719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2720 => Predicted: 1\n",
      "Row 2721 => Predicted: 1\n",
      "Row 2722 => Predicted: 1\n",
      "Row 2723 => Predicted: 1\n",
      "Row 2724 => Predicted: 0\n",
      "Row 2725 => Predicted: 1\n",
      "Row 2726 => Predicted: 1\n",
      "Row 2727 => Predicted: 0\n",
      "Row 2728 => Predicted: 0\n",
      "Row 2729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2720 to 2729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2730 => Predicted: 1\n",
      "Row 2731 => Predicted: 0\n",
      "Row 2732 => Predicted: 1\n",
      "Row 2733 => Predicted: 0\n",
      "Row 2734 => Predicted: 0\n",
      "Row 2735 => Predicted: 1\n",
      "Row 2736 => Predicted: 0\n",
      "Row 2737 => Predicted: 1\n",
      "Row 2738 => Predicted: 0\n",
      "Row 2739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2730 to 2739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2740 => Predicted: 1\n",
      "Row 2741 => Predicted: 0\n",
      "Row 2742 => Predicted: 1\n",
      "Row 2743 => Predicted: 1\n",
      "Row 2744 => Predicted: 1\n",
      "Row 2745 => Predicted: 1\n",
      "Row 2746 => Predicted: 0\n",
      "Row 2747 => Predicted: 0\n",
      "Row 2748 => Predicted: 1\n",
      "Row 2749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2740 to 2749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2750 => Predicted: 0\n",
      "Row 2751 => Predicted: 1\n",
      "Row 2752 => Predicted: 1\n",
      "Row 2753 => Predicted: 0\n",
      "Row 2754 => Predicted: 1\n",
      "Row 2755 => Predicted: 1\n",
      "Row 2756 => Predicted: 0\n",
      "Row 2757 => Predicted: 0\n",
      "Row 2758 => Predicted: 0\n",
      "Row 2759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2750 to 2759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2760 => Predicted: 0\n",
      "Row 2761 => Predicted: 1\n",
      "Row 2762 => Predicted: 0\n",
      "Row 2763 => Predicted: 1\n",
      "Row 2764 => Predicted: 1\n",
      "Row 2765 => Predicted: 1\n",
      "Row 2766 => Predicted: 1\n",
      "Row 2767 => Predicted: 1\n",
      "Row 2768 => Predicted: 0\n",
      "Row 2769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2760 to 2769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2770 => Predicted: 1\n",
      "Row 2771 => Predicted: 0\n",
      "Row 2772 => Predicted: 1\n",
      "Row 2773 => Predicted: 1\n",
      "Row 2774 => Predicted: 0\n",
      "Row 2775 => Predicted: 0\n",
      "Row 2776 => Predicted: 1\n",
      "Row 2777 => Predicted: 1\n",
      "Row 2778 => Predicted: 1\n",
      "Row 2779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2770 to 2779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2780 => Predicted: 0\n",
      "Row 2781 => Predicted: 1\n",
      "Row 2782 => Predicted: 1\n",
      "Row 2783 => Predicted: 0\n",
      "Row 2784 => Predicted: 0\n",
      "Row 2785 => Predicted: 0\n",
      "Row 2786 => Predicted: 0\n",
      "Row 2787 => Predicted: 1\n",
      "Row 2788 => Predicted: 1\n",
      "Row 2789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2780 to 2789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2790 => Predicted: 0\n",
      "Row 2791 => Predicted: 1\n",
      "Row 2792 => Predicted: 1\n",
      "Row 2793 => Predicted: 1\n",
      "Row 2794 => Predicted: 1\n",
      "Row 2795 => Predicted: 1\n",
      "Row 2796 => Predicted: 1\n",
      "Row 2797 => Predicted: 1\n",
      "Row 2798 => Predicted: 1\n",
      "Row 2799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2790 to 2799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2800 => Predicted: 0\n",
      "Row 2801 => Predicted: 0\n",
      "Row 2802 => Predicted: 0\n",
      "Row 2803 => Predicted: 1\n",
      "Row 2804 => Predicted: 1\n",
      "Row 2805 => Predicted: 1\n",
      "Row 2806 => Predicted: 1\n",
      "Row 2807 => Predicted: 1\n",
      "Row 2808 => Predicted: 1\n",
      "Row 2809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2800 to 2809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2810 => Predicted: 1\n",
      "Row 2811 => Predicted: 0\n",
      "Row 2812 => Predicted: 0\n",
      "Row 2813 => Predicted: 1\n",
      "Row 2814 => Predicted: 1\n",
      "Row 2815 => Predicted: 0\n",
      "Row 2816 => Predicted: 0\n",
      "Row 2817 => Predicted: 1\n",
      "Row 2818 => Predicted: 0\n",
      "Row 2819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2810 to 2819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2820 => Predicted: 0\n",
      "Row 2821 => Predicted: 1\n",
      "Row 2822 => Predicted: 1\n",
      "Row 2823 => Predicted: 1\n",
      "Row 2824 => Predicted: 1\n",
      "Row 2825 => Predicted: 1\n",
      "Row 2826 => Predicted: 0\n",
      "Row 2827 => Predicted: 1\n",
      "Row 2828 => Predicted: 0\n",
      "Row 2829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2820 to 2829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2830 => Predicted: 0\n",
      "Row 2831 => Predicted: 1\n",
      "Row 2832 => Predicted: 1\n",
      "Row 2833 => Predicted: 1\n",
      "Row 2834 => Predicted: 1\n",
      "Row 2835 => Predicted: 1\n",
      "Row 2836 => Predicted: 0\n",
      "Row 2837 => Predicted: 0\n",
      "Row 2838 => Predicted: 0\n",
      "Row 2839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2830 to 2839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2840 => Predicted: 1\n",
      "Row 2841 => Predicted: 0\n",
      "Row 2842 => Predicted: 1\n",
      "Row 2843 => Predicted: 0\n",
      "Row 2844 => Predicted: 1\n",
      "Row 2845 => Predicted: 0\n",
      "Row 2846 => Predicted: 0\n",
      "Row 2847 => Predicted: 0\n",
      "Row 2848 => Predicted: 0\n",
      "Row 2849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2840 to 2849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2850 => Predicted: 1\n",
      "Row 2851 => Predicted: 0\n",
      "Row 2852 => Predicted: 1\n",
      "Row 2853 => Predicted: 1\n",
      "Row 2854 => Predicted: 0\n",
      "Row 2855 => Predicted: 1\n",
      "Row 2856 => Predicted: 1\n",
      "Row 2857 => Predicted: 1\n",
      "Row 2858 => Predicted: 1\n",
      "Row 2859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2850 to 2859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2860 => Predicted: 0\n",
      "Row 2861 => Predicted: 0\n",
      "Row 2862 => Predicted: 1\n",
      "Row 2863 => Predicted: 0\n",
      "Row 2864 => Predicted: 0\n",
      "Row 2865 => Predicted: 1\n",
      "Row 2866 => Predicted: 0\n",
      "Row 2867 => Predicted: 1\n",
      "Row 2868 => Predicted: 0\n",
      "Row 2869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2860 to 2869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2870 => Predicted: 1\n",
      "Row 2871 => Predicted: 1\n",
      "Row 2872 => Predicted: 0\n",
      "Row 2873 => Predicted: 1\n",
      "Row 2874 => Predicted: 0\n",
      "Row 2875 => Predicted: 1\n",
      "Row 2876 => Predicted: 1\n",
      "Row 2877 => Predicted: 0\n",
      "Row 2878 => Predicted: 0\n",
      "Row 2879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2870 to 2879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2880 => Predicted: 1\n",
      "Row 2881 => Predicted: 1\n",
      "Row 2882 => Predicted: 0\n",
      "Row 2883 => Predicted: 0\n",
      "Row 2884 => Predicted: 1\n",
      "Row 2885 => Predicted: 1\n",
      "Row 2886 => Predicted: 1\n",
      "Row 2887 => Predicted: 0\n",
      "Row 2888 => Predicted: 1\n",
      "Row 2889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2880 to 2889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2890 => Predicted: 1\n",
      "Row 2891 => Predicted: 1\n",
      "Row 2892 => Predicted: 1\n",
      "Row 2893 => Predicted: 1\n",
      "Row 2894 => Predicted: 1\n",
      "Row 2895 => Predicted: 1\n",
      "Row 2896 => Predicted: 1\n",
      "Row 2897 => Predicted: 0\n",
      "Row 2898 => Predicted: 1\n",
      "Row 2899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2890 to 2899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2900 => Predicted: 0\n",
      "Row 2901 => Predicted: 1\n",
      "Row 2902 => Predicted: 0\n",
      "Row 2903 => Predicted: 0\n",
      "Row 2904 => Predicted: 0\n",
      "Row 2905 => Predicted: 1\n",
      "Row 2906 => Predicted: 0\n",
      "Row 2907 => Predicted: 1\n",
      "Row 2908 => Predicted: 1\n",
      "Row 2909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2900 to 2909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2910 => Predicted: 0\n",
      "Row 2911 => Predicted: 0\n",
      "Row 2912 => Predicted: 1\n",
      "Row 2913 => Predicted: 0\n",
      "Row 2914 => Predicted: 1\n",
      "Row 2915 => Predicted: 1\n",
      "Row 2916 => Predicted: 0\n",
      "Row 2917 => Predicted: 1\n",
      "Row 2918 => Predicted: 0\n",
      "Row 2919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2910 to 2919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2920 => Predicted: 1\n",
      "Row 2921 => Predicted: 0\n",
      "Row 2922 => Predicted: 1\n",
      "Row 2923 => Predicted: 1\n",
      "Row 2924 => Predicted: 1\n",
      "Row 2925 => Predicted: 1\n",
      "Row 2926 => Predicted: 1\n",
      "Row 2927 => Predicted: 1\n",
      "Row 2928 => Predicted: 1\n",
      "Row 2929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2920 to 2929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2930 => Predicted: 0\n",
      "Row 2931 => Predicted: 0\n",
      "Row 2932 => Predicted: 0\n",
      "Row 2933 => Predicted: 0\n",
      "Row 2934 => Predicted: 0\n",
      "Row 2935 => Predicted: 1\n",
      "Row 2936 => Predicted: 0\n",
      "Row 2937 => Predicted: 0\n",
      "Row 2938 => Predicted: 1\n",
      "Row 2939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2930 to 2939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2940 => Predicted: 1\n",
      "Row 2941 => Predicted: 0\n",
      "Row 2942 => Predicted: 0\n",
      "Row 2943 => Predicted: 1\n",
      "Row 2944 => Predicted: 0\n",
      "Row 2945 => Predicted: 0\n",
      "Row 2946 => Predicted: 1\n",
      "Row 2947 => Predicted: 1\n",
      "Row 2948 => Predicted: 0\n",
      "Row 2949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2940 to 2949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2950 => Predicted: 1\n",
      "Row 2951 => Predicted: 1\n",
      "Row 2952 => Predicted: 0\n",
      "Row 2953 => Predicted: 1\n",
      "Row 2954 => Predicted: 0\n",
      "Row 2955 => Predicted: 1\n",
      "Row 2956 => Predicted: 1\n",
      "Row 2957 => Predicted: 1\n",
      "Row 2958 => Predicted: 0\n",
      "Row 2959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2950 to 2959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2960 => Predicted: 0\n",
      "Row 2961 => Predicted: 0\n",
      "Row 2962 => Predicted: 0\n",
      "Row 2963 => Predicted: 0\n",
      "Row 2964 => Predicted: 0\n",
      "Row 2965 => Predicted: 1\n",
      "Row 2966 => Predicted: 0\n",
      "Row 2967 => Predicted: 0\n",
      "Row 2968 => Predicted: 1\n",
      "Row 2969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2960 to 2969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2970 => Predicted: 1\n",
      "Row 2971 => Predicted: 0\n",
      "Row 2972 => Predicted: 0\n",
      "Row 2973 => Predicted: 0\n",
      "Row 2974 => Predicted: 1\n",
      "Row 2975 => Predicted: 1\n",
      "Row 2976 => Predicted: 1\n",
      "Row 2977 => Predicted: 0\n",
      "Row 2978 => Predicted: 0\n",
      "Row 2979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2970 to 2979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2980 => Predicted: 0\n",
      "Row 2981 => Predicted: 0\n",
      "Row 2982 => Predicted: 0\n",
      "Row 2983 => Predicted: 0\n",
      "Row 2984 => Predicted: 0\n",
      "Row 2985 => Predicted: 0\n",
      "Row 2986 => Predicted: 0\n",
      "Row 2987 => Predicted: 1\n",
      "Row 2988 => Predicted: 1\n",
      "Row 2989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 2980 to 2989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2990 => Predicted: 0\n",
      "Row 2991 => Predicted: 1\n",
      "Row 2992 => Predicted: 1\n",
      "Row 2993 => Predicted: 1\n",
      "Row 2994 => Predicted: 1\n",
      "Row 2995 => Predicted: 0\n",
      "Row 2996 => Predicted: 0\n",
      "Row 2997 => Predicted: 0\n",
      "Row 2998 => Predicted: 1\n",
      "Row 2999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 2990 to 2999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3000 => Predicted: 0\n",
      "Row 3001 => Predicted: 0\n",
      "Row 3002 => Predicted: 1\n",
      "Row 3003 => Predicted: 0\n",
      "Row 3004 => Predicted: 1\n",
      "Row 3005 => Predicted: 0\n",
      "Row 3006 => Predicted: 0\n",
      "Row 3007 => Predicted: 0\n",
      "Row 3008 => Predicted: 1\n",
      "Row 3009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3000 to 3009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3010 => Predicted: 0\n",
      "Row 3011 => Predicted: 0\n",
      "Row 3012 => Predicted: 1\n",
      "Row 3013 => Predicted: 1\n",
      "Row 3014 => Predicted: 0\n",
      "Row 3015 => Predicted: 1\n",
      "Row 3016 => Predicted: 1\n",
      "Row 3017 => Predicted: 1\n",
      "Row 3018 => Predicted: 1\n",
      "Row 3019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3010 to 3019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3020 => Predicted: 0\n",
      "Row 3021 => Predicted: 1\n",
      "Row 3022 => Predicted: 1\n",
      "Row 3023 => Predicted: 0\n",
      "Row 3024 => Predicted: 0\n",
      "Row 3025 => Predicted: 1\n",
      "Row 3026 => Predicted: 1\n",
      "Row 3027 => Predicted: 1\n",
      "Row 3028 => Predicted: 0\n",
      "Row 3029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3020 to 3029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3030 => Predicted: 0\n",
      "Row 3031 => Predicted: 1\n",
      "Row 3032 => Predicted: 1\n",
      "Row 3033 => Predicted: 0\n",
      "Row 3034 => Predicted: 0\n",
      "Row 3035 => Predicted: 0\n",
      "Row 3036 => Predicted: 0\n",
      "Row 3037 => Predicted: 1\n",
      "Row 3038 => Predicted: 1\n",
      "Row 3039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3030 to 3039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3040 => Predicted: 1\n",
      "Row 3041 => Predicted: 1\n",
      "Row 3042 => Predicted: 1\n",
      "Row 3043 => Predicted: 1\n",
      "Row 3044 => Predicted: 1\n",
      "Row 3045 => Predicted: 0\n",
      "Row 3046 => Predicted: 0\n",
      "Row 3047 => Predicted: 1\n",
      "Row 3048 => Predicted: 1\n",
      "Row 3049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3040 to 3049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3050 => Predicted: 0\n",
      "Row 3051 => Predicted: 0\n",
      "Row 3052 => Predicted: 0\n",
      "Row 3053 => Predicted: 1\n",
      "Row 3054 => Predicted: 0\n",
      "Row 3055 => Predicted: 1\n",
      "Row 3056 => Predicted: 1\n",
      "Row 3057 => Predicted: 0\n",
      "Row 3058 => Predicted: 1\n",
      "Row 3059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3050 to 3059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3060 => Predicted: 0\n",
      "Row 3061 => Predicted: 0\n",
      "Row 3062 => Predicted: 1\n",
      "Row 3063 => Predicted: 1\n",
      "Row 3064 => Predicted: 1\n",
      "Row 3065 => Predicted: 0\n",
      "Row 3066 => Predicted: 1\n",
      "Row 3067 => Predicted: 1\n",
      "Row 3068 => Predicted: 1\n",
      "Row 3069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3060 to 3069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3070 => Predicted: 1\n",
      "Row 3071 => Predicted: 0\n",
      "Row 3072 => Predicted: 0\n",
      "Row 3073 => Predicted: 1\n",
      "Row 3074 => Predicted: 1\n",
      "Row 3075 => Predicted: 0\n",
      "Row 3076 => Predicted: 0\n",
      "Row 3077 => Predicted: 1\n",
      "Row 3078 => Predicted: 0\n",
      "Row 3079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3070 to 3079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3080 => Predicted: 0\n",
      "Row 3081 => Predicted: 0\n",
      "Row 3082 => Predicted: 1\n",
      "Row 3083 => Predicted: 0\n",
      "Row 3084 => Predicted: 1\n",
      "Row 3085 => Predicted: 0\n",
      "Row 3086 => Predicted: 1\n",
      "Row 3087 => Predicted: 0\n",
      "Row 3088 => Predicted: 1\n",
      "Row 3089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3080 to 3089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3090 => Predicted: 1\n",
      "Row 3091 => Predicted: 1\n",
      "Row 3092 => Predicted: 1\n",
      "Row 3093 => Predicted: 0\n",
      "Row 3094 => Predicted: 1\n",
      "Row 3095 => Predicted: 1\n",
      "Row 3096 => Predicted: 0\n",
      "Row 3097 => Predicted: 0\n",
      "Row 3098 => Predicted: 1\n",
      "Row 3099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3090 to 3099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3100 => Predicted: 0\n",
      "Row 3101 => Predicted: 1\n",
      "Row 3102 => Predicted: 1\n",
      "Row 3103 => Predicted: 1\n",
      "Row 3104 => Predicted: 1\n",
      "Row 3105 => Predicted: 0\n",
      "Row 3106 => Predicted: 1\n",
      "Row 3107 => Predicted: 1\n",
      "Row 3108 => Predicted: 0\n",
      "Row 3109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3100 to 3109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3110 => Predicted: 1\n",
      "Row 3111 => Predicted: 0\n",
      "Row 3112 => Predicted: 1\n",
      "Row 3113 => Predicted: 1\n",
      "Row 3114 => Predicted: 0\n",
      "Row 3115 => Predicted: 0\n",
      "Row 3116 => Predicted: 1\n",
      "Row 3117 => Predicted: 0\n",
      "Row 3118 => Predicted: 1\n",
      "Row 3119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3110 to 3119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3120 => Predicted: 1\n",
      "Row 3121 => Predicted: 1\n",
      "Row 3122 => Predicted: 0\n",
      "Row 3123 => Predicted: 1\n",
      "Row 3124 => Predicted: 1\n",
      "Row 3125 => Predicted: 1\n",
      "Row 3126 => Predicted: 0\n",
      "Row 3127 => Predicted: 1\n",
      "Row 3128 => Predicted: 1\n",
      "Row 3129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3120 to 3129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3130 => Predicted: 1\n",
      "Row 3131 => Predicted: 1\n",
      "Row 3132 => Predicted: 0\n",
      "Row 3133 => Predicted: 1\n",
      "Row 3134 => Predicted: 1\n",
      "Row 3135 => Predicted: 0\n",
      "Row 3136 => Predicted: 0\n",
      "Row 3137 => Predicted: 0\n",
      "Row 3138 => Predicted: 1\n",
      "Row 3139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3130 to 3139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3140 => Predicted: 1\n",
      "Row 3141 => Predicted: 1\n",
      "Row 3142 => Predicted: 1\n",
      "Row 3143 => Predicted: 0\n",
      "Row 3144 => Predicted: 0\n",
      "Row 3145 => Predicted: 1\n",
      "Row 3146 => Predicted: 1\n",
      "Row 3147 => Predicted: 0\n",
      "Row 3148 => Predicted: 1\n",
      "Row 3149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3140 to 3149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3150 => Predicted: 1\n",
      "Row 3151 => Predicted: 1\n",
      "Row 3152 => Predicted: 1\n",
      "Row 3153 => Predicted: 0\n",
      "Row 3154 => Predicted: 0\n",
      "Row 3155 => Predicted: 1\n",
      "Row 3156 => Predicted: 0\n",
      "Row 3157 => Predicted: 0\n",
      "Row 3158 => Predicted: 1\n",
      "Row 3159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3150 to 3159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3160 => Predicted: 0\n",
      "Row 3161 => Predicted: 1\n",
      "Row 3162 => Predicted: 0\n",
      "Row 3163 => Predicted: 1\n",
      "Row 3164 => Predicted: 0\n",
      "Row 3165 => Predicted: 1\n",
      "Row 3166 => Predicted: 1\n",
      "Row 3167 => Predicted: 1\n",
      "Row 3168 => Predicted: 1\n",
      "Row 3169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3160 to 3169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3170 => Predicted: 1\n",
      "Row 3171 => Predicted: 1\n",
      "Row 3172 => Predicted: 1\n",
      "Row 3173 => Predicted: 1\n",
      "Row 3174 => Predicted: 0\n",
      "Row 3175 => Predicted: 0\n",
      "Row 3176 => Predicted: 0\n",
      "Row 3177 => Predicted: 0\n",
      "Row 3178 => Predicted: 0\n",
      "Row 3179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3170 to 3179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3180 => Predicted: 0\n",
      "Row 3181 => Predicted: 0\n",
      "Row 3182 => Predicted: 0\n",
      "Row 3183 => Predicted: 0\n",
      "Row 3184 => Predicted: 0\n",
      "Row 3185 => Predicted: 0\n",
      "Row 3186 => Predicted: 0\n",
      "Row 3187 => Predicted: 0\n",
      "Row 3188 => Predicted: 0\n",
      "Row 3189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3180 to 3189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3190 => Predicted: 1\n",
      "Row 3191 => Predicted: 0\n",
      "Row 3192 => Predicted: 0\n",
      "Row 3193 => Predicted: 1\n",
      "Row 3194 => Predicted: 1\n",
      "Row 3195 => Predicted: 1\n",
      "Row 3196 => Predicted: 1\n",
      "Row 3197 => Predicted: 1\n",
      "Row 3198 => Predicted: 1\n",
      "Row 3199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3190 to 3199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3200 => Predicted: 1\n",
      "Row 3201 => Predicted: 0\n",
      "Row 3202 => Predicted: 0\n",
      "Row 3203 => Predicted: 1\n",
      "Row 3204 => Predicted: 1\n",
      "Row 3205 => Predicted: 1\n",
      "Row 3206 => Predicted: 1\n",
      "Row 3207 => Predicted: 0\n",
      "Row 3208 => Predicted: 0\n",
      "Row 3209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3200 to 3209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3210 => Predicted: 1\n",
      "Row 3211 => Predicted: 0\n",
      "Row 3212 => Predicted: 1\n",
      "Row 3213 => Predicted: 1\n",
      "Row 3214 => Predicted: 0\n",
      "Row 3215 => Predicted: 1\n",
      "Row 3216 => Predicted: 0\n",
      "Row 3217 => Predicted: 1\n",
      "Row 3218 => Predicted: 1\n",
      "Row 3219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3210 to 3219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3220 => Predicted: 1\n",
      "Row 3221 => Predicted: 0\n",
      "Row 3222 => Predicted: 0\n",
      "Row 3223 => Predicted: 1\n",
      "Row 3224 => Predicted: 0\n",
      "Row 3225 => Predicted: 1\n",
      "Row 3226 => Predicted: 0\n",
      "Row 3227 => Predicted: 1\n",
      "Row 3228 => Predicted: 0\n",
      "Row 3229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3220 to 3229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3230 => Predicted: 0\n",
      "Row 3231 => Predicted: 1\n",
      "Row 3232 => Predicted: 1\n",
      "Row 3233 => Predicted: 1\n",
      "Row 3234 => Predicted: 1\n",
      "Row 3235 => Predicted: 1\n",
      "Row 3236 => Predicted: 0\n",
      "Row 3237 => Predicted: 1\n",
      "Row 3238 => Predicted: 1\n",
      "Row 3239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3230 to 3239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3240 => Predicted: 0\n",
      "Row 3241 => Predicted: 0\n",
      "Row 3242 => Predicted: 0\n",
      "Row 3243 => Predicted: 0\n",
      "Row 3244 => Predicted: 0\n",
      "Row 3245 => Predicted: 1\n",
      "Row 3246 => Predicted: 1\n",
      "Row 3247 => Predicted: 1\n",
      "Row 3248 => Predicted: 0\n",
      "Row 3249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3240 to 3249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3250 => Predicted: 0\n",
      "Row 3251 => Predicted: 0\n",
      "Row 3252 => Predicted: 0\n",
      "Row 3253 => Predicted: 0\n",
      "Row 3254 => Predicted: 1\n",
      "Row 3255 => Predicted: 1\n",
      "Row 3256 => Predicted: 1\n",
      "Row 3257 => Predicted: 0\n",
      "Row 3258 => Predicted: 0\n",
      "Row 3259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3250 to 3259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3260 => Predicted: 0\n",
      "Row 3261 => Predicted: 1\n",
      "Row 3262 => Predicted: 1\n",
      "Row 3263 => Predicted: 0\n",
      "Row 3264 => Predicted: 0\n",
      "Row 3265 => Predicted: 1\n",
      "Row 3266 => Predicted: 0\n",
      "Row 3267 => Predicted: 1\n",
      "Row 3268 => Predicted: 1\n",
      "Row 3269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3260 to 3269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3270 => Predicted: 1\n",
      "Row 3271 => Predicted: 1\n",
      "Row 3272 => Predicted: 1\n",
      "Row 3273 => Predicted: 1\n",
      "Row 3274 => Predicted: 0\n",
      "Row 3275 => Predicted: 1\n",
      "Row 3276 => Predicted: 1\n",
      "Row 3277 => Predicted: 0\n",
      "Row 3278 => Predicted: 0\n",
      "Row 3279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3270 to 3279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3280 => Predicted: 0\n",
      "Row 3281 => Predicted: 1\n",
      "Row 3282 => Predicted: 1\n",
      "Row 3283 => Predicted: 1\n",
      "Row 3284 => Predicted: 0\n",
      "Row 3285 => Predicted: 0\n",
      "Row 3286 => Predicted: 1\n",
      "Row 3287 => Predicted: 1\n",
      "Row 3288 => Predicted: 0\n",
      "Row 3289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3280 to 3289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3290 => Predicted: 0\n",
      "Row 3291 => Predicted: 0\n",
      "Row 3292 => Predicted: 0\n",
      "Row 3293 => Predicted: 0\n",
      "Row 3294 => Predicted: 1\n",
      "Row 3295 => Predicted: 0\n",
      "Row 3296 => Predicted: 0\n",
      "Row 3297 => Predicted: 0\n",
      "Row 3298 => Predicted: 1\n",
      "Row 3299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3290 to 3299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3300 => Predicted: 0\n",
      "Row 3301 => Predicted: 0\n",
      "Row 3302 => Predicted: 0\n",
      "Row 3303 => Predicted: 0\n",
      "Row 3304 => Predicted: 0\n",
      "Row 3305 => Predicted: 1\n",
      "Row 3306 => Predicted: 1\n",
      "Row 3307 => Predicted: 0\n",
      "Row 3308 => Predicted: 0\n",
      "Row 3309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3300 to 3309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3310 => Predicted: 0\n",
      "Row 3311 => Predicted: 1\n",
      "Row 3312 => Predicted: 1\n",
      "Row 3313 => Predicted: 0\n",
      "Row 3314 => Predicted: 0\n",
      "Row 3315 => Predicted: 0\n",
      "Row 3316 => Predicted: 1\n",
      "Row 3317 => Predicted: 1\n",
      "Row 3318 => Predicted: 0\n",
      "Row 3319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3310 to 3319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3320 => Predicted: 0\n",
      "Row 3321 => Predicted: 1\n",
      "Row 3322 => Predicted: 0\n",
      "Row 3323 => Predicted: 0\n",
      "Row 3324 => Predicted: 0\n",
      "Row 3325 => Predicted: 1\n",
      "Row 3326 => Predicted: 1\n",
      "Row 3327 => Predicted: 1\n",
      "Row 3328 => Predicted: 1\n",
      "Row 3329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3320 to 3329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3330 => Predicted: 1\n",
      "Row 3331 => Predicted: 1\n",
      "Row 3332 => Predicted: 0\n",
      "Row 3333 => Predicted: 0\n",
      "Row 3334 => Predicted: 0\n",
      "Row 3335 => Predicted: 0\n",
      "Row 3336 => Predicted: 1\n",
      "Row 3337 => Predicted: 0\n",
      "Row 3338 => Predicted: 1\n",
      "Row 3339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3330 to 3339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3340 => Predicted: 1\n",
      "Row 3341 => Predicted: 1\n",
      "Row 3342 => Predicted: 1\n",
      "Row 3343 => Predicted: 0\n",
      "Row 3344 => Predicted: 0\n",
      "Row 3345 => Predicted: 0\n",
      "Row 3346 => Predicted: 0\n",
      "Row 3347 => Predicted: 1\n",
      "Row 3348 => Predicted: 0\n",
      "Row 3349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3340 to 3349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3350 => Predicted: 0\n",
      "Row 3351 => Predicted: 0\n",
      "Row 3352 => Predicted: 1\n",
      "Row 3353 => Predicted: 0\n",
      "Row 3354 => Predicted: 1\n",
      "Row 3355 => Predicted: 0\n",
      "Row 3356 => Predicted: 1\n",
      "Row 3357 => Predicted: 0\n",
      "Row 3358 => Predicted: 1\n",
      "Row 3359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3350 to 3359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3360 => Predicted: 0\n",
      "Row 3361 => Predicted: 1\n",
      "Row 3362 => Predicted: 1\n",
      "Row 3363 => Predicted: 1\n",
      "Row 3364 => Predicted: 1\n",
      "Row 3365 => Predicted: 0\n",
      "Row 3366 => Predicted: 1\n",
      "Row 3367 => Predicted: 0\n",
      "Row 3368 => Predicted: 1\n",
      "Row 3369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3360 to 3369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3370 => Predicted: 0\n",
      "Row 3371 => Predicted: 0\n",
      "Row 3372 => Predicted: 1\n",
      "Row 3373 => Predicted: 0\n",
      "Row 3374 => Predicted: 1\n",
      "Row 3375 => Predicted: 1\n",
      "Row 3376 => Predicted: 0\n",
      "Row 3377 => Predicted: 1\n",
      "Row 3378 => Predicted: 0\n",
      "Row 3379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3370 to 3379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3380 => Predicted: 1\n",
      "Row 3381 => Predicted: 0\n",
      "Row 3382 => Predicted: 1\n",
      "Row 3383 => Predicted: 1\n",
      "Row 3384 => Predicted: 1\n",
      "Row 3385 => Predicted: 1\n",
      "Row 3386 => Predicted: 1\n",
      "Row 3387 => Predicted: 0\n",
      "Row 3388 => Predicted: 0\n",
      "Row 3389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3380 to 3389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3390 => Predicted: 0\n",
      "Row 3391 => Predicted: 1\n",
      "Row 3392 => Predicted: 1\n",
      "Row 3393 => Predicted: 1\n",
      "Row 3394 => Predicted: 1\n",
      "Row 3395 => Predicted: 1\n",
      "Row 3396 => Predicted: 1\n",
      "Row 3397 => Predicted: 0\n",
      "Row 3398 => Predicted: 1\n",
      "Row 3399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3390 to 3399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3400 => Predicted: 0\n",
      "Row 3401 => Predicted: 1\n",
      "Row 3402 => Predicted: 0\n",
      "Row 3403 => Predicted: 1\n",
      "Row 3404 => Predicted: 1\n",
      "Row 3405 => Predicted: 1\n",
      "Row 3406 => Predicted: 1\n",
      "Row 3407 => Predicted: 0\n",
      "Row 3408 => Predicted: 1\n",
      "Row 3409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3400 to 3409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3410 => Predicted: 0\n",
      "Row 3411 => Predicted: 0\n",
      "Row 3412 => Predicted: 1\n",
      "Row 3413 => Predicted: 1\n",
      "Row 3414 => Predicted: 1\n",
      "Row 3415 => Predicted: 1\n",
      "Row 3416 => Predicted: 1\n",
      "Row 3417 => Predicted: 0\n",
      "Row 3418 => Predicted: 1\n",
      "Row 3419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3410 to 3419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3420 => Predicted: 1\n",
      "Row 3421 => Predicted: 1\n",
      "Row 3422 => Predicted: 1\n",
      "Row 3423 => Predicted: 1\n",
      "Row 3424 => Predicted: 0\n",
      "Row 3425 => Predicted: 0\n",
      "Row 3426 => Predicted: 0\n",
      "Row 3427 => Predicted: 1\n",
      "Row 3428 => Predicted: 1\n",
      "Row 3429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3420 to 3429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3430 => Predicted: 1\n",
      "Row 3431 => Predicted: 1\n",
      "Row 3432 => Predicted: 1\n",
      "Row 3433 => Predicted: 1\n",
      "Row 3434 => Predicted: 1\n",
      "Row 3435 => Predicted: 0\n",
      "Row 3436 => Predicted: 0\n",
      "Row 3437 => Predicted: 0\n",
      "Row 3438 => Predicted: 1\n",
      "Row 3439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3430 to 3439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3440 => Predicted: 0\n",
      "Row 3441 => Predicted: 1\n",
      "Row 3442 => Predicted: 1\n",
      "Row 3443 => Predicted: 0\n",
      "Row 3444 => Predicted: 1\n",
      "Row 3445 => Predicted: 1\n",
      "Row 3446 => Predicted: 0\n",
      "Row 3447 => Predicted: 0\n",
      "Row 3448 => Predicted: 0\n",
      "Row 3449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3440 to 3449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3450 => Predicted: 0\n",
      "Row 3451 => Predicted: 1\n",
      "Row 3452 => Predicted: 1\n",
      "Row 3453 => Predicted: 0\n",
      "Row 3454 => Predicted: 1\n",
      "Row 3455 => Predicted: 1\n",
      "Row 3456 => Predicted: 1\n",
      "Row 3457 => Predicted: 0\n",
      "Row 3458 => Predicted: 0\n",
      "Row 3459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3450 to 3459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3460 => Predicted: 1\n",
      "Row 3461 => Predicted: 1\n",
      "Row 3462 => Predicted: 1\n",
      "Row 3463 => Predicted: 0\n",
      "Row 3464 => Predicted: 0\n",
      "Row 3465 => Predicted: 1\n",
      "Row 3466 => Predicted: 1\n",
      "Row 3467 => Predicted: 1\n",
      "Row 3468 => Predicted: 0\n",
      "Row 3469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3460 to 3469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3470 => Predicted: 0\n",
      "Row 3471 => Predicted: 0\n",
      "Row 3472 => Predicted: 1\n",
      "Row 3473 => Predicted: 0\n",
      "Row 3474 => Predicted: 0\n",
      "Row 3475 => Predicted: 0\n",
      "Row 3476 => Predicted: 1\n",
      "Row 3477 => Predicted: 1\n",
      "Row 3478 => Predicted: 1\n",
      "Row 3479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3470 to 3479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3480 => Predicted: 1\n",
      "Row 3481 => Predicted: 1\n",
      "Row 3482 => Predicted: 1\n",
      "Row 3483 => Predicted: 1\n",
      "Row 3484 => Predicted: 1\n",
      "Row 3485 => Predicted: 0\n",
      "Row 3486 => Predicted: 0\n",
      "Row 3487 => Predicted: 0\n",
      "Row 3488 => Predicted: 0\n",
      "Row 3489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3480 to 3489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3490 => Predicted: 0\n",
      "Row 3491 => Predicted: 1\n",
      "Row 3492 => Predicted: 1\n",
      "Row 3493 => Predicted: 1\n",
      "Row 3494 => Predicted: 0\n",
      "Row 3495 => Predicted: 0\n",
      "Row 3496 => Predicted: 0\n",
      "Row 3497 => Predicted: 1\n",
      "Row 3498 => Predicted: 0\n",
      "Row 3499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3490 to 3499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3500 => Predicted: 0\n",
      "Row 3501 => Predicted: 0\n",
      "Row 3502 => Predicted: 0\n",
      "Row 3503 => Predicted: 0\n",
      "Row 3504 => Predicted: 1\n",
      "Row 3505 => Predicted: 1\n",
      "Row 3506 => Predicted: 1\n",
      "Row 3507 => Predicted: 0\n",
      "Row 3508 => Predicted: 1\n",
      "Row 3509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3500 to 3509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3510 => Predicted: 1\n",
      "Row 3511 => Predicted: 0\n",
      "Row 3512 => Predicted: 1\n",
      "Row 3513 => Predicted: 1\n",
      "Row 3514 => Predicted: 0\n",
      "Row 3515 => Predicted: 0\n",
      "Row 3516 => Predicted: 0\n",
      "Row 3517 => Predicted: 1\n",
      "Row 3518 => Predicted: 0\n",
      "Row 3519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3510 to 3519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3520 => Predicted: 1\n",
      "Row 3521 => Predicted: 1\n",
      "Row 3522 => Predicted: 0\n",
      "Row 3523 => Predicted: 0\n",
      "Row 3524 => Predicted: 1\n",
      "Row 3525 => Predicted: 1\n",
      "Row 3526 => Predicted: 1\n",
      "Row 3527 => Predicted: 1\n",
      "Row 3528 => Predicted: 0\n",
      "Row 3529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3520 to 3529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3530 => Predicted: 1\n",
      "Row 3531 => Predicted: 1\n",
      "Row 3532 => Predicted: 1\n",
      "Row 3533 => Predicted: 1\n",
      "Row 3534 => Predicted: 0\n",
      "Row 3535 => Predicted: 1\n",
      "Row 3536 => Predicted: 0\n",
      "Row 3537 => Predicted: 0\n",
      "Row 3538 => Predicted: 0\n",
      "Row 3539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3530 to 3539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3540 => Predicted: 0\n",
      "Row 3541 => Predicted: 0\n",
      "Row 3542 => Predicted: 0\n",
      "Row 3543 => Predicted: 0\n",
      "Row 3544 => Predicted: 1\n",
      "Row 3545 => Predicted: 1\n",
      "Row 3546 => Predicted: 0\n",
      "Row 3547 => Predicted: 1\n",
      "Row 3548 => Predicted: 0\n",
      "Row 3549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3540 to 3549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3550 => Predicted: 0\n",
      "Row 3551 => Predicted: 0\n",
      "Row 3552 => Predicted: 0\n",
      "Row 3553 => Predicted: 0\n",
      "Row 3554 => Predicted: 0\n",
      "Row 3555 => Predicted: 1\n",
      "Row 3556 => Predicted: 1\n",
      "Row 3557 => Predicted: 1\n",
      "Row 3558 => Predicted: 1\n",
      "Row 3559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3550 to 3559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3560 => Predicted: 1\n",
      "Row 3561 => Predicted: 1\n",
      "Row 3562 => Predicted: 1\n",
      "Row 3563 => Predicted: 1\n",
      "Row 3564 => Predicted: 1\n",
      "Row 3565 => Predicted: 1\n",
      "Row 3566 => Predicted: 0\n",
      "Row 3567 => Predicted: 0\n",
      "Row 3568 => Predicted: 0\n",
      "Row 3569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3560 to 3569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3570 => Predicted: 0\n",
      "Row 3571 => Predicted: 1\n",
      "Row 3572 => Predicted: 1\n",
      "Row 3573 => Predicted: 0\n",
      "Row 3574 => Predicted: 1\n",
      "Row 3575 => Predicted: 0\n",
      "Row 3576 => Predicted: 0\n",
      "Row 3577 => Predicted: 1\n",
      "Row 3578 => Predicted: 0\n",
      "Row 3579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3570 to 3579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3580 => Predicted: 0\n",
      "Row 3581 => Predicted: 1\n",
      "Row 3582 => Predicted: 0\n",
      "Row 3583 => Predicted: 1\n",
      "Row 3584 => Predicted: 1\n",
      "Row 3585 => Predicted: 0\n",
      "Row 3586 => Predicted: 1\n",
      "Row 3587 => Predicted: 1\n",
      "Row 3588 => Predicted: 1\n",
      "Row 3589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3580 to 3589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3590 => Predicted: 0\n",
      "Row 3591 => Predicted: 0\n",
      "Row 3592 => Predicted: 1\n",
      "Row 3593 => Predicted: 0\n",
      "Row 3594 => Predicted: 0\n",
      "Row 3595 => Predicted: 1\n",
      "Row 3596 => Predicted: 0\n",
      "Row 3597 => Predicted: 0\n",
      "Row 3598 => Predicted: 0\n",
      "Row 3599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3590 to 3599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3600 => Predicted: 0\n",
      "Row 3601 => Predicted: 1\n",
      "Row 3602 => Predicted: 1\n",
      "Row 3603 => Predicted: 0\n",
      "Row 3604 => Predicted: 0\n",
      "Row 3605 => Predicted: 0\n",
      "Row 3606 => Predicted: 1\n",
      "Row 3607 => Predicted: 0\n",
      "Row 3608 => Predicted: 1\n",
      "Row 3609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3600 to 3609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3610 => Predicted: 0\n",
      "Row 3611 => Predicted: 0\n",
      "Row 3612 => Predicted: 1\n",
      "Row 3613 => Predicted: 0\n",
      "Row 3614 => Predicted: 0\n",
      "Row 3615 => Predicted: 1\n",
      "Row 3616 => Predicted: 1\n",
      "Row 3617 => Predicted: 0\n",
      "Row 3618 => Predicted: 0\n",
      "Row 3619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3610 to 3619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3620 => Predicted: 1\n",
      "Row 3621 => Predicted: 1\n",
      "Row 3622 => Predicted: 1\n",
      "Row 3623 => Predicted: 1\n",
      "Row 3624 => Predicted: 0\n",
      "Row 3625 => Predicted: 1\n",
      "Row 3626 => Predicted: 1\n",
      "Row 3627 => Predicted: 1\n",
      "Row 3628 => Predicted: 1\n",
      "Row 3629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3620 to 3629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3630 => Predicted: 0\n",
      "Row 3631 => Predicted: 0\n",
      "Row 3632 => Predicted: 1\n",
      "Row 3633 => Predicted: 0\n",
      "Row 3634 => Predicted: 1\n",
      "Row 3635 => Predicted: 0\n",
      "Row 3636 => Predicted: 1\n",
      "Row 3637 => Predicted: 1\n",
      "Row 3638 => Predicted: 0\n",
      "Row 3639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3630 to 3639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3640 => Predicted: 0\n",
      "Row 3641 => Predicted: 0\n",
      "Row 3642 => Predicted: 1\n",
      "Row 3643 => Predicted: 1\n",
      "Row 3644 => Predicted: 1\n",
      "Row 3645 => Predicted: 0\n",
      "Row 3646 => Predicted: 1\n",
      "Row 3647 => Predicted: 1\n",
      "Row 3648 => Predicted: 0\n",
      "Row 3649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3640 to 3649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3650 => Predicted: 1\n",
      "Row 3651 => Predicted: 1\n",
      "Row 3652 => Predicted: 1\n",
      "Row 3653 => Predicted: 0\n",
      "Row 3654 => Predicted: 1\n",
      "Row 3655 => Predicted: 1\n",
      "Row 3656 => Predicted: 0\n",
      "Row 3657 => Predicted: 1\n",
      "Row 3658 => Predicted: 0\n",
      "Row 3659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3650 to 3659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3660 => Predicted: 1\n",
      "Row 3661 => Predicted: 1\n",
      "Row 3662 => Predicted: 1\n",
      "Row 3663 => Predicted: 0\n",
      "Row 3664 => Predicted: 1\n",
      "Row 3665 => Predicted: 1\n",
      "Row 3666 => Predicted: 0\n",
      "Row 3667 => Predicted: 0\n",
      "Row 3668 => Predicted: 0\n",
      "Row 3669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3660 to 3669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3670 => Predicted: 1\n",
      "Row 3671 => Predicted: 0\n",
      "Row 3672 => Predicted: 0\n",
      "Row 3673 => Predicted: 1\n",
      "Row 3674 => Predicted: 0\n",
      "Row 3675 => Predicted: 1\n",
      "Row 3676 => Predicted: 1\n",
      "Row 3677 => Predicted: 1\n",
      "Row 3678 => Predicted: 1\n",
      "Row 3679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3670 to 3679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3680 => Predicted: 1\n",
      "Row 3681 => Predicted: 1\n",
      "Row 3682 => Predicted: 0\n",
      "Row 3683 => Predicted: 0\n",
      "Row 3684 => Predicted: 1\n",
      "Row 3685 => Predicted: 1\n",
      "Row 3686 => Predicted: 1\n",
      "Row 3687 => Predicted: 1\n",
      "Row 3688 => Predicted: 1\n",
      "Row 3689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3680 to 3689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3690 => Predicted: 0\n",
      "Row 3691 => Predicted: 1\n",
      "Row 3692 => Predicted: 0\n",
      "Row 3693 => Predicted: 1\n",
      "Row 3694 => Predicted: 1\n",
      "Row 3695 => Predicted: 0\n",
      "Row 3696 => Predicted: 1\n",
      "Row 3697 => Predicted: 0\n",
      "Row 3698 => Predicted: 0\n",
      "Row 3699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3690 to 3699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3700 => Predicted: 1\n",
      "Row 3701 => Predicted: 0\n",
      "Row 3702 => Predicted: 0\n",
      "Row 3703 => Predicted: 0\n",
      "Row 3704 => Predicted: 0\n",
      "Row 3705 => Predicted: 0\n",
      "Row 3706 => Predicted: 1\n",
      "Row 3707 => Predicted: 1\n",
      "Row 3708 => Predicted: 1\n",
      "Row 3709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3700 to 3709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3710 => Predicted: 1\n",
      "Row 3711 => Predicted: 0\n",
      "Row 3712 => Predicted: 0\n",
      "Row 3713 => Predicted: 0\n",
      "Row 3714 => Predicted: 0\n",
      "Row 3715 => Predicted: 1\n",
      "Row 3716 => Predicted: 0\n",
      "Row 3717 => Predicted: 1\n",
      "Row 3718 => Predicted: 1\n",
      "Row 3719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3710 to 3719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3720 => Predicted: 1\n",
      "Row 3721 => Predicted: 1\n",
      "Row 3722 => Predicted: 0\n",
      "Row 3723 => Predicted: 1\n",
      "Row 3724 => Predicted: 0\n",
      "Row 3725 => Predicted: 0\n",
      "Row 3726 => Predicted: 0\n",
      "Row 3727 => Predicted: 1\n",
      "Row 3728 => Predicted: 1\n",
      "Row 3729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3720 to 3729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3730 => Predicted: 0\n",
      "Row 3731 => Predicted: 0\n",
      "Row 3732 => Predicted: 0\n",
      "Row 3733 => Predicted: 1\n",
      "Row 3734 => Predicted: 0\n",
      "Row 3735 => Predicted: 1\n",
      "Row 3736 => Predicted: 1\n",
      "Row 3737 => Predicted: 1\n",
      "Row 3738 => Predicted: 1\n",
      "Row 3739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3730 to 3739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3740 => Predicted: 0\n",
      "Row 3741 => Predicted: 0\n",
      "Row 3742 => Predicted: 1\n",
      "Row 3743 => Predicted: 1\n",
      "Row 3744 => Predicted: 0\n",
      "Row 3745 => Predicted: 0\n",
      "Row 3746 => Predicted: 0\n",
      "Row 3747 => Predicted: 0\n",
      "Row 3748 => Predicted: 1\n",
      "Row 3749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3740 to 3749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3750 => Predicted: 1\n",
      "Row 3751 => Predicted: 1\n",
      "Row 3752 => Predicted: 0\n",
      "Row 3753 => Predicted: 1\n",
      "Row 3754 => Predicted: 0\n",
      "Row 3755 => Predicted: 0\n",
      "Row 3756 => Predicted: 0\n",
      "Row 3757 => Predicted: 0\n",
      "Row 3758 => Predicted: 0\n",
      "Row 3759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3750 to 3759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3760 => Predicted: 0\n",
      "Row 3761 => Predicted: 0\n",
      "Row 3762 => Predicted: 1\n",
      "Row 3763 => Predicted: 1\n",
      "Row 3764 => Predicted: 1\n",
      "Row 3765 => Predicted: 0\n",
      "Row 3766 => Predicted: 1\n",
      "Row 3767 => Predicted: 0\n",
      "Row 3768 => Predicted: 1\n",
      "Row 3769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3760 to 3769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3770 => Predicted: 0\n",
      "Row 3771 => Predicted: 1\n",
      "Row 3772 => Predicted: 1\n",
      "Row 3773 => Predicted: 0\n",
      "Row 3774 => Predicted: 0\n",
      "Row 3775 => Predicted: 1\n",
      "Row 3776 => Predicted: 1\n",
      "Row 3777 => Predicted: 1\n",
      "Row 3778 => Predicted: 0\n",
      "Row 3779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3770 to 3779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3780 => Predicted: 1\n",
      "Row 3781 => Predicted: 0\n",
      "Row 3782 => Predicted: 1\n",
      "Row 3783 => Predicted: 1\n",
      "Row 3784 => Predicted: 0\n",
      "Row 3785 => Predicted: 1\n",
      "Row 3786 => Predicted: 0\n",
      "Row 3787 => Predicted: 1\n",
      "Row 3788 => Predicted: 1\n",
      "Row 3789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3780 to 3789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3790 => Predicted: 1\n",
      "Row 3791 => Predicted: 0\n",
      "Row 3792 => Predicted: 1\n",
      "Row 3793 => Predicted: 0\n",
      "Row 3794 => Predicted: 1\n",
      "Row 3795 => Predicted: 0\n",
      "Row 3796 => Predicted: 1\n",
      "Row 3797 => Predicted: 1\n",
      "Row 3798 => Predicted: 1\n",
      "Row 3799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3790 to 3799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3800 => Predicted: 1\n",
      "Row 3801 => Predicted: 1\n",
      "Row 3802 => Predicted: 0\n",
      "Row 3803 => Predicted: 0\n",
      "Row 3804 => Predicted: 1\n",
      "Row 3805 => Predicted: 1\n",
      "Row 3806 => Predicted: 0\n",
      "Row 3807 => Predicted: 1\n",
      "Row 3808 => Predicted: 1\n",
      "Row 3809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3800 to 3809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3810 => Predicted: 0\n",
      "Row 3811 => Predicted: 0\n",
      "Row 3812 => Predicted: 1\n",
      "Row 3813 => Predicted: 1\n",
      "Row 3814 => Predicted: 0\n",
      "Row 3815 => Predicted: 0\n",
      "Row 3816 => Predicted: 1\n",
      "Row 3817 => Predicted: 1\n",
      "Row 3818 => Predicted: 1\n",
      "Row 3819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3810 to 3819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3820 => Predicted: 0\n",
      "Row 3821 => Predicted: 1\n",
      "Row 3822 => Predicted: 1\n",
      "Row 3823 => Predicted: 0\n",
      "Row 3824 => Predicted: 1\n",
      "Row 3825 => Predicted: 0\n",
      "Row 3826 => Predicted: 1\n",
      "Row 3827 => Predicted: 1\n",
      "Row 3828 => Predicted: 1\n",
      "Row 3829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3820 to 3829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3830 => Predicted: 1\n",
      "Row 3831 => Predicted: 0\n",
      "Row 3832 => Predicted: 1\n",
      "Row 3833 => Predicted: 0\n",
      "Row 3834 => Predicted: 0\n",
      "Row 3835 => Predicted: 0\n",
      "Row 3836 => Predicted: 0\n",
      "Row 3837 => Predicted: 0\n",
      "Row 3838 => Predicted: 1\n",
      "Row 3839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3830 to 3839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3840 => Predicted: 0\n",
      "Row 3841 => Predicted: 0\n",
      "Row 3842 => Predicted: 0\n",
      "Row 3843 => Predicted: 0\n",
      "Row 3844 => Predicted: 0\n",
      "Row 3845 => Predicted: 1\n",
      "Row 3846 => Predicted: 0\n",
      "Row 3847 => Predicted: 1\n",
      "Row 3848 => Predicted: 0\n",
      "Row 3849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3840 to 3849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3850 => Predicted: 1\n",
      "Row 3851 => Predicted: 1\n",
      "Row 3852 => Predicted: 1\n",
      "Row 3853 => Predicted: 0\n",
      "Row 3854 => Predicted: 0\n",
      "Row 3855 => Predicted: 1\n",
      "Row 3856 => Predicted: 0\n",
      "Row 3857 => Predicted: 0\n",
      "Row 3858 => Predicted: 1\n",
      "Row 3859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3850 to 3859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3860 => Predicted: 0\n",
      "Row 3861 => Predicted: 0\n",
      "Row 3862 => Predicted: 0\n",
      "Row 3863 => Predicted: 0\n",
      "Row 3864 => Predicted: 1\n",
      "Row 3865 => Predicted: 0\n",
      "Row 3866 => Predicted: 1\n",
      "Row 3867 => Predicted: 0\n",
      "Row 3868 => Predicted: 0\n",
      "Row 3869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3860 to 3869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3870 => Predicted: 0\n",
      "Row 3871 => Predicted: 0\n",
      "Row 3872 => Predicted: 1\n",
      "Row 3873 => Predicted: 1\n",
      "Row 3874 => Predicted: 1\n",
      "Row 3875 => Predicted: 0\n",
      "Row 3876 => Predicted: 1\n",
      "Row 3877 => Predicted: 0\n",
      "Row 3878 => Predicted: 1\n",
      "Row 3879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3870 to 3879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3880 => Predicted: 1\n",
      "Row 3881 => Predicted: 0\n",
      "Row 3882 => Predicted: 0\n",
      "Row 3883 => Predicted: 1\n",
      "Row 3884 => Predicted: 0\n",
      "Row 3885 => Predicted: 0\n",
      "Row 3886 => Predicted: 1\n",
      "Row 3887 => Predicted: 0\n",
      "Row 3888 => Predicted: 0\n",
      "Row 3889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3880 to 3889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3890 => Predicted: 0\n",
      "Row 3891 => Predicted: 0\n",
      "Row 3892 => Predicted: 0\n",
      "Row 3893 => Predicted: 0\n",
      "Row 3894 => Predicted: 0\n",
      "Row 3895 => Predicted: 1\n",
      "Row 3896 => Predicted: 1\n",
      "Row 3897 => Predicted: 0\n",
      "Row 3898 => Predicted: 0\n",
      "Row 3899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3890 to 3899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3900 => Predicted: 0\n",
      "Row 3901 => Predicted: 1\n",
      "Row 3902 => Predicted: 0\n",
      "Row 3903 => Predicted: 1\n",
      "Row 3904 => Predicted: 1\n",
      "Row 3905 => Predicted: 0\n",
      "Row 3906 => Predicted: 1\n",
      "Row 3907 => Predicted: 0\n",
      "Row 3908 => Predicted: 0\n",
      "Row 3909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3900 to 3909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3910 => Predicted: 1\n",
      "Row 3911 => Predicted: 0\n",
      "Row 3912 => Predicted: 0\n",
      "Row 3913 => Predicted: 0\n",
      "Row 3914 => Predicted: 0\n",
      "Row 3915 => Predicted: 1\n",
      "Row 3916 => Predicted: 1\n",
      "Row 3917 => Predicted: 1\n",
      "Row 3918 => Predicted: 1\n",
      "Row 3919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3910 to 3919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3920 => Predicted: 0\n",
      "Row 3921 => Predicted: 1\n",
      "Row 3922 => Predicted: 0\n",
      "Row 3923 => Predicted: 1\n",
      "Row 3924 => Predicted: 0\n",
      "Row 3925 => Predicted: 0\n",
      "Row 3926 => Predicted: 0\n",
      "Row 3927 => Predicted: 1\n",
      "Row 3928 => Predicted: 1\n",
      "Row 3929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3920 to 3929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3930 => Predicted: 0\n",
      "Row 3931 => Predicted: 0\n",
      "Row 3932 => Predicted: 1\n",
      "Row 3933 => Predicted: 0\n",
      "Row 3934 => Predicted: 0\n",
      "Row 3935 => Predicted: 1\n",
      "Row 3936 => Predicted: 0\n",
      "Row 3937 => Predicted: 1\n",
      "Row 3938 => Predicted: 0\n",
      "Row 3939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3930 to 3939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3940 => Predicted: 1\n",
      "Row 3941 => Predicted: 0\n",
      "Row 3942 => Predicted: 0\n",
      "Row 3943 => Predicted: 0\n",
      "Row 3944 => Predicted: 1\n",
      "Row 3945 => Predicted: 1\n",
      "Row 3946 => Predicted: 1\n",
      "Row 3947 => Predicted: 0\n",
      "Row 3948 => Predicted: 0\n",
      "Row 3949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3940 to 3949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3950 => Predicted: 0\n",
      "Row 3951 => Predicted: 1\n",
      "Row 3952 => Predicted: 0\n",
      "Row 3953 => Predicted: 1\n",
      "Row 3954 => Predicted: 1\n",
      "Row 3955 => Predicted: 1\n",
      "Row 3956 => Predicted: 1\n",
      "Row 3957 => Predicted: 1\n",
      "Row 3958 => Predicted: 1\n",
      "Row 3959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3950 to 3959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3960 => Predicted: 0\n",
      "Row 3961 => Predicted: 0\n",
      "Row 3962 => Predicted: 1\n",
      "Row 3963 => Predicted: 0\n",
      "Row 3964 => Predicted: 1\n",
      "Row 3965 => Predicted: 1\n",
      "Row 3966 => Predicted: 1\n",
      "Row 3967 => Predicted: 1\n",
      "Row 3968 => Predicted: 1\n",
      "Row 3969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3960 to 3969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3970 => Predicted: 1\n",
      "Row 3971 => Predicted: 0\n",
      "Row 3972 => Predicted: 0\n",
      "Row 3973 => Predicted: 0\n",
      "Row 3974 => Predicted: 1\n",
      "Row 3975 => Predicted: 1\n",
      "Row 3976 => Predicted: 1\n",
      "Row 3977 => Predicted: 1\n",
      "Row 3978 => Predicted: 0\n",
      "Row 3979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3970 to 3979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3980 => Predicted: 0\n",
      "Row 3981 => Predicted: 0\n",
      "Row 3982 => Predicted: 0\n",
      "Row 3983 => Predicted: 1\n",
      "Row 3984 => Predicted: 0\n",
      "Row 3985 => Predicted: 0\n",
      "Row 3986 => Predicted: 0\n",
      "Row 3987 => Predicted: 1\n",
      "Row 3988 => Predicted: 1\n",
      "Row 3989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 3980 to 3989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3990 => Predicted: 1\n",
      "Row 3991 => Predicted: 1\n",
      "Row 3992 => Predicted: 0\n",
      "Row 3993 => Predicted: 0\n",
      "Row 3994 => Predicted: 1\n",
      "Row 3995 => Predicted: 0\n",
      "Row 3996 => Predicted: 1\n",
      "Row 3997 => Predicted: 1\n",
      "Row 3998 => Predicted: 0\n",
      "Row 3999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 3990 to 3999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4000 => Predicted: 0\n",
      "Row 4001 => Predicted: 1\n",
      "Row 4002 => Predicted: 1\n",
      "Row 4003 => Predicted: 1\n",
      "Row 4004 => Predicted: 1\n",
      "Row 4005 => Predicted: 1\n",
      "Row 4006 => Predicted: 0\n",
      "Row 4007 => Predicted: 1\n",
      "Row 4008 => Predicted: 0\n",
      "Row 4009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4000 to 4009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4010 => Predicted: 0\n",
      "Row 4011 => Predicted: 1\n",
      "Row 4012 => Predicted: 0\n",
      "Row 4013 => Predicted: 1\n",
      "Row 4014 => Predicted: 0\n",
      "Row 4015 => Predicted: 0\n",
      "Row 4016 => Predicted: 1\n",
      "Row 4017 => Predicted: 1\n",
      "Row 4018 => Predicted: 1\n",
      "Row 4019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4010 to 4019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4020 => Predicted: 0\n",
      "Row 4021 => Predicted: 1\n",
      "Row 4022 => Predicted: 0\n",
      "Row 4023 => Predicted: 1\n",
      "Row 4024 => Predicted: 1\n",
      "Row 4025 => Predicted: 1\n",
      "Row 4026 => Predicted: 1\n",
      "Row 4027 => Predicted: 0\n",
      "Row 4028 => Predicted: 0\n",
      "Row 4029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4020 to 4029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4030 => Predicted: 1\n",
      "Row 4031 => Predicted: 1\n",
      "Row 4032 => Predicted: 1\n",
      "Row 4033 => Predicted: 0\n",
      "Row 4034 => Predicted: 1\n",
      "Row 4035 => Predicted: 0\n",
      "Row 4036 => Predicted: 0\n",
      "Row 4037 => Predicted: 0\n",
      "Row 4038 => Predicted: 0\n",
      "Row 4039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4030 to 4039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4040 => Predicted: 1\n",
      "Row 4041 => Predicted: 1\n",
      "Row 4042 => Predicted: 0\n",
      "Row 4043 => Predicted: 0\n",
      "Row 4044 => Predicted: 0\n",
      "Row 4045 => Predicted: 0\n",
      "Row 4046 => Predicted: 0\n",
      "Row 4047 => Predicted: 1\n",
      "Row 4048 => Predicted: 1\n",
      "Row 4049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4040 to 4049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4050 => Predicted: 0\n",
      "Row 4051 => Predicted: 1\n",
      "Row 4052 => Predicted: 0\n",
      "Row 4053 => Predicted: 0\n",
      "Row 4054 => Predicted: 0\n",
      "Row 4055 => Predicted: 0\n",
      "Row 4056 => Predicted: 1\n",
      "Row 4057 => Predicted: 1\n",
      "Row 4058 => Predicted: 1\n",
      "Row 4059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4050 to 4059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4060 => Predicted: 1\n",
      "Row 4061 => Predicted: 0\n",
      "Row 4062 => Predicted: 1\n",
      "Row 4063 => Predicted: 0\n",
      "Row 4064 => Predicted: 1\n",
      "Row 4065 => Predicted: 0\n",
      "Row 4066 => Predicted: 0\n",
      "Row 4067 => Predicted: 0\n",
      "Row 4068 => Predicted: 0\n",
      "Row 4069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4060 to 4069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4070 => Predicted: 1\n",
      "Row 4071 => Predicted: 1\n",
      "Row 4072 => Predicted: 0\n",
      "Row 4073 => Predicted: 0\n",
      "Row 4074 => Predicted: 0\n",
      "Row 4075 => Predicted: 0\n",
      "Row 4076 => Predicted: 1\n",
      "Row 4077 => Predicted: 0\n",
      "Row 4078 => Predicted: 0\n",
      "Row 4079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4070 to 4079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4080 => Predicted: 0\n",
      "Row 4081 => Predicted: 0\n",
      "Row 4082 => Predicted: 0\n",
      "Row 4083 => Predicted: 0\n",
      "Row 4084 => Predicted: 1\n",
      "Row 4085 => Predicted: 1\n",
      "Row 4086 => Predicted: 0\n",
      "Row 4087 => Predicted: 0\n",
      "Row 4088 => Predicted: 0\n",
      "Row 4089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4080 to 4089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4090 => Predicted: 1\n",
      "Row 4091 => Predicted: 1\n",
      "Row 4092 => Predicted: 1\n",
      "Row 4093 => Predicted: 1\n",
      "Row 4094 => Predicted: 0\n",
      "Row 4095 => Predicted: 0\n",
      "Row 4096 => Predicted: 0\n",
      "Row 4097 => Predicted: 1\n",
      "Row 4098 => Predicted: 0\n",
      "Row 4099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4090 to 4099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4100 => Predicted: 0\n",
      "Row 4101 => Predicted: 1\n",
      "Row 4102 => Predicted: 1\n",
      "Row 4103 => Predicted: 1\n",
      "Row 4104 => Predicted: 0\n",
      "Row 4105 => Predicted: 1\n",
      "Row 4106 => Predicted: 0\n",
      "Row 4107 => Predicted: 0\n",
      "Row 4108 => Predicted: 1\n",
      "Row 4109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4100 to 4109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4110 => Predicted: 0\n",
      "Row 4111 => Predicted: 1\n",
      "Row 4112 => Predicted: 0\n",
      "Row 4113 => Predicted: 1\n",
      "Row 4114 => Predicted: 1\n",
      "Row 4115 => Predicted: 0\n",
      "Row 4116 => Predicted: 0\n",
      "Row 4117 => Predicted: 0\n",
      "Row 4118 => Predicted: 0\n",
      "Row 4119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4110 to 4119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4120 => Predicted: 0\n",
      "Row 4121 => Predicted: 0\n",
      "Row 4122 => Predicted: 1\n",
      "Row 4123 => Predicted: 0\n",
      "Row 4124 => Predicted: 1\n",
      "Row 4125 => Predicted: 0\n",
      "Row 4126 => Predicted: 1\n",
      "Row 4127 => Predicted: 1\n",
      "Row 4128 => Predicted: 0\n",
      "Row 4129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4120 to 4129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4130 => Predicted: 1\n",
      "Row 4131 => Predicted: 0\n",
      "Row 4132 => Predicted: 1\n",
      "Row 4133 => Predicted: 1\n",
      "Row 4134 => Predicted: 0\n",
      "Row 4135 => Predicted: 1\n",
      "Row 4136 => Predicted: 0\n",
      "Row 4137 => Predicted: 1\n",
      "Row 4138 => Predicted: 0\n",
      "Row 4139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4130 to 4139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4140 => Predicted: 1\n",
      "Row 4141 => Predicted: 1\n",
      "Row 4142 => Predicted: 0\n",
      "Row 4143 => Predicted: 1\n",
      "Row 4144 => Predicted: 0\n",
      "Row 4145 => Predicted: 1\n",
      "Row 4146 => Predicted: 1\n",
      "Row 4147 => Predicted: 1\n",
      "Row 4148 => Predicted: 0\n",
      "Row 4149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4140 to 4149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4150 => Predicted: 1\n",
      "Row 4151 => Predicted: 0\n",
      "Row 4152 => Predicted: 0\n",
      "Row 4153 => Predicted: 0\n",
      "Row 4154 => Predicted: 1\n",
      "Row 4155 => Predicted: 1\n",
      "Row 4156 => Predicted: 0\n",
      "Row 4157 => Predicted: 1\n",
      "Row 4158 => Predicted: 1\n",
      "Row 4159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4150 to 4159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4160 => Predicted: 1\n",
      "Row 4161 => Predicted: 1\n",
      "Row 4162 => Predicted: 0\n",
      "Row 4163 => Predicted: 1\n",
      "Row 4164 => Predicted: 1\n",
      "Row 4165 => Predicted: 1\n",
      "Row 4166 => Predicted: 1\n",
      "Row 4167 => Predicted: 1\n",
      "Row 4168 => Predicted: 0\n",
      "Row 4169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4160 to 4169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4170 => Predicted: 1\n",
      "Row 4171 => Predicted: 0\n",
      "Row 4172 => Predicted: 0\n",
      "Row 4173 => Predicted: 1\n",
      "Row 4174 => Predicted: 1\n",
      "Row 4175 => Predicted: 1\n",
      "Row 4176 => Predicted: 0\n",
      "Row 4177 => Predicted: 1\n",
      "Row 4178 => Predicted: 0\n",
      "Row 4179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4170 to 4179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4180 => Predicted: 0\n",
      "Row 4181 => Predicted: 0\n",
      "Row 4182 => Predicted: 1\n",
      "Row 4183 => Predicted: 0\n",
      "Row 4184 => Predicted: 1\n",
      "Row 4185 => Predicted: 1\n",
      "Row 4186 => Predicted: 0\n",
      "Row 4187 => Predicted: 1\n",
      "Row 4188 => Predicted: 0\n",
      "Row 4189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4180 to 4189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4190 => Predicted: 0\n",
      "Row 4191 => Predicted: 1\n",
      "Row 4192 => Predicted: 0\n",
      "Row 4193 => Predicted: 1\n",
      "Row 4194 => Predicted: 1\n",
      "Row 4195 => Predicted: 1\n",
      "Row 4196 => Predicted: 0\n",
      "Row 4197 => Predicted: 1\n",
      "Row 4198 => Predicted: 0\n",
      "Row 4199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4190 to 4199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4200 => Predicted: 0\n",
      "Row 4201 => Predicted: 1\n",
      "Row 4202 => Predicted: 1\n",
      "Row 4203 => Predicted: 1\n",
      "Row 4204 => Predicted: 0\n",
      "Row 4205 => Predicted: 1\n",
      "Row 4206 => Predicted: 1\n",
      "Row 4207 => Predicted: 0\n",
      "Row 4208 => Predicted: 1\n",
      "Row 4209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4200 to 4209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4210 => Predicted: 1\n",
      "Row 4211 => Predicted: 0\n",
      "Row 4212 => Predicted: 0\n",
      "Row 4213 => Predicted: 0\n",
      "Row 4214 => Predicted: 1\n",
      "Row 4215 => Predicted: 1\n",
      "Row 4216 => Predicted: 0\n",
      "Row 4217 => Predicted: 0\n",
      "Row 4218 => Predicted: 1\n",
      "Row 4219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4210 to 4219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4220 => Predicted: 1\n",
      "Row 4221 => Predicted: 1\n",
      "Row 4222 => Predicted: 1\n",
      "Row 4223 => Predicted: 0\n",
      "Row 4224 => Predicted: 0\n",
      "Row 4225 => Predicted: 0\n",
      "Row 4226 => Predicted: 1\n",
      "Row 4227 => Predicted: 0\n",
      "Row 4228 => Predicted: 0\n",
      "Row 4229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4220 to 4229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4230 => Predicted: 0\n",
      "Row 4231 => Predicted: 0\n",
      "Row 4232 => Predicted: 0\n",
      "Row 4233 => Predicted: 0\n",
      "Row 4234 => Predicted: 0\n",
      "Row 4235 => Predicted: 0\n",
      "Row 4236 => Predicted: 0\n",
      "Row 4237 => Predicted: 0\n",
      "Row 4238 => Predicted: 1\n",
      "Row 4239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4230 to 4239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4240 => Predicted: 1\n",
      "Row 4241 => Predicted: 1\n",
      "Row 4242 => Predicted: 0\n",
      "Row 4243 => Predicted: 1\n",
      "Row 4244 => Predicted: 1\n",
      "Row 4245 => Predicted: 1\n",
      "Row 4246 => Predicted: 1\n",
      "Row 4247 => Predicted: 0\n",
      "Row 4248 => Predicted: 0\n",
      "Row 4249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4240 to 4249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4250 => Predicted: 0\n",
      "Row 4251 => Predicted: 0\n",
      "Row 4252 => Predicted: 1\n",
      "Row 4253 => Predicted: 0\n",
      "Row 4254 => Predicted: 1\n",
      "Row 4255 => Predicted: 1\n",
      "Row 4256 => Predicted: 0\n",
      "Row 4257 => Predicted: 1\n",
      "Row 4258 => Predicted: 1\n",
      "Row 4259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4250 to 4259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4260 => Predicted: 0\n",
      "Row 4261 => Predicted: 1\n",
      "Row 4262 => Predicted: 1\n",
      "Row 4263 => Predicted: 0\n",
      "Row 4264 => Predicted: 0\n",
      "Row 4265 => Predicted: 1\n",
      "Row 4266 => Predicted: 1\n",
      "Row 4267 => Predicted: 0\n",
      "Row 4268 => Predicted: 1\n",
      "Row 4269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4260 to 4269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4270 => Predicted: 1\n",
      "Row 4271 => Predicted: 1\n",
      "Row 4272 => Predicted: 0\n",
      "Row 4273 => Predicted: 0\n",
      "Row 4274 => Predicted: 0\n",
      "Row 4275 => Predicted: 1\n",
      "Row 4276 => Predicted: 1\n",
      "Row 4277 => Predicted: 0\n",
      "Row 4278 => Predicted: 0\n",
      "Row 4279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4270 to 4279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4280 => Predicted: 1\n",
      "Row 4281 => Predicted: 0\n",
      "Row 4282 => Predicted: 1\n",
      "Row 4283 => Predicted: 0\n",
      "Row 4284 => Predicted: 1\n",
      "Row 4285 => Predicted: 0\n",
      "Row 4286 => Predicted: 0\n",
      "Row 4287 => Predicted: 1\n",
      "Row 4288 => Predicted: 0\n",
      "Row 4289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4280 to 4289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4290 => Predicted: 0\n",
      "Row 4291 => Predicted: 1\n",
      "Row 4292 => Predicted: 0\n",
      "Row 4293 => Predicted: 0\n",
      "Row 4294 => Predicted: 1\n",
      "Row 4295 => Predicted: 0\n",
      "Row 4296 => Predicted: 0\n",
      "Row 4297 => Predicted: 0\n",
      "Row 4298 => Predicted: 1\n",
      "Row 4299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4290 to 4299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4300 => Predicted: 0\n",
      "Row 4301 => Predicted: 0\n",
      "Row 4302 => Predicted: 1\n",
      "Row 4303 => Predicted: 1\n",
      "Row 4304 => Predicted: 0\n",
      "Row 4305 => Predicted: 0\n",
      "Row 4306 => Predicted: 1\n",
      "Row 4307 => Predicted: 1\n",
      "Row 4308 => Predicted: 0\n",
      "Row 4309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4300 to 4309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4310 => Predicted: 1\n",
      "Row 4311 => Predicted: 1\n",
      "Row 4312 => Predicted: 0\n",
      "Row 4313 => Predicted: 0\n",
      "Row 4314 => Predicted: 0\n",
      "Row 4315 => Predicted: 0\n",
      "Row 4316 => Predicted: 0\n",
      "Row 4317 => Predicted: 0\n",
      "Row 4318 => Predicted: 1\n",
      "Row 4319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4310 to 4319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4320 => Predicted: 1\n",
      "Row 4321 => Predicted: 1\n",
      "Row 4322 => Predicted: 0\n",
      "Row 4323 => Predicted: 1\n",
      "Row 4324 => Predicted: 1\n",
      "Row 4325 => Predicted: 1\n",
      "Row 4326 => Predicted: 1\n",
      "Row 4327 => Predicted: 1\n",
      "Row 4328 => Predicted: 1\n",
      "Row 4329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4320 to 4329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4330 => Predicted: 1\n",
      "Row 4331 => Predicted: 1\n",
      "Row 4332 => Predicted: 0\n",
      "Row 4333 => Predicted: 1\n",
      "Row 4334 => Predicted: 1\n",
      "Row 4335 => Predicted: 1\n",
      "Row 4336 => Predicted: 0\n",
      "Row 4337 => Predicted: 1\n",
      "Row 4338 => Predicted: 1\n",
      "Row 4339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4330 to 4339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4340 => Predicted: 1\n",
      "Row 4341 => Predicted: 0\n",
      "Row 4342 => Predicted: 1\n",
      "Row 4343 => Predicted: 0\n",
      "Row 4344 => Predicted: 1\n",
      "Row 4345 => Predicted: 1\n",
      "Row 4346 => Predicted: 0\n",
      "Row 4347 => Predicted: 1\n",
      "Row 4348 => Predicted: 1\n",
      "Row 4349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4340 to 4349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4350 => Predicted: 0\n",
      "Row 4351 => Predicted: 1\n",
      "Row 4352 => Predicted: 0\n",
      "Row 4353 => Predicted: 0\n",
      "Row 4354 => Predicted: 0\n",
      "Row 4355 => Predicted: 0\n",
      "Row 4356 => Predicted: 0\n",
      "Row 4357 => Predicted: 1\n",
      "Row 4358 => Predicted: 0\n",
      "Row 4359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4350 to 4359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4360 => Predicted: 1\n",
      "Row 4361 => Predicted: 1\n",
      "Row 4362 => Predicted: 1\n",
      "Row 4363 => Predicted: 1\n",
      "Row 4364 => Predicted: 0\n",
      "Row 4365 => Predicted: 0\n",
      "Row 4366 => Predicted: 1\n",
      "Row 4367 => Predicted: 0\n",
      "Row 4368 => Predicted: 1\n",
      "Row 4369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4360 to 4369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4370 => Predicted: 0\n",
      "Row 4371 => Predicted: 0\n",
      "Row 4372 => Predicted: 0\n",
      "Row 4373 => Predicted: 0\n",
      "Row 4374 => Predicted: 0\n",
      "Row 4375 => Predicted: 1\n",
      "Row 4376 => Predicted: 1\n",
      "Row 4377 => Predicted: 0\n",
      "Row 4378 => Predicted: 1\n",
      "Row 4379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4370 to 4379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4380 => Predicted: 1\n",
      "Row 4381 => Predicted: 1\n",
      "Row 4382 => Predicted: 1\n",
      "Row 4383 => Predicted: 0\n",
      "Row 4384 => Predicted: 1\n",
      "Row 4385 => Predicted: 0\n",
      "Row 4386 => Predicted: 1\n",
      "Row 4387 => Predicted: 0\n",
      "Row 4388 => Predicted: 0\n",
      "Row 4389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4380 to 4389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4390 => Predicted: 0\n",
      "Row 4391 => Predicted: 0\n",
      "Row 4392 => Predicted: 0\n",
      "Row 4393 => Predicted: 0\n",
      "Row 4394 => Predicted: 0\n",
      "Row 4395 => Predicted: 1\n",
      "Row 4396 => Predicted: 0\n",
      "Row 4397 => Predicted: 0\n",
      "Row 4398 => Predicted: 1\n",
      "Row 4399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4390 to 4399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4400 => Predicted: 0\n",
      "Row 4401 => Predicted: 0\n",
      "Row 4402 => Predicted: 1\n",
      "Row 4403 => Predicted: 1\n",
      "Row 4404 => Predicted: 0\n",
      "Row 4405 => Predicted: 0\n",
      "Row 4406 => Predicted: 1\n",
      "Row 4407 => Predicted: 1\n",
      "Row 4408 => Predicted: 0\n",
      "Row 4409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4400 to 4409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4410 => Predicted: 1\n",
      "Row 4411 => Predicted: 0\n",
      "Row 4412 => Predicted: 0\n",
      "Row 4413 => Predicted: 0\n",
      "Row 4414 => Predicted: 1\n",
      "Row 4415 => Predicted: 0\n",
      "Row 4416 => Predicted: 1\n",
      "Row 4417 => Predicted: 0\n",
      "Row 4418 => Predicted: 1\n",
      "Row 4419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4410 to 4419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4420 => Predicted: 1\n",
      "Row 4421 => Predicted: 1\n",
      "Row 4422 => Predicted: 0\n",
      "Row 4423 => Predicted: 1\n",
      "Row 4424 => Predicted: 1\n",
      "Row 4425 => Predicted: 1\n",
      "Row 4426 => Predicted: 1\n",
      "Row 4427 => Predicted: 0\n",
      "Row 4428 => Predicted: 1\n",
      "Row 4429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4420 to 4429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4430 => Predicted: 1\n",
      "Row 4431 => Predicted: 0\n",
      "Row 4432 => Predicted: 1\n",
      "Row 4433 => Predicted: 1\n",
      "Row 4434 => Predicted: 1\n",
      "Row 4435 => Predicted: 1\n",
      "Row 4436 => Predicted: 0\n",
      "Row 4437 => Predicted: 0\n",
      "Row 4438 => Predicted: 1\n",
      "Row 4439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4430 to 4439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4440 => Predicted: 1\n",
      "Row 4441 => Predicted: 0\n",
      "Row 4442 => Predicted: 1\n",
      "Row 4443 => Predicted: 0\n",
      "Row 4444 => Predicted: 1\n",
      "Row 4445 => Predicted: 1\n",
      "Row 4446 => Predicted: 1\n",
      "Row 4447 => Predicted: 1\n",
      "Row 4448 => Predicted: 1\n",
      "Row 4449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4440 to 4449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4450 => Predicted: 1\n",
      "Row 4451 => Predicted: 0\n",
      "Row 4452 => Predicted: 0\n",
      "Row 4453 => Predicted: 0\n",
      "Row 4454 => Predicted: 0\n",
      "Row 4455 => Predicted: 1\n",
      "Row 4456 => Predicted: 1\n",
      "Row 4457 => Predicted: 0\n",
      "Row 4458 => Predicted: 0\n",
      "Row 4459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4450 to 4459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4460 => Predicted: 1\n",
      "Row 4461 => Predicted: 0\n",
      "Row 4462 => Predicted: 0\n",
      "Row 4463 => Predicted: 1\n",
      "Row 4464 => Predicted: 0\n",
      "Row 4465 => Predicted: 0\n",
      "Row 4466 => Predicted: 1\n",
      "Row 4467 => Predicted: 0\n",
      "Row 4468 => Predicted: 0\n",
      "Row 4469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4460 to 4469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4470 => Predicted: 0\n",
      "Row 4471 => Predicted: 0\n",
      "Row 4472 => Predicted: 1\n",
      "Row 4473 => Predicted: 0\n",
      "Row 4474 => Predicted: 1\n",
      "Row 4475 => Predicted: 1\n",
      "Row 4476 => Predicted: 0\n",
      "Row 4477 => Predicted: 1\n",
      "Row 4478 => Predicted: 1\n",
      "Row 4479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4470 to 4479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4480 => Predicted: 0\n",
      "Row 4481 => Predicted: 0\n",
      "Row 4482 => Predicted: 0\n",
      "Row 4483 => Predicted: 1\n",
      "Row 4484 => Predicted: 1\n",
      "Row 4485 => Predicted: 0\n",
      "Row 4486 => Predicted: 1\n",
      "Row 4487 => Predicted: 0\n",
      "Row 4488 => Predicted: 0\n",
      "Row 4489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4480 to 4489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4490 => Predicted: 1\n",
      "Row 4491 => Predicted: 1\n",
      "Row 4492 => Predicted: 0\n",
      "Row 4493 => Predicted: 0\n",
      "Row 4494 => Predicted: 0\n",
      "Row 4495 => Predicted: 0\n",
      "Row 4496 => Predicted: 1\n",
      "Row 4497 => Predicted: 1\n",
      "Row 4498 => Predicted: 0\n",
      "Row 4499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4490 to 4499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4500 => Predicted: 0\n",
      "Row 4501 => Predicted: 0\n",
      "Row 4502 => Predicted: 1\n",
      "Row 4503 => Predicted: 1\n",
      "Row 4504 => Predicted: 1\n",
      "Row 4505 => Predicted: 1\n",
      "Row 4506 => Predicted: 0\n",
      "Row 4507 => Predicted: 1\n",
      "Row 4508 => Predicted: 1\n",
      "Row 4509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4500 to 4509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4510 => Predicted: 0\n",
      "Row 4511 => Predicted: 0\n",
      "Row 4512 => Predicted: 1\n",
      "Row 4513 => Predicted: 0\n",
      "Row 4514 => Predicted: 0\n",
      "Row 4515 => Predicted: 1\n",
      "Row 4516 => Predicted: 0\n",
      "Row 4517 => Predicted: 1\n",
      "Row 4518 => Predicted: 1\n",
      "Row 4519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4510 to 4519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4520 => Predicted: 1\n",
      "Row 4521 => Predicted: 1\n",
      "Row 4522 => Predicted: 1\n",
      "Row 4523 => Predicted: 0\n",
      "Row 4524 => Predicted: 1\n",
      "Row 4525 => Predicted: 0\n",
      "Row 4526 => Predicted: 1\n",
      "Row 4527 => Predicted: 0\n",
      "Row 4528 => Predicted: 1\n",
      "Row 4529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4520 to 4529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4530 => Predicted: 1\n",
      "Row 4531 => Predicted: 1\n",
      "Row 4532 => Predicted: 1\n",
      "Row 4533 => Predicted: 0\n",
      "Row 4534 => Predicted: 0\n",
      "Row 4535 => Predicted: 0\n",
      "Row 4536 => Predicted: 0\n",
      "Row 4537 => Predicted: 0\n",
      "Row 4538 => Predicted: 0\n",
      "Row 4539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4530 to 4539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4540 => Predicted: 1\n",
      "Row 4541 => Predicted: 1\n",
      "Row 4542 => Predicted: 1\n",
      "Row 4543 => Predicted: 1\n",
      "Row 4544 => Predicted: 0\n",
      "Row 4545 => Predicted: 0\n",
      "Row 4546 => Predicted: 0\n",
      "Row 4547 => Predicted: 0\n",
      "Row 4548 => Predicted: 1\n",
      "Row 4549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4540 to 4549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4550 => Predicted: 1\n",
      "Row 4551 => Predicted: 1\n",
      "Row 4552 => Predicted: 1\n",
      "Row 4553 => Predicted: 0\n",
      "Row 4554 => Predicted: 0\n",
      "Row 4555 => Predicted: 0\n",
      "Row 4556 => Predicted: 1\n",
      "Row 4557 => Predicted: 1\n",
      "Row 4558 => Predicted: 0\n",
      "Row 4559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4550 to 4559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4560 => Predicted: 0\n",
      "Row 4561 => Predicted: 1\n",
      "Row 4562 => Predicted: 0\n",
      "Row 4563 => Predicted: 0\n",
      "Row 4564 => Predicted: 0\n",
      "Row 4565 => Predicted: 0\n",
      "Row 4566 => Predicted: 0\n",
      "Row 4567 => Predicted: 1\n",
      "Row 4568 => Predicted: 1\n",
      "Row 4569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4560 to 4569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4570 => Predicted: 0\n",
      "Row 4571 => Predicted: 0\n",
      "Row 4572 => Predicted: 1\n",
      "Row 4573 => Predicted: 1\n",
      "Row 4574 => Predicted: 0\n",
      "Row 4575 => Predicted: 1\n",
      "Row 4576 => Predicted: 0\n",
      "Row 4577 => Predicted: 1\n",
      "Row 4578 => Predicted: 1\n",
      "Row 4579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4570 to 4579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4580 => Predicted: 0\n",
      "Row 4581 => Predicted: 0\n",
      "Row 4582 => Predicted: 0\n",
      "Row 4583 => Predicted: 1\n",
      "Row 4584 => Predicted: 1\n",
      "Row 4585 => Predicted: 0\n",
      "Row 4586 => Predicted: 1\n",
      "Row 4587 => Predicted: 1\n",
      "Row 4588 => Predicted: 1\n",
      "Row 4589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4580 to 4589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4590 => Predicted: 0\n",
      "Row 4591 => Predicted: 1\n",
      "Row 4592 => Predicted: 1\n",
      "Row 4593 => Predicted: 1\n",
      "Row 4594 => Predicted: 0\n",
      "Row 4595 => Predicted: 1\n",
      "Row 4596 => Predicted: 0\n",
      "Row 4597 => Predicted: 0\n",
      "Row 4598 => Predicted: 1\n",
      "Row 4599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4590 to 4599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4600 => Predicted: 1\n",
      "Row 4601 => Predicted: 0\n",
      "Row 4602 => Predicted: 0\n",
      "Row 4603 => Predicted: 1\n",
      "Row 4604 => Predicted: 1\n",
      "Row 4605 => Predicted: 1\n",
      "Row 4606 => Predicted: 0\n",
      "Row 4607 => Predicted: 0\n",
      "Row 4608 => Predicted: 0\n",
      "Row 4609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4600 to 4609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4610 => Predicted: 0\n",
      "Row 4611 => Predicted: 1\n",
      "Row 4612 => Predicted: 1\n",
      "Row 4613 => Predicted: 0\n",
      "Row 4614 => Predicted: 0\n",
      "Row 4615 => Predicted: 0\n",
      "Row 4616 => Predicted: 0\n",
      "Row 4617 => Predicted: 0\n",
      "Row 4618 => Predicted: 0\n",
      "Row 4619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4610 to 4619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4620 => Predicted: 1\n",
      "Row 4621 => Predicted: 1\n",
      "Row 4622 => Predicted: 1\n",
      "Row 4623 => Predicted: 1\n",
      "Row 4624 => Predicted: 0\n",
      "Row 4625 => Predicted: 0\n",
      "Row 4626 => Predicted: 1\n",
      "Row 4627 => Predicted: 1\n",
      "Row 4628 => Predicted: 1\n",
      "Row 4629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4620 to 4629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4630 => Predicted: 1\n",
      "Row 4631 => Predicted: 1\n",
      "Row 4632 => Predicted: 1\n",
      "Row 4633 => Predicted: 1\n",
      "Row 4634 => Predicted: 0\n",
      "Row 4635 => Predicted: 1\n",
      "Row 4636 => Predicted: 0\n",
      "Row 4637 => Predicted: 1\n",
      "Row 4638 => Predicted: 1\n",
      "Row 4639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4630 to 4639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4640 => Predicted: 1\n",
      "Row 4641 => Predicted: 1\n",
      "Row 4642 => Predicted: 0\n",
      "Row 4643 => Predicted: 1\n",
      "Row 4644 => Predicted: 1\n",
      "Row 4645 => Predicted: 0\n",
      "Row 4646 => Predicted: 0\n",
      "Row 4647 => Predicted: 1\n",
      "Row 4648 => Predicted: 0\n",
      "Row 4649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4640 to 4649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4650 => Predicted: 0\n",
      "Row 4651 => Predicted: 1\n",
      "Row 4652 => Predicted: 0\n",
      "Row 4653 => Predicted: 0\n",
      "Row 4654 => Predicted: 1\n",
      "Row 4655 => Predicted: 1\n",
      "Row 4656 => Predicted: 0\n",
      "Row 4657 => Predicted: 0\n",
      "Row 4658 => Predicted: 1\n",
      "Row 4659 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4650 to 4659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4660 => Predicted: 0\n",
      "Row 4661 => Predicted: 1\n",
      "Row 4662 => Predicted: 1\n",
      "Row 4663 => Predicted: 0\n",
      "Row 4664 => Predicted: 1\n",
      "Row 4665 => Predicted: 1\n",
      "Row 4666 => Predicted: 1\n",
      "Row 4667 => Predicted: 0\n",
      "Row 4668 => Predicted: 1\n",
      "Row 4669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4660 to 4669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4670 => Predicted: 0\n",
      "Row 4671 => Predicted: 0\n",
      "Row 4672 => Predicted: 1\n",
      "Row 4673 => Predicted: 0\n",
      "Row 4674 => Predicted: 0\n",
      "Row 4675 => Predicted: 1\n",
      "Row 4676 => Predicted: 1\n",
      "Row 4677 => Predicted: 0\n",
      "Row 4678 => Predicted: 0\n",
      "Row 4679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4670 to 4679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4680 => Predicted: 0\n",
      "Row 4681 => Predicted: 0\n",
      "Row 4682 => Predicted: 0\n",
      "Row 4683 => Predicted: 1\n",
      "Row 4684 => Predicted: 0\n",
      "Row 4685 => Predicted: 1\n",
      "Row 4686 => Predicted: 1\n",
      "Row 4687 => Predicted: 1\n",
      "Row 4688 => Predicted: 0\n",
      "Row 4689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4680 to 4689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4690 => Predicted: 1\n",
      "Row 4691 => Predicted: 1\n",
      "Row 4692 => Predicted: 0\n",
      "Row 4693 => Predicted: 0\n",
      "Row 4694 => Predicted: 1\n",
      "Row 4695 => Predicted: 0\n",
      "Row 4696 => Predicted: 0\n",
      "Row 4697 => Predicted: 1\n",
      "Row 4698 => Predicted: 0\n",
      "Row 4699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4690 to 4699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4700 => Predicted: 0\n",
      "Row 4701 => Predicted: 1\n",
      "Row 4702 => Predicted: 0\n",
      "Row 4703 => Predicted: 0\n",
      "Row 4704 => Predicted: 1\n",
      "Row 4705 => Predicted: 0\n",
      "Row 4706 => Predicted: 0\n",
      "Row 4707 => Predicted: 1\n",
      "Row 4708 => Predicted: 1\n",
      "Row 4709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4700 to 4709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4710 => Predicted: 0\n",
      "Row 4711 => Predicted: 1\n",
      "Row 4712 => Predicted: 1\n",
      "Row 4713 => Predicted: 1\n",
      "Row 4714 => Predicted: 1\n",
      "Row 4715 => Predicted: 0\n",
      "Row 4716 => Predicted: 0\n",
      "Row 4717 => Predicted: 0\n",
      "Row 4718 => Predicted: 0\n",
      "Row 4719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4710 to 4719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4720 => Predicted: 0\n",
      "Row 4721 => Predicted: 0\n",
      "Row 4722 => Predicted: 0\n",
      "Row 4723 => Predicted: 0\n",
      "Row 4724 => Predicted: 0\n",
      "Row 4725 => Predicted: 1\n",
      "Row 4726 => Predicted: 1\n",
      "Row 4727 => Predicted: 1\n",
      "Row 4728 => Predicted: 0\n",
      "Row 4729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4720 to 4729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4730 => Predicted: 0\n",
      "Row 4731 => Predicted: 1\n",
      "Row 4732 => Predicted: 0\n",
      "Row 4733 => Predicted: 0\n",
      "Row 4734 => Predicted: 1\n",
      "Row 4735 => Predicted: 0\n",
      "Row 4736 => Predicted: 0\n",
      "Row 4737 => Predicted: 0\n",
      "Row 4738 => Predicted: 1\n",
      "Row 4739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4730 to 4739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4740 => Predicted: 0\n",
      "Row 4741 => Predicted: 1\n",
      "Row 4742 => Predicted: 1\n",
      "Row 4743 => Predicted: 0\n",
      "Row 4744 => Predicted: 0\n",
      "Row 4745 => Predicted: 0\n",
      "Row 4746 => Predicted: 1\n",
      "Row 4747 => Predicted: 0\n",
      "Row 4748 => Predicted: 0\n",
      "Row 4749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4740 to 4749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4750 => Predicted: 0\n",
      "Row 4751 => Predicted: 0\n",
      "Row 4752 => Predicted: 0\n",
      "Row 4753 => Predicted: 0\n",
      "Row 4754 => Predicted: 0\n",
      "Row 4755 => Predicted: 1\n",
      "Row 4756 => Predicted: 1\n",
      "Row 4757 => Predicted: 1\n",
      "Row 4758 => Predicted: 0\n",
      "Row 4759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4750 to 4759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4760 => Predicted: 1\n",
      "Row 4761 => Predicted: 0\n",
      "Row 4762 => Predicted: 0\n",
      "Row 4763 => Predicted: 1\n",
      "Row 4764 => Predicted: 1\n",
      "Row 4765 => Predicted: 0\n",
      "Row 4766 => Predicted: 1\n",
      "Row 4767 => Predicted: 1\n",
      "Row 4768 => Predicted: 1\n",
      "Row 4769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4760 to 4769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4770 => Predicted: 0\n",
      "Row 4771 => Predicted: 0\n",
      "Row 4772 => Predicted: 1\n",
      "Row 4773 => Predicted: 0\n",
      "Row 4774 => Predicted: 1\n",
      "Row 4775 => Predicted: 0\n",
      "Row 4776 => Predicted: 0\n",
      "Row 4777 => Predicted: 0\n",
      "Row 4778 => Predicted: 1\n",
      "Row 4779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4770 to 4779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4780 => Predicted: 0\n",
      "Row 4781 => Predicted: 0\n",
      "Row 4782 => Predicted: 0\n",
      "Row 4783 => Predicted: 0\n",
      "Row 4784 => Predicted: 0\n",
      "Row 4785 => Predicted: 1\n",
      "Row 4786 => Predicted: 1\n",
      "Row 4787 => Predicted: 0\n",
      "Row 4788 => Predicted: 1\n",
      "Row 4789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4780 to 4789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4790 => Predicted: 1\n",
      "Row 4791 => Predicted: 1\n",
      "Row 4792 => Predicted: 0\n",
      "Row 4793 => Predicted: 0\n",
      "Row 4794 => Predicted: 0\n",
      "Row 4795 => Predicted: 1\n",
      "Row 4796 => Predicted: 0\n",
      "Row 4797 => Predicted: 1\n",
      "Row 4798 => Predicted: 0\n",
      "Row 4799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4790 to 4799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4800 => Predicted: 0\n",
      "Row 4801 => Predicted: 0\n",
      "Row 4802 => Predicted: 1\n",
      "Row 4803 => Predicted: 1\n",
      "Row 4804 => Predicted: 1\n",
      "Row 4805 => Predicted: 0\n",
      "Row 4806 => Predicted: 0\n",
      "Row 4807 => Predicted: 0\n",
      "Row 4808 => Predicted: 0\n",
      "Row 4809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4800 to 4809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4810 => Predicted: 1\n",
      "Row 4811 => Predicted: 1\n",
      "Row 4812 => Predicted: 0\n",
      "Row 4813 => Predicted: 1\n",
      "Row 4814 => Predicted: 0\n",
      "Row 4815 => Predicted: 1\n",
      "Row 4816 => Predicted: 1\n",
      "Row 4817 => Predicted: 0\n",
      "Row 4818 => Predicted: 0\n",
      "Row 4819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4810 to 4819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4820 => Predicted: 1\n",
      "Row 4821 => Predicted: 1\n",
      "Row 4822 => Predicted: 1\n",
      "Row 4823 => Predicted: 1\n",
      "Row 4824 => Predicted: 1\n",
      "Row 4825 => Predicted: 1\n",
      "Row 4826 => Predicted: 0\n",
      "Row 4827 => Predicted: 1\n",
      "Row 4828 => Predicted: 1\n",
      "Row 4829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4820 to 4829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4830 => Predicted: 0\n",
      "Row 4831 => Predicted: 1\n",
      "Row 4832 => Predicted: 0\n",
      "Row 4833 => Predicted: 1\n",
      "Row 4834 => Predicted: 0\n",
      "Row 4835 => Predicted: 0\n",
      "Row 4836 => Predicted: 0\n",
      "Row 4837 => Predicted: 0\n",
      "Row 4838 => Predicted: 0\n",
      "Row 4839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4830 to 4839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4840 => Predicted: 1\n",
      "Row 4841 => Predicted: 0\n",
      "Row 4842 => Predicted: 1\n",
      "Row 4843 => Predicted: 0\n",
      "Row 4844 => Predicted: 0\n",
      "Row 4845 => Predicted: 1\n",
      "Row 4846 => Predicted: 1\n",
      "Row 4847 => Predicted: 1\n",
      "Row 4848 => Predicted: 0\n",
      "Row 4849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4840 to 4849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4850 => Predicted: 0\n",
      "Row 4851 => Predicted: 1\n",
      "Row 4852 => Predicted: 1\n",
      "Row 4853 => Predicted: 0\n",
      "Row 4854 => Predicted: 1\n",
      "Row 4855 => Predicted: 1\n",
      "Row 4856 => Predicted: 1\n",
      "Row 4857 => Predicted: 1\n",
      "Row 4858 => Predicted: 1\n",
      "Row 4859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4850 to 4859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4860 => Predicted: 1\n",
      "Row 4861 => Predicted: 1\n",
      "Row 4862 => Predicted: 0\n",
      "Row 4863 => Predicted: 0\n",
      "Row 4864 => Predicted: 1\n",
      "Row 4865 => Predicted: 0\n",
      "Row 4866 => Predicted: 0\n",
      "Row 4867 => Predicted: 1\n",
      "Row 4868 => Predicted: 0\n",
      "Row 4869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4860 to 4869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4870 => Predicted: 1\n",
      "Row 4871 => Predicted: 1\n",
      "Row 4872 => Predicted: 1\n",
      "Row 4873 => Predicted: 1\n",
      "Row 4874 => Predicted: 1\n",
      "Row 4875 => Predicted: 1\n",
      "Row 4876 => Predicted: 0\n",
      "Row 4877 => Predicted: 0\n",
      "Row 4878 => Predicted: 0\n",
      "Row 4879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4870 to 4879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4880 => Predicted: 0\n",
      "Row 4881 => Predicted: 1\n",
      "Row 4882 => Predicted: 1\n",
      "Row 4883 => Predicted: 0\n",
      "Row 4884 => Predicted: 1\n",
      "Row 4885 => Predicted: 0\n",
      "Row 4886 => Predicted: 0\n",
      "Row 4887 => Predicted: 1\n",
      "Row 4888 => Predicted: 1\n",
      "Row 4889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4880 to 4889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4890 => Predicted: 0\n",
      "Row 4891 => Predicted: 1\n",
      "Row 4892 => Predicted: 0\n",
      "Row 4893 => Predicted: 1\n",
      "Row 4894 => Predicted: 1\n",
      "Row 4895 => Predicted: 1\n",
      "Row 4896 => Predicted: 0\n",
      "Row 4897 => Predicted: 1\n",
      "Row 4898 => Predicted: 1\n",
      "Row 4899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4890 to 4899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4900 => Predicted: 0\n",
      "Row 4901 => Predicted: 1\n",
      "Row 4902 => Predicted: 0\n",
      "Row 4903 => Predicted: 0\n",
      "Row 4904 => Predicted: 0\n",
      "Row 4905 => Predicted: 0\n",
      "Row 4906 => Predicted: 1\n",
      "Row 4907 => Predicted: 0\n",
      "Row 4908 => Predicted: 1\n",
      "Row 4909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4900 to 4909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4910 => Predicted: 0\n",
      "Row 4911 => Predicted: 0\n",
      "Row 4912 => Predicted: 1\n",
      "Row 4913 => Predicted: 1\n",
      "Row 4914 => Predicted: 1\n",
      "Row 4915 => Predicted: 1\n",
      "Row 4916 => Predicted: 1\n",
      "Row 4917 => Predicted: 1\n",
      "Row 4918 => Predicted: 1\n",
      "Row 4919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4910 to 4919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4920 => Predicted: 1\n",
      "Row 4921 => Predicted: 1\n",
      "Row 4922 => Predicted: 1\n",
      "Row 4923 => Predicted: 1\n",
      "Row 4924 => Predicted: 0\n",
      "Row 4925 => Predicted: 0\n",
      "Row 4926 => Predicted: 1\n",
      "Row 4927 => Predicted: 1\n",
      "Row 4928 => Predicted: 0\n",
      "Row 4929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4920 to 4929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4930 => Predicted: 1\n",
      "Row 4931 => Predicted: 1\n",
      "Row 4932 => Predicted: 1\n",
      "Row 4933 => Predicted: 1\n",
      "Row 4934 => Predicted: 0\n",
      "Row 4935 => Predicted: 1\n",
      "Row 4936 => Predicted: 0\n",
      "Row 4937 => Predicted: 1\n",
      "Row 4938 => Predicted: 1\n",
      "Row 4939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4930 to 4939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4940 => Predicted: 0\n",
      "Row 4941 => Predicted: 0\n",
      "Row 4942 => Predicted: 0\n",
      "Row 4943 => Predicted: 1\n",
      "Row 4944 => Predicted: 1\n",
      "Row 4945 => Predicted: 0\n",
      "Row 4946 => Predicted: 0\n",
      "Row 4947 => Predicted: 0\n",
      "Row 4948 => Predicted: 0\n",
      "Row 4949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4940 to 4949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4950 => Predicted: 0\n",
      "Row 4951 => Predicted: 1\n",
      "Row 4952 => Predicted: 1\n",
      "Row 4953 => Predicted: 1\n",
      "Row 4954 => Predicted: 0\n",
      "Row 4955 => Predicted: 0\n",
      "Row 4956 => Predicted: 0\n",
      "Row 4957 => Predicted: 1\n",
      "Row 4958 => Predicted: 1\n",
      "Row 4959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4950 to 4959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4960 => Predicted: 0\n",
      "Row 4961 => Predicted: 0\n",
      "Row 4962 => Predicted: 1\n",
      "Row 4963 => Predicted: 0\n",
      "Row 4964 => Predicted: 1\n",
      "Row 4965 => Predicted: 0\n",
      "Row 4966 => Predicted: 1\n",
      "Row 4967 => Predicted: 1\n",
      "Row 4968 => Predicted: 0\n",
      "Row 4969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4960 to 4969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4970 => Predicted: 1\n",
      "Row 4971 => Predicted: 0\n",
      "Row 4972 => Predicted: 1\n",
      "Row 4973 => Predicted: 1\n",
      "Row 4974 => Predicted: 0\n",
      "Row 4975 => Predicted: 0\n",
      "Row 4976 => Predicted: 0\n",
      "Row 4977 => Predicted: 1\n",
      "Row 4978 => Predicted: 0\n",
      "Row 4979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 4970 to 4979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4980 => Predicted: 0\n",
      "Row 4981 => Predicted: 1\n",
      "Row 4982 => Predicted: 0\n",
      "Row 4983 => Predicted: 0\n",
      "Row 4984 => Predicted: 1\n",
      "Row 4985 => Predicted: 0\n",
      "Row 4986 => Predicted: 0\n",
      "Row 4987 => Predicted: 0\n",
      "Row 4988 => Predicted: 0\n",
      "Row 4989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4980 to 4989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4990 => Predicted: 0\n",
      "Row 4991 => Predicted: 1\n",
      "Row 4992 => Predicted: 1\n",
      "Row 4993 => Predicted: 0\n",
      "Row 4994 => Predicted: 1\n",
      "Row 4995 => Predicted: 0\n",
      "Row 4996 => Predicted: 0\n",
      "Row 4997 => Predicted: 1\n",
      "Row 4998 => Predicted: 1\n",
      "Row 4999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 4990 to 4999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5000 => Predicted: 1\n",
      "Row 5001 => Predicted: 0\n",
      "Row 5002 => Predicted: 0\n",
      "Row 5003 => Predicted: 1\n",
      "Row 5004 => Predicted: 1\n",
      "Row 5005 => Predicted: 0\n",
      "Row 5006 => Predicted: 1\n",
      "Row 5007 => Predicted: 1\n",
      "Row 5008 => Predicted: 1\n",
      "Row 5009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5000 to 5009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5010 => Predicted: 1\n",
      "Row 5011 => Predicted: 1\n",
      "Row 5012 => Predicted: 1\n",
      "Row 5013 => Predicted: 0\n",
      "Row 5014 => Predicted: 0\n",
      "Row 5015 => Predicted: 1\n",
      "Row 5016 => Predicted: 1\n",
      "Row 5017 => Predicted: 0\n",
      "Row 5018 => Predicted: 1\n",
      "Row 5019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5010 to 5019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5020 => Predicted: 0\n",
      "Row 5021 => Predicted: 1\n",
      "Row 5022 => Predicted: 0\n",
      "Row 5023 => Predicted: 1\n",
      "Row 5024 => Predicted: 0\n",
      "Row 5025 => Predicted: 1\n",
      "Row 5026 => Predicted: 0\n",
      "Row 5027 => Predicted: 0\n",
      "Row 5028 => Predicted: 0\n",
      "Row 5029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5020 to 5029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5030 => Predicted: 0\n",
      "Row 5031 => Predicted: 0\n",
      "Row 5032 => Predicted: 0\n",
      "Row 5033 => Predicted: 0\n",
      "Row 5034 => Predicted: 0\n",
      "Row 5035 => Predicted: 0\n",
      "Row 5036 => Predicted: 1\n",
      "Row 5037 => Predicted: 0\n",
      "Row 5038 => Predicted: 0\n",
      "Row 5039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5030 to 5039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5040 => Predicted: 1\n",
      "Row 5041 => Predicted: 0\n",
      "Row 5042 => Predicted: 0\n",
      "Row 5043 => Predicted: 1\n",
      "Row 5044 => Predicted: 1\n",
      "Row 5045 => Predicted: 1\n",
      "Row 5046 => Predicted: 1\n",
      "Row 5047 => Predicted: 0\n",
      "Row 5048 => Predicted: 1\n",
      "Row 5049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5040 to 5049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5050 => Predicted: 1\n",
      "Row 5051 => Predicted: 0\n",
      "Row 5052 => Predicted: 1\n",
      "Row 5053 => Predicted: 0\n",
      "Row 5054 => Predicted: 0\n",
      "Row 5055 => Predicted: 1\n",
      "Row 5056 => Predicted: 1\n",
      "Row 5057 => Predicted: 1\n",
      "Row 5058 => Predicted: 0\n",
      "Row 5059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5050 to 5059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5060 => Predicted: 1\n",
      "Row 5061 => Predicted: 0\n",
      "Row 5062 => Predicted: 1\n",
      "Row 5063 => Predicted: 0\n",
      "Row 5064 => Predicted: 0\n",
      "Row 5065 => Predicted: 0\n",
      "Row 5066 => Predicted: 1\n",
      "Row 5067 => Predicted: 1\n",
      "Row 5068 => Predicted: 0\n",
      "Row 5069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5060 to 5069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5070 => Predicted: 1\n",
      "Row 5071 => Predicted: 1\n",
      "Row 5072 => Predicted: 0\n",
      "Row 5073 => Predicted: 0\n",
      "Row 5074 => Predicted: 1\n",
      "Row 5075 => Predicted: 1\n",
      "Row 5076 => Predicted: 1\n",
      "Row 5077 => Predicted: 1\n",
      "Row 5078 => Predicted: 1\n",
      "Row 5079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5070 to 5079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5080 => Predicted: 0\n",
      "Row 5081 => Predicted: 1\n",
      "Row 5082 => Predicted: 1\n",
      "Row 5083 => Predicted: 0\n",
      "Row 5084 => Predicted: 1\n",
      "Row 5085 => Predicted: 1\n",
      "Row 5086 => Predicted: 1\n",
      "Row 5087 => Predicted: 1\n",
      "Row 5088 => Predicted: 1\n",
      "Row 5089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5080 to 5089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5090 => Predicted: 1\n",
      "Row 5091 => Predicted: 0\n",
      "Row 5092 => Predicted: 1\n",
      "Row 5093 => Predicted: 1\n",
      "Row 5094 => Predicted: 0\n",
      "Row 5095 => Predicted: 1\n",
      "Row 5096 => Predicted: 1\n",
      "Row 5097 => Predicted: 1\n",
      "Row 5098 => Predicted: 1\n",
      "Row 5099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5090 to 5099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5100 => Predicted: 0\n",
      "Row 5101 => Predicted: 1\n",
      "Row 5102 => Predicted: 0\n",
      "Row 5103 => Predicted: 0\n",
      "Row 5104 => Predicted: 0\n",
      "Row 5105 => Predicted: 0\n",
      "Row 5106 => Predicted: 0\n",
      "Row 5107 => Predicted: 0\n",
      "Row 5108 => Predicted: 1\n",
      "Row 5109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5100 to 5109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5110 => Predicted: 0\n",
      "Row 5111 => Predicted: 1\n",
      "Row 5112 => Predicted: 1\n",
      "Row 5113 => Predicted: 0\n",
      "Row 5114 => Predicted: 1\n",
      "Row 5115 => Predicted: 1\n",
      "Row 5116 => Predicted: 0\n",
      "Row 5117 => Predicted: 1\n",
      "Row 5118 => Predicted: 0\n",
      "Row 5119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5110 to 5119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5120 => Predicted: 0\n",
      "Row 5121 => Predicted: 1\n",
      "Row 5122 => Predicted: 1\n",
      "Row 5123 => Predicted: 1\n",
      "Row 5124 => Predicted: 0\n",
      "Row 5125 => Predicted: 1\n",
      "Row 5126 => Predicted: 1\n",
      "Row 5127 => Predicted: 1\n",
      "Row 5128 => Predicted: 1\n",
      "Row 5129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5120 to 5129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5130 => Predicted: 0\n",
      "Row 5131 => Predicted: 0\n",
      "Row 5132 => Predicted: 1\n",
      "Row 5133 => Predicted: 1\n",
      "Row 5134 => Predicted: 1\n",
      "Row 5135 => Predicted: 1\n",
      "Row 5136 => Predicted: 0\n",
      "Row 5137 => Predicted: 0\n",
      "Row 5138 => Predicted: 0\n",
      "Row 5139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5130 to 5139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5140 => Predicted: 0\n",
      "Row 5141 => Predicted: 0\n",
      "Row 5142 => Predicted: 0\n",
      "Row 5143 => Predicted: 0\n",
      "Row 5144 => Predicted: 0\n",
      "Row 5145 => Predicted: 1\n",
      "Row 5146 => Predicted: 0\n",
      "Row 5147 => Predicted: 1\n",
      "Row 5148 => Predicted: 0\n",
      "Row 5149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5140 to 5149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5150 => Predicted: 1\n",
      "Row 5151 => Predicted: 1\n",
      "Row 5152 => Predicted: 0\n",
      "Row 5153 => Predicted: 1\n",
      "Row 5154 => Predicted: 0\n",
      "Row 5155 => Predicted: 0\n",
      "Row 5156 => Predicted: 1\n",
      "Row 5157 => Predicted: 0\n",
      "Row 5158 => Predicted: 1\n",
      "Row 5159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5150 to 5159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5160 => Predicted: 0\n",
      "Row 5161 => Predicted: 1\n",
      "Row 5162 => Predicted: 0\n",
      "Row 5163 => Predicted: 0\n",
      "Row 5164 => Predicted: 1\n",
      "Row 5165 => Predicted: 0\n",
      "Row 5166 => Predicted: 1\n",
      "Row 5167 => Predicted: 0\n",
      "Row 5168 => Predicted: 0\n",
      "Row 5169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5160 to 5169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5170 => Predicted: 0\n",
      "Row 5171 => Predicted: 0\n",
      "Row 5172 => Predicted: 1\n",
      "Row 5173 => Predicted: 1\n",
      "Row 5174 => Predicted: 1\n",
      "Row 5175 => Predicted: 1\n",
      "Row 5176 => Predicted: 0\n",
      "Row 5177 => Predicted: 0\n",
      "Row 5178 => Predicted: 1\n",
      "Row 5179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5170 to 5179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5180 => Predicted: 1\n",
      "Row 5181 => Predicted: 0\n",
      "Row 5182 => Predicted: 0\n",
      "Row 5183 => Predicted: 0\n",
      "Row 5184 => Predicted: 1\n",
      "Row 5185 => Predicted: 0\n",
      "Row 5186 => Predicted: 1\n",
      "Row 5187 => Predicted: 0\n",
      "Row 5188 => Predicted: 1\n",
      "Row 5189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5180 to 5189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5190 => Predicted: 1\n",
      "Row 5191 => Predicted: 0\n",
      "Row 5192 => Predicted: 1\n",
      "Row 5193 => Predicted: 0\n",
      "Row 5194 => Predicted: 0\n",
      "Row 5195 => Predicted: 1\n",
      "Row 5196 => Predicted: 0\n",
      "Row 5197 => Predicted: 0\n",
      "Row 5198 => Predicted: 1\n",
      "Row 5199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5190 to 5199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5200 => Predicted: 1\n",
      "Row 5201 => Predicted: 0\n",
      "Row 5202 => Predicted: 1\n",
      "Row 5203 => Predicted: 1\n",
      "Row 5204 => Predicted: 1\n",
      "Row 5205 => Predicted: 1\n",
      "Row 5206 => Predicted: 0\n",
      "Row 5207 => Predicted: 0\n",
      "Row 5208 => Predicted: 0\n",
      "Row 5209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5200 to 5209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5210 => Predicted: 0\n",
      "Row 5211 => Predicted: 1\n",
      "Row 5212 => Predicted: 1\n",
      "Row 5213 => Predicted: 0\n",
      "Row 5214 => Predicted: 0\n",
      "Row 5215 => Predicted: 0\n",
      "Row 5216 => Predicted: 1\n",
      "Row 5217 => Predicted: 0\n",
      "Row 5218 => Predicted: 1\n",
      "Row 5219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5210 to 5219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5220 => Predicted: 1\n",
      "Row 5221 => Predicted: 0\n",
      "Row 5222 => Predicted: 0\n",
      "Row 5223 => Predicted: 0\n",
      "Row 5224 => Predicted: 0\n",
      "Row 5225 => Predicted: 1\n",
      "Row 5226 => Predicted: 0\n",
      "Row 5227 => Predicted: 1\n",
      "Row 5228 => Predicted: 0\n",
      "Row 5229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5220 to 5229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5230 => Predicted: 1\n",
      "Row 5231 => Predicted: 1\n",
      "Row 5232 => Predicted: 0\n",
      "Row 5233 => Predicted: 1\n",
      "Row 5234 => Predicted: 1\n",
      "Row 5235 => Predicted: 1\n",
      "Row 5236 => Predicted: 0\n",
      "Row 5237 => Predicted: 1\n",
      "Row 5238 => Predicted: 1\n",
      "Row 5239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5230 to 5239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5240 => Predicted: 1\n",
      "Row 5241 => Predicted: 1\n",
      "Row 5242 => Predicted: 0\n",
      "Row 5243 => Predicted: 0\n",
      "Row 5244 => Predicted: 1\n",
      "Row 5245 => Predicted: 0\n",
      "Row 5246 => Predicted: 1\n",
      "Row 5247 => Predicted: 1\n",
      "Row 5248 => Predicted: 1\n",
      "Row 5249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5240 to 5249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5250 => Predicted: 1\n",
      "Row 5251 => Predicted: 1\n",
      "Row 5252 => Predicted: 0\n",
      "Row 5253 => Predicted: 0\n",
      "Row 5254 => Predicted: 1\n",
      "Row 5255 => Predicted: 1\n",
      "Row 5256 => Predicted: 0\n",
      "Row 5257 => Predicted: 0\n",
      "Row 5258 => Predicted: 1\n",
      "Row 5259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5250 to 5259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5260 => Predicted: 0\n",
      "Row 5261 => Predicted: 0\n",
      "Row 5262 => Predicted: 0\n",
      "Row 5263 => Predicted: 1\n",
      "Row 5264 => Predicted: 1\n",
      "Row 5265 => Predicted: 0\n",
      "Row 5266 => Predicted: 1\n",
      "Row 5267 => Predicted: 0\n",
      "Row 5268 => Predicted: 1\n",
      "Row 5269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5260 to 5269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5270 => Predicted: 1\n",
      "Row 5271 => Predicted: 0\n",
      "Row 5272 => Predicted: 0\n",
      "Row 5273 => Predicted: 0\n",
      "Row 5274 => Predicted: 1\n",
      "Row 5275 => Predicted: 0\n",
      "Row 5276 => Predicted: 1\n",
      "Row 5277 => Predicted: 1\n",
      "Row 5278 => Predicted: 0\n",
      "Row 5279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5270 to 5279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5280 => Predicted: 0\n",
      "Row 5281 => Predicted: 0\n",
      "Row 5282 => Predicted: 1\n",
      "Row 5283 => Predicted: 1\n",
      "Row 5284 => Predicted: 1\n",
      "Row 5285 => Predicted: 1\n",
      "Row 5286 => Predicted: 1\n",
      "Row 5287 => Predicted: 0\n",
      "Row 5288 => Predicted: 0\n",
      "Row 5289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5280 to 5289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5290 => Predicted: 0\n",
      "Row 5291 => Predicted: 1\n",
      "Row 5292 => Predicted: 1\n",
      "Row 5293 => Predicted: 0\n",
      "Row 5294 => Predicted: 0\n",
      "Row 5295 => Predicted: 0\n",
      "Row 5296 => Predicted: 1\n",
      "Row 5297 => Predicted: 1\n",
      "Row 5298 => Predicted: 0\n",
      "Row 5299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5290 to 5299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5300 => Predicted: 0\n",
      "Row 5301 => Predicted: 0\n",
      "Row 5302 => Predicted: 0\n",
      "Row 5303 => Predicted: 0\n",
      "Row 5304 => Predicted: 1\n",
      "Row 5305 => Predicted: 1\n",
      "Row 5306 => Predicted: 0\n",
      "Row 5307 => Predicted: 1\n",
      "Row 5308 => Predicted: 1\n",
      "Row 5309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5300 to 5309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5310 => Predicted: 1\n",
      "Row 5311 => Predicted: 0\n",
      "Row 5312 => Predicted: 0\n",
      "Row 5313 => Predicted: 1\n",
      "Row 5314 => Predicted: 1\n",
      "Row 5315 => Predicted: 1\n",
      "Row 5316 => Predicted: 0\n",
      "Row 5317 => Predicted: 1\n",
      "Row 5318 => Predicted: 0\n",
      "Row 5319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5310 to 5319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5320 => Predicted: 0\n",
      "Row 5321 => Predicted: 1\n",
      "Row 5322 => Predicted: 1\n",
      "Row 5323 => Predicted: 0\n",
      "Row 5324 => Predicted: 1\n",
      "Row 5325 => Predicted: 0\n",
      "Row 5326 => Predicted: 0\n",
      "Row 5327 => Predicted: 0\n",
      "Row 5328 => Predicted: 0\n",
      "Row 5329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5320 to 5329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5330 => Predicted: 1\n",
      "Row 5331 => Predicted: 0\n",
      "Row 5332 => Predicted: 0\n",
      "Row 5333 => Predicted: 0\n",
      "Row 5334 => Predicted: 0\n",
      "Row 5335 => Predicted: 0\n",
      "Row 5336 => Predicted: 0\n",
      "Row 5337 => Predicted: 1\n",
      "Row 5338 => Predicted: 1\n",
      "Row 5339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5330 to 5339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5340 => Predicted: 1\n",
      "Row 5341 => Predicted: 1\n",
      "Row 5342 => Predicted: 0\n",
      "Row 5343 => Predicted: 1\n",
      "Row 5344 => Predicted: 1\n",
      "Row 5345 => Predicted: 1\n",
      "Row 5346 => Predicted: 0\n",
      "Row 5347 => Predicted: 1\n",
      "Row 5348 => Predicted: 1\n",
      "Row 5349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5340 to 5349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5350 => Predicted: 0\n",
      "Row 5351 => Predicted: 0\n",
      "Row 5352 => Predicted: 0\n",
      "Row 5353 => Predicted: 1\n",
      "Row 5354 => Predicted: 1\n",
      "Row 5355 => Predicted: 1\n",
      "Row 5356 => Predicted: 1\n",
      "Row 5357 => Predicted: 0\n",
      "Row 5358 => Predicted: 1\n",
      "Row 5359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5350 to 5359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5360 => Predicted: 1\n",
      "Row 5361 => Predicted: 1\n",
      "Row 5362 => Predicted: 0\n",
      "Row 5363 => Predicted: 1\n",
      "Row 5364 => Predicted: 0\n",
      "Row 5365 => Predicted: 1\n",
      "Row 5366 => Predicted: 0\n",
      "Row 5367 => Predicted: 1\n",
      "Row 5368 => Predicted: 1\n",
      "Row 5369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5360 to 5369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5370 => Predicted: 1\n",
      "Row 5371 => Predicted: 1\n",
      "Row 5372 => Predicted: 0\n",
      "Row 5373 => Predicted: 1\n",
      "Row 5374 => Predicted: 0\n",
      "Row 5375 => Predicted: 1\n",
      "Row 5376 => Predicted: 0\n",
      "Row 5377 => Predicted: 0\n",
      "Row 5378 => Predicted: 0\n",
      "Row 5379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5370 to 5379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5380 => Predicted: 0\n",
      "Row 5381 => Predicted: 1\n",
      "Row 5382 => Predicted: 1\n",
      "Row 5383 => Predicted: 1\n",
      "Row 5384 => Predicted: 1\n",
      "Row 5385 => Predicted: 1\n",
      "Row 5386 => Predicted: 0\n",
      "Row 5387 => Predicted: 1\n",
      "Row 5388 => Predicted: 1\n",
      "Row 5389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5380 to 5389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5390 => Predicted: 0\n",
      "Row 5391 => Predicted: 1\n",
      "Row 5392 => Predicted: 1\n",
      "Row 5393 => Predicted: 1\n",
      "Row 5394 => Predicted: 0\n",
      "Row 5395 => Predicted: 0\n",
      "Row 5396 => Predicted: 1\n",
      "Row 5397 => Predicted: 0\n",
      "Row 5398 => Predicted: 0\n",
      "Row 5399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5390 to 5399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5400 => Predicted: 0\n",
      "Row 5401 => Predicted: 0\n",
      "Row 5402 => Predicted: 0\n",
      "Row 5403 => Predicted: 0\n",
      "Row 5404 => Predicted: 0\n",
      "Row 5405 => Predicted: 0\n",
      "Row 5406 => Predicted: 1\n",
      "Row 5407 => Predicted: 0\n",
      "Row 5408 => Predicted: 1\n",
      "Row 5409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5400 to 5409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5410 => Predicted: 1\n",
      "Row 5411 => Predicted: 1\n",
      "Row 5412 => Predicted: 1\n",
      "Row 5413 => Predicted: 1\n",
      "Row 5414 => Predicted: 1\n",
      "Row 5415 => Predicted: 1\n",
      "Row 5416 => Predicted: 1\n",
      "Row 5417 => Predicted: 1\n",
      "Row 5418 => Predicted: 0\n",
      "Row 5419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5410 to 5419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5420 => Predicted: 1\n",
      "Row 5421 => Predicted: 0\n",
      "Row 5422 => Predicted: 0\n",
      "Row 5423 => Predicted: 1\n",
      "Row 5424 => Predicted: 0\n",
      "Row 5425 => Predicted: 0\n",
      "Row 5426 => Predicted: 0\n",
      "Row 5427 => Predicted: 1\n",
      "Row 5428 => Predicted: 0\n",
      "Row 5429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5420 to 5429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5430 => Predicted: 0\n",
      "Row 5431 => Predicted: 0\n",
      "Row 5432 => Predicted: 1\n",
      "Row 5433 => Predicted: 1\n",
      "Row 5434 => Predicted: 0\n",
      "Row 5435 => Predicted: 1\n",
      "Row 5436 => Predicted: 0\n",
      "Row 5437 => Predicted: 1\n",
      "Row 5438 => Predicted: 1\n",
      "Row 5439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5430 to 5439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5440 => Predicted: 0\n",
      "Row 5441 => Predicted: 0\n",
      "Row 5442 => Predicted: 1\n",
      "Row 5443 => Predicted: 1\n",
      "Row 5444 => Predicted: 1\n",
      "Row 5445 => Predicted: 1\n",
      "Row 5446 => Predicted: 0\n",
      "Row 5447 => Predicted: 1\n",
      "Row 5448 => Predicted: 1\n",
      "Row 5449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5440 to 5449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5450 => Predicted: 0\n",
      "Row 5451 => Predicted: 0\n",
      "Row 5452 => Predicted: 1\n",
      "Row 5453 => Predicted: 1\n",
      "Row 5454 => Predicted: 1\n",
      "Row 5455 => Predicted: 0\n",
      "Row 5456 => Predicted: 1\n",
      "Row 5457 => Predicted: 0\n",
      "Row 5458 => Predicted: 1\n",
      "Row 5459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5450 to 5459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5460 => Predicted: 1\n",
      "Row 5461 => Predicted: 0\n",
      "Row 5462 => Predicted: 1\n",
      "Row 5463 => Predicted: 0\n",
      "Row 5464 => Predicted: 1\n",
      "Row 5465 => Predicted: 0\n",
      "Row 5466 => Predicted: 0\n",
      "Row 5467 => Predicted: 1\n",
      "Row 5468 => Predicted: 1\n",
      "Row 5469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5460 to 5469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5470 => Predicted: 1\n",
      "Row 5471 => Predicted: 1\n",
      "Row 5472 => Predicted: 0\n",
      "Row 5473 => Predicted: 1\n",
      "Row 5474 => Predicted: 1\n",
      "Row 5475 => Predicted: 0\n",
      "Row 5476 => Predicted: 0\n",
      "Row 5477 => Predicted: 0\n",
      "Row 5478 => Predicted: 1\n",
      "Row 5479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5470 to 5479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5480 => Predicted: 0\n",
      "Row 5481 => Predicted: 1\n",
      "Row 5482 => Predicted: 0\n",
      "Row 5483 => Predicted: 0\n",
      "Row 5484 => Predicted: 0\n",
      "Row 5485 => Predicted: 0\n",
      "Row 5486 => Predicted: 1\n",
      "Row 5487 => Predicted: 0\n",
      "Row 5488 => Predicted: 1\n",
      "Row 5489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5480 to 5489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5490 => Predicted: 0\n",
      "Row 5491 => Predicted: 0\n",
      "Row 5492 => Predicted: 1\n",
      "Row 5493 => Predicted: 0\n",
      "Row 5494 => Predicted: 1\n",
      "Row 5495 => Predicted: 1\n",
      "Row 5496 => Predicted: 1\n",
      "Row 5497 => Predicted: 0\n",
      "Row 5498 => Predicted: 1\n",
      "Row 5499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5490 to 5499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5500 => Predicted: 0\n",
      "Row 5501 => Predicted: 0\n",
      "Row 5502 => Predicted: 1\n",
      "Row 5503 => Predicted: 0\n",
      "Row 5504 => Predicted: 0\n",
      "Row 5505 => Predicted: 0\n",
      "Row 5506 => Predicted: 0\n",
      "Row 5507 => Predicted: 0\n",
      "Row 5508 => Predicted: 1\n",
      "Row 5509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5500 to 5509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5510 => Predicted: 0\n",
      "Row 5511 => Predicted: 1\n",
      "Row 5512 => Predicted: 1\n",
      "Row 5513 => Predicted: 0\n",
      "Row 5514 => Predicted: 1\n",
      "Row 5515 => Predicted: 0\n",
      "Row 5516 => Predicted: 1\n",
      "Row 5517 => Predicted: 1\n",
      "Row 5518 => Predicted: 0\n",
      "Row 5519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5510 to 5519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5520 => Predicted: 1\n",
      "Row 5521 => Predicted: 0\n",
      "Row 5522 => Predicted: 1\n",
      "Row 5523 => Predicted: 0\n",
      "Row 5524 => Predicted: 0\n",
      "Row 5525 => Predicted: 0\n",
      "Row 5526 => Predicted: 1\n",
      "Row 5527 => Predicted: 1\n",
      "Row 5528 => Predicted: 0\n",
      "Row 5529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5520 to 5529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5530 => Predicted: 1\n",
      "Row 5531 => Predicted: 1\n",
      "Row 5532 => Predicted: 1\n",
      "Row 5533 => Predicted: 1\n",
      "Row 5534 => Predicted: 0\n",
      "Row 5535 => Predicted: 0\n",
      "Row 5536 => Predicted: 0\n",
      "Row 5537 => Predicted: 0\n",
      "Row 5538 => Predicted: 1\n",
      "Row 5539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5530 to 5539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5540 => Predicted: 1\n",
      "Row 5541 => Predicted: 1\n",
      "Row 5542 => Predicted: 0\n",
      "Row 5543 => Predicted: 0\n",
      "Row 5544 => Predicted: 1\n",
      "Row 5545 => Predicted: 0\n",
      "Row 5546 => Predicted: 0\n",
      "Row 5547 => Predicted: 1\n",
      "Row 5548 => Predicted: 1\n",
      "Row 5549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5540 to 5549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5550 => Predicted: 0\n",
      "Row 5551 => Predicted: 1\n",
      "Row 5552 => Predicted: 1\n",
      "Row 5553 => Predicted: 1\n",
      "Row 5554 => Predicted: 1\n",
      "Row 5555 => Predicted: 1\n",
      "Row 5556 => Predicted: 0\n",
      "Row 5557 => Predicted: 0\n",
      "Row 5558 => Predicted: 0\n",
      "Row 5559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5550 to 5559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5560 => Predicted: 1\n",
      "Row 5561 => Predicted: 0\n",
      "Row 5562 => Predicted: 1\n",
      "Row 5563 => Predicted: 0\n",
      "Row 5564 => Predicted: 0\n",
      "Row 5565 => Predicted: 0\n",
      "Row 5566 => Predicted: 0\n",
      "Row 5567 => Predicted: 0\n",
      "Row 5568 => Predicted: 0\n",
      "Row 5569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5560 to 5569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5570 => Predicted: 1\n",
      "Row 5571 => Predicted: 0\n",
      "Row 5572 => Predicted: 1\n",
      "Row 5573 => Predicted: 1\n",
      "Row 5574 => Predicted: 0\n",
      "Row 5575 => Predicted: 1\n",
      "Row 5576 => Predicted: 1\n",
      "Row 5577 => Predicted: 1\n",
      "Row 5578 => Predicted: 1\n",
      "Row 5579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5570 to 5579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5580 => Predicted: 1\n",
      "Row 5581 => Predicted: 0\n",
      "Row 5582 => Predicted: 0\n",
      "Row 5583 => Predicted: 1\n",
      "Row 5584 => Predicted: 1\n",
      "Row 5585 => Predicted: 0\n",
      "Row 5586 => Predicted: 1\n",
      "Row 5587 => Predicted: 1\n",
      "Row 5588 => Predicted: 1\n",
      "Row 5589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5580 to 5589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5590 => Predicted: 1\n",
      "Row 5591 => Predicted: 0\n",
      "Row 5592 => Predicted: 1\n",
      "Row 5593 => Predicted: 0\n",
      "Row 5594 => Predicted: 0\n",
      "Row 5595 => Predicted: 1\n",
      "Row 5596 => Predicted: 0\n",
      "Row 5597 => Predicted: 0\n",
      "Row 5598 => Predicted: 1\n",
      "Row 5599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5590 to 5599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5600 => Predicted: 0\n",
      "Row 5601 => Predicted: 1\n",
      "Row 5602 => Predicted: 0\n",
      "Row 5603 => Predicted: 1\n",
      "Row 5604 => Predicted: 0\n",
      "Row 5605 => Predicted: 0\n",
      "Row 5606 => Predicted: 1\n",
      "Row 5607 => Predicted: 0\n",
      "Row 5608 => Predicted: 1\n",
      "Row 5609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5600 to 5609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5610 => Predicted: 1\n",
      "Row 5611 => Predicted: 0\n",
      "Row 5612 => Predicted: 0\n",
      "Row 5613 => Predicted: 0\n",
      "Row 5614 => Predicted: 0\n",
      "Row 5615 => Predicted: 1\n",
      "Row 5616 => Predicted: 0\n",
      "Row 5617 => Predicted: 0\n",
      "Row 5618 => Predicted: 1\n",
      "Row 5619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5610 to 5619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5620 => Predicted: 1\n",
      "Row 5621 => Predicted: 1\n",
      "Row 5622 => Predicted: 1\n",
      "Row 5623 => Predicted: 0\n",
      "Row 5624 => Predicted: 1\n",
      "Row 5625 => Predicted: 1\n",
      "Row 5626 => Predicted: 0\n",
      "Row 5627 => Predicted: 0\n",
      "Row 5628 => Predicted: 1\n",
      "Row 5629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5620 to 5629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5630 => Predicted: 1\n",
      "Row 5631 => Predicted: 0\n",
      "Row 5632 => Predicted: 0\n",
      "Row 5633 => Predicted: 1\n",
      "Row 5634 => Predicted: 1\n",
      "Row 5635 => Predicted: 1\n",
      "Row 5636 => Predicted: 1\n",
      "Row 5637 => Predicted: 1\n",
      "Row 5638 => Predicted: 0\n",
      "Row 5639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5630 to 5639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5640 => Predicted: 0\n",
      "Row 5641 => Predicted: 1\n",
      "Row 5642 => Predicted: 1\n",
      "Row 5643 => Predicted: 0\n",
      "Row 5644 => Predicted: 1\n",
      "Row 5645 => Predicted: 1\n",
      "Row 5646 => Predicted: 1\n",
      "Row 5647 => Predicted: 1\n",
      "Row 5648 => Predicted: 0\n",
      "Row 5649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5640 to 5649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5650 => Predicted: 1\n",
      "Row 5651 => Predicted: 0\n",
      "Row 5652 => Predicted: 1\n",
      "Row 5653 => Predicted: 1\n",
      "Row 5654 => Predicted: 1\n",
      "Row 5655 => Predicted: 0\n",
      "Row 5656 => Predicted: 1\n",
      "Row 5657 => Predicted: 1\n",
      "Row 5658 => Predicted: 1\n",
      "Row 5659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5650 to 5659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5660 => Predicted: 1\n",
      "Row 5661 => Predicted: 0\n",
      "Row 5662 => Predicted: 1\n",
      "Row 5663 => Predicted: 1\n",
      "Row 5664 => Predicted: 0\n",
      "Row 5665 => Predicted: 0\n",
      "Row 5666 => Predicted: 0\n",
      "Row 5667 => Predicted: 1\n",
      "Row 5668 => Predicted: 1\n",
      "Row 5669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5660 to 5669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5670 => Predicted: 1\n",
      "Row 5671 => Predicted: 1\n",
      "Row 5672 => Predicted: 1\n",
      "Row 5673 => Predicted: 1\n",
      "Row 5674 => Predicted: 1\n",
      "Row 5675 => Predicted: 0\n",
      "Row 5676 => Predicted: 0\n",
      "Row 5677 => Predicted: 1\n",
      "Row 5678 => Predicted: 1\n",
      "Row 5679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5670 to 5679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5680 => Predicted: 0\n",
      "Row 5681 => Predicted: 1\n",
      "Row 5682 => Predicted: 1\n",
      "Row 5683 => Predicted: 0\n",
      "Row 5684 => Predicted: 1\n",
      "Row 5685 => Predicted: 0\n",
      "Row 5686 => Predicted: 0\n",
      "Row 5687 => Predicted: 1\n",
      "Row 5688 => Predicted: 0\n",
      "Row 5689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5680 to 5689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5690 => Predicted: 0\n",
      "Row 5691 => Predicted: 1\n",
      "Row 5692 => Predicted: 0\n",
      "Row 5693 => Predicted: 1\n",
      "Row 5694 => Predicted: 1\n",
      "Row 5695 => Predicted: 1\n",
      "Row 5696 => Predicted: 1\n",
      "Row 5697 => Predicted: 1\n",
      "Row 5698 => Predicted: 1\n",
      "Row 5699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5690 to 5699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5700 => Predicted: 1\n",
      "Row 5701 => Predicted: 1\n",
      "Row 5702 => Predicted: 1\n",
      "Row 5703 => Predicted: 0\n",
      "Row 5704 => Predicted: 0\n",
      "Row 5705 => Predicted: 1\n",
      "Row 5706 => Predicted: 1\n",
      "Row 5707 => Predicted: 1\n",
      "Row 5708 => Predicted: 0\n",
      "Row 5709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5700 to 5709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5710 => Predicted: 0\n",
      "Row 5711 => Predicted: 1\n",
      "Row 5712 => Predicted: 0\n",
      "Row 5713 => Predicted: 1\n",
      "Row 5714 => Predicted: 0\n",
      "Row 5715 => Predicted: 0\n",
      "Row 5716 => Predicted: 0\n",
      "Row 5717 => Predicted: 1\n",
      "Row 5718 => Predicted: 0\n",
      "Row 5719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5710 to 5719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5720 => Predicted: 1\n",
      "Row 5721 => Predicted: 1\n",
      "Row 5722 => Predicted: 0\n",
      "Row 5723 => Predicted: 1\n",
      "Row 5724 => Predicted: 1\n",
      "Row 5725 => Predicted: 0\n",
      "Row 5726 => Predicted: 1\n",
      "Row 5727 => Predicted: 1\n",
      "Row 5728 => Predicted: 0\n",
      "Row 5729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5720 to 5729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5730 => Predicted: 1\n",
      "Row 5731 => Predicted: 1\n",
      "Row 5732 => Predicted: 1\n",
      "Row 5733 => Predicted: 1\n",
      "Row 5734 => Predicted: 0\n",
      "Row 5735 => Predicted: 1\n",
      "Row 5736 => Predicted: 1\n",
      "Row 5737 => Predicted: 1\n",
      "Row 5738 => Predicted: 1\n",
      "Row 5739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5730 to 5739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5740 => Predicted: 1\n",
      "Row 5741 => Predicted: 0\n",
      "Row 5742 => Predicted: 0\n",
      "Row 5743 => Predicted: 1\n",
      "Row 5744 => Predicted: 0\n",
      "Row 5745 => Predicted: 1\n",
      "Row 5746 => Predicted: 1\n",
      "Row 5747 => Predicted: 0\n",
      "Row 5748 => Predicted: 1\n",
      "Row 5749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5740 to 5749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5750 => Predicted: 0\n",
      "Row 5751 => Predicted: 0\n",
      "Row 5752 => Predicted: 0\n",
      "Row 5753 => Predicted: 1\n",
      "Row 5754 => Predicted: 0\n",
      "Row 5755 => Predicted: 1\n",
      "Row 5756 => Predicted: 0\n",
      "Row 5757 => Predicted: 1\n",
      "Row 5758 => Predicted: 0\n",
      "Row 5759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5750 to 5759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5760 => Predicted: 1\n",
      "Row 5761 => Predicted: 1\n",
      "Row 5762 => Predicted: 0\n",
      "Row 5763 => Predicted: 1\n",
      "Row 5764 => Predicted: 0\n",
      "Row 5765 => Predicted: 1\n",
      "Row 5766 => Predicted: 0\n",
      "Row 5767 => Predicted: 1\n",
      "Row 5768 => Predicted: 1\n",
      "Row 5769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5760 to 5769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5770 => Predicted: 1\n",
      "Row 5771 => Predicted: 0\n",
      "Row 5772 => Predicted: 0\n",
      "Row 5773 => Predicted: 0\n",
      "Row 5774 => Predicted: 0\n",
      "Row 5775 => Predicted: 0\n",
      "Row 5776 => Predicted: 1\n",
      "Row 5777 => Predicted: 0\n",
      "Row 5778 => Predicted: 0\n",
      "Row 5779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5770 to 5779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5780 => Predicted: 0\n",
      "Row 5781 => Predicted: 1\n",
      "Row 5782 => Predicted: 0\n",
      "Row 5783 => Predicted: 0\n",
      "Row 5784 => Predicted: 1\n",
      "Row 5785 => Predicted: 0\n",
      "Row 5786 => Predicted: 1\n",
      "Row 5787 => Predicted: 0\n",
      "Row 5788 => Predicted: 1\n",
      "Row 5789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5780 to 5789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5790 => Predicted: 1\n",
      "Row 5791 => Predicted: 0\n",
      "Row 5792 => Predicted: 1\n",
      "Row 5793 => Predicted: 0\n",
      "Row 5794 => Predicted: 0\n",
      "Row 5795 => Predicted: 0\n",
      "Row 5796 => Predicted: 0\n",
      "Row 5797 => Predicted: 0\n",
      "Row 5798 => Predicted: 1\n",
      "Row 5799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5790 to 5799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5800 => Predicted: 1\n",
      "Row 5801 => Predicted: 1\n",
      "Row 5802 => Predicted: 0\n",
      "Row 5803 => Predicted: 0\n",
      "Row 5804 => Predicted: 0\n",
      "Row 5805 => Predicted: 1\n",
      "Row 5806 => Predicted: 1\n",
      "Row 5807 => Predicted: 1\n",
      "Row 5808 => Predicted: 1\n",
      "Row 5809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5800 to 5809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5810 => Predicted: 0\n",
      "Row 5811 => Predicted: 1\n",
      "Row 5812 => Predicted: 1\n",
      "Row 5813 => Predicted: 0\n",
      "Row 5814 => Predicted: 0\n",
      "Row 5815 => Predicted: 0\n",
      "Row 5816 => Predicted: 0\n",
      "Row 5817 => Predicted: 1\n",
      "Row 5818 => Predicted: 1\n",
      "Row 5819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5810 to 5819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5820 => Predicted: 0\n",
      "Row 5821 => Predicted: 1\n",
      "Row 5822 => Predicted: 0\n",
      "Row 5823 => Predicted: 0\n",
      "Row 5824 => Predicted: 1\n",
      "Row 5825 => Predicted: 0\n",
      "Row 5826 => Predicted: 0\n",
      "Row 5827 => Predicted: 1\n",
      "Row 5828 => Predicted: 0\n",
      "Row 5829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5820 to 5829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5830 => Predicted: 0\n",
      "Row 5831 => Predicted: 1\n",
      "Row 5832 => Predicted: 1\n",
      "Row 5833 => Predicted: 0\n",
      "Row 5834 => Predicted: 1\n",
      "Row 5835 => Predicted: 0\n",
      "Row 5836 => Predicted: 1\n",
      "Row 5837 => Predicted: 1\n",
      "Row 5838 => Predicted: 1\n",
      "Row 5839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5830 to 5839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5840 => Predicted: 1\n",
      "Row 5841 => Predicted: 0\n",
      "Row 5842 => Predicted: 0\n",
      "Row 5843 => Predicted: 1\n",
      "Row 5844 => Predicted: 0\n",
      "Row 5845 => Predicted: 0\n",
      "Row 5846 => Predicted: 1\n",
      "Row 5847 => Predicted: 0\n",
      "Row 5848 => Predicted: 0\n",
      "Row 5849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5840 to 5849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5850 => Predicted: 0\n",
      "Row 5851 => Predicted: 1\n",
      "Row 5852 => Predicted: 1\n",
      "Row 5853 => Predicted: 1\n",
      "Row 5854 => Predicted: 1\n",
      "Row 5855 => Predicted: 1\n",
      "Row 5856 => Predicted: 1\n",
      "Row 5857 => Predicted: 0\n",
      "Row 5858 => Predicted: 0\n",
      "Row 5859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5850 to 5859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5860 => Predicted: 0\n",
      "Row 5861 => Predicted: 1\n",
      "Row 5862 => Predicted: 0\n",
      "Row 5863 => Predicted: 1\n",
      "Row 5864 => Predicted: 1\n",
      "Row 5865 => Predicted: 1\n",
      "Row 5866 => Predicted: 0\n",
      "Row 5867 => Predicted: 1\n",
      "Row 5868 => Predicted: 0\n",
      "Row 5869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5860 to 5869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5870 => Predicted: 0\n",
      "Row 5871 => Predicted: 0\n",
      "Row 5872 => Predicted: 0\n",
      "Row 5873 => Predicted: 0\n",
      "Row 5874 => Predicted: 1\n",
      "Row 5875 => Predicted: 1\n",
      "Row 5876 => Predicted: 0\n",
      "Row 5877 => Predicted: 1\n",
      "Row 5878 => Predicted: 1\n",
      "Row 5879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5870 to 5879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5880 => Predicted: 0\n",
      "Row 5881 => Predicted: 1\n",
      "Row 5882 => Predicted: 0\n",
      "Row 5883 => Predicted: 0\n",
      "Row 5884 => Predicted: 1\n",
      "Row 5885 => Predicted: 1\n",
      "Row 5886 => Predicted: 1\n",
      "Row 5887 => Predicted: 1\n",
      "Row 5888 => Predicted: 0\n",
      "Row 5889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5880 to 5889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5890 => Predicted: 0\n",
      "Row 5891 => Predicted: 1\n",
      "Row 5892 => Predicted: 1\n",
      "Row 5893 => Predicted: 0\n",
      "Row 5894 => Predicted: 1\n",
      "Row 5895 => Predicted: 0\n",
      "Row 5896 => Predicted: 1\n",
      "Row 5897 => Predicted: 0\n",
      "Row 5898 => Predicted: 0\n",
      "Row 5899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5890 to 5899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5900 => Predicted: 0\n",
      "Row 5901 => Predicted: 0\n",
      "Row 5902 => Predicted: 0\n",
      "Row 5903 => Predicted: 0\n",
      "Row 5904 => Predicted: 0\n",
      "Row 5905 => Predicted: 0\n",
      "Row 5906 => Predicted: 1\n",
      "Row 5907 => Predicted: 1\n",
      "Row 5908 => Predicted: 1\n",
      "Row 5909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5900 to 5909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5910 => Predicted: 1\n",
      "Row 5911 => Predicted: 0\n",
      "Row 5912 => Predicted: 1\n",
      "Row 5913 => Predicted: 1\n",
      "Row 5914 => Predicted: 1\n",
      "Row 5915 => Predicted: 0\n",
      "Row 5916 => Predicted: 1\n",
      "Row 5917 => Predicted: 1\n",
      "Row 5918 => Predicted: 1\n",
      "Row 5919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5910 to 5919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5920 => Predicted: 1\n",
      "Row 5921 => Predicted: 1\n",
      "Row 5922 => Predicted: 0\n",
      "Row 5923 => Predicted: 0\n",
      "Row 5924 => Predicted: 1\n",
      "Row 5925 => Predicted: 0\n",
      "Row 5926 => Predicted: 1\n",
      "Row 5927 => Predicted: 0\n",
      "Row 5928 => Predicted: 1\n",
      "Row 5929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5920 to 5929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5930 => Predicted: 1\n",
      "Row 5931 => Predicted: 0\n",
      "Row 5932 => Predicted: 0\n",
      "Row 5933 => Predicted: 1\n",
      "Row 5934 => Predicted: 0\n",
      "Row 5935 => Predicted: 0\n",
      "Row 5936 => Predicted: 0\n",
      "Row 5937 => Predicted: 0\n",
      "Row 5938 => Predicted: 1\n",
      "Row 5939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 5930 to 5939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5940 => Predicted: 1\n",
      "Row 5941 => Predicted: 0\n",
      "Row 5942 => Predicted: 1\n",
      "Row 5943 => Predicted: 1\n",
      "Row 5944 => Predicted: 1\n",
      "Row 5945 => Predicted: 1\n",
      "Row 5946 => Predicted: 0\n",
      "Row 5947 => Predicted: 1\n",
      "Row 5948 => Predicted: 0\n",
      "Row 5949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5940 to 5949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5950 => Predicted: 1\n",
      "Row 5951 => Predicted: 1\n",
      "Row 5952 => Predicted: 0\n",
      "Row 5953 => Predicted: 1\n",
      "Row 5954 => Predicted: 0\n",
      "Row 5955 => Predicted: 0\n",
      "Row 5956 => Predicted: 0\n",
      "Row 5957 => Predicted: 1\n",
      "Row 5958 => Predicted: 1\n",
      "Row 5959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5950 to 5959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5960 => Predicted: 0\n",
      "Row 5961 => Predicted: 1\n",
      "Row 5962 => Predicted: 1\n",
      "Row 5963 => Predicted: 1\n",
      "Row 5964 => Predicted: 1\n",
      "Row 5965 => Predicted: 0\n",
      "Row 5966 => Predicted: 0\n",
      "Row 5967 => Predicted: 1\n",
      "Row 5968 => Predicted: 0\n",
      "Row 5969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5960 to 5969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5970 => Predicted: 1\n",
      "Row 5971 => Predicted: 0\n",
      "Row 5972 => Predicted: 0\n",
      "Row 5973 => Predicted: 1\n",
      "Row 5974 => Predicted: 0\n",
      "Row 5975 => Predicted: 0\n",
      "Row 5976 => Predicted: 1\n",
      "Row 5977 => Predicted: 0\n",
      "Row 5978 => Predicted: 0\n",
      "Row 5979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5970 to 5979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5980 => Predicted: 0\n",
      "Row 5981 => Predicted: 1\n",
      "Row 5982 => Predicted: 1\n",
      "Row 5983 => Predicted: 0\n",
      "Row 5984 => Predicted: 1\n",
      "Row 5985 => Predicted: 0\n",
      "Row 5986 => Predicted: 1\n",
      "Row 5987 => Predicted: 0\n",
      "Row 5988 => Predicted: 0\n",
      "Row 5989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5980 to 5989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5990 => Predicted: 1\n",
      "Row 5991 => Predicted: 1\n",
      "Row 5992 => Predicted: 1\n",
      "Row 5993 => Predicted: 0\n",
      "Row 5994 => Predicted: 0\n",
      "Row 5995 => Predicted: 0\n",
      "Row 5996 => Predicted: 0\n",
      "Row 5997 => Predicted: 1\n",
      "Row 5998 => Predicted: 0\n",
      "Row 5999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 5990 to 5999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6000 => Predicted: 0\n",
      "Row 6001 => Predicted: 0\n",
      "Row 6002 => Predicted: 1\n",
      "Row 6003 => Predicted: 1\n",
      "Row 6004 => Predicted: 1\n",
      "Row 6005 => Predicted: 0\n",
      "Row 6006 => Predicted: 0\n",
      "Row 6007 => Predicted: 0\n",
      "Row 6008 => Predicted: 1\n",
      "Row 6009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6000 to 6009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6010 => Predicted: 1\n",
      "Row 6011 => Predicted: 0\n",
      "Row 6012 => Predicted: 0\n",
      "Row 6013 => Predicted: 0\n",
      "Row 6014 => Predicted: 1\n",
      "Row 6015 => Predicted: 1\n",
      "Row 6016 => Predicted: 1\n",
      "Row 6017 => Predicted: 0\n",
      "Row 6018 => Predicted: 0\n",
      "Row 6019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6010 to 6019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6020 => Predicted: 0\n",
      "Row 6021 => Predicted: 0\n",
      "Row 6022 => Predicted: 0\n",
      "Row 6023 => Predicted: 1\n",
      "Row 6024 => Predicted: 0\n",
      "Row 6025 => Predicted: 1\n",
      "Row 6026 => Predicted: 1\n",
      "Row 6027 => Predicted: 1\n",
      "Row 6028 => Predicted: 1\n",
      "Row 6029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6020 to 6029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6030 => Predicted: 1\n",
      "Row 6031 => Predicted: 0\n",
      "Row 6032 => Predicted: 1\n",
      "Row 6033 => Predicted: 1\n",
      "Row 6034 => Predicted: 1\n",
      "Row 6035 => Predicted: 1\n",
      "Row 6036 => Predicted: 1\n",
      "Row 6037 => Predicted: 1\n",
      "Row 6038 => Predicted: 1\n",
      "Row 6039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6030 to 6039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6040 => Predicted: 0\n",
      "Row 6041 => Predicted: 0\n",
      "Row 6042 => Predicted: 1\n",
      "Row 6043 => Predicted: 1\n",
      "Row 6044 => Predicted: 1\n",
      "Row 6045 => Predicted: 0\n",
      "Row 6046 => Predicted: 0\n",
      "Row 6047 => Predicted: 1\n",
      "Row 6048 => Predicted: 0\n",
      "Row 6049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6040 to 6049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6050 => Predicted: 1\n",
      "Row 6051 => Predicted: 0\n",
      "Row 6052 => Predicted: 1\n",
      "Row 6053 => Predicted: 1\n",
      "Row 6054 => Predicted: 0\n",
      "Row 6055 => Predicted: 1\n",
      "Row 6056 => Predicted: 1\n",
      "Row 6057 => Predicted: 1\n",
      "Row 6058 => Predicted: 1\n",
      "Row 6059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6050 to 6059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6060 => Predicted: 1\n",
      "Row 6061 => Predicted: 1\n",
      "Row 6062 => Predicted: 1\n",
      "Row 6063 => Predicted: 0\n",
      "Row 6064 => Predicted: 0\n",
      "Row 6065 => Predicted: 0\n",
      "Row 6066 => Predicted: 0\n",
      "Row 6067 => Predicted: 1\n",
      "Row 6068 => Predicted: 0\n",
      "Row 6069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6060 to 6069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6070 => Predicted: 0\n",
      "Row 6071 => Predicted: 0\n",
      "Row 6072 => Predicted: 0\n",
      "Row 6073 => Predicted: 0\n",
      "Row 6074 => Predicted: 0\n",
      "Row 6075 => Predicted: 1\n",
      "Row 6076 => Predicted: 1\n",
      "Row 6077 => Predicted: 0\n",
      "Row 6078 => Predicted: 1\n",
      "Row 6079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6070 to 6079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6080 => Predicted: 1\n",
      "Row 6081 => Predicted: 0\n",
      "Row 6082 => Predicted: 1\n",
      "Row 6083 => Predicted: 1\n",
      "Row 6084 => Predicted: 0\n",
      "Row 6085 => Predicted: 0\n",
      "Row 6086 => Predicted: 0\n",
      "Row 6087 => Predicted: 1\n",
      "Row 6088 => Predicted: 1\n",
      "Row 6089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6080 to 6089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6090 => Predicted: 0\n",
      "Row 6091 => Predicted: 0\n",
      "Row 6092 => Predicted: 0\n",
      "Row 6093 => Predicted: 1\n",
      "Row 6094 => Predicted: 1\n",
      "Row 6095 => Predicted: 1\n",
      "Row 6096 => Predicted: 0\n",
      "Row 6097 => Predicted: 1\n",
      "Row 6098 => Predicted: 0\n",
      "Row 6099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6090 to 6099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6100 => Predicted: 0\n",
      "Row 6101 => Predicted: 1\n",
      "Row 6102 => Predicted: 1\n",
      "Row 6103 => Predicted: 1\n",
      "Row 6104 => Predicted: 1\n",
      "Row 6105 => Predicted: 0\n",
      "Row 6106 => Predicted: 1\n",
      "Row 6107 => Predicted: 1\n",
      "Row 6108 => Predicted: 0\n",
      "Row 6109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6100 to 6109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6110 => Predicted: 1\n",
      "Row 6111 => Predicted: 0\n",
      "Row 6112 => Predicted: 0\n",
      "Row 6113 => Predicted: 1\n",
      "Row 6114 => Predicted: 1\n",
      "Row 6115 => Predicted: 1\n",
      "Row 6116 => Predicted: 1\n",
      "Row 6117 => Predicted: 1\n",
      "Row 6118 => Predicted: 1\n",
      "Row 6119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6110 to 6119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6120 => Predicted: 1\n",
      "Row 6121 => Predicted: 0\n",
      "Row 6122 => Predicted: 1\n",
      "Row 6123 => Predicted: 1\n",
      "Row 6124 => Predicted: 0\n",
      "Row 6125 => Predicted: 0\n",
      "Row 6126 => Predicted: 1\n",
      "Row 6127 => Predicted: 0\n",
      "Row 6128 => Predicted: 1\n",
      "Row 6129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6120 to 6129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6130 => Predicted: 0\n",
      "Row 6131 => Predicted: 0\n",
      "Row 6132 => Predicted: 1\n",
      "Row 6133 => Predicted: 1\n",
      "Row 6134 => Predicted: 0\n",
      "Row 6135 => Predicted: 1\n",
      "Row 6136 => Predicted: 1\n",
      "Row 6137 => Predicted: 1\n",
      "Row 6138 => Predicted: 0\n",
      "Row 6139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6130 to 6139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6140 => Predicted: 0\n",
      "Row 6141 => Predicted: 1\n",
      "Row 6142 => Predicted: 0\n",
      "Row 6143 => Predicted: 1\n",
      "Row 6144 => Predicted: 0\n",
      "Row 6145 => Predicted: 1\n",
      "Row 6146 => Predicted: 0\n",
      "Row 6147 => Predicted: 0\n",
      "Row 6148 => Predicted: 0\n",
      "Row 6149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6140 to 6149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6150 => Predicted: 0\n",
      "Row 6151 => Predicted: 1\n",
      "Row 6152 => Predicted: 1\n",
      "Row 6153 => Predicted: 1\n",
      "Row 6154 => Predicted: 0\n",
      "Row 6155 => Predicted: 0\n",
      "Row 6156 => Predicted: 0\n",
      "Row 6157 => Predicted: 1\n",
      "Row 6158 => Predicted: 1\n",
      "Row 6159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6150 to 6159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6160 => Predicted: 0\n",
      "Row 6161 => Predicted: 0\n",
      "Row 6162 => Predicted: 0\n",
      "Row 6163 => Predicted: 0\n",
      "Row 6164 => Predicted: 1\n",
      "Row 6165 => Predicted: 1\n",
      "Row 6166 => Predicted: 0\n",
      "Row 6167 => Predicted: 1\n",
      "Row 6168 => Predicted: 0\n",
      "Row 6169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6160 to 6169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6170 => Predicted: 0\n",
      "Row 6171 => Predicted: 0\n",
      "Row 6172 => Predicted: 1\n",
      "Row 6173 => Predicted: 0\n",
      "Row 6174 => Predicted: 1\n",
      "Row 6175 => Predicted: 1\n",
      "Row 6176 => Predicted: 1\n",
      "Row 6177 => Predicted: 0\n",
      "Row 6178 => Predicted: 0\n",
      "Row 6179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6170 to 6179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6180 => Predicted: 1\n",
      "Row 6181 => Predicted: 0\n",
      "Row 6182 => Predicted: 1\n",
      "Row 6183 => Predicted: 1\n",
      "Row 6184 => Predicted: 0\n",
      "Row 6185 => Predicted: 1\n",
      "Row 6186 => Predicted: 0\n",
      "Row 6187 => Predicted: 0\n",
      "Row 6188 => Predicted: 0\n",
      "Row 6189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6180 to 6189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6190 => Predicted: 0\n",
      "Row 6191 => Predicted: 0\n",
      "Row 6192 => Predicted: 0\n",
      "Row 6193 => Predicted: 0\n",
      "Row 6194 => Predicted: 0\n",
      "Row 6195 => Predicted: 1\n",
      "Row 6196 => Predicted: 1\n",
      "Row 6197 => Predicted: 0\n",
      "Row 6198 => Predicted: 0\n",
      "Row 6199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6190 to 6199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6200 => Predicted: 1\n",
      "Row 6201 => Predicted: 1\n",
      "Row 6202 => Predicted: 0\n",
      "Row 6203 => Predicted: 1\n",
      "Row 6204 => Predicted: 0\n",
      "Row 6205 => Predicted: 1\n",
      "Row 6206 => Predicted: 1\n",
      "Row 6207 => Predicted: 1\n",
      "Row 6208 => Predicted: 0\n",
      "Row 6209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6200 to 6209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6210 => Predicted: 1\n",
      "Row 6211 => Predicted: 0\n",
      "Row 6212 => Predicted: 0\n",
      "Row 6213 => Predicted: 1\n",
      "Row 6214 => Predicted: 1\n",
      "Row 6215 => Predicted: 0\n",
      "Row 6216 => Predicted: 0\n",
      "Row 6217 => Predicted: 1\n",
      "Row 6218 => Predicted: 0\n",
      "Row 6219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6210 to 6219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6220 => Predicted: 1\n",
      "Row 6221 => Predicted: 0\n",
      "Row 6222 => Predicted: 0\n",
      "Row 6223 => Predicted: 0\n",
      "Row 6224 => Predicted: 0\n",
      "Row 6225 => Predicted: 1\n",
      "Row 6226 => Predicted: 1\n",
      "Row 6227 => Predicted: 1\n",
      "Row 6228 => Predicted: 1\n",
      "Row 6229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6220 to 6229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6230 => Predicted: 1\n",
      "Row 6231 => Predicted: 0\n",
      "Row 6232 => Predicted: 0\n",
      "Row 6233 => Predicted: 0\n",
      "Row 6234 => Predicted: 1\n",
      "Row 6235 => Predicted: 0\n",
      "Row 6236 => Predicted: 1\n",
      "Row 6237 => Predicted: 0\n",
      "Row 6238 => Predicted: 1\n",
      "Row 6239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6230 to 6239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6240 => Predicted: 1\n",
      "Row 6241 => Predicted: 1\n",
      "Row 6242 => Predicted: 1\n",
      "Row 6243 => Predicted: 0\n",
      "Row 6244 => Predicted: 0\n",
      "Row 6245 => Predicted: 0\n",
      "Row 6246 => Predicted: 0\n",
      "Row 6247 => Predicted: 0\n",
      "Row 6248 => Predicted: 0\n",
      "Row 6249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6240 to 6249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6250 => Predicted: 1\n",
      "Row 6251 => Predicted: 1\n",
      "Row 6252 => Predicted: 1\n",
      "Row 6253 => Predicted: 1\n",
      "Row 6254 => Predicted: 1\n",
      "Row 6255 => Predicted: 1\n",
      "Row 6256 => Predicted: 1\n",
      "Row 6257 => Predicted: 0\n",
      "Row 6258 => Predicted: 0\n",
      "Row 6259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6250 to 6259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6260 => Predicted: 1\n",
      "Row 6261 => Predicted: 0\n",
      "Row 6262 => Predicted: 1\n",
      "Row 6263 => Predicted: 0\n",
      "Row 6264 => Predicted: 1\n",
      "Row 6265 => Predicted: 1\n",
      "Row 6266 => Predicted: 0\n",
      "Row 6267 => Predicted: 1\n",
      "Row 6268 => Predicted: 0\n",
      "Row 6269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6260 to 6269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6270 => Predicted: 0\n",
      "Row 6271 => Predicted: 1\n",
      "Row 6272 => Predicted: 1\n",
      "Row 6273 => Predicted: 0\n",
      "Row 6274 => Predicted: 1\n",
      "Row 6275 => Predicted: 0\n",
      "Row 6276 => Predicted: 0\n",
      "Row 6277 => Predicted: 1\n",
      "Row 6278 => Predicted: 0\n",
      "Row 6279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6270 to 6279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6280 => Predicted: 0\n",
      "Row 6281 => Predicted: 1\n",
      "Row 6282 => Predicted: 1\n",
      "Row 6283 => Predicted: 0\n",
      "Row 6284 => Predicted: 1\n",
      "Row 6285 => Predicted: 0\n",
      "Row 6286 => Predicted: 1\n",
      "Row 6287 => Predicted: 1\n",
      "Row 6288 => Predicted: 0\n",
      "Row 6289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6280 to 6289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6290 => Predicted: 0\n",
      "Row 6291 => Predicted: 0\n",
      "Row 6292 => Predicted: 1\n",
      "Row 6293 => Predicted: 0\n",
      "Row 6294 => Predicted: 1\n",
      "Row 6295 => Predicted: 0\n",
      "Row 6296 => Predicted: 0\n",
      "Row 6297 => Predicted: 0\n",
      "Row 6298 => Predicted: 1\n",
      "Row 6299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6290 to 6299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6300 => Predicted: 0\n",
      "Row 6301 => Predicted: 1\n",
      "Row 6302 => Predicted: 1\n",
      "Row 6303 => Predicted: 0\n",
      "Row 6304 => Predicted: 1\n",
      "Row 6305 => Predicted: 0\n",
      "Row 6306 => Predicted: 1\n",
      "Row 6307 => Predicted: 0\n",
      "Row 6308 => Predicted: 0\n",
      "Row 6309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6300 to 6309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6310 => Predicted: 0\n",
      "Row 6311 => Predicted: 0\n",
      "Row 6312 => Predicted: 1\n",
      "Row 6313 => Predicted: 0\n",
      "Row 6314 => Predicted: 1\n",
      "Row 6315 => Predicted: 1\n",
      "Row 6316 => Predicted: 0\n",
      "Row 6317 => Predicted: 0\n",
      "Row 6318 => Predicted: 1\n",
      "Row 6319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6310 to 6319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6320 => Predicted: 0\n",
      "Row 6321 => Predicted: 0\n",
      "Row 6322 => Predicted: 0\n",
      "Row 6323 => Predicted: 1\n",
      "Row 6324 => Predicted: 0\n",
      "Row 6325 => Predicted: 0\n",
      "Row 6326 => Predicted: 0\n",
      "Row 6327 => Predicted: 1\n",
      "Row 6328 => Predicted: 1\n",
      "Row 6329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6320 to 6329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6330 => Predicted: 1\n",
      "Row 6331 => Predicted: 1\n",
      "Row 6332 => Predicted: 1\n",
      "Row 6333 => Predicted: 0\n",
      "Row 6334 => Predicted: 0\n",
      "Row 6335 => Predicted: 1\n",
      "Row 6336 => Predicted: 1\n",
      "Row 6337 => Predicted: 1\n",
      "Row 6338 => Predicted: 0\n",
      "Row 6339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6330 to 6339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6340 => Predicted: 1\n",
      "Row 6341 => Predicted: 0\n",
      "Row 6342 => Predicted: 0\n",
      "Row 6343 => Predicted: 0\n",
      "Row 6344 => Predicted: 0\n",
      "Row 6345 => Predicted: 1\n",
      "Row 6346 => Predicted: 1\n",
      "Row 6347 => Predicted: 0\n",
      "Row 6348 => Predicted: 0\n",
      "Row 6349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6340 to 6349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6350 => Predicted: 0\n",
      "Row 6351 => Predicted: 0\n",
      "Row 6352 => Predicted: 1\n",
      "Row 6353 => Predicted: 0\n",
      "Row 6354 => Predicted: 0\n",
      "Row 6355 => Predicted: 1\n",
      "Row 6356 => Predicted: 1\n",
      "Row 6357 => Predicted: 0\n",
      "Row 6358 => Predicted: 1\n",
      "Row 6359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6350 to 6359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6360 => Predicted: 1\n",
      "Row 6361 => Predicted: 0\n",
      "Row 6362 => Predicted: 0\n",
      "Row 6363 => Predicted: 0\n",
      "Row 6364 => Predicted: 1\n",
      "Row 6365 => Predicted: 1\n",
      "Row 6366 => Predicted: 1\n",
      "Row 6367 => Predicted: 0\n",
      "Row 6368 => Predicted: 0\n",
      "Row 6369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6360 to 6369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6370 => Predicted: 1\n",
      "Row 6371 => Predicted: 1\n",
      "Row 6372 => Predicted: 0\n",
      "Row 6373 => Predicted: 0\n",
      "Row 6374 => Predicted: 1\n",
      "Row 6375 => Predicted: 1\n",
      "Row 6376 => Predicted: 0\n",
      "Row 6377 => Predicted: 0\n",
      "Row 6378 => Predicted: 0\n",
      "Row 6379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6370 to 6379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6380 => Predicted: 1\n",
      "Row 6381 => Predicted: 0\n",
      "Row 6382 => Predicted: 0\n",
      "Row 6383 => Predicted: 1\n",
      "Row 6384 => Predicted: 1\n",
      "Row 6385 => Predicted: 1\n",
      "Row 6386 => Predicted: 1\n",
      "Row 6387 => Predicted: 0\n",
      "Row 6388 => Predicted: 1\n",
      "Row 6389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6380 to 6389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6390 => Predicted: 1\n",
      "Row 6391 => Predicted: 1\n",
      "Row 6392 => Predicted: 0\n",
      "Row 6393 => Predicted: 0\n",
      "Row 6394 => Predicted: 1\n",
      "Row 6395 => Predicted: 0\n",
      "Row 6396 => Predicted: 0\n",
      "Row 6397 => Predicted: 0\n",
      "Row 6398 => Predicted: 1\n",
      "Row 6399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6390 to 6399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6400 => Predicted: 0\n",
      "Row 6401 => Predicted: 0\n",
      "Row 6402 => Predicted: 0\n",
      "Row 6403 => Predicted: 1\n",
      "Row 6404 => Predicted: 1\n",
      "Row 6405 => Predicted: 0\n",
      "Row 6406 => Predicted: 1\n",
      "Row 6407 => Predicted: 1\n",
      "Row 6408 => Predicted: 1\n",
      "Row 6409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6400 to 6409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6410 => Predicted: 0\n",
      "Row 6411 => Predicted: 0\n",
      "Row 6412 => Predicted: 0\n",
      "Row 6413 => Predicted: 0\n",
      "Row 6414 => Predicted: 0\n",
      "Row 6415 => Predicted: 1\n",
      "Row 6416 => Predicted: 1\n",
      "Row 6417 => Predicted: 0\n",
      "Row 6418 => Predicted: 0\n",
      "Row 6419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6410 to 6419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6420 => Predicted: 0\n",
      "Row 6421 => Predicted: 0\n",
      "Row 6422 => Predicted: 1\n",
      "Row 6423 => Predicted: 1\n",
      "Row 6424 => Predicted: 1\n",
      "Row 6425 => Predicted: 1\n",
      "Row 6426 => Predicted: 0\n",
      "Row 6427 => Predicted: 0\n",
      "Row 6428 => Predicted: 0\n",
      "Row 6429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6420 to 6429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6430 => Predicted: 1\n",
      "Row 6431 => Predicted: 1\n",
      "Row 6432 => Predicted: 0\n",
      "Row 6433 => Predicted: 0\n",
      "Row 6434 => Predicted: 1\n",
      "Row 6435 => Predicted: 1\n",
      "Row 6436 => Predicted: 1\n",
      "Row 6437 => Predicted: 1\n",
      "Row 6438 => Predicted: 0\n",
      "Row 6439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6430 to 6439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6440 => Predicted: 1\n",
      "Row 6441 => Predicted: 0\n",
      "Row 6442 => Predicted: 1\n",
      "Row 6443 => Predicted: 0\n",
      "Row 6444 => Predicted: 1\n",
      "Row 6445 => Predicted: 0\n",
      "Row 6446 => Predicted: 0\n",
      "Row 6447 => Predicted: 1\n",
      "Row 6448 => Predicted: 1\n",
      "Row 6449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6440 to 6449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6450 => Predicted: 0\n",
      "Row 6451 => Predicted: 0\n",
      "Row 6452 => Predicted: 1\n",
      "Row 6453 => Predicted: 0\n",
      "Row 6454 => Predicted: 0\n",
      "Row 6455 => Predicted: 0\n",
      "Row 6456 => Predicted: 1\n",
      "Row 6457 => Predicted: 0\n",
      "Row 6458 => Predicted: 1\n",
      "Row 6459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6450 to 6459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6460 => Predicted: 1\n",
      "Row 6461 => Predicted: 1\n",
      "Row 6462 => Predicted: 0\n",
      "Row 6463 => Predicted: 1\n",
      "Row 6464 => Predicted: 0\n",
      "Row 6465 => Predicted: 1\n",
      "Row 6466 => Predicted: 0\n",
      "Row 6467 => Predicted: 1\n",
      "Row 6468 => Predicted: 0\n",
      "Row 6469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6460 to 6469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6470 => Predicted: 0\n",
      "Row 6471 => Predicted: 1\n",
      "Row 6472 => Predicted: 1\n",
      "Row 6473 => Predicted: 1\n",
      "Row 6474 => Predicted: 0\n",
      "Row 6475 => Predicted: 0\n",
      "Row 6476 => Predicted: 1\n",
      "Row 6477 => Predicted: 0\n",
      "Row 6478 => Predicted: 0\n",
      "Row 6479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6470 to 6479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6480 => Predicted: 0\n",
      "Row 6481 => Predicted: 0\n",
      "Row 6482 => Predicted: 0\n",
      "Row 6483 => Predicted: 0\n",
      "Row 6484 => Predicted: 1\n",
      "Row 6485 => Predicted: 1\n",
      "Row 6486 => Predicted: 1\n",
      "Row 6487 => Predicted: 1\n",
      "Row 6488 => Predicted: 1\n",
      "Row 6489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6480 to 6489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6490 => Predicted: 0\n",
      "Row 6491 => Predicted: 0\n",
      "Row 6492 => Predicted: 0\n",
      "Row 6493 => Predicted: 1\n",
      "Row 6494 => Predicted: 1\n",
      "Row 6495 => Predicted: 0\n",
      "Row 6496 => Predicted: 0\n",
      "Row 6497 => Predicted: 0\n",
      "Row 6498 => Predicted: 1\n",
      "Row 6499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6490 to 6499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6500 => Predicted: 0\n",
      "Row 6501 => Predicted: 1\n",
      "Row 6502 => Predicted: 0\n",
      "Row 6503 => Predicted: 1\n",
      "Row 6504 => Predicted: 0\n",
      "Row 6505 => Predicted: 1\n",
      "Row 6506 => Predicted: 1\n",
      "Row 6507 => Predicted: 1\n",
      "Row 6508 => Predicted: 0\n",
      "Row 6509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6500 to 6509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6510 => Predicted: 0\n",
      "Row 6511 => Predicted: 1\n",
      "Row 6512 => Predicted: 1\n",
      "Row 6513 => Predicted: 0\n",
      "Row 6514 => Predicted: 0\n",
      "Row 6515 => Predicted: 1\n",
      "Row 6516 => Predicted: 1\n",
      "Row 6517 => Predicted: 1\n",
      "Row 6518 => Predicted: 1\n",
      "Row 6519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6510 to 6519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6520 => Predicted: 1\n",
      "Row 6521 => Predicted: 0\n",
      "Row 6522 => Predicted: 1\n",
      "Row 6523 => Predicted: 1\n",
      "Row 6524 => Predicted: 0\n",
      "Row 6525 => Predicted: 1\n",
      "Row 6526 => Predicted: 0\n",
      "Row 6527 => Predicted: 0\n",
      "Row 6528 => Predicted: 1\n",
      "Row 6529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6520 to 6529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6530 => Predicted: 1\n",
      "Row 6531 => Predicted: 0\n",
      "Row 6532 => Predicted: 0\n",
      "Row 6533 => Predicted: 0\n",
      "Row 6534 => Predicted: 0\n",
      "Row 6535 => Predicted: 1\n",
      "Row 6536 => Predicted: 1\n",
      "Row 6537 => Predicted: 1\n",
      "Row 6538 => Predicted: 1\n",
      "Row 6539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6530 to 6539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6540 => Predicted: 0\n",
      "Row 6541 => Predicted: 0\n",
      "Row 6542 => Predicted: 0\n",
      "Row 6543 => Predicted: 1\n",
      "Row 6544 => Predicted: 0\n",
      "Row 6545 => Predicted: 1\n",
      "Row 6546 => Predicted: 1\n",
      "Row 6547 => Predicted: 1\n",
      "Row 6548 => Predicted: 1\n",
      "Row 6549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6540 to 6549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6550 => Predicted: 1\n",
      "Row 6551 => Predicted: 1\n",
      "Row 6552 => Predicted: 0\n",
      "Row 6553 => Predicted: 1\n",
      "Row 6554 => Predicted: 1\n",
      "Row 6555 => Predicted: 1\n",
      "Row 6556 => Predicted: 1\n",
      "Row 6557 => Predicted: 0\n",
      "Row 6558 => Predicted: 0\n",
      "Row 6559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6550 to 6559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6560 => Predicted: 0\n",
      "Row 6561 => Predicted: 1\n",
      "Row 6562 => Predicted: 0\n",
      "Row 6563 => Predicted: 0\n",
      "Row 6564 => Predicted: 0\n",
      "Row 6565 => Predicted: 0\n",
      "Row 6566 => Predicted: 0\n",
      "Row 6567 => Predicted: 0\n",
      "Row 6568 => Predicted: 0\n",
      "Row 6569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6560 to 6569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6570 => Predicted: 0\n",
      "Row 6571 => Predicted: 0\n",
      "Row 6572 => Predicted: 0\n",
      "Row 6573 => Predicted: 0\n",
      "Row 6574 => Predicted: 0\n",
      "Row 6575 => Predicted: 1\n",
      "Row 6576 => Predicted: 1\n",
      "Row 6577 => Predicted: 0\n",
      "Row 6578 => Predicted: 0\n",
      "Row 6579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6570 to 6579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6580 => Predicted: 1\n",
      "Row 6581 => Predicted: 1\n",
      "Row 6582 => Predicted: 0\n",
      "Row 6583 => Predicted: 1\n",
      "Row 6584 => Predicted: 0\n",
      "Row 6585 => Predicted: 1\n",
      "Row 6586 => Predicted: 0\n",
      "Row 6587 => Predicted: 0\n",
      "Row 6588 => Predicted: 0\n",
      "Row 6589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6580 to 6589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6590 => Predicted: 0\n",
      "Row 6591 => Predicted: 0\n",
      "Row 6592 => Predicted: 0\n",
      "Row 6593 => Predicted: 0\n",
      "Row 6594 => Predicted: 0\n",
      "Row 6595 => Predicted: 1\n",
      "Row 6596 => Predicted: 1\n",
      "Row 6597 => Predicted: 1\n",
      "Row 6598 => Predicted: 1\n",
      "Row 6599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6590 to 6599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6600 => Predicted: 0\n",
      "Row 6601 => Predicted: 1\n",
      "Row 6602 => Predicted: 1\n",
      "Row 6603 => Predicted: 1\n",
      "Row 6604 => Predicted: 0\n",
      "Row 6605 => Predicted: 0\n",
      "Row 6606 => Predicted: 0\n",
      "Row 6607 => Predicted: 1\n",
      "Row 6608 => Predicted: 0\n",
      "Row 6609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6600 to 6609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6610 => Predicted: 1\n",
      "Row 6611 => Predicted: 0\n",
      "Row 6612 => Predicted: 0\n",
      "Row 6613 => Predicted: 1\n",
      "Row 6614 => Predicted: 0\n",
      "Row 6615 => Predicted: 0\n",
      "Row 6616 => Predicted: 1\n",
      "Row 6617 => Predicted: 1\n",
      "Row 6618 => Predicted: 1\n",
      "Row 6619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6610 to 6619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6620 => Predicted: 1\n",
      "Row 6621 => Predicted: 0\n",
      "Row 6622 => Predicted: 1\n",
      "Row 6623 => Predicted: 0\n",
      "Row 6624 => Predicted: 1\n",
      "Row 6625 => Predicted: 1\n",
      "Row 6626 => Predicted: 0\n",
      "Row 6627 => Predicted: 1\n",
      "Row 6628 => Predicted: 0\n",
      "Row 6629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6620 to 6629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6630 => Predicted: 1\n",
      "Row 6631 => Predicted: 0\n",
      "Row 6632 => Predicted: 1\n",
      "Row 6633 => Predicted: 1\n",
      "Row 6634 => Predicted: 0\n",
      "Row 6635 => Predicted: 0\n",
      "Row 6636 => Predicted: 1\n",
      "Row 6637 => Predicted: 1\n",
      "Row 6638 => Predicted: 1\n",
      "Row 6639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6630 to 6639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6640 => Predicted: 1\n",
      "Row 6641 => Predicted: 0\n",
      "Row 6642 => Predicted: 0\n",
      "Row 6643 => Predicted: 1\n",
      "Row 6644 => Predicted: 0\n",
      "Row 6645 => Predicted: 0\n",
      "Row 6646 => Predicted: 0\n",
      "Row 6647 => Predicted: 0\n",
      "Row 6648 => Predicted: 1\n",
      "Row 6649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6640 to 6649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6650 => Predicted: 0\n",
      "Row 6651 => Predicted: 1\n",
      "Row 6652 => Predicted: 0\n",
      "Row 6653 => Predicted: 1\n",
      "Row 6654 => Predicted: 0\n",
      "Row 6655 => Predicted: 1\n",
      "Row 6656 => Predicted: 1\n",
      "Row 6657 => Predicted: 1\n",
      "Row 6658 => Predicted: 0\n",
      "Row 6659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6650 to 6659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6660 => Predicted: 1\n",
      "Row 6661 => Predicted: 1\n",
      "Row 6662 => Predicted: 1\n",
      "Row 6663 => Predicted: 1\n",
      "Row 6664 => Predicted: 0\n",
      "Row 6665 => Predicted: 1\n",
      "Row 6666 => Predicted: 0\n",
      "Row 6667 => Predicted: 1\n",
      "Row 6668 => Predicted: 1\n",
      "Row 6669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6660 to 6669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6670 => Predicted: 0\n",
      "Row 6671 => Predicted: 0\n",
      "Row 6672 => Predicted: 0\n",
      "Row 6673 => Predicted: 0\n",
      "Row 6674 => Predicted: 0\n",
      "Row 6675 => Predicted: 1\n",
      "Row 6676 => Predicted: 1\n",
      "Row 6677 => Predicted: 0\n",
      "Row 6678 => Predicted: 1\n",
      "Row 6679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6670 to 6679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6680 => Predicted: 1\n",
      "Row 6681 => Predicted: 1\n",
      "Row 6682 => Predicted: 0\n",
      "Row 6683 => Predicted: 0\n",
      "Row 6684 => Predicted: 1\n",
      "Row 6685 => Predicted: 1\n",
      "Row 6686 => Predicted: 0\n",
      "Row 6687 => Predicted: 1\n",
      "Row 6688 => Predicted: 0\n",
      "Row 6689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6680 to 6689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6690 => Predicted: 1\n",
      "Row 6691 => Predicted: 0\n",
      "Row 6692 => Predicted: 0\n",
      "Row 6693 => Predicted: 1\n",
      "Row 6694 => Predicted: 1\n",
      "Row 6695 => Predicted: 0\n",
      "Row 6696 => Predicted: 0\n",
      "Row 6697 => Predicted: 1\n",
      "Row 6698 => Predicted: 1\n",
      "Row 6699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6690 to 6699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6700 => Predicted: 1\n",
      "Row 6701 => Predicted: 0\n",
      "Row 6702 => Predicted: 1\n",
      "Row 6703 => Predicted: 1\n",
      "Row 6704 => Predicted: 1\n",
      "Row 6705 => Predicted: 1\n",
      "Row 6706 => Predicted: 0\n",
      "Row 6707 => Predicted: 1\n",
      "Row 6708 => Predicted: 0\n",
      "Row 6709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6700 to 6709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6710 => Predicted: 0\n",
      "Row 6711 => Predicted: 1\n",
      "Row 6712 => Predicted: 1\n",
      "Row 6713 => Predicted: 0\n",
      "Row 6714 => Predicted: 0\n",
      "Row 6715 => Predicted: 1\n",
      "Row 6716 => Predicted: 0\n",
      "Row 6717 => Predicted: 1\n",
      "Row 6718 => Predicted: 0\n",
      "Row 6719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6710 to 6719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6720 => Predicted: 0\n",
      "Row 6721 => Predicted: 0\n",
      "Row 6722 => Predicted: 0\n",
      "Row 6723 => Predicted: 0\n",
      "Row 6724 => Predicted: 1\n",
      "Row 6725 => Predicted: 1\n",
      "Row 6726 => Predicted: 0\n",
      "Row 6727 => Predicted: 1\n",
      "Row 6728 => Predicted: 1\n",
      "Row 6729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6720 to 6729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6730 => Predicted: 0\n",
      "Row 6731 => Predicted: 1\n",
      "Row 6732 => Predicted: 1\n",
      "Row 6733 => Predicted: 0\n",
      "Row 6734 => Predicted: 0\n",
      "Row 6735 => Predicted: 1\n",
      "Row 6736 => Predicted: 0\n",
      "Row 6737 => Predicted: 1\n",
      "Row 6738 => Predicted: 1\n",
      "Row 6739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6730 to 6739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6740 => Predicted: 1\n",
      "Row 6741 => Predicted: 1\n",
      "Row 6742 => Predicted: 1\n",
      "Row 6743 => Predicted: 1\n",
      "Row 6744 => Predicted: 1\n",
      "Row 6745 => Predicted: 0\n",
      "Row 6746 => Predicted: 1\n",
      "Row 6747 => Predicted: 1\n",
      "Row 6748 => Predicted: 1\n",
      "Row 6749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6740 to 6749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6750 => Predicted: 0\n",
      "Row 6751 => Predicted: 1\n",
      "Row 6752 => Predicted: 1\n",
      "Row 6753 => Predicted: 0\n",
      "Row 6754 => Predicted: 1\n",
      "Row 6755 => Predicted: 0\n",
      "Row 6756 => Predicted: 1\n",
      "Row 6757 => Predicted: 0\n",
      "Row 6758 => Predicted: 1\n",
      "Row 6759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6750 to 6759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6760 => Predicted: 1\n",
      "Row 6761 => Predicted: 1\n",
      "Row 6762 => Predicted: 0\n",
      "Row 6763 => Predicted: 0\n",
      "Row 6764 => Predicted: 0\n",
      "Row 6765 => Predicted: 1\n",
      "Row 6766 => Predicted: 1\n",
      "Row 6767 => Predicted: 0\n",
      "Row 6768 => Predicted: 1\n",
      "Row 6769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6760 to 6769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6770 => Predicted: 0\n",
      "Row 6771 => Predicted: 1\n",
      "Row 6772 => Predicted: 0\n",
      "Row 6773 => Predicted: 1\n",
      "Row 6774 => Predicted: 1\n",
      "Row 6775 => Predicted: 1\n",
      "Row 6776 => Predicted: 1\n",
      "Row 6777 => Predicted: 0\n",
      "Row 6778 => Predicted: 1\n",
      "Row 6779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6770 to 6779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6780 => Predicted: 1\n",
      "Row 6781 => Predicted: 1\n",
      "Row 6782 => Predicted: 1\n",
      "Row 6783 => Predicted: 1\n",
      "Row 6784 => Predicted: 0\n",
      "Row 6785 => Predicted: 0\n",
      "Row 6786 => Predicted: 1\n",
      "Row 6787 => Predicted: 0\n",
      "Row 6788 => Predicted: 1\n",
      "Row 6789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6780 to 6789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6790 => Predicted: 0\n",
      "Row 6791 => Predicted: 1\n",
      "Row 6792 => Predicted: 0\n",
      "Row 6793 => Predicted: 0\n",
      "Row 6794 => Predicted: 1\n",
      "Row 6795 => Predicted: 0\n",
      "Row 6796 => Predicted: 0\n",
      "Row 6797 => Predicted: 0\n",
      "Row 6798 => Predicted: 1\n",
      "Row 6799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6790 to 6799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6800 => Predicted: 0\n",
      "Row 6801 => Predicted: 1\n",
      "Row 6802 => Predicted: 0\n",
      "Row 6803 => Predicted: 0\n",
      "Row 6804 => Predicted: 0\n",
      "Row 6805 => Predicted: 1\n",
      "Row 6806 => Predicted: 0\n",
      "Row 6807 => Predicted: 1\n",
      "Row 6808 => Predicted: 1\n",
      "Row 6809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6800 to 6809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6810 => Predicted: 0\n",
      "Row 6811 => Predicted: 1\n",
      "Row 6812 => Predicted: 0\n",
      "Row 6813 => Predicted: 1\n",
      "Row 6814 => Predicted: 1\n",
      "Row 6815 => Predicted: 0\n",
      "Row 6816 => Predicted: 0\n",
      "Row 6817 => Predicted: 0\n",
      "Row 6818 => Predicted: 1\n",
      "Row 6819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6810 to 6819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6820 => Predicted: 0\n",
      "Row 6821 => Predicted: 0\n",
      "Row 6822 => Predicted: 1\n",
      "Row 6823 => Predicted: 1\n",
      "Row 6824 => Predicted: 0\n",
      "Row 6825 => Predicted: 0\n",
      "Row 6826 => Predicted: 1\n",
      "Row 6827 => Predicted: 1\n",
      "Row 6828 => Predicted: 0\n",
      "Row 6829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6820 to 6829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6830 => Predicted: 0\n",
      "Row 6831 => Predicted: 1\n",
      "Row 6832 => Predicted: 0\n",
      "Row 6833 => Predicted: 1\n",
      "Row 6834 => Predicted: 1\n",
      "Row 6835 => Predicted: 0\n",
      "Row 6836 => Predicted: 1\n",
      "Row 6837 => Predicted: 0\n",
      "Row 6838 => Predicted: 0\n",
      "Row 6839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6830 to 6839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6840 => Predicted: 0\n",
      "Row 6841 => Predicted: 1\n",
      "Row 6842 => Predicted: 1\n",
      "Row 6843 => Predicted: 0\n",
      "Row 6844 => Predicted: 0\n",
      "Row 6845 => Predicted: 1\n",
      "Row 6846 => Predicted: 0\n",
      "Row 6847 => Predicted: 1\n",
      "Row 6848 => Predicted: 0\n",
      "Row 6849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6840 to 6849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6850 => Predicted: 1\n",
      "Row 6851 => Predicted: 1\n",
      "Row 6852 => Predicted: 0\n",
      "Row 6853 => Predicted: 0\n",
      "Row 6854 => Predicted: 0\n",
      "Row 6855 => Predicted: 1\n",
      "Row 6856 => Predicted: 1\n",
      "Row 6857 => Predicted: 0\n",
      "Row 6858 => Predicted: 1\n",
      "Row 6859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6850 to 6859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6860 => Predicted: 0\n",
      "Row 6861 => Predicted: 0\n",
      "Row 6862 => Predicted: 1\n",
      "Row 6863 => Predicted: 1\n",
      "Row 6864 => Predicted: 0\n",
      "Row 6865 => Predicted: 1\n",
      "Row 6866 => Predicted: 1\n",
      "Row 6867 => Predicted: 0\n",
      "Row 6868 => Predicted: 0\n",
      "Row 6869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6860 to 6869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6870 => Predicted: 1\n",
      "Row 6871 => Predicted: 0\n",
      "Row 6872 => Predicted: 0\n",
      "Row 6873 => Predicted: 1\n",
      "Row 6874 => Predicted: 1\n",
      "Row 6875 => Predicted: 1\n",
      "Row 6876 => Predicted: 1\n",
      "Row 6877 => Predicted: 1\n",
      "Row 6878 => Predicted: 1\n",
      "Row 6879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6870 to 6879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6880 => Predicted: 0\n",
      "Row 6881 => Predicted: 0\n",
      "Row 6882 => Predicted: 0\n",
      "Row 6883 => Predicted: 1\n",
      "Row 6884 => Predicted: 0\n",
      "Row 6885 => Predicted: 1\n",
      "Row 6886 => Predicted: 0\n",
      "Row 6887 => Predicted: 0\n",
      "Row 6888 => Predicted: 0\n",
      "Row 6889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6880 to 6889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6890 => Predicted: 1\n",
      "Row 6891 => Predicted: 0\n",
      "Row 6892 => Predicted: 0\n",
      "Row 6893 => Predicted: 1\n",
      "Row 6894 => Predicted: 0\n",
      "Row 6895 => Predicted: 0\n",
      "Row 6896 => Predicted: 1\n",
      "Row 6897 => Predicted: 1\n",
      "Row 6898 => Predicted: 1\n",
      "Row 6899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6890 to 6899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6900 => Predicted: 1\n",
      "Row 6901 => Predicted: 1\n",
      "Row 6902 => Predicted: 1\n",
      "Row 6903 => Predicted: 0\n",
      "Row 6904 => Predicted: 0\n",
      "Row 6905 => Predicted: 1\n",
      "Row 6906 => Predicted: 0\n",
      "Row 6907 => Predicted: 0\n",
      "Row 6908 => Predicted: 1\n",
      "Row 6909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6900 to 6909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6910 => Predicted: 0\n",
      "Row 6911 => Predicted: 1\n",
      "Row 6912 => Predicted: 0\n",
      "Row 6913 => Predicted: 1\n",
      "Row 6914 => Predicted: 0\n",
      "Row 6915 => Predicted: 1\n",
      "Row 6916 => Predicted: 0\n",
      "Row 6917 => Predicted: 0\n",
      "Row 6918 => Predicted: 1\n",
      "Row 6919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6910 to 6919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6920 => Predicted: 1\n",
      "Row 6921 => Predicted: 1\n",
      "Row 6922 => Predicted: 0\n",
      "Row 6923 => Predicted: 0\n",
      "Row 6924 => Predicted: 1\n",
      "Row 6925 => Predicted: 0\n",
      "Row 6926 => Predicted: 1\n",
      "Row 6927 => Predicted: 1\n",
      "Row 6928 => Predicted: 1\n",
      "Row 6929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6920 to 6929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6930 => Predicted: 1\n",
      "Row 6931 => Predicted: 1\n",
      "Row 6932 => Predicted: 1\n",
      "Row 6933 => Predicted: 0\n",
      "Row 6934 => Predicted: 0\n",
      "Row 6935 => Predicted: 1\n",
      "Row 6936 => Predicted: 0\n",
      "Row 6937 => Predicted: 0\n",
      "Row 6938 => Predicted: 1\n",
      "Row 6939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6930 to 6939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6940 => Predicted: 1\n",
      "Row 6941 => Predicted: 0\n",
      "Row 6942 => Predicted: 0\n",
      "Row 6943 => Predicted: 0\n",
      "Row 6944 => Predicted: 0\n",
      "Row 6945 => Predicted: 1\n",
      "Row 6946 => Predicted: 0\n",
      "Row 6947 => Predicted: 1\n",
      "Row 6948 => Predicted: 1\n",
      "Row 6949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6940 to 6949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6950 => Predicted: 0\n",
      "Row 6951 => Predicted: 1\n",
      "Row 6952 => Predicted: 0\n",
      "Row 6953 => Predicted: 0\n",
      "Row 6954 => Predicted: 1\n",
      "Row 6955 => Predicted: 1\n",
      "Row 6956 => Predicted: 1\n",
      "Row 6957 => Predicted: 0\n",
      "Row 6958 => Predicted: 0\n",
      "Row 6959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6950 to 6959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6960 => Predicted: 0\n",
      "Row 6961 => Predicted: 1\n",
      "Row 6962 => Predicted: 0\n",
      "Row 6963 => Predicted: 0\n",
      "Row 6964 => Predicted: 1\n",
      "Row 6965 => Predicted: 1\n",
      "Row 6966 => Predicted: 0\n",
      "Row 6967 => Predicted: 0\n",
      "Row 6968 => Predicted: 1\n",
      "Row 6969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6960 to 6969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6970 => Predicted: 1\n",
      "Row 6971 => Predicted: 0\n",
      "Row 6972 => Predicted: 1\n",
      "Row 6973 => Predicted: 0\n",
      "Row 6974 => Predicted: 0\n",
      "Row 6975 => Predicted: 1\n",
      "Row 6976 => Predicted: 1\n",
      "Row 6977 => Predicted: 1\n",
      "Row 6978 => Predicted: 1\n",
      "Row 6979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6970 to 6979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6980 => Predicted: 1\n",
      "Row 6981 => Predicted: 1\n",
      "Row 6982 => Predicted: 0\n",
      "Row 6983 => Predicted: 0\n",
      "Row 6984 => Predicted: 1\n",
      "Row 6985 => Predicted: 0\n",
      "Row 6986 => Predicted: 0\n",
      "Row 6987 => Predicted: 0\n",
      "Row 6988 => Predicted: 1\n",
      "Row 6989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 6980 to 6989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6990 => Predicted: 1\n",
      "Row 6991 => Predicted: 0\n",
      "Row 6992 => Predicted: 0\n",
      "Row 6993 => Predicted: 0\n",
      "Row 6994 => Predicted: 0\n",
      "Row 6995 => Predicted: 1\n",
      "Row 6996 => Predicted: 1\n",
      "Row 6997 => Predicted: 1\n",
      "Row 6998 => Predicted: 0\n",
      "Row 6999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 6990 to 6999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7000 => Predicted: 1\n",
      "Row 7001 => Predicted: 1\n",
      "Row 7002 => Predicted: 0\n",
      "Row 7003 => Predicted: 1\n",
      "Row 7004 => Predicted: 0\n",
      "Row 7005 => Predicted: 1\n",
      "Row 7006 => Predicted: 0\n",
      "Row 7007 => Predicted: 0\n",
      "Row 7008 => Predicted: 0\n",
      "Row 7009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7000 to 7009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7010 => Predicted: 1\n",
      "Row 7011 => Predicted: 0\n",
      "Row 7012 => Predicted: 0\n",
      "Row 7013 => Predicted: 1\n",
      "Row 7014 => Predicted: 1\n",
      "Row 7015 => Predicted: 1\n",
      "Row 7016 => Predicted: 1\n",
      "Row 7017 => Predicted: 0\n",
      "Row 7018 => Predicted: 1\n",
      "Row 7019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7010 to 7019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7020 => Predicted: 1\n",
      "Row 7021 => Predicted: 1\n",
      "Row 7022 => Predicted: 1\n",
      "Row 7023 => Predicted: 0\n",
      "Row 7024 => Predicted: 1\n",
      "Row 7025 => Predicted: 0\n",
      "Row 7026 => Predicted: 0\n",
      "Row 7027 => Predicted: 0\n",
      "Row 7028 => Predicted: 1\n",
      "Row 7029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7020 to 7029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7030 => Predicted: 1\n",
      "Row 7031 => Predicted: 1\n",
      "Row 7032 => Predicted: 1\n",
      "Row 7033 => Predicted: 1\n",
      "Row 7034 => Predicted: 1\n",
      "Row 7035 => Predicted: 1\n",
      "Row 7036 => Predicted: 1\n",
      "Row 7037 => Predicted: 1\n",
      "Row 7038 => Predicted: 1\n",
      "Row 7039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7030 to 7039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7040 => Predicted: 0\n",
      "Row 7041 => Predicted: 1\n",
      "Row 7042 => Predicted: 0\n",
      "Row 7043 => Predicted: 0\n",
      "Row 7044 => Predicted: 0\n",
      "Row 7045 => Predicted: 1\n",
      "Row 7046 => Predicted: 1\n",
      "Row 7047 => Predicted: 0\n",
      "Row 7048 => Predicted: 0\n",
      "Row 7049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7040 to 7049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7050 => Predicted: 0\n",
      "Row 7051 => Predicted: 1\n",
      "Row 7052 => Predicted: 0\n",
      "Row 7053 => Predicted: 1\n",
      "Row 7054 => Predicted: 1\n",
      "Row 7055 => Predicted: 0\n",
      "Row 7056 => Predicted: 1\n",
      "Row 7057 => Predicted: 1\n",
      "Row 7058 => Predicted: 1\n",
      "Row 7059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7050 to 7059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7060 => Predicted: 1\n",
      "Row 7061 => Predicted: 1\n",
      "Row 7062 => Predicted: 1\n",
      "Row 7063 => Predicted: 1\n",
      "Row 7064 => Predicted: 0\n",
      "Row 7065 => Predicted: 0\n",
      "Row 7066 => Predicted: 0\n",
      "Row 7067 => Predicted: 1\n",
      "Row 7068 => Predicted: 1\n",
      "Row 7069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7060 to 7069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7070 => Predicted: 0\n",
      "Row 7071 => Predicted: 0\n",
      "Row 7072 => Predicted: 1\n",
      "Row 7073 => Predicted: 0\n",
      "Row 7074 => Predicted: 0\n",
      "Row 7075 => Predicted: 0\n",
      "Row 7076 => Predicted: 0\n",
      "Row 7077 => Predicted: 1\n",
      "Row 7078 => Predicted: 1\n",
      "Row 7079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7070 to 7079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7080 => Predicted: 1\n",
      "Row 7081 => Predicted: 1\n",
      "Row 7082 => Predicted: 0\n",
      "Row 7083 => Predicted: 0\n",
      "Row 7084 => Predicted: 0\n",
      "Row 7085 => Predicted: 0\n",
      "Row 7086 => Predicted: 1\n",
      "Row 7087 => Predicted: 0\n",
      "Row 7088 => Predicted: 1\n",
      "Row 7089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7080 to 7089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7090 => Predicted: 0\n",
      "Row 7091 => Predicted: 0\n",
      "Row 7092 => Predicted: 0\n",
      "Row 7093 => Predicted: 0\n",
      "Row 7094 => Predicted: 0\n",
      "Row 7095 => Predicted: 0\n",
      "Row 7096 => Predicted: 1\n",
      "Row 7097 => Predicted: 0\n",
      "Row 7098 => Predicted: 1\n",
      "Row 7099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7090 to 7099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7100 => Predicted: 1\n",
      "Row 7101 => Predicted: 1\n",
      "Row 7102 => Predicted: 0\n",
      "Row 7103 => Predicted: 1\n",
      "Row 7104 => Predicted: 0\n",
      "Row 7105 => Predicted: 1\n",
      "Row 7106 => Predicted: 0\n",
      "Row 7107 => Predicted: 0\n",
      "Row 7108 => Predicted: 0\n",
      "Row 7109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7100 to 7109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7110 => Predicted: 0\n",
      "Row 7111 => Predicted: 0\n",
      "Row 7112 => Predicted: 1\n",
      "Row 7113 => Predicted: 0\n",
      "Row 7114 => Predicted: 1\n",
      "Row 7115 => Predicted: 0\n",
      "Row 7116 => Predicted: 0\n",
      "Row 7117 => Predicted: 1\n",
      "Row 7118 => Predicted: 1\n",
      "Row 7119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7110 to 7119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7120 => Predicted: 1\n",
      "Row 7121 => Predicted: 1\n",
      "Row 7122 => Predicted: 0\n",
      "Row 7123 => Predicted: 0\n",
      "Row 7124 => Predicted: 0\n",
      "Row 7125 => Predicted: 1\n",
      "Row 7126 => Predicted: 0\n",
      "Row 7127 => Predicted: 0\n",
      "Row 7128 => Predicted: 1\n",
      "Row 7129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7120 to 7129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7130 => Predicted: 1\n",
      "Row 7131 => Predicted: 1\n",
      "Row 7132 => Predicted: 1\n",
      "Row 7133 => Predicted: 0\n",
      "Row 7134 => Predicted: 0\n",
      "Row 7135 => Predicted: 0\n",
      "Row 7136 => Predicted: 1\n",
      "Row 7137 => Predicted: 0\n",
      "Row 7138 => Predicted: 0\n",
      "Row 7139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7130 to 7139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7140 => Predicted: 0\n",
      "Row 7141 => Predicted: 0\n",
      "Row 7142 => Predicted: 0\n",
      "Row 7143 => Predicted: 0\n",
      "Row 7144 => Predicted: 0\n",
      "Row 7145 => Predicted: 1\n",
      "Row 7146 => Predicted: 0\n",
      "Row 7147 => Predicted: 1\n",
      "Row 7148 => Predicted: 0\n",
      "Row 7149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7140 to 7149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7150 => Predicted: 0\n",
      "Row 7151 => Predicted: 0\n",
      "Row 7152 => Predicted: 1\n",
      "Row 7153 => Predicted: 0\n",
      "Row 7154 => Predicted: 1\n",
      "Row 7155 => Predicted: 1\n",
      "Row 7156 => Predicted: 1\n",
      "Row 7157 => Predicted: 0\n",
      "Row 7158 => Predicted: 1\n",
      "Row 7159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7150 to 7159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7160 => Predicted: 1\n",
      "Row 7161 => Predicted: 0\n",
      "Row 7162 => Predicted: 0\n",
      "Row 7163 => Predicted: 0\n",
      "Row 7164 => Predicted: 0\n",
      "Row 7165 => Predicted: 0\n",
      "Row 7166 => Predicted: 0\n",
      "Row 7167 => Predicted: 0\n",
      "Row 7168 => Predicted: 1\n",
      "Row 7169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7160 to 7169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7170 => Predicted: 0\n",
      "Row 7171 => Predicted: 0\n",
      "Row 7172 => Predicted: 0\n",
      "Row 7173 => Predicted: 0\n",
      "Row 7174 => Predicted: 1\n",
      "Row 7175 => Predicted: 0\n",
      "Row 7176 => Predicted: 0\n",
      "Row 7177 => Predicted: 1\n",
      "Row 7178 => Predicted: 0\n",
      "Row 7179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7170 to 7179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7180 => Predicted: 1\n",
      "Row 7181 => Predicted: 0\n",
      "Row 7182 => Predicted: 1\n",
      "Row 7183 => Predicted: 0\n",
      "Row 7184 => Predicted: 1\n",
      "Row 7185 => Predicted: 1\n",
      "Row 7186 => Predicted: 1\n",
      "Row 7187 => Predicted: 0\n",
      "Row 7188 => Predicted: 0\n",
      "Row 7189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7180 to 7189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7190 => Predicted: 1\n",
      "Row 7191 => Predicted: 0\n",
      "Row 7192 => Predicted: 1\n",
      "Row 7193 => Predicted: 1\n",
      "Row 7194 => Predicted: 1\n",
      "Row 7195 => Predicted: 1\n",
      "Row 7196 => Predicted: 0\n",
      "Row 7197 => Predicted: 1\n",
      "Row 7198 => Predicted: 1\n",
      "Row 7199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7190 to 7199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7200 => Predicted: 1\n",
      "Row 7201 => Predicted: 1\n",
      "Row 7202 => Predicted: 0\n",
      "Row 7203 => Predicted: 0\n",
      "Row 7204 => Predicted: 0\n",
      "Row 7205 => Predicted: 1\n",
      "Row 7206 => Predicted: 1\n",
      "Row 7207 => Predicted: 1\n",
      "Row 7208 => Predicted: 1\n",
      "Row 7209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7200 to 7209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7210 => Predicted: 1\n",
      "Row 7211 => Predicted: 1\n",
      "Row 7212 => Predicted: 1\n",
      "Row 7213 => Predicted: 1\n",
      "Row 7214 => Predicted: 0\n",
      "Row 7215 => Predicted: 1\n",
      "Row 7216 => Predicted: 1\n",
      "Row 7217 => Predicted: 0\n",
      "Row 7218 => Predicted: 1\n",
      "Row 7219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7210 to 7219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7220 => Predicted: 1\n",
      "Row 7221 => Predicted: 0\n",
      "Row 7222 => Predicted: 0\n",
      "Row 7223 => Predicted: 1\n",
      "Row 7224 => Predicted: 1\n",
      "Row 7225 => Predicted: 0\n",
      "Row 7226 => Predicted: 1\n",
      "Row 7227 => Predicted: 0\n",
      "Row 7228 => Predicted: 1\n",
      "Row 7229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7220 to 7229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7230 => Predicted: 1\n",
      "Row 7231 => Predicted: 1\n",
      "Row 7232 => Predicted: 1\n",
      "Row 7233 => Predicted: 1\n",
      "Row 7234 => Predicted: 0\n",
      "Row 7235 => Predicted: 1\n",
      "Row 7236 => Predicted: 1\n",
      "Row 7237 => Predicted: 0\n",
      "Row 7238 => Predicted: 1\n",
      "Row 7239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7230 to 7239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7240 => Predicted: 0\n",
      "Row 7241 => Predicted: 1\n",
      "Row 7242 => Predicted: 1\n",
      "Row 7243 => Predicted: 1\n",
      "Row 7244 => Predicted: 1\n",
      "Row 7245 => Predicted: 0\n",
      "Row 7246 => Predicted: 1\n",
      "Row 7247 => Predicted: 1\n",
      "Row 7248 => Predicted: 1\n",
      "Row 7249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7240 to 7249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7250 => Predicted: 0\n",
      "Row 7251 => Predicted: 0\n",
      "Row 7252 => Predicted: 0\n",
      "Row 7253 => Predicted: 1\n",
      "Row 7254 => Predicted: 1\n",
      "Row 7255 => Predicted: 0\n",
      "Row 7256 => Predicted: 0\n",
      "Row 7257 => Predicted: 0\n",
      "Row 7258 => Predicted: 1\n",
      "Row 7259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7250 to 7259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7260 => Predicted: 1\n",
      "Row 7261 => Predicted: 1\n",
      "Row 7262 => Predicted: 0\n",
      "Row 7263 => Predicted: 0\n",
      "Row 7264 => Predicted: 1\n",
      "Row 7265 => Predicted: 1\n",
      "Row 7266 => Predicted: 1\n",
      "Row 7267 => Predicted: 1\n",
      "Row 7268 => Predicted: 1\n",
      "Row 7269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7260 to 7269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7270 => Predicted: 1\n",
      "Row 7271 => Predicted: 1\n",
      "Row 7272 => Predicted: 1\n",
      "Row 7273 => Predicted: 0\n",
      "Row 7274 => Predicted: 1\n",
      "Row 7275 => Predicted: 0\n",
      "Row 7276 => Predicted: 0\n",
      "Row 7277 => Predicted: 0\n",
      "Row 7278 => Predicted: 0\n",
      "Row 7279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7270 to 7279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7280 => Predicted: 1\n",
      "Row 7281 => Predicted: 0\n",
      "Row 7282 => Predicted: 0\n",
      "Row 7283 => Predicted: 0\n",
      "Row 7284 => Predicted: 1\n",
      "Row 7285 => Predicted: 0\n",
      "Row 7286 => Predicted: 1\n",
      "Row 7287 => Predicted: 0\n",
      "Row 7288 => Predicted: 0\n",
      "Row 7289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7280 to 7289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7290 => Predicted: 1\n",
      "Row 7291 => Predicted: 1\n",
      "Row 7292 => Predicted: 0\n",
      "Row 7293 => Predicted: 0\n",
      "Row 7294 => Predicted: 0\n",
      "Row 7295 => Predicted: 1\n",
      "Row 7296 => Predicted: 1\n",
      "Row 7297 => Predicted: 0\n",
      "Row 7298 => Predicted: 1\n",
      "Row 7299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7290 to 7299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7300 => Predicted: 0\n",
      "Row 7301 => Predicted: 0\n",
      "Row 7302 => Predicted: 1\n",
      "Row 7303 => Predicted: 1\n",
      "Row 7304 => Predicted: 0\n",
      "Row 7305 => Predicted: 1\n",
      "Row 7306 => Predicted: 1\n",
      "Row 7307 => Predicted: 1\n",
      "Row 7308 => Predicted: 1\n",
      "Row 7309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7300 to 7309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7310 => Predicted: 1\n",
      "Row 7311 => Predicted: 0\n",
      "Row 7312 => Predicted: 1\n",
      "Row 7313 => Predicted: 0\n",
      "Row 7314 => Predicted: 1\n",
      "Row 7315 => Predicted: 1\n",
      "Row 7316 => Predicted: 0\n",
      "Row 7317 => Predicted: 0\n",
      "Row 7318 => Predicted: 0\n",
      "Row 7319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7310 to 7319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7320 => Predicted: 1\n",
      "Row 7321 => Predicted: 0\n",
      "Row 7322 => Predicted: 1\n",
      "Row 7323 => Predicted: 1\n",
      "Row 7324 => Predicted: 1\n",
      "Row 7325 => Predicted: 1\n",
      "Row 7326 => Predicted: 1\n",
      "Row 7327 => Predicted: 0\n",
      "Row 7328 => Predicted: 1\n",
      "Row 7329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7320 to 7329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7330 => Predicted: 0\n",
      "Row 7331 => Predicted: 1\n",
      "Row 7332 => Predicted: 0\n",
      "Row 7333 => Predicted: 0\n",
      "Row 7334 => Predicted: 0\n",
      "Row 7335 => Predicted: 1\n",
      "Row 7336 => Predicted: 0\n",
      "Row 7337 => Predicted: 0\n",
      "Row 7338 => Predicted: 0\n",
      "Row 7339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7330 to 7339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7340 => Predicted: 1\n",
      "Row 7341 => Predicted: 0\n",
      "Row 7342 => Predicted: 0\n",
      "Row 7343 => Predicted: 1\n",
      "Row 7344 => Predicted: 1\n",
      "Row 7345 => Predicted: 1\n",
      "Row 7346 => Predicted: 0\n",
      "Row 7347 => Predicted: 1\n",
      "Row 7348 => Predicted: 0\n",
      "Row 7349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7340 to 7349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7350 => Predicted: 0\n",
      "Row 7351 => Predicted: 1\n",
      "Row 7352 => Predicted: 1\n",
      "Row 7353 => Predicted: 1\n",
      "Row 7354 => Predicted: 0\n",
      "Row 7355 => Predicted: 0\n",
      "Row 7356 => Predicted: 1\n",
      "Row 7357 => Predicted: 0\n",
      "Row 7358 => Predicted: 1\n",
      "Row 7359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7350 to 7359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7360 => Predicted: 0\n",
      "Row 7361 => Predicted: 0\n",
      "Row 7362 => Predicted: 0\n",
      "Row 7363 => Predicted: 0\n",
      "Row 7364 => Predicted: 1\n",
      "Row 7365 => Predicted: 1\n",
      "Row 7366 => Predicted: 1\n",
      "Row 7367 => Predicted: 1\n",
      "Row 7368 => Predicted: 0\n",
      "Row 7369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7360 to 7369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7370 => Predicted: 0\n",
      "Row 7371 => Predicted: 1\n",
      "Row 7372 => Predicted: 1\n",
      "Row 7373 => Predicted: 0\n",
      "Row 7374 => Predicted: 0\n",
      "Row 7375 => Predicted: 1\n",
      "Row 7376 => Predicted: 1\n",
      "Row 7377 => Predicted: 1\n",
      "Row 7378 => Predicted: 0\n",
      "Row 7379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7370 to 7379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7380 => Predicted: 0\n",
      "Row 7381 => Predicted: 0\n",
      "Row 7382 => Predicted: 1\n",
      "Row 7383 => Predicted: 1\n",
      "Row 7384 => Predicted: 1\n",
      "Row 7385 => Predicted: 0\n",
      "Row 7386 => Predicted: 0\n",
      "Row 7387 => Predicted: 0\n",
      "Row 7388 => Predicted: 1\n",
      "Row 7389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7380 to 7389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7390 => Predicted: 0\n",
      "Row 7391 => Predicted: 1\n",
      "Row 7392 => Predicted: 1\n",
      "Row 7393 => Predicted: 1\n",
      "Row 7394 => Predicted: 0\n",
      "Row 7395 => Predicted: 1\n",
      "Row 7396 => Predicted: 0\n",
      "Row 7397 => Predicted: 0\n",
      "Row 7398 => Predicted: 1\n",
      "Row 7399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7390 to 7399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7400 => Predicted: 1\n",
      "Row 7401 => Predicted: 0\n",
      "Row 7402 => Predicted: 1\n",
      "Row 7403 => Predicted: 0\n",
      "Row 7404 => Predicted: 1\n",
      "Row 7405 => Predicted: 0\n",
      "Row 7406 => Predicted: 1\n",
      "Row 7407 => Predicted: 0\n",
      "Row 7408 => Predicted: 1\n",
      "Row 7409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7400 to 7409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7410 => Predicted: 0\n",
      "Row 7411 => Predicted: 0\n",
      "Row 7412 => Predicted: 0\n",
      "Row 7413 => Predicted: 1\n",
      "Row 7414 => Predicted: 1\n",
      "Row 7415 => Predicted: 1\n",
      "Row 7416 => Predicted: 1\n",
      "Row 7417 => Predicted: 1\n",
      "Row 7418 => Predicted: 0\n",
      "Row 7419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7410 to 7419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7420 => Predicted: 0\n",
      "Row 7421 => Predicted: 1\n",
      "Row 7422 => Predicted: 0\n",
      "Row 7423 => Predicted: 1\n",
      "Row 7424 => Predicted: 1\n",
      "Row 7425 => Predicted: 1\n",
      "Row 7426 => Predicted: 1\n",
      "Row 7427 => Predicted: 0\n",
      "Row 7428 => Predicted: 0\n",
      "Row 7429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7420 to 7429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7430 => Predicted: 0\n",
      "Row 7431 => Predicted: 0\n",
      "Row 7432 => Predicted: 0\n",
      "Row 7433 => Predicted: 1\n",
      "Row 7434 => Predicted: 1\n",
      "Row 7435 => Predicted: 1\n",
      "Row 7436 => Predicted: 0\n",
      "Row 7437 => Predicted: 0\n",
      "Row 7438 => Predicted: 1\n",
      "Row 7439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7430 to 7439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7440 => Predicted: 0\n",
      "Row 7441 => Predicted: 1\n",
      "Row 7442 => Predicted: 0\n",
      "Row 7443 => Predicted: 1\n",
      "Row 7444 => Predicted: 0\n",
      "Row 7445 => Predicted: 0\n",
      "Row 7446 => Predicted: 1\n",
      "Row 7447 => Predicted: 1\n",
      "Row 7448 => Predicted: 1\n",
      "Row 7449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7440 to 7449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7450 => Predicted: 0\n",
      "Row 7451 => Predicted: 1\n",
      "Row 7452 => Predicted: 1\n",
      "Row 7453 => Predicted: 0\n",
      "Row 7454 => Predicted: 1\n",
      "Row 7455 => Predicted: 0\n",
      "Row 7456 => Predicted: 0\n",
      "Row 7457 => Predicted: 1\n",
      "Row 7458 => Predicted: 0\n",
      "Row 7459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7450 to 7459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7460 => Predicted: 1\n",
      "Row 7461 => Predicted: 1\n",
      "Row 7462 => Predicted: 0\n",
      "Row 7463 => Predicted: 0\n",
      "Row 7464 => Predicted: 1\n",
      "Row 7465 => Predicted: 0\n",
      "Row 7466 => Predicted: 1\n",
      "Row 7467 => Predicted: 1\n",
      "Row 7468 => Predicted: 0\n",
      "Row 7469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7460 to 7469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7470 => Predicted: 1\n",
      "Row 7471 => Predicted: 0\n",
      "Row 7472 => Predicted: 1\n",
      "Row 7473 => Predicted: 1\n",
      "Row 7474 => Predicted: 0\n",
      "Row 7475 => Predicted: 0\n",
      "Row 7476 => Predicted: 0\n",
      "Row 7477 => Predicted: 1\n",
      "Row 7478 => Predicted: 1\n",
      "Row 7479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7470 to 7479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7480 => Predicted: 1\n",
      "Row 7481 => Predicted: 1\n",
      "Row 7482 => Predicted: 0\n",
      "Row 7483 => Predicted: 0\n",
      "Row 7484 => Predicted: 1\n",
      "Row 7485 => Predicted: 1\n",
      "Row 7486 => Predicted: 0\n",
      "Row 7487 => Predicted: 0\n",
      "Row 7488 => Predicted: 0\n",
      "Row 7489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7480 to 7489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7490 => Predicted: 1\n",
      "Row 7491 => Predicted: 0\n",
      "Row 7492 => Predicted: 0\n",
      "Row 7493 => Predicted: 1\n",
      "Row 7494 => Predicted: 1\n",
      "Row 7495 => Predicted: 0\n",
      "Row 7496 => Predicted: 1\n",
      "Row 7497 => Predicted: 1\n",
      "Row 7498 => Predicted: 0\n",
      "Row 7499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7490 to 7499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7500 => Predicted: 1\n",
      "Row 7501 => Predicted: 0\n",
      "Row 7502 => Predicted: 0\n",
      "Row 7503 => Predicted: 0\n",
      "Row 7504 => Predicted: 1\n",
      "Row 7505 => Predicted: 0\n",
      "Row 7506 => Predicted: 1\n",
      "Row 7507 => Predicted: 1\n",
      "Row 7508 => Predicted: 1\n",
      "Row 7509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7500 to 7509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7510 => Predicted: 0\n",
      "Row 7511 => Predicted: 0\n",
      "Row 7512 => Predicted: 1\n",
      "Row 7513 => Predicted: 1\n",
      "Row 7514 => Predicted: 1\n",
      "Row 7515 => Predicted: 0\n",
      "Row 7516 => Predicted: 1\n",
      "Row 7517 => Predicted: 1\n",
      "Row 7518 => Predicted: 1\n",
      "Row 7519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7510 to 7519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7520 => Predicted: 1\n",
      "Row 7521 => Predicted: 1\n",
      "Row 7522 => Predicted: 1\n",
      "Row 7523 => Predicted: 1\n",
      "Row 7524 => Predicted: 1\n",
      "Row 7525 => Predicted: 0\n",
      "Row 7526 => Predicted: 0\n",
      "Row 7527 => Predicted: 1\n",
      "Row 7528 => Predicted: 1\n",
      "Row 7529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7520 to 7529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7530 => Predicted: 1\n",
      "Row 7531 => Predicted: 0\n",
      "Row 7532 => Predicted: 0\n",
      "Row 7533 => Predicted: 1\n",
      "Row 7534 => Predicted: 0\n",
      "Row 7535 => Predicted: 1\n",
      "Row 7536 => Predicted: 1\n",
      "Row 7537 => Predicted: 0\n",
      "Row 7538 => Predicted: 1\n",
      "Row 7539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7530 to 7539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7540 => Predicted: 0\n",
      "Row 7541 => Predicted: 1\n",
      "Row 7542 => Predicted: 0\n",
      "Row 7543 => Predicted: 0\n",
      "Row 7544 => Predicted: 1\n",
      "Row 7545 => Predicted: 0\n",
      "Row 7546 => Predicted: 1\n",
      "Row 7547 => Predicted: 1\n",
      "Row 7548 => Predicted: 0\n",
      "Row 7549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7540 to 7549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7550 => Predicted: 0\n",
      "Row 7551 => Predicted: 1\n",
      "Row 7552 => Predicted: 1\n",
      "Row 7553 => Predicted: 1\n",
      "Row 7554 => Predicted: 0\n",
      "Row 7555 => Predicted: 0\n",
      "Row 7556 => Predicted: 1\n",
      "Row 7557 => Predicted: 1\n",
      "Row 7558 => Predicted: 1\n",
      "Row 7559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7550 to 7559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7560 => Predicted: 1\n",
      "Row 7561 => Predicted: 0\n",
      "Row 7562 => Predicted: 0\n",
      "Row 7563 => Predicted: 1\n",
      "Row 7564 => Predicted: 1\n",
      "Row 7565 => Predicted: 1\n",
      "Row 7566 => Predicted: 1\n",
      "Row 7567 => Predicted: 1\n",
      "Row 7568 => Predicted: 0\n",
      "Row 7569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7560 to 7569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7570 => Predicted: 0\n",
      "Row 7571 => Predicted: 1\n",
      "Row 7572 => Predicted: 0\n",
      "Row 7573 => Predicted: 0\n",
      "Row 7574 => Predicted: 0\n",
      "Row 7575 => Predicted: 1\n",
      "Row 7576 => Predicted: 1\n",
      "Row 7577 => Predicted: 0\n",
      "Row 7578 => Predicted: 0\n",
      "Row 7579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7570 to 7579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7580 => Predicted: 1\n",
      "Row 7581 => Predicted: 1\n",
      "Row 7582 => Predicted: 0\n",
      "Row 7583 => Predicted: 1\n",
      "Row 7584 => Predicted: 0\n",
      "Row 7585 => Predicted: 1\n",
      "Row 7586 => Predicted: 1\n",
      "Row 7587 => Predicted: 0\n",
      "Row 7588 => Predicted: 1\n",
      "Row 7589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7580 to 7589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7590 => Predicted: 1\n",
      "Row 7591 => Predicted: 1\n",
      "Row 7592 => Predicted: 0\n",
      "Row 7593 => Predicted: 1\n",
      "Row 7594 => Predicted: 1\n",
      "Row 7595 => Predicted: 1\n",
      "Row 7596 => Predicted: 0\n",
      "Row 7597 => Predicted: 1\n",
      "Row 7598 => Predicted: 0\n",
      "Row 7599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7590 to 7599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7600 => Predicted: 1\n",
      "Row 7601 => Predicted: 0\n",
      "Row 7602 => Predicted: 0\n",
      "Row 7603 => Predicted: 1\n",
      "Row 7604 => Predicted: 0\n",
      "Row 7605 => Predicted: 1\n",
      "Row 7606 => Predicted: 0\n",
      "Row 7607 => Predicted: 1\n",
      "Row 7608 => Predicted: 1\n",
      "Row 7609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7600 to 7609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7610 => Predicted: 0\n",
      "Row 7611 => Predicted: 0\n",
      "Row 7612 => Predicted: 1\n",
      "Row 7613 => Predicted: 1\n",
      "Row 7614 => Predicted: 1\n",
      "Row 7615 => Predicted: 0\n",
      "Row 7616 => Predicted: 0\n",
      "Row 7617 => Predicted: 1\n",
      "Row 7618 => Predicted: 0\n",
      "Row 7619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7610 to 7619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7620 => Predicted: 1\n",
      "Row 7621 => Predicted: 0\n",
      "Row 7622 => Predicted: 0\n",
      "Row 7623 => Predicted: 1\n",
      "Row 7624 => Predicted: 1\n",
      "Row 7625 => Predicted: 1\n",
      "Row 7626 => Predicted: 1\n",
      "Row 7627 => Predicted: 0\n",
      "Row 7628 => Predicted: 0\n",
      "Row 7629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7620 to 7629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7630 => Predicted: 0\n",
      "Row 7631 => Predicted: 0\n",
      "Row 7632 => Predicted: 1\n",
      "Row 7633 => Predicted: 0\n",
      "Row 7634 => Predicted: 0\n",
      "Row 7635 => Predicted: 1\n",
      "Row 7636 => Predicted: 1\n",
      "Row 7637 => Predicted: 1\n",
      "Row 7638 => Predicted: 0\n",
      "Row 7639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7630 to 7639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7640 => Predicted: 1\n",
      "Row 7641 => Predicted: 0\n",
      "Row 7642 => Predicted: 0\n",
      "Row 7643 => Predicted: 0\n",
      "Row 7644 => Predicted: 1\n",
      "Row 7645 => Predicted: 1\n",
      "Row 7646 => Predicted: 1\n",
      "Row 7647 => Predicted: 0\n",
      "Row 7648 => Predicted: 1\n",
      "Row 7649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7640 to 7649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7650 => Predicted: 1\n",
      "Row 7651 => Predicted: 0\n",
      "Row 7652 => Predicted: 0\n",
      "Row 7653 => Predicted: 1\n",
      "Row 7654 => Predicted: 0\n",
      "Row 7655 => Predicted: 1\n",
      "Row 7656 => Predicted: 0\n",
      "Row 7657 => Predicted: 1\n",
      "Row 7658 => Predicted: 1\n",
      "Row 7659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7650 to 7659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7660 => Predicted: 0\n",
      "Row 7661 => Predicted: 0\n",
      "Row 7662 => Predicted: 0\n",
      "Row 7663 => Predicted: 1\n",
      "Row 7664 => Predicted: 1\n",
      "Row 7665 => Predicted: 0\n",
      "Row 7666 => Predicted: 1\n",
      "Row 7667 => Predicted: 1\n",
      "Row 7668 => Predicted: 0\n",
      "Row 7669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7660 to 7669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7670 => Predicted: 1\n",
      "Row 7671 => Predicted: 0\n",
      "Row 7672 => Predicted: 1\n",
      "Row 7673 => Predicted: 0\n",
      "Row 7674 => Predicted: 1\n",
      "Row 7675 => Predicted: 0\n",
      "Row 7676 => Predicted: 0\n",
      "Row 7677 => Predicted: 1\n",
      "Row 7678 => Predicted: 1\n",
      "Row 7679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7670 to 7679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7680 => Predicted: 0\n",
      "Row 7681 => Predicted: 0\n",
      "Row 7682 => Predicted: 0\n",
      "Row 7683 => Predicted: 1\n",
      "Row 7684 => Predicted: 0\n",
      "Row 7685 => Predicted: 0\n",
      "Row 7686 => Predicted: 1\n",
      "Row 7687 => Predicted: 1\n",
      "Row 7688 => Predicted: 0\n",
      "Row 7689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7680 to 7689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7690 => Predicted: 0\n",
      "Row 7691 => Predicted: 0\n",
      "Row 7692 => Predicted: 1\n",
      "Row 7693 => Predicted: 0\n",
      "Row 7694 => Predicted: 0\n",
      "Row 7695 => Predicted: 1\n",
      "Row 7696 => Predicted: 1\n",
      "Row 7697 => Predicted: 1\n",
      "Row 7698 => Predicted: 1\n",
      "Row 7699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7690 to 7699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7700 => Predicted: 0\n",
      "Row 7701 => Predicted: 0\n",
      "Row 7702 => Predicted: 1\n",
      "Row 7703 => Predicted: 1\n",
      "Row 7704 => Predicted: 1\n",
      "Row 7705 => Predicted: 1\n",
      "Row 7706 => Predicted: 0\n",
      "Row 7707 => Predicted: 1\n",
      "Row 7708 => Predicted: 1\n",
      "Row 7709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7700 to 7709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7710 => Predicted: 1\n",
      "Row 7711 => Predicted: 1\n",
      "Row 7712 => Predicted: 0\n",
      "Row 7713 => Predicted: 1\n",
      "Row 7714 => Predicted: 1\n",
      "Row 7715 => Predicted: 0\n",
      "Row 7716 => Predicted: 0\n",
      "Row 7717 => Predicted: 1\n",
      "Row 7718 => Predicted: 0\n",
      "Row 7719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7710 to 7719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7720 => Predicted: 1\n",
      "Row 7721 => Predicted: 0\n",
      "Row 7722 => Predicted: 1\n",
      "Row 7723 => Predicted: 0\n",
      "Row 7724 => Predicted: 0\n",
      "Row 7725 => Predicted: 1\n",
      "Row 7726 => Predicted: 1\n",
      "Row 7727 => Predicted: 0\n",
      "Row 7728 => Predicted: 1\n",
      "Row 7729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7720 to 7729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7730 => Predicted: 1\n",
      "Row 7731 => Predicted: 0\n",
      "Row 7732 => Predicted: 1\n",
      "Row 7733 => Predicted: 1\n",
      "Row 7734 => Predicted: 1\n",
      "Row 7735 => Predicted: 0\n",
      "Row 7736 => Predicted: 0\n",
      "Row 7737 => Predicted: 1\n",
      "Row 7738 => Predicted: 1\n",
      "Row 7739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7730 to 7739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7740 => Predicted: 1\n",
      "Row 7741 => Predicted: 0\n",
      "Row 7742 => Predicted: 0\n",
      "Row 7743 => Predicted: 1\n",
      "Row 7744 => Predicted: 0\n",
      "Row 7745 => Predicted: 1\n",
      "Row 7746 => Predicted: 0\n",
      "Row 7747 => Predicted: 1\n",
      "Row 7748 => Predicted: 0\n",
      "Row 7749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7740 to 7749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7750 => Predicted: 0\n",
      "Row 7751 => Predicted: 0\n",
      "Row 7752 => Predicted: 0\n",
      "Row 7753 => Predicted: 0\n",
      "Row 7754 => Predicted: 0\n",
      "Row 7755 => Predicted: 1\n",
      "Row 7756 => Predicted: 1\n",
      "Row 7757 => Predicted: 1\n",
      "Row 7758 => Predicted: 1\n",
      "Row 7759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7750 to 7759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7760 => Predicted: 0\n",
      "Row 7761 => Predicted: 0\n",
      "Row 7762 => Predicted: 1\n",
      "Row 7763 => Predicted: 1\n",
      "Row 7764 => Predicted: 1\n",
      "Row 7765 => Predicted: 1\n",
      "Row 7766 => Predicted: 1\n",
      "Row 7767 => Predicted: 0\n",
      "Row 7768 => Predicted: 0\n",
      "Row 7769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7760 to 7769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7770 => Predicted: 0\n",
      "Row 7771 => Predicted: 1\n",
      "Row 7772 => Predicted: 1\n",
      "Row 7773 => Predicted: 0\n",
      "Row 7774 => Predicted: 1\n",
      "Row 7775 => Predicted: 1\n",
      "Row 7776 => Predicted: 1\n",
      "Row 7777 => Predicted: 0\n",
      "Row 7778 => Predicted: 1\n",
      "Row 7779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7770 to 7779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7780 => Predicted: 1\n",
      "Row 7781 => Predicted: 1\n",
      "Row 7782 => Predicted: 0\n",
      "Row 7783 => Predicted: 1\n",
      "Row 7784 => Predicted: 0\n",
      "Row 7785 => Predicted: 1\n",
      "Row 7786 => Predicted: 0\n",
      "Row 7787 => Predicted: 0\n",
      "Row 7788 => Predicted: 0\n",
      "Row 7789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7780 to 7789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7790 => Predicted: 1\n",
      "Row 7791 => Predicted: 1\n",
      "Row 7792 => Predicted: 0\n",
      "Row 7793 => Predicted: 0\n",
      "Row 7794 => Predicted: 1\n",
      "Row 7795 => Predicted: 1\n",
      "Row 7796 => Predicted: 1\n",
      "Row 7797 => Predicted: 0\n",
      "Row 7798 => Predicted: 1\n",
      "Row 7799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7790 to 7799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7800 => Predicted: 1\n",
      "Row 7801 => Predicted: 0\n",
      "Row 7802 => Predicted: 1\n",
      "Row 7803 => Predicted: 0\n",
      "Row 7804 => Predicted: 1\n",
      "Row 7805 => Predicted: 1\n",
      "Row 7806 => Predicted: 1\n",
      "Row 7807 => Predicted: 0\n",
      "Row 7808 => Predicted: 0\n",
      "Row 7809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7800 to 7809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7810 => Predicted: 0\n",
      "Row 7811 => Predicted: 1\n",
      "Row 7812 => Predicted: 1\n",
      "Row 7813 => Predicted: 0\n",
      "Row 7814 => Predicted: 0\n",
      "Row 7815 => Predicted: 0\n",
      "Row 7816 => Predicted: 0\n",
      "Row 7817 => Predicted: 0\n",
      "Row 7818 => Predicted: 0\n",
      "Row 7819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7810 to 7819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7820 => Predicted: 0\n",
      "Row 7821 => Predicted: 0\n",
      "Row 7822 => Predicted: 1\n",
      "Row 7823 => Predicted: 0\n",
      "Row 7824 => Predicted: 0\n",
      "Row 7825 => Predicted: 1\n",
      "Row 7826 => Predicted: 1\n",
      "Row 7827 => Predicted: 1\n",
      "Row 7828 => Predicted: 0\n",
      "Row 7829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7820 to 7829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7830 => Predicted: 0\n",
      "Row 7831 => Predicted: 0\n",
      "Row 7832 => Predicted: 0\n",
      "Row 7833 => Predicted: 0\n",
      "Row 7834 => Predicted: 0\n",
      "Row 7835 => Predicted: 1\n",
      "Row 7836 => Predicted: 0\n",
      "Row 7837 => Predicted: 0\n",
      "Row 7838 => Predicted: 0\n",
      "Row 7839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7830 to 7839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7840 => Predicted: 1\n",
      "Row 7841 => Predicted: 1\n",
      "Row 7842 => Predicted: 0\n",
      "Row 7843 => Predicted: 1\n",
      "Row 7844 => Predicted: 0\n",
      "Row 7845 => Predicted: 1\n",
      "Row 7846 => Predicted: 0\n",
      "Row 7847 => Predicted: 1\n",
      "Row 7848 => Predicted: 1\n",
      "Row 7849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7840 to 7849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7850 => Predicted: 0\n",
      "Row 7851 => Predicted: 0\n",
      "Row 7852 => Predicted: 0\n",
      "Row 7853 => Predicted: 0\n",
      "Row 7854 => Predicted: 0\n",
      "Row 7855 => Predicted: 0\n",
      "Row 7856 => Predicted: 1\n",
      "Row 7857 => Predicted: 1\n",
      "Row 7858 => Predicted: 0\n",
      "Row 7859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7850 to 7859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7860 => Predicted: 1\n",
      "Row 7861 => Predicted: 1\n",
      "Row 7862 => Predicted: 0\n",
      "Row 7863 => Predicted: 1\n",
      "Row 7864 => Predicted: 0\n",
      "Row 7865 => Predicted: 1\n",
      "Row 7866 => Predicted: 0\n",
      "Row 7867 => Predicted: 1\n",
      "Row 7868 => Predicted: 0\n",
      "Row 7869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7860 to 7869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7870 => Predicted: 1\n",
      "Row 7871 => Predicted: 0\n",
      "Row 7872 => Predicted: 0\n",
      "Row 7873 => Predicted: 1\n",
      "Row 7874 => Predicted: 0\n",
      "Row 7875 => Predicted: 0\n",
      "Row 7876 => Predicted: 0\n",
      "Row 7877 => Predicted: 1\n",
      "Row 7878 => Predicted: 0\n",
      "Row 7879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7870 to 7879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7880 => Predicted: 1\n",
      "Row 7881 => Predicted: 1\n",
      "Row 7882 => Predicted: 0\n",
      "Row 7883 => Predicted: 1\n",
      "Row 7884 => Predicted: 0\n",
      "Row 7885 => Predicted: 1\n",
      "Row 7886 => Predicted: 1\n",
      "Row 7887 => Predicted: 0\n",
      "Row 7888 => Predicted: 0\n",
      "Row 7889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7880 to 7889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7890 => Predicted: 1\n",
      "Row 7891 => Predicted: 1\n",
      "Row 7892 => Predicted: 1\n",
      "Row 7893 => Predicted: 0\n",
      "Row 7894 => Predicted: 1\n",
      "Row 7895 => Predicted: 1\n",
      "Row 7896 => Predicted: 1\n",
      "Row 7897 => Predicted: 1\n",
      "Row 7898 => Predicted: 0\n",
      "Row 7899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7890 to 7899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7900 => Predicted: 0\n",
      "Row 7901 => Predicted: 0\n",
      "Row 7902 => Predicted: 0\n",
      "Row 7903 => Predicted: 1\n",
      "Row 7904 => Predicted: 0\n",
      "Row 7905 => Predicted: 1\n",
      "Row 7906 => Predicted: 1\n",
      "Row 7907 => Predicted: 0\n",
      "Row 7908 => Predicted: 1\n",
      "Row 7909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7900 to 7909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7910 => Predicted: 0\n",
      "Row 7911 => Predicted: 1\n",
      "Row 7912 => Predicted: 1\n",
      "Row 7913 => Predicted: 1\n",
      "Row 7914 => Predicted: 1\n",
      "Row 7915 => Predicted: 1\n",
      "Row 7916 => Predicted: 0\n",
      "Row 7917 => Predicted: 1\n",
      "Row 7918 => Predicted: 1\n",
      "Row 7919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7910 to 7919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7920 => Predicted: 1\n",
      "Row 7921 => Predicted: 1\n",
      "Row 7922 => Predicted: 1\n",
      "Row 7923 => Predicted: 1\n",
      "Row 7924 => Predicted: 1\n",
      "Row 7925 => Predicted: 0\n",
      "Row 7926 => Predicted: 0\n",
      "Row 7927 => Predicted: 1\n",
      "Row 7928 => Predicted: 0\n",
      "Row 7929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7920 to 7929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7930 => Predicted: 0\n",
      "Row 7931 => Predicted: 0\n",
      "Row 7932 => Predicted: 1\n",
      "Row 7933 => Predicted: 1\n",
      "Row 7934 => Predicted: 0\n",
      "Row 7935 => Predicted: 0\n",
      "Row 7936 => Predicted: 0\n",
      "Row 7937 => Predicted: 1\n",
      "Row 7938 => Predicted: 1\n",
      "Row 7939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7930 to 7939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7940 => Predicted: 1\n",
      "Row 7941 => Predicted: 0\n",
      "Row 7942 => Predicted: 1\n",
      "Row 7943 => Predicted: 1\n",
      "Row 7944 => Predicted: 1\n",
      "Row 7945 => Predicted: 1\n",
      "Row 7946 => Predicted: 1\n",
      "Row 7947 => Predicted: 1\n",
      "Row 7948 => Predicted: 1\n",
      "Row 7949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7940 to 7949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7950 => Predicted: 0\n",
      "Row 7951 => Predicted: 1\n",
      "Row 7952 => Predicted: 1\n",
      "Row 7953 => Predicted: 0\n",
      "Row 7954 => Predicted: 0\n",
      "Row 7955 => Predicted: 0\n",
      "Row 7956 => Predicted: 0\n",
      "Row 7957 => Predicted: 1\n",
      "Row 7958 => Predicted: 0\n",
      "Row 7959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7950 to 7959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7960 => Predicted: 1\n",
      "Row 7961 => Predicted: 0\n",
      "Row 7962 => Predicted: 0\n",
      "Row 7963 => Predicted: 1\n",
      "Row 7964 => Predicted: 0\n",
      "Row 7965 => Predicted: 0\n",
      "Row 7966 => Predicted: 0\n",
      "Row 7967 => Predicted: 0\n",
      "Row 7968 => Predicted: 1\n",
      "Row 7969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7960 to 7969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7970 => Predicted: 0\n",
      "Row 7971 => Predicted: 0\n",
      "Row 7972 => Predicted: 0\n",
      "Row 7973 => Predicted: 0\n",
      "Row 7974 => Predicted: 1\n",
      "Row 7975 => Predicted: 0\n",
      "Row 7976 => Predicted: 0\n",
      "Row 7977 => Predicted: 0\n",
      "Row 7978 => Predicted: 1\n",
      "Row 7979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7970 to 7979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7980 => Predicted: 1\n",
      "Row 7981 => Predicted: 0\n",
      "Row 7982 => Predicted: 1\n",
      "Row 7983 => Predicted: 1\n",
      "Row 7984 => Predicted: 1\n",
      "Row 7985 => Predicted: 1\n",
      "Row 7986 => Predicted: 1\n",
      "Row 7987 => Predicted: 1\n",
      "Row 7988 => Predicted: 0\n",
      "Row 7989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 7980 to 7989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7990 => Predicted: 1\n",
      "Row 7991 => Predicted: 0\n",
      "Row 7992 => Predicted: 1\n",
      "Row 7993 => Predicted: 1\n",
      "Row 7994 => Predicted: 0\n",
      "Row 7995 => Predicted: 0\n",
      "Row 7996 => Predicted: 0\n",
      "Row 7997 => Predicted: 1\n",
      "Row 7998 => Predicted: 1\n",
      "Row 7999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 7990 to 7999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8000 => Predicted: 0\n",
      "Row 8001 => Predicted: 1\n",
      "Row 8002 => Predicted: 0\n",
      "Row 8003 => Predicted: 0\n",
      "Row 8004 => Predicted: 1\n",
      "Row 8005 => Predicted: 0\n",
      "Row 8006 => Predicted: 0\n",
      "Row 8007 => Predicted: 1\n",
      "Row 8008 => Predicted: 1\n",
      "Row 8009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8000 to 8009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8010 => Predicted: 0\n",
      "Row 8011 => Predicted: 0\n",
      "Row 8012 => Predicted: 1\n",
      "Row 8013 => Predicted: 1\n",
      "Row 8014 => Predicted: 1\n",
      "Row 8015 => Predicted: 0\n",
      "Row 8016 => Predicted: 0\n",
      "Row 8017 => Predicted: 0\n",
      "Row 8018 => Predicted: 0\n",
      "Row 8019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8010 to 8019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8020 => Predicted: 1\n",
      "Row 8021 => Predicted: 0\n",
      "Row 8022 => Predicted: 0\n",
      "Row 8023 => Predicted: 1\n",
      "Row 8024 => Predicted: 1\n",
      "Row 8025 => Predicted: 0\n",
      "Row 8026 => Predicted: 0\n",
      "Row 8027 => Predicted: 0\n",
      "Row 8028 => Predicted: 0\n",
      "Row 8029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8020 to 8029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8030 => Predicted: 0\n",
      "Row 8031 => Predicted: 1\n",
      "Row 8032 => Predicted: 1\n",
      "Row 8033 => Predicted: 1\n",
      "Row 8034 => Predicted: 0\n",
      "Row 8035 => Predicted: 0\n",
      "Row 8036 => Predicted: 1\n",
      "Row 8037 => Predicted: 0\n",
      "Row 8038 => Predicted: 0\n",
      "Row 8039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8030 to 8039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8040 => Predicted: 0\n",
      "Row 8041 => Predicted: 1\n",
      "Row 8042 => Predicted: 1\n",
      "Row 8043 => Predicted: 1\n",
      "Row 8044 => Predicted: 1\n",
      "Row 8045 => Predicted: 1\n",
      "Row 8046 => Predicted: 0\n",
      "Row 8047 => Predicted: 1\n",
      "Row 8048 => Predicted: 1\n",
      "Row 8049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8040 to 8049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8050 => Predicted: 0\n",
      "Row 8051 => Predicted: 1\n",
      "Row 8052 => Predicted: 1\n",
      "Row 8053 => Predicted: 0\n",
      "Row 8054 => Predicted: 0\n",
      "Row 8055 => Predicted: 1\n",
      "Row 8056 => Predicted: 1\n",
      "Row 8057 => Predicted: 0\n",
      "Row 8058 => Predicted: 0\n",
      "Row 8059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8050 to 8059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8060 => Predicted: 0\n",
      "Row 8061 => Predicted: 0\n",
      "Row 8062 => Predicted: 1\n",
      "Row 8063 => Predicted: 0\n",
      "Row 8064 => Predicted: 1\n",
      "Row 8065 => Predicted: 0\n",
      "Row 8066 => Predicted: 0\n",
      "Row 8067 => Predicted: 1\n",
      "Row 8068 => Predicted: 1\n",
      "Row 8069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8060 to 8069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8070 => Predicted: 0\n",
      "Row 8071 => Predicted: 0\n",
      "Row 8072 => Predicted: 1\n",
      "Row 8073 => Predicted: 1\n",
      "Row 8074 => Predicted: 1\n",
      "Row 8075 => Predicted: 0\n",
      "Row 8076 => Predicted: 0\n",
      "Row 8077 => Predicted: 1\n",
      "Row 8078 => Predicted: 0\n",
      "Row 8079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8070 to 8079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8080 => Predicted: 0\n",
      "Row 8081 => Predicted: 0\n",
      "Row 8082 => Predicted: 1\n",
      "Row 8083 => Predicted: 1\n",
      "Row 8084 => Predicted: 1\n",
      "Row 8085 => Predicted: 0\n",
      "Row 8086 => Predicted: 0\n",
      "Row 8087 => Predicted: 0\n",
      "Row 8088 => Predicted: 1\n",
      "Row 8089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8080 to 8089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8090 => Predicted: 0\n",
      "Row 8091 => Predicted: 0\n",
      "Row 8092 => Predicted: 1\n",
      "Row 8093 => Predicted: 0\n",
      "Row 8094 => Predicted: 0\n",
      "Row 8095 => Predicted: 1\n",
      "Row 8096 => Predicted: 0\n",
      "Row 8097 => Predicted: 0\n",
      "Row 8098 => Predicted: 1\n",
      "Row 8099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8090 to 8099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8100 => Predicted: 0\n",
      "Row 8101 => Predicted: 1\n",
      "Row 8102 => Predicted: 0\n",
      "Row 8103 => Predicted: 0\n",
      "Row 8104 => Predicted: 0\n",
      "Row 8105 => Predicted: 1\n",
      "Row 8106 => Predicted: 0\n",
      "Row 8107 => Predicted: 0\n",
      "Row 8108 => Predicted: 0\n",
      "Row 8109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8100 to 8109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8110 => Predicted: 0\n",
      "Row 8111 => Predicted: 0\n",
      "Row 8112 => Predicted: 1\n",
      "Row 8113 => Predicted: 1\n",
      "Row 8114 => Predicted: 0\n",
      "Row 8115 => Predicted: 1\n",
      "Row 8116 => Predicted: 0\n",
      "Row 8117 => Predicted: 0\n",
      "Row 8118 => Predicted: 0\n",
      "Row 8119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8110 to 8119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8120 => Predicted: 1\n",
      "Row 8121 => Predicted: 1\n",
      "Row 8122 => Predicted: 0\n",
      "Row 8123 => Predicted: 0\n",
      "Row 8124 => Predicted: 1\n",
      "Row 8125 => Predicted: 1\n",
      "Row 8126 => Predicted: 1\n",
      "Row 8127 => Predicted: 0\n",
      "Row 8128 => Predicted: 1\n",
      "Row 8129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8120 to 8129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8130 => Predicted: 0\n",
      "Row 8131 => Predicted: 0\n",
      "Row 8132 => Predicted: 0\n",
      "Row 8133 => Predicted: 1\n",
      "Row 8134 => Predicted: 0\n",
      "Row 8135 => Predicted: 0\n",
      "Row 8136 => Predicted: 0\n",
      "Row 8137 => Predicted: 0\n",
      "Row 8138 => Predicted: 1\n",
      "Row 8139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8130 to 8139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8140 => Predicted: 0\n",
      "Row 8141 => Predicted: 0\n",
      "Row 8142 => Predicted: 1\n",
      "Row 8143 => Predicted: 1\n",
      "Row 8144 => Predicted: 1\n",
      "Row 8145 => Predicted: 1\n",
      "Row 8146 => Predicted: 1\n",
      "Row 8147 => Predicted: 0\n",
      "Row 8148 => Predicted: 1\n",
      "Row 8149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8140 to 8149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8150 => Predicted: 1\n",
      "Row 8151 => Predicted: 0\n",
      "Row 8152 => Predicted: 0\n",
      "Row 8153 => Predicted: 0\n",
      "Row 8154 => Predicted: 0\n",
      "Row 8155 => Predicted: 1\n",
      "Row 8156 => Predicted: 0\n",
      "Row 8157 => Predicted: 0\n",
      "Row 8158 => Predicted: 1\n",
      "Row 8159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8150 to 8159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8160 => Predicted: 0\n",
      "Row 8161 => Predicted: 1\n",
      "Row 8162 => Predicted: 0\n",
      "Row 8163 => Predicted: 0\n",
      "Row 8164 => Predicted: 1\n",
      "Row 8165 => Predicted: 0\n",
      "Row 8166 => Predicted: 1\n",
      "Row 8167 => Predicted: 0\n",
      "Row 8168 => Predicted: 0\n",
      "Row 8169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8160 to 8169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8170 => Predicted: 0\n",
      "Row 8171 => Predicted: 1\n",
      "Row 8172 => Predicted: 0\n",
      "Row 8173 => Predicted: 1\n",
      "Row 8174 => Predicted: 1\n",
      "Row 8175 => Predicted: 0\n",
      "Row 8176 => Predicted: 1\n",
      "Row 8177 => Predicted: 0\n",
      "Row 8178 => Predicted: 1\n",
      "Row 8179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8170 to 8179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8180 => Predicted: 0\n",
      "Row 8181 => Predicted: 0\n",
      "Row 8182 => Predicted: 1\n",
      "Row 8183 => Predicted: 1\n",
      "Row 8184 => Predicted: 0\n",
      "Row 8185 => Predicted: 1\n",
      "Row 8186 => Predicted: 0\n",
      "Row 8187 => Predicted: 0\n",
      "Row 8188 => Predicted: 0\n",
      "Row 8189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8180 to 8189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8190 => Predicted: 0\n",
      "Row 8191 => Predicted: 1\n",
      "Row 8192 => Predicted: 1\n",
      "Row 8193 => Predicted: 1\n",
      "Row 8194 => Predicted: 0\n",
      "Row 8195 => Predicted: 1\n",
      "Row 8196 => Predicted: 1\n",
      "Row 8197 => Predicted: 0\n",
      "Row 8198 => Predicted: 1\n",
      "Row 8199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8190 to 8199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8200 => Predicted: 1\n",
      "Row 8201 => Predicted: 0\n",
      "Row 8202 => Predicted: 1\n",
      "Row 8203 => Predicted: 1\n",
      "Row 8204 => Predicted: 0\n",
      "Row 8205 => Predicted: 1\n",
      "Row 8206 => Predicted: 1\n",
      "Row 8207 => Predicted: 1\n",
      "Row 8208 => Predicted: 0\n",
      "Row 8209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8200 to 8209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8210 => Predicted: 1\n",
      "Row 8211 => Predicted: 0\n",
      "Row 8212 => Predicted: 0\n",
      "Row 8213 => Predicted: 0\n",
      "Row 8214 => Predicted: 0\n",
      "Row 8215 => Predicted: 1\n",
      "Row 8216 => Predicted: 0\n",
      "Row 8217 => Predicted: 1\n",
      "Row 8218 => Predicted: 1\n",
      "Row 8219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8210 to 8219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8220 => Predicted: 1\n",
      "Row 8221 => Predicted: 1\n",
      "Row 8222 => Predicted: 0\n",
      "Row 8223 => Predicted: 0\n",
      "Row 8224 => Predicted: 1\n",
      "Row 8225 => Predicted: 0\n",
      "Row 8226 => Predicted: 0\n",
      "Row 8227 => Predicted: 1\n",
      "Row 8228 => Predicted: 0\n",
      "Row 8229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8220 to 8229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8230 => Predicted: 1\n",
      "Row 8231 => Predicted: 0\n",
      "Row 8232 => Predicted: 0\n",
      "Row 8233 => Predicted: 1\n",
      "Row 8234 => Predicted: 0\n",
      "Row 8235 => Predicted: 1\n",
      "Row 8236 => Predicted: 0\n",
      "Row 8237 => Predicted: 0\n",
      "Row 8238 => Predicted: 0\n",
      "Row 8239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8230 to 8239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8240 => Predicted: 1\n",
      "Row 8241 => Predicted: 0\n",
      "Row 8242 => Predicted: 1\n",
      "Row 8243 => Predicted: 1\n",
      "Row 8244 => Predicted: 0\n",
      "Row 8245 => Predicted: 0\n",
      "Row 8246 => Predicted: 0\n",
      "Row 8247 => Predicted: 0\n",
      "Row 8248 => Predicted: 1\n",
      "Row 8249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8240 to 8249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8250 => Predicted: 1\n",
      "Row 8251 => Predicted: 0\n",
      "Row 8252 => Predicted: 0\n",
      "Row 8253 => Predicted: 0\n",
      "Row 8254 => Predicted: 1\n",
      "Row 8255 => Predicted: 1\n",
      "Row 8256 => Predicted: 0\n",
      "Row 8257 => Predicted: 0\n",
      "Row 8258 => Predicted: 0\n",
      "Row 8259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8250 to 8259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8260 => Predicted: 0\n",
      "Row 8261 => Predicted: 1\n",
      "Row 8262 => Predicted: 1\n",
      "Row 8263 => Predicted: 1\n",
      "Row 8264 => Predicted: 1\n",
      "Row 8265 => Predicted: 1\n",
      "Row 8266 => Predicted: 1\n",
      "Row 8267 => Predicted: 0\n",
      "Row 8268 => Predicted: 0\n",
      "Row 8269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8260 to 8269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8270 => Predicted: 1\n",
      "Row 8271 => Predicted: 1\n",
      "Row 8272 => Predicted: 1\n",
      "Row 8273 => Predicted: 0\n",
      "Row 8274 => Predicted: 0\n",
      "Row 8275 => Predicted: 1\n",
      "Row 8276 => Predicted: 1\n",
      "Row 8277 => Predicted: 0\n",
      "Row 8278 => Predicted: 1\n",
      "Row 8279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8270 to 8279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8280 => Predicted: 0\n",
      "Row 8281 => Predicted: 0\n",
      "Row 8282 => Predicted: 0\n",
      "Row 8283 => Predicted: 1\n",
      "Row 8284 => Predicted: 0\n",
      "Row 8285 => Predicted: 1\n",
      "Row 8286 => Predicted: 0\n",
      "Row 8287 => Predicted: 1\n",
      "Row 8288 => Predicted: 0\n",
      "Row 8289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8280 to 8289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8290 => Predicted: 0\n",
      "Row 8291 => Predicted: 1\n",
      "Row 8292 => Predicted: 1\n",
      "Row 8293 => Predicted: 1\n",
      "Row 8294 => Predicted: 1\n",
      "Row 8295 => Predicted: 1\n",
      "Row 8296 => Predicted: 1\n",
      "Row 8297 => Predicted: 1\n",
      "Row 8298 => Predicted: 1\n",
      "Row 8299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8290 to 8299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8300 => Predicted: 1\n",
      "Row 8301 => Predicted: 0\n",
      "Row 8302 => Predicted: 0\n",
      "Row 8303 => Predicted: 0\n",
      "Row 8304 => Predicted: 1\n",
      "Row 8305 => Predicted: 0\n",
      "Row 8306 => Predicted: 0\n",
      "Row 8307 => Predicted: 1\n",
      "Row 8308 => Predicted: 1\n",
      "Row 8309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8300 to 8309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8310 => Predicted: 1\n",
      "Row 8311 => Predicted: 0\n",
      "Row 8312 => Predicted: 1\n",
      "Row 8313 => Predicted: 1\n",
      "Row 8314 => Predicted: 0\n",
      "Row 8315 => Predicted: 0\n",
      "Row 8316 => Predicted: 0\n",
      "Row 8317 => Predicted: 1\n",
      "Row 8318 => Predicted: 0\n",
      "Row 8319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8310 to 8319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8320 => Predicted: 1\n",
      "Row 8321 => Predicted: 1\n",
      "Row 8322 => Predicted: 0\n",
      "Row 8323 => Predicted: 1\n",
      "Row 8324 => Predicted: 0\n",
      "Row 8325 => Predicted: 0\n",
      "Row 8326 => Predicted: 1\n",
      "Row 8327 => Predicted: 0\n",
      "Row 8328 => Predicted: 1\n",
      "Row 8329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8320 to 8329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8330 => Predicted: 1\n",
      "Row 8331 => Predicted: 0\n",
      "Row 8332 => Predicted: 1\n",
      "Row 8333 => Predicted: 1\n",
      "Row 8334 => Predicted: 1\n",
      "Row 8335 => Predicted: 1\n",
      "Row 8336 => Predicted: 1\n",
      "Row 8337 => Predicted: 0\n",
      "Row 8338 => Predicted: 0\n",
      "Row 8339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8330 to 8339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8340 => Predicted: 1\n",
      "Row 8341 => Predicted: 1\n",
      "Row 8342 => Predicted: 1\n",
      "Row 8343 => Predicted: 1\n",
      "Row 8344 => Predicted: 0\n",
      "Row 8345 => Predicted: 1\n",
      "Row 8346 => Predicted: 0\n",
      "Row 8347 => Predicted: 0\n",
      "Row 8348 => Predicted: 1\n",
      "Row 8349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8340 to 8349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8350 => Predicted: 0\n",
      "Row 8351 => Predicted: 0\n",
      "Row 8352 => Predicted: 0\n",
      "Row 8353 => Predicted: 0\n",
      "Row 8354 => Predicted: 0\n",
      "Row 8355 => Predicted: 0\n",
      "Row 8356 => Predicted: 1\n",
      "Row 8357 => Predicted: 0\n",
      "Row 8358 => Predicted: 1\n",
      "Row 8359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8350 to 8359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8360 => Predicted: 0\n",
      "Row 8361 => Predicted: 0\n",
      "Row 8362 => Predicted: 1\n",
      "Row 8363 => Predicted: 0\n",
      "Row 8364 => Predicted: 0\n",
      "Row 8365 => Predicted: 0\n",
      "Row 8366 => Predicted: 1\n",
      "Row 8367 => Predicted: 1\n",
      "Row 8368 => Predicted: 1\n",
      "Row 8369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8360 to 8369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8370 => Predicted: 0\n",
      "Row 8371 => Predicted: 0\n",
      "Row 8372 => Predicted: 1\n",
      "Row 8373 => Predicted: 1\n",
      "Row 8374 => Predicted: 1\n",
      "Row 8375 => Predicted: 1\n",
      "Row 8376 => Predicted: 1\n",
      "Row 8377 => Predicted: 0\n",
      "Row 8378 => Predicted: 1\n",
      "Row 8379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8370 to 8379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8380 => Predicted: 1\n",
      "Row 8381 => Predicted: 1\n",
      "Row 8382 => Predicted: 0\n",
      "Row 8383 => Predicted: 1\n",
      "Row 8384 => Predicted: 1\n",
      "Row 8385 => Predicted: 0\n",
      "Row 8386 => Predicted: 1\n",
      "Row 8387 => Predicted: 1\n",
      "Row 8388 => Predicted: 0\n",
      "Row 8389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8380 to 8389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8390 => Predicted: 0\n",
      "Row 8391 => Predicted: 0\n",
      "Row 8392 => Predicted: 0\n",
      "Row 8393 => Predicted: 0\n",
      "Row 8394 => Predicted: 1\n",
      "Row 8395 => Predicted: 1\n",
      "Row 8396 => Predicted: 1\n",
      "Row 8397 => Predicted: 1\n",
      "Row 8398 => Predicted: 0\n",
      "Row 8399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8390 to 8399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8400 => Predicted: 0\n",
      "Row 8401 => Predicted: 1\n",
      "Row 8402 => Predicted: 1\n",
      "Row 8403 => Predicted: 0\n",
      "Row 8404 => Predicted: 1\n",
      "Row 8405 => Predicted: 0\n",
      "Row 8406 => Predicted: 1\n",
      "Row 8407 => Predicted: 1\n",
      "Row 8408 => Predicted: 1\n",
      "Row 8409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8400 to 8409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8410 => Predicted: 0\n",
      "Row 8411 => Predicted: 0\n",
      "Row 8412 => Predicted: 0\n",
      "Row 8413 => Predicted: 0\n",
      "Row 8414 => Predicted: 1\n",
      "Row 8415 => Predicted: 1\n",
      "Row 8416 => Predicted: 1\n",
      "Row 8417 => Predicted: 1\n",
      "Row 8418 => Predicted: 1\n",
      "Row 8419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8410 to 8419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8420 => Predicted: 0\n",
      "Row 8421 => Predicted: 1\n",
      "Row 8422 => Predicted: 1\n",
      "Row 8423 => Predicted: 0\n",
      "Row 8424 => Predicted: 0\n",
      "Row 8425 => Predicted: 1\n",
      "Row 8426 => Predicted: 1\n",
      "Row 8427 => Predicted: 0\n",
      "Row 8428 => Predicted: 0\n",
      "Row 8429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8420 to 8429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8430 => Predicted: 0\n",
      "Row 8431 => Predicted: 1\n",
      "Row 8432 => Predicted: 0\n",
      "Row 8433 => Predicted: 0\n",
      "Row 8434 => Predicted: 0\n",
      "Row 8435 => Predicted: 0\n",
      "Row 8436 => Predicted: 0\n",
      "Row 8437 => Predicted: 0\n",
      "Row 8438 => Predicted: 1\n",
      "Row 8439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8430 to 8439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8440 => Predicted: 0\n",
      "Row 8441 => Predicted: 1\n",
      "Row 8442 => Predicted: 0\n",
      "Row 8443 => Predicted: 0\n",
      "Row 8444 => Predicted: 1\n",
      "Row 8445 => Predicted: 1\n",
      "Row 8446 => Predicted: 1\n",
      "Row 8447 => Predicted: 0\n",
      "Row 8448 => Predicted: 0\n",
      "Row 8449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8440 to 8449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8450 => Predicted: 0\n",
      "Row 8451 => Predicted: 1\n",
      "Row 8452 => Predicted: 0\n",
      "Row 8453 => Predicted: 0\n",
      "Row 8454 => Predicted: 1\n",
      "Row 8455 => Predicted: 0\n",
      "Row 8456 => Predicted: 1\n",
      "Row 8457 => Predicted: 1\n",
      "Row 8458 => Predicted: 0\n",
      "Row 8459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8450 to 8459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8460 => Predicted: 1\n",
      "Row 8461 => Predicted: 1\n",
      "Row 8462 => Predicted: 0\n",
      "Row 8463 => Predicted: 0\n",
      "Row 8464 => Predicted: 0\n",
      "Row 8465 => Predicted: 0\n",
      "Row 8466 => Predicted: 1\n",
      "Row 8467 => Predicted: 1\n",
      "Row 8468 => Predicted: 1\n",
      "Row 8469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8460 to 8469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8470 => Predicted: 1\n",
      "Row 8471 => Predicted: 1\n",
      "Row 8472 => Predicted: 1\n",
      "Row 8473 => Predicted: 0\n",
      "Row 8474 => Predicted: 0\n",
      "Row 8475 => Predicted: 1\n",
      "Row 8476 => Predicted: 1\n",
      "Row 8477 => Predicted: 0\n",
      "Row 8478 => Predicted: 0\n",
      "Row 8479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8470 to 8479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8480 => Predicted: 1\n",
      "Row 8481 => Predicted: 0\n",
      "Row 8482 => Predicted: 1\n",
      "Row 8483 => Predicted: 1\n",
      "Row 8484 => Predicted: 1\n",
      "Row 8485 => Predicted: 0\n",
      "Row 8486 => Predicted: 0\n",
      "Row 8487 => Predicted: 1\n",
      "Row 8488 => Predicted: 1\n",
      "Row 8489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8480 to 8489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8490 => Predicted: 1\n",
      "Row 8491 => Predicted: 0\n",
      "Row 8492 => Predicted: 1\n",
      "Row 8493 => Predicted: 0\n",
      "Row 8494 => Predicted: 0\n",
      "Row 8495 => Predicted: 1\n",
      "Row 8496 => Predicted: 0\n",
      "Row 8497 => Predicted: 1\n",
      "Row 8498 => Predicted: 1\n",
      "Row 8499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8490 to 8499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8500 => Predicted: 0\n",
      "Row 8501 => Predicted: 0\n",
      "Row 8502 => Predicted: 1\n",
      "Row 8503 => Predicted: 0\n",
      "Row 8504 => Predicted: 0\n",
      "Row 8505 => Predicted: 0\n",
      "Row 8506 => Predicted: 1\n",
      "Row 8507 => Predicted: 0\n",
      "Row 8508 => Predicted: 0\n",
      "Row 8509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8500 to 8509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8510 => Predicted: 0\n",
      "Row 8511 => Predicted: 0\n",
      "Row 8512 => Predicted: 1\n",
      "Row 8513 => Predicted: 1\n",
      "Row 8514 => Predicted: 0\n",
      "Row 8515 => Predicted: 0\n",
      "Row 8516 => Predicted: 0\n",
      "Row 8517 => Predicted: 1\n",
      "Row 8518 => Predicted: 1\n",
      "Row 8519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8510 to 8519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8520 => Predicted: 0\n",
      "Row 8521 => Predicted: 1\n",
      "Row 8522 => Predicted: 0\n",
      "Row 8523 => Predicted: 0\n",
      "Row 8524 => Predicted: 1\n",
      "Row 8525 => Predicted: 1\n",
      "Row 8526 => Predicted: 0\n",
      "Row 8527 => Predicted: 1\n",
      "Row 8528 => Predicted: 1\n",
      "Row 8529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8520 to 8529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8530 => Predicted: 1\n",
      "Row 8531 => Predicted: 1\n",
      "Row 8532 => Predicted: 0\n",
      "Row 8533 => Predicted: 0\n",
      "Row 8534 => Predicted: 0\n",
      "Row 8535 => Predicted: 0\n",
      "Row 8536 => Predicted: 0\n",
      "Row 8537 => Predicted: 0\n",
      "Row 8538 => Predicted: 0\n",
      "Row 8539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8530 to 8539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8540 => Predicted: 0\n",
      "Row 8541 => Predicted: 1\n",
      "Row 8542 => Predicted: 0\n",
      "Row 8543 => Predicted: 1\n",
      "Row 8544 => Predicted: 0\n",
      "Row 8545 => Predicted: 1\n",
      "Row 8546 => Predicted: 1\n",
      "Row 8547 => Predicted: 0\n",
      "Row 8548 => Predicted: 0\n",
      "Row 8549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8540 to 8549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8550 => Predicted: 0\n",
      "Row 8551 => Predicted: 1\n",
      "Row 8552 => Predicted: 0\n",
      "Row 8553 => Predicted: 1\n",
      "Row 8554 => Predicted: 0\n",
      "Row 8555 => Predicted: 0\n",
      "Row 8556 => Predicted: 0\n",
      "Row 8557 => Predicted: 1\n",
      "Row 8558 => Predicted: 1\n",
      "Row 8559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8550 to 8559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8560 => Predicted: 1\n",
      "Row 8561 => Predicted: 1\n",
      "Row 8562 => Predicted: 1\n",
      "Row 8563 => Predicted: 0\n",
      "Row 8564 => Predicted: 1\n",
      "Row 8565 => Predicted: 0\n",
      "Row 8566 => Predicted: 1\n",
      "Row 8567 => Predicted: 0\n",
      "Row 8568 => Predicted: 0\n",
      "Row 8569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8560 to 8569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8570 => Predicted: 0\n",
      "Row 8571 => Predicted: 0\n",
      "Row 8572 => Predicted: 1\n",
      "Row 8573 => Predicted: 1\n",
      "Row 8574 => Predicted: 1\n",
      "Row 8575 => Predicted: 0\n",
      "Row 8576 => Predicted: 1\n",
      "Row 8577 => Predicted: 0\n",
      "Row 8578 => Predicted: 0\n",
      "Row 8579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8570 to 8579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8580 => Predicted: 1\n",
      "Row 8581 => Predicted: 1\n",
      "Row 8582 => Predicted: 1\n",
      "Row 8583 => Predicted: 0\n",
      "Row 8584 => Predicted: 1\n",
      "Row 8585 => Predicted: 0\n",
      "Row 8586 => Predicted: 0\n",
      "Row 8587 => Predicted: 0\n",
      "Row 8588 => Predicted: 0\n",
      "Row 8589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8580 to 8589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8590 => Predicted: 1\n",
      "Row 8591 => Predicted: 0\n",
      "Row 8592 => Predicted: 1\n",
      "Row 8593 => Predicted: 0\n",
      "Row 8594 => Predicted: 0\n",
      "Row 8595 => Predicted: 0\n",
      "Row 8596 => Predicted: 0\n",
      "Row 8597 => Predicted: 0\n",
      "Row 8598 => Predicted: 1\n",
      "Row 8599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8590 to 8599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8600 => Predicted: 1\n",
      "Row 8601 => Predicted: 1\n",
      "Row 8602 => Predicted: 1\n",
      "Row 8603 => Predicted: 1\n",
      "Row 8604 => Predicted: 1\n",
      "Row 8605 => Predicted: 1\n",
      "Row 8606 => Predicted: 0\n",
      "Row 8607 => Predicted: 0\n",
      "Row 8608 => Predicted: 0\n",
      "Row 8609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8600 to 8609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8610 => Predicted: 0\n",
      "Row 8611 => Predicted: 0\n",
      "Row 8612 => Predicted: 0\n",
      "Row 8613 => Predicted: 0\n",
      "Row 8614 => Predicted: 1\n",
      "Row 8615 => Predicted: 1\n",
      "Row 8616 => Predicted: 1\n",
      "Row 8617 => Predicted: 1\n",
      "Row 8618 => Predicted: 0\n",
      "Row 8619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8610 to 8619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8620 => Predicted: 0\n",
      "Row 8621 => Predicted: 1\n",
      "Row 8622 => Predicted: 0\n",
      "Row 8623 => Predicted: 0\n",
      "Row 8624 => Predicted: 1\n",
      "Row 8625 => Predicted: 0\n",
      "Row 8626 => Predicted: 1\n",
      "Row 8627 => Predicted: 0\n",
      "Row 8628 => Predicted: 0\n",
      "Row 8629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8620 to 8629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8630 => Predicted: 1\n",
      "Row 8631 => Predicted: 0\n",
      "Row 8632 => Predicted: 0\n",
      "Row 8633 => Predicted: 0\n",
      "Row 8634 => Predicted: 1\n",
      "Row 8635 => Predicted: 1\n",
      "Row 8636 => Predicted: 0\n",
      "Row 8637 => Predicted: 1\n",
      "Row 8638 => Predicted: 0\n",
      "Row 8639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8630 to 8639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8640 => Predicted: 1\n",
      "Row 8641 => Predicted: 1\n",
      "Row 8642 => Predicted: 1\n",
      "Row 8643 => Predicted: 1\n",
      "Row 8644 => Predicted: 1\n",
      "Row 8645 => Predicted: 0\n",
      "Row 8646 => Predicted: 0\n",
      "Row 8647 => Predicted: 0\n",
      "Row 8648 => Predicted: 0\n",
      "Row 8649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8640 to 8649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8650 => Predicted: 0\n",
      "Row 8651 => Predicted: 1\n",
      "Row 8652 => Predicted: 1\n",
      "Row 8653 => Predicted: 1\n",
      "Row 8654 => Predicted: 0\n",
      "Row 8655 => Predicted: 0\n",
      "Row 8656 => Predicted: 1\n",
      "Row 8657 => Predicted: 0\n",
      "Row 8658 => Predicted: 0\n",
      "Row 8659 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8650 to 8659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8660 => Predicted: 0\n",
      "Row 8661 => Predicted: 1\n",
      "Row 8662 => Predicted: 0\n",
      "Row 8663 => Predicted: 0\n",
      "Row 8664 => Predicted: 0\n",
      "Row 8665 => Predicted: 1\n",
      "Row 8666 => Predicted: 0\n",
      "Row 8667 => Predicted: 1\n",
      "Row 8668 => Predicted: 0\n",
      "Row 8669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8660 to 8669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8670 => Predicted: 0\n",
      "Row 8671 => Predicted: 1\n",
      "Row 8672 => Predicted: 1\n",
      "Row 8673 => Predicted: 0\n",
      "Row 8674 => Predicted: 1\n",
      "Row 8675 => Predicted: 0\n",
      "Row 8676 => Predicted: 1\n",
      "Row 8677 => Predicted: 0\n",
      "Row 8678 => Predicted: 1\n",
      "Row 8679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8670 to 8679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8680 => Predicted: 1\n",
      "Row 8681 => Predicted: 1\n",
      "Row 8682 => Predicted: 0\n",
      "Row 8683 => Predicted: 1\n",
      "Row 8684 => Predicted: 1\n",
      "Row 8685 => Predicted: 0\n",
      "Row 8686 => Predicted: 0\n",
      "Row 8687 => Predicted: 1\n",
      "Row 8688 => Predicted: 1\n",
      "Row 8689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8680 to 8689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8690 => Predicted: 1\n",
      "Row 8691 => Predicted: 0\n",
      "Row 8692 => Predicted: 0\n",
      "Row 8693 => Predicted: 1\n",
      "Row 8694 => Predicted: 0\n",
      "Row 8695 => Predicted: 0\n",
      "Row 8696 => Predicted: 1\n",
      "Row 8697 => Predicted: 1\n",
      "Row 8698 => Predicted: 0\n",
      "Row 8699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8690 to 8699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8700 => Predicted: 0\n",
      "Row 8701 => Predicted: 0\n",
      "Row 8702 => Predicted: 0\n",
      "Row 8703 => Predicted: 1\n",
      "Row 8704 => Predicted: 0\n",
      "Row 8705 => Predicted: 1\n",
      "Row 8706 => Predicted: 0\n",
      "Row 8707 => Predicted: 0\n",
      "Row 8708 => Predicted: 1\n",
      "Row 8709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8700 to 8709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8710 => Predicted: 1\n",
      "Row 8711 => Predicted: 1\n",
      "Row 8712 => Predicted: 0\n",
      "Row 8713 => Predicted: 0\n",
      "Row 8714 => Predicted: 1\n",
      "Row 8715 => Predicted: 1\n",
      "Row 8716 => Predicted: 0\n",
      "Row 8717 => Predicted: 0\n",
      "Row 8718 => Predicted: 0\n",
      "Row 8719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8710 to 8719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8720 => Predicted: 0\n",
      "Row 8721 => Predicted: 0\n",
      "Row 8722 => Predicted: 1\n",
      "Row 8723 => Predicted: 1\n",
      "Row 8724 => Predicted: 0\n",
      "Row 8725 => Predicted: 1\n",
      "Row 8726 => Predicted: 0\n",
      "Row 8727 => Predicted: 1\n",
      "Row 8728 => Predicted: 1\n",
      "Row 8729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8720 to 8729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8730 => Predicted: 1\n",
      "Row 8731 => Predicted: 1\n",
      "Row 8732 => Predicted: 1\n",
      "Row 8733 => Predicted: 0\n",
      "Row 8734 => Predicted: 0\n",
      "Row 8735 => Predicted: 1\n",
      "Row 8736 => Predicted: 1\n",
      "Row 8737 => Predicted: 0\n",
      "Row 8738 => Predicted: 1\n",
      "Row 8739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8730 to 8739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8740 => Predicted: 0\n",
      "Row 8741 => Predicted: 0\n",
      "Row 8742 => Predicted: 1\n",
      "Row 8743 => Predicted: 0\n",
      "Row 8744 => Predicted: 0\n",
      "Row 8745 => Predicted: 1\n",
      "Row 8746 => Predicted: 0\n",
      "Row 8747 => Predicted: 0\n",
      "Row 8748 => Predicted: 0\n",
      "Row 8749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8740 to 8749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8750 => Predicted: 1\n",
      "Row 8751 => Predicted: 1\n",
      "Row 8752 => Predicted: 0\n",
      "Row 8753 => Predicted: 1\n",
      "Row 8754 => Predicted: 0\n",
      "Row 8755 => Predicted: 0\n",
      "Row 8756 => Predicted: 1\n",
      "Row 8757 => Predicted: 0\n",
      "Row 8758 => Predicted: 1\n",
      "Row 8759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8750 to 8759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8760 => Predicted: 1\n",
      "Row 8761 => Predicted: 0\n",
      "Row 8762 => Predicted: 1\n",
      "Row 8763 => Predicted: 1\n",
      "Row 8764 => Predicted: 0\n",
      "Row 8765 => Predicted: 0\n",
      "Row 8766 => Predicted: 0\n",
      "Row 8767 => Predicted: 0\n",
      "Row 8768 => Predicted: 1\n",
      "Row 8769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8760 to 8769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8770 => Predicted: 1\n",
      "Row 8771 => Predicted: 1\n",
      "Row 8772 => Predicted: 1\n",
      "Row 8773 => Predicted: 0\n",
      "Row 8774 => Predicted: 1\n",
      "Row 8775 => Predicted: 0\n",
      "Row 8776 => Predicted: 1\n",
      "Row 8777 => Predicted: 1\n",
      "Row 8778 => Predicted: 1\n",
      "Row 8779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8770 to 8779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8780 => Predicted: 0\n",
      "Row 8781 => Predicted: 0\n",
      "Row 8782 => Predicted: 1\n",
      "Row 8783 => Predicted: 0\n",
      "Row 8784 => Predicted: 1\n",
      "Row 8785 => Predicted: 0\n",
      "Row 8786 => Predicted: 0\n",
      "Row 8787 => Predicted: 0\n",
      "Row 8788 => Predicted: 0\n",
      "Row 8789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8780 to 8789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8790 => Predicted: 0\n",
      "Row 8791 => Predicted: 0\n",
      "Row 8792 => Predicted: 1\n",
      "Row 8793 => Predicted: 0\n",
      "Row 8794 => Predicted: 1\n",
      "Row 8795 => Predicted: 0\n",
      "Row 8796 => Predicted: 0\n",
      "Row 8797 => Predicted: 0\n",
      "Row 8798 => Predicted: 0\n",
      "Row 8799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8790 to 8799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8800 => Predicted: 0\n",
      "Row 8801 => Predicted: 0\n",
      "Row 8802 => Predicted: 1\n",
      "Row 8803 => Predicted: 0\n",
      "Row 8804 => Predicted: 0\n",
      "Row 8805 => Predicted: 0\n",
      "Row 8806 => Predicted: 0\n",
      "Row 8807 => Predicted: 1\n",
      "Row 8808 => Predicted: 1\n",
      "Row 8809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8800 to 8809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8810 => Predicted: 1\n",
      "Row 8811 => Predicted: 1\n",
      "Row 8812 => Predicted: 0\n",
      "Row 8813 => Predicted: 1\n",
      "Row 8814 => Predicted: 0\n",
      "Row 8815 => Predicted: 1\n",
      "Row 8816 => Predicted: 0\n",
      "Row 8817 => Predicted: 1\n",
      "Row 8818 => Predicted: 0\n",
      "Row 8819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8810 to 8819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8820 => Predicted: 0\n",
      "Row 8821 => Predicted: 0\n",
      "Row 8822 => Predicted: 1\n",
      "Row 8823 => Predicted: 1\n",
      "Row 8824 => Predicted: 1\n",
      "Row 8825 => Predicted: 1\n",
      "Row 8826 => Predicted: 0\n",
      "Row 8827 => Predicted: 0\n",
      "Row 8828 => Predicted: 0\n",
      "Row 8829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8820 to 8829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8830 => Predicted: 0\n",
      "Row 8831 => Predicted: 1\n",
      "Row 8832 => Predicted: 0\n",
      "Row 8833 => Predicted: 1\n",
      "Row 8834 => Predicted: 0\n",
      "Row 8835 => Predicted: 0\n",
      "Row 8836 => Predicted: 0\n",
      "Row 8837 => Predicted: 0\n",
      "Row 8838 => Predicted: 1\n",
      "Row 8839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8830 to 8839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8840 => Predicted: 0\n",
      "Row 8841 => Predicted: 0\n",
      "Row 8842 => Predicted: 1\n",
      "Row 8843 => Predicted: 1\n",
      "Row 8844 => Predicted: 0\n",
      "Row 8845 => Predicted: 1\n",
      "Row 8846 => Predicted: 0\n",
      "Row 8847 => Predicted: 1\n",
      "Row 8848 => Predicted: 0\n",
      "Row 8849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8840 to 8849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8850 => Predicted: 1\n",
      "Row 8851 => Predicted: 0\n",
      "Row 8852 => Predicted: 1\n",
      "Row 8853 => Predicted: 1\n",
      "Row 8854 => Predicted: 1\n",
      "Row 8855 => Predicted: 1\n",
      "Row 8856 => Predicted: 0\n",
      "Row 8857 => Predicted: 1\n",
      "Row 8858 => Predicted: 0\n",
      "Row 8859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8850 to 8859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8860 => Predicted: 0\n",
      "Row 8861 => Predicted: 1\n",
      "Row 8862 => Predicted: 1\n",
      "Row 8863 => Predicted: 1\n",
      "Row 8864 => Predicted: 1\n",
      "Row 8865 => Predicted: 0\n",
      "Row 8866 => Predicted: 0\n",
      "Row 8867 => Predicted: 1\n",
      "Row 8868 => Predicted: 0\n",
      "Row 8869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8860 to 8869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8870 => Predicted: 1\n",
      "Row 8871 => Predicted: 1\n",
      "Row 8872 => Predicted: 0\n",
      "Row 8873 => Predicted: 1\n",
      "Row 8874 => Predicted: 0\n",
      "Row 8875 => Predicted: 1\n",
      "Row 8876 => Predicted: 0\n",
      "Row 8877 => Predicted: 1\n",
      "Row 8878 => Predicted: 1\n",
      "Row 8879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8870 to 8879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8880 => Predicted: 0\n",
      "Row 8881 => Predicted: 0\n",
      "Row 8882 => Predicted: 1\n",
      "Row 8883 => Predicted: 0\n",
      "Row 8884 => Predicted: 1\n",
      "Row 8885 => Predicted: 1\n",
      "Row 8886 => Predicted: 1\n",
      "Row 8887 => Predicted: 0\n",
      "Row 8888 => Predicted: 1\n",
      "Row 8889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8880 to 8889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8890 => Predicted: 0\n",
      "Row 8891 => Predicted: 1\n",
      "Row 8892 => Predicted: 1\n",
      "Row 8893 => Predicted: 1\n",
      "Row 8894 => Predicted: 0\n",
      "Row 8895 => Predicted: 0\n",
      "Row 8896 => Predicted: 1\n",
      "Row 8897 => Predicted: 1\n",
      "Row 8898 => Predicted: 1\n",
      "Row 8899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8890 to 8899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8900 => Predicted: 0\n",
      "Row 8901 => Predicted: 0\n",
      "Row 8902 => Predicted: 0\n",
      "Row 8903 => Predicted: 1\n",
      "Row 8904 => Predicted: 1\n",
      "Row 8905 => Predicted: 0\n",
      "Row 8906 => Predicted: 0\n",
      "Row 8907 => Predicted: 0\n",
      "Row 8908 => Predicted: 0\n",
      "Row 8909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8900 to 8909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8910 => Predicted: 1\n",
      "Row 8911 => Predicted: 0\n",
      "Row 8912 => Predicted: 0\n",
      "Row 8913 => Predicted: 1\n",
      "Row 8914 => Predicted: 0\n",
      "Row 8915 => Predicted: 1\n",
      "Row 8916 => Predicted: 1\n",
      "Row 8917 => Predicted: 0\n",
      "Row 8918 => Predicted: 1\n",
      "Row 8919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8910 to 8919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8920 => Predicted: 1\n",
      "Row 8921 => Predicted: 1\n",
      "Row 8922 => Predicted: 0\n",
      "Row 8923 => Predicted: 0\n",
      "Row 8924 => Predicted: 1\n",
      "Row 8925 => Predicted: 0\n",
      "Row 8926 => Predicted: 1\n",
      "Row 8927 => Predicted: 0\n",
      "Row 8928 => Predicted: 1\n",
      "Row 8929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8920 to 8929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8930 => Predicted: 0\n",
      "Row 8931 => Predicted: 1\n",
      "Row 8932 => Predicted: 1\n",
      "Row 8933 => Predicted: 1\n",
      "Row 8934 => Predicted: 0\n",
      "Row 8935 => Predicted: 0\n",
      "Row 8936 => Predicted: 0\n",
      "Row 8937 => Predicted: 0\n",
      "Row 8938 => Predicted: 1\n",
      "Row 8939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8930 to 8939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8940 => Predicted: 0\n",
      "Row 8941 => Predicted: 1\n",
      "Row 8942 => Predicted: 0\n",
      "Row 8943 => Predicted: 0\n",
      "Row 8944 => Predicted: 0\n",
      "Row 8945 => Predicted: 1\n",
      "Row 8946 => Predicted: 0\n",
      "Row 8947 => Predicted: 0\n",
      "Row 8948 => Predicted: 1\n",
      "Row 8949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8940 to 8949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8950 => Predicted: 0\n",
      "Row 8951 => Predicted: 1\n",
      "Row 8952 => Predicted: 0\n",
      "Row 8953 => Predicted: 0\n",
      "Row 8954 => Predicted: 1\n",
      "Row 8955 => Predicted: 1\n",
      "Row 8956 => Predicted: 0\n",
      "Row 8957 => Predicted: 1\n",
      "Row 8958 => Predicted: 1\n",
      "Row 8959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8950 to 8959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8960 => Predicted: 0\n",
      "Row 8961 => Predicted: 1\n",
      "Row 8962 => Predicted: 0\n",
      "Row 8963 => Predicted: 1\n",
      "Row 8964 => Predicted: 1\n",
      "Row 8965 => Predicted: 0\n",
      "Row 8966 => Predicted: 1\n",
      "Row 8967 => Predicted: 0\n",
      "Row 8968 => Predicted: 0\n",
      "Row 8969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8960 to 8969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8970 => Predicted: 0\n",
      "Row 8971 => Predicted: 1\n",
      "Row 8972 => Predicted: 1\n",
      "Row 8973 => Predicted: 1\n",
      "Row 8974 => Predicted: 1\n",
      "Row 8975 => Predicted: 1\n",
      "Row 8976 => Predicted: 1\n",
      "Row 8977 => Predicted: 1\n",
      "Row 8978 => Predicted: 0\n",
      "Row 8979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8970 to 8979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8980 => Predicted: 0\n",
      "Row 8981 => Predicted: 1\n",
      "Row 8982 => Predicted: 1\n",
      "Row 8983 => Predicted: 0\n",
      "Row 8984 => Predicted: 1\n",
      "Row 8985 => Predicted: 0\n",
      "Row 8986 => Predicted: 0\n",
      "Row 8987 => Predicted: 1\n",
      "Row 8988 => Predicted: 0\n",
      "Row 8989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 8980 to 8989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8990 => Predicted: 0\n",
      "Row 8991 => Predicted: 0\n",
      "Row 8992 => Predicted: 1\n",
      "Row 8993 => Predicted: 1\n",
      "Row 8994 => Predicted: 1\n",
      "Row 8995 => Predicted: 0\n",
      "Row 8996 => Predicted: 0\n",
      "Row 8997 => Predicted: 1\n",
      "Row 8998 => Predicted: 1\n",
      "Row 8999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 8990 to 8999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9000 => Predicted: 1\n",
      "Row 9001 => Predicted: 1\n",
      "Row 9002 => Predicted: 1\n",
      "Row 9003 => Predicted: 1\n",
      "Row 9004 => Predicted: 0\n",
      "Row 9005 => Predicted: 0\n",
      "Row 9006 => Predicted: 1\n",
      "Row 9007 => Predicted: 1\n",
      "Row 9008 => Predicted: 0\n",
      "Row 9009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9000 to 9009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9010 => Predicted: 0\n",
      "Row 9011 => Predicted: 0\n",
      "Row 9012 => Predicted: 0\n",
      "Row 9013 => Predicted: 0\n",
      "Row 9014 => Predicted: 0\n",
      "Row 9015 => Predicted: 0\n",
      "Row 9016 => Predicted: 1\n",
      "Row 9017 => Predicted: 0\n",
      "Row 9018 => Predicted: 0\n",
      "Row 9019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9010 to 9019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9020 => Predicted: 1\n",
      "Row 9021 => Predicted: 1\n",
      "Row 9022 => Predicted: 1\n",
      "Row 9023 => Predicted: 1\n",
      "Row 9024 => Predicted: 1\n",
      "Row 9025 => Predicted: 0\n",
      "Row 9026 => Predicted: 1\n",
      "Row 9027 => Predicted: 0\n",
      "Row 9028 => Predicted: 1\n",
      "Row 9029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9020 to 9029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9030 => Predicted: 1\n",
      "Row 9031 => Predicted: 1\n",
      "Row 9032 => Predicted: 1\n",
      "Row 9033 => Predicted: 1\n",
      "Row 9034 => Predicted: 1\n",
      "Row 9035 => Predicted: 1\n",
      "Row 9036 => Predicted: 0\n",
      "Row 9037 => Predicted: 1\n",
      "Row 9038 => Predicted: 1\n",
      "Row 9039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9030 to 9039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9040 => Predicted: 1\n",
      "Row 9041 => Predicted: 1\n",
      "Row 9042 => Predicted: 0\n",
      "Row 9043 => Predicted: 0\n",
      "Row 9044 => Predicted: 0\n",
      "Row 9045 => Predicted: 1\n",
      "Row 9046 => Predicted: 1\n",
      "Row 9047 => Predicted: 0\n",
      "Row 9048 => Predicted: 0\n",
      "Row 9049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9040 to 9049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9050 => Predicted: 0\n",
      "Row 9051 => Predicted: 0\n",
      "Row 9052 => Predicted: 1\n",
      "Row 9053 => Predicted: 0\n",
      "Row 9054 => Predicted: 1\n",
      "Row 9055 => Predicted: 1\n",
      "Row 9056 => Predicted: 1\n",
      "Row 9057 => Predicted: 1\n",
      "Row 9058 => Predicted: 0\n",
      "Row 9059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9050 to 9059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9060 => Predicted: 0\n",
      "Row 9061 => Predicted: 1\n",
      "Row 9062 => Predicted: 1\n",
      "Row 9063 => Predicted: 1\n",
      "Row 9064 => Predicted: 1\n",
      "Row 9065 => Predicted: 0\n",
      "Row 9066 => Predicted: 0\n",
      "Row 9067 => Predicted: 1\n",
      "Row 9068 => Predicted: 0\n",
      "Row 9069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9060 to 9069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9070 => Predicted: 0\n",
      "Row 9071 => Predicted: 0\n",
      "Row 9072 => Predicted: 0\n",
      "Row 9073 => Predicted: 1\n",
      "Row 9074 => Predicted: 1\n",
      "Row 9075 => Predicted: 1\n",
      "Row 9076 => Predicted: 1\n",
      "Row 9077 => Predicted: 1\n",
      "Row 9078 => Predicted: 0\n",
      "Row 9079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9070 to 9079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9080 => Predicted: 1\n",
      "Row 9081 => Predicted: 1\n",
      "Row 9082 => Predicted: 1\n",
      "Row 9083 => Predicted: 1\n",
      "Row 9084 => Predicted: 1\n",
      "Row 9085 => Predicted: 0\n",
      "Row 9086 => Predicted: 1\n",
      "Row 9087 => Predicted: 1\n",
      "Row 9088 => Predicted: 0\n",
      "Row 9089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9080 to 9089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9090 => Predicted: 0\n",
      "Row 9091 => Predicted: 0\n",
      "Row 9092 => Predicted: 0\n",
      "Row 9093 => Predicted: 1\n",
      "Row 9094 => Predicted: 0\n",
      "Row 9095 => Predicted: 1\n",
      "Row 9096 => Predicted: 0\n",
      "Row 9097 => Predicted: 1\n",
      "Row 9098 => Predicted: 1\n",
      "Row 9099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9090 to 9099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9100 => Predicted: 0\n",
      "Row 9101 => Predicted: 0\n",
      "Row 9102 => Predicted: 1\n",
      "Row 9103 => Predicted: 1\n",
      "Row 9104 => Predicted: 0\n",
      "Row 9105 => Predicted: 1\n",
      "Row 9106 => Predicted: 0\n",
      "Row 9107 => Predicted: 0\n",
      "Row 9108 => Predicted: 1\n",
      "Row 9109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9100 to 9109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9110 => Predicted: 0\n",
      "Row 9111 => Predicted: 0\n",
      "Row 9112 => Predicted: 1\n",
      "Row 9113 => Predicted: 1\n",
      "Row 9114 => Predicted: 1\n",
      "Row 9115 => Predicted: 0\n",
      "Row 9116 => Predicted: 1\n",
      "Row 9117 => Predicted: 0\n",
      "Row 9118 => Predicted: 0\n",
      "Row 9119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9110 to 9119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9120 => Predicted: 0\n",
      "Row 9121 => Predicted: 1\n",
      "Row 9122 => Predicted: 0\n",
      "Row 9123 => Predicted: 1\n",
      "Row 9124 => Predicted: 0\n",
      "Row 9125 => Predicted: 0\n",
      "Row 9126 => Predicted: 0\n",
      "Row 9127 => Predicted: 1\n",
      "Row 9128 => Predicted: 0\n",
      "Row 9129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9120 to 9129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9130 => Predicted: 1\n",
      "Row 9131 => Predicted: 0\n",
      "Row 9132 => Predicted: 0\n",
      "Row 9133 => Predicted: 0\n",
      "Row 9134 => Predicted: 1\n",
      "Row 9135 => Predicted: 0\n",
      "Row 9136 => Predicted: 1\n",
      "Row 9137 => Predicted: 0\n",
      "Row 9138 => Predicted: 0\n",
      "Row 9139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9130 to 9139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9140 => Predicted: 1\n",
      "Row 9141 => Predicted: 1\n",
      "Row 9142 => Predicted: 0\n",
      "Row 9143 => Predicted: 0\n",
      "Row 9144 => Predicted: 1\n",
      "Row 9145 => Predicted: 1\n",
      "Row 9146 => Predicted: 1\n",
      "Row 9147 => Predicted: 0\n",
      "Row 9148 => Predicted: 1\n",
      "Row 9149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9140 to 9149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9150 => Predicted: 0\n",
      "Row 9151 => Predicted: 0\n",
      "Row 9152 => Predicted: 0\n",
      "Row 9153 => Predicted: 0\n",
      "Row 9154 => Predicted: 1\n",
      "Row 9155 => Predicted: 0\n",
      "Row 9156 => Predicted: 0\n",
      "Row 9157 => Predicted: 0\n",
      "Row 9158 => Predicted: 0\n",
      "Row 9159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9150 to 9159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9160 => Predicted: 0\n",
      "Row 9161 => Predicted: 0\n",
      "Row 9162 => Predicted: 1\n",
      "Row 9163 => Predicted: 1\n",
      "Row 9164 => Predicted: 0\n",
      "Row 9165 => Predicted: 0\n",
      "Row 9166 => Predicted: 0\n",
      "Row 9167 => Predicted: 1\n",
      "Row 9168 => Predicted: 0\n",
      "Row 9169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9160 to 9169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9170 => Predicted: 1\n",
      "Row 9171 => Predicted: 0\n",
      "Row 9172 => Predicted: 0\n",
      "Row 9173 => Predicted: 1\n",
      "Row 9174 => Predicted: 0\n",
      "Row 9175 => Predicted: 0\n",
      "Row 9176 => Predicted: 0\n",
      "Row 9177 => Predicted: 1\n",
      "Row 9178 => Predicted: 0\n",
      "Row 9179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9170 to 9179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9180 => Predicted: 1\n",
      "Row 9181 => Predicted: 0\n",
      "Row 9182 => Predicted: 0\n",
      "Row 9183 => Predicted: 1\n",
      "Row 9184 => Predicted: 1\n",
      "Row 9185 => Predicted: 0\n",
      "Row 9186 => Predicted: 0\n",
      "Row 9187 => Predicted: 0\n",
      "Row 9188 => Predicted: 1\n",
      "Row 9189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9180 to 9189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9190 => Predicted: 0\n",
      "Row 9191 => Predicted: 0\n",
      "Row 9192 => Predicted: 0\n",
      "Row 9193 => Predicted: 1\n",
      "Row 9194 => Predicted: 1\n",
      "Row 9195 => Predicted: 0\n",
      "Row 9196 => Predicted: 0\n",
      "Row 9197 => Predicted: 0\n",
      "Row 9198 => Predicted: 1\n",
      "Row 9199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9190 to 9199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9200 => Predicted: 0\n",
      "Row 9201 => Predicted: 0\n",
      "Row 9202 => Predicted: 1\n",
      "Row 9203 => Predicted: 0\n",
      "Row 9204 => Predicted: 1\n",
      "Row 9205 => Predicted: 0\n",
      "Row 9206 => Predicted: 1\n",
      "Row 9207 => Predicted: 0\n",
      "Row 9208 => Predicted: 1\n",
      "Row 9209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9200 to 9209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9210 => Predicted: 1\n",
      "Row 9211 => Predicted: 0\n",
      "Row 9212 => Predicted: 1\n",
      "Row 9213 => Predicted: 1\n",
      "Row 9214 => Predicted: 0\n",
      "Row 9215 => Predicted: 0\n",
      "Row 9216 => Predicted: 0\n",
      "Row 9217 => Predicted: 0\n",
      "Row 9218 => Predicted: 0\n",
      "Row 9219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9210 to 9219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9220 => Predicted: 1\n",
      "Row 9221 => Predicted: 1\n",
      "Row 9222 => Predicted: 0\n",
      "Row 9223 => Predicted: 0\n",
      "Row 9224 => Predicted: 1\n",
      "Row 9225 => Predicted: 1\n",
      "Row 9226 => Predicted: 1\n",
      "Row 9227 => Predicted: 0\n",
      "Row 9228 => Predicted: 1\n",
      "Row 9229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9220 to 9229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9230 => Predicted: 1\n",
      "Row 9231 => Predicted: 0\n",
      "Row 9232 => Predicted: 1\n",
      "Row 9233 => Predicted: 1\n",
      "Row 9234 => Predicted: 1\n",
      "Row 9235 => Predicted: 1\n",
      "Row 9236 => Predicted: 1\n",
      "Row 9237 => Predicted: 1\n",
      "Row 9238 => Predicted: 0\n",
      "Row 9239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9230 to 9239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9240 => Predicted: 0\n",
      "Row 9241 => Predicted: 0\n",
      "Row 9242 => Predicted: 1\n",
      "Row 9243 => Predicted: 0\n",
      "Row 9244 => Predicted: 1\n",
      "Row 9245 => Predicted: 0\n",
      "Row 9246 => Predicted: 1\n",
      "Row 9247 => Predicted: 1\n",
      "Row 9248 => Predicted: 1\n",
      "Row 9249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9240 to 9249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9250 => Predicted: 0\n",
      "Row 9251 => Predicted: 1\n",
      "Row 9252 => Predicted: 1\n",
      "Row 9253 => Predicted: 1\n",
      "Row 9254 => Predicted: 1\n",
      "Row 9255 => Predicted: 1\n",
      "Row 9256 => Predicted: 0\n",
      "Row 9257 => Predicted: 0\n",
      "Row 9258 => Predicted: 1\n",
      "Row 9259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9250 to 9259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9260 => Predicted: 1\n",
      "Row 9261 => Predicted: 1\n",
      "Row 9262 => Predicted: 0\n",
      "Row 9263 => Predicted: 1\n",
      "Row 9264 => Predicted: 0\n",
      "Row 9265 => Predicted: 0\n",
      "Row 9266 => Predicted: 0\n",
      "Row 9267 => Predicted: 1\n",
      "Row 9268 => Predicted: 1\n",
      "Row 9269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9260 to 9269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9270 => Predicted: 0\n",
      "Row 9271 => Predicted: 1\n",
      "Row 9272 => Predicted: 0\n",
      "Row 9273 => Predicted: 1\n",
      "Row 9274 => Predicted: 1\n",
      "Row 9275 => Predicted: 0\n",
      "Row 9276 => Predicted: 1\n",
      "Row 9277 => Predicted: 0\n",
      "Row 9278 => Predicted: 0\n",
      "Row 9279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9270 to 9279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9280 => Predicted: 0\n",
      "Row 9281 => Predicted: 0\n",
      "Row 9282 => Predicted: 1\n",
      "Row 9283 => Predicted: 1\n",
      "Row 9284 => Predicted: 0\n",
      "Row 9285 => Predicted: 1\n",
      "Row 9286 => Predicted: 1\n",
      "Row 9287 => Predicted: 1\n",
      "Row 9288 => Predicted: 1\n",
      "Row 9289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9280 to 9289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9290 => Predicted: 1\n",
      "Row 9291 => Predicted: 0\n",
      "Row 9292 => Predicted: 1\n",
      "Row 9293 => Predicted: 0\n",
      "Row 9294 => Predicted: 0\n",
      "Row 9295 => Predicted: 0\n",
      "Row 9296 => Predicted: 0\n",
      "Row 9297 => Predicted: 0\n",
      "Row 9298 => Predicted: 0\n",
      "Row 9299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9290 to 9299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9300 => Predicted: 1\n",
      "Row 9301 => Predicted: 1\n",
      "Row 9302 => Predicted: 1\n",
      "Row 9303 => Predicted: 1\n",
      "Row 9304 => Predicted: 1\n",
      "Row 9305 => Predicted: 1\n",
      "Row 9306 => Predicted: 1\n",
      "Row 9307 => Predicted: 1\n",
      "Row 9308 => Predicted: 1\n",
      "Row 9309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9300 to 9309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9310 => Predicted: 1\n",
      "Row 9311 => Predicted: 0\n",
      "Row 9312 => Predicted: 0\n",
      "Row 9313 => Predicted: 1\n",
      "Row 9314 => Predicted: 1\n",
      "Row 9315 => Predicted: 0\n",
      "Row 9316 => Predicted: 0\n",
      "Row 9317 => Predicted: 0\n",
      "Row 9318 => Predicted: 1\n",
      "Row 9319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9310 to 9319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9320 => Predicted: 1\n",
      "Row 9321 => Predicted: 0\n",
      "Row 9322 => Predicted: 0\n",
      "Row 9323 => Predicted: 1\n",
      "Row 9324 => Predicted: 1\n",
      "Row 9325 => Predicted: 0\n",
      "Row 9326 => Predicted: 0\n",
      "Row 9327 => Predicted: 1\n",
      "Row 9328 => Predicted: 1\n",
      "Row 9329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9320 to 9329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9330 => Predicted: 0\n",
      "Row 9331 => Predicted: 0\n",
      "Row 9332 => Predicted: 1\n",
      "Row 9333 => Predicted: 0\n",
      "Row 9334 => Predicted: 0\n",
      "Row 9335 => Predicted: 1\n",
      "Row 9336 => Predicted: 1\n",
      "Row 9337 => Predicted: 1\n",
      "Row 9338 => Predicted: 1\n",
      "Row 9339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9330 to 9339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9340 => Predicted: 1\n",
      "Row 9341 => Predicted: 1\n",
      "Row 9342 => Predicted: 0\n",
      "Row 9343 => Predicted: 0\n",
      "Row 9344 => Predicted: 1\n",
      "Row 9345 => Predicted: 1\n",
      "Row 9346 => Predicted: 1\n",
      "Row 9347 => Predicted: 0\n",
      "Row 9348 => Predicted: 1\n",
      "Row 9349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9340 to 9349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9350 => Predicted: 1\n",
      "Row 9351 => Predicted: 0\n",
      "Row 9352 => Predicted: 0\n",
      "Row 9353 => Predicted: 1\n",
      "Row 9354 => Predicted: 0\n",
      "Row 9355 => Predicted: 0\n",
      "Row 9356 => Predicted: 1\n",
      "Row 9357 => Predicted: 1\n",
      "Row 9358 => Predicted: 1\n",
      "Row 9359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9350 to 9359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9360 => Predicted: 0\n",
      "Row 9361 => Predicted: 1\n",
      "Row 9362 => Predicted: 1\n",
      "Row 9363 => Predicted: 0\n",
      "Row 9364 => Predicted: 0\n",
      "Row 9365 => Predicted: 0\n",
      "Row 9366 => Predicted: 1\n",
      "Row 9367 => Predicted: 0\n",
      "Row 9368 => Predicted: 0\n",
      "Row 9369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9360 to 9369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9370 => Predicted: 1\n",
      "Row 9371 => Predicted: 1\n",
      "Row 9372 => Predicted: 0\n",
      "Row 9373 => Predicted: 0\n",
      "Row 9374 => Predicted: 1\n",
      "Row 9375 => Predicted: 0\n",
      "Row 9376 => Predicted: 0\n",
      "Row 9377 => Predicted: 0\n",
      "Row 9378 => Predicted: 1\n",
      "Row 9379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9370 to 9379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9380 => Predicted: 1\n",
      "Row 9381 => Predicted: 1\n",
      "Row 9382 => Predicted: 0\n",
      "Row 9383 => Predicted: 1\n",
      "Row 9384 => Predicted: 0\n",
      "Row 9385 => Predicted: 1\n",
      "Row 9386 => Predicted: 1\n",
      "Row 9387 => Predicted: 0\n",
      "Row 9388 => Predicted: 1\n",
      "Row 9389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9380 to 9389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9390 => Predicted: 0\n",
      "Row 9391 => Predicted: 1\n",
      "Row 9392 => Predicted: 1\n",
      "Row 9393 => Predicted: 0\n",
      "Row 9394 => Predicted: 1\n",
      "Row 9395 => Predicted: 1\n",
      "Row 9396 => Predicted: 1\n",
      "Row 9397 => Predicted: 1\n",
      "Row 9398 => Predicted: 0\n",
      "Row 9399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9390 to 9399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9400 => Predicted: 0\n",
      "Row 9401 => Predicted: 1\n",
      "Row 9402 => Predicted: 0\n",
      "Row 9403 => Predicted: 0\n",
      "Row 9404 => Predicted: 1\n",
      "Row 9405 => Predicted: 1\n",
      "Row 9406 => Predicted: 0\n",
      "Row 9407 => Predicted: 0\n",
      "Row 9408 => Predicted: 0\n",
      "Row 9409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9400 to 9409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9410 => Predicted: 0\n",
      "Row 9411 => Predicted: 1\n",
      "Row 9412 => Predicted: 0\n",
      "Row 9413 => Predicted: 0\n",
      "Row 9414 => Predicted: 1\n",
      "Row 9415 => Predicted: 1\n",
      "Row 9416 => Predicted: 1\n",
      "Row 9417 => Predicted: 1\n",
      "Row 9418 => Predicted: 1\n",
      "Row 9419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9410 to 9419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9420 => Predicted: 0\n",
      "Row 9421 => Predicted: 0\n",
      "Row 9422 => Predicted: 0\n",
      "Row 9423 => Predicted: 0\n",
      "Row 9424 => Predicted: 1\n",
      "Row 9425 => Predicted: 0\n",
      "Row 9426 => Predicted: 0\n",
      "Row 9427 => Predicted: 0\n",
      "Row 9428 => Predicted: 1\n",
      "Row 9429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9420 to 9429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9430 => Predicted: 1\n",
      "Row 9431 => Predicted: 1\n",
      "Row 9432 => Predicted: 0\n",
      "Row 9433 => Predicted: 0\n",
      "Row 9434 => Predicted: 0\n",
      "Row 9435 => Predicted: 1\n",
      "Row 9436 => Predicted: 1\n",
      "Row 9437 => Predicted: 0\n",
      "Row 9438 => Predicted: 1\n",
      "Row 9439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9430 to 9439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9440 => Predicted: 0\n",
      "Row 9441 => Predicted: 0\n",
      "Row 9442 => Predicted: 1\n",
      "Row 9443 => Predicted: 1\n",
      "Row 9444 => Predicted: 0\n",
      "Row 9445 => Predicted: 0\n",
      "Row 9446 => Predicted: 1\n",
      "Row 9447 => Predicted: 0\n",
      "Row 9448 => Predicted: 0\n",
      "Row 9449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9440 to 9449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9450 => Predicted: 0\n",
      "Row 9451 => Predicted: 1\n",
      "Row 9452 => Predicted: 0\n",
      "Row 9453 => Predicted: 1\n",
      "Row 9454 => Predicted: 1\n",
      "Row 9455 => Predicted: 0\n",
      "Row 9456 => Predicted: 1\n",
      "Row 9457 => Predicted: 0\n",
      "Row 9458 => Predicted: 0\n",
      "Row 9459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9450 to 9459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9460 => Predicted: 0\n",
      "Row 9461 => Predicted: 0\n",
      "Row 9462 => Predicted: 0\n",
      "Row 9463 => Predicted: 0\n",
      "Row 9464 => Predicted: 0\n",
      "Row 9465 => Predicted: 1\n",
      "Row 9466 => Predicted: 0\n",
      "Row 9467 => Predicted: 1\n",
      "Row 9468 => Predicted: 0\n",
      "Row 9469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9460 to 9469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9470 => Predicted: 0\n",
      "Row 9471 => Predicted: 0\n",
      "Row 9472 => Predicted: 1\n",
      "Row 9473 => Predicted: 1\n",
      "Row 9474 => Predicted: 0\n",
      "Row 9475 => Predicted: 1\n",
      "Row 9476 => Predicted: 0\n",
      "Row 9477 => Predicted: 1\n",
      "Row 9478 => Predicted: 0\n",
      "Row 9479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9470 to 9479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9480 => Predicted: 1\n",
      "Row 9481 => Predicted: 0\n",
      "Row 9482 => Predicted: 1\n",
      "Row 9483 => Predicted: 1\n",
      "Row 9484 => Predicted: 1\n",
      "Row 9485 => Predicted: 1\n",
      "Row 9486 => Predicted: 1\n",
      "Row 9487 => Predicted: 1\n",
      "Row 9488 => Predicted: 0\n",
      "Row 9489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9480 to 9489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9490 => Predicted: 1\n",
      "Row 9491 => Predicted: 1\n",
      "Row 9492 => Predicted: 1\n",
      "Row 9493 => Predicted: 0\n",
      "Row 9494 => Predicted: 1\n",
      "Row 9495 => Predicted: 1\n",
      "Row 9496 => Predicted: 1\n",
      "Row 9497 => Predicted: 0\n",
      "Row 9498 => Predicted: 1\n",
      "Row 9499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9490 to 9499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9500 => Predicted: 1\n",
      "Row 9501 => Predicted: 1\n",
      "Row 9502 => Predicted: 1\n",
      "Row 9503 => Predicted: 0\n",
      "Row 9504 => Predicted: 1\n",
      "Row 9505 => Predicted: 1\n",
      "Row 9506 => Predicted: 0\n",
      "Row 9507 => Predicted: 1\n",
      "Row 9508 => Predicted: 1\n",
      "Row 9509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9500 to 9509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9510 => Predicted: 1\n",
      "Row 9511 => Predicted: 0\n",
      "Row 9512 => Predicted: 1\n",
      "Row 9513 => Predicted: 0\n",
      "Row 9514 => Predicted: 1\n",
      "Row 9515 => Predicted: 0\n",
      "Row 9516 => Predicted: 1\n",
      "Row 9517 => Predicted: 0\n",
      "Row 9518 => Predicted: 0\n",
      "Row 9519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9510 to 9519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9520 => Predicted: 1\n",
      "Row 9521 => Predicted: 1\n",
      "Row 9522 => Predicted: 1\n",
      "Row 9523 => Predicted: 0\n",
      "Row 9524 => Predicted: 0\n",
      "Row 9525 => Predicted: 1\n",
      "Row 9526 => Predicted: 1\n",
      "Row 9527 => Predicted: 1\n",
      "Row 9528 => Predicted: 1\n",
      "Row 9529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9520 to 9529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9530 => Predicted: 1\n",
      "Row 9531 => Predicted: 0\n",
      "Row 9532 => Predicted: 0\n",
      "Row 9533 => Predicted: 0\n",
      "Row 9534 => Predicted: 1\n",
      "Row 9535 => Predicted: 0\n",
      "Row 9536 => Predicted: 1\n",
      "Row 9537 => Predicted: 0\n",
      "Row 9538 => Predicted: 0\n",
      "Row 9539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9530 to 9539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9540 => Predicted: 0\n",
      "Row 9541 => Predicted: 1\n",
      "Row 9542 => Predicted: 0\n",
      "Row 9543 => Predicted: 1\n",
      "Row 9544 => Predicted: 1\n",
      "Row 9545 => Predicted: 0\n",
      "Row 9546 => Predicted: 1\n",
      "Row 9547 => Predicted: 1\n",
      "Row 9548 => Predicted: 1\n",
      "Row 9549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9540 to 9549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9550 => Predicted: 0\n",
      "Row 9551 => Predicted: 1\n",
      "Row 9552 => Predicted: 1\n",
      "Row 9553 => Predicted: 1\n",
      "Row 9554 => Predicted: 1\n",
      "Row 9555 => Predicted: 1\n",
      "Row 9556 => Predicted: 1\n",
      "Row 9557 => Predicted: 1\n",
      "Row 9558 => Predicted: 0\n",
      "Row 9559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9550 to 9559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9560 => Predicted: 0\n",
      "Row 9561 => Predicted: 1\n",
      "Row 9562 => Predicted: 0\n",
      "Row 9563 => Predicted: 0\n",
      "Row 9564 => Predicted: 0\n",
      "Row 9565 => Predicted: 0\n",
      "Row 9566 => Predicted: 1\n",
      "Row 9567 => Predicted: 1\n",
      "Row 9568 => Predicted: 1\n",
      "Row 9569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9560 to 9569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9570 => Predicted: 0\n",
      "Row 9571 => Predicted: 1\n",
      "Row 9572 => Predicted: 0\n",
      "Row 9573 => Predicted: 1\n",
      "Row 9574 => Predicted: 0\n",
      "Row 9575 => Predicted: 0\n",
      "Row 9576 => Predicted: 0\n",
      "Row 9577 => Predicted: 1\n",
      "Row 9578 => Predicted: 0\n",
      "Row 9579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9570 to 9579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9580 => Predicted: 0\n",
      "Row 9581 => Predicted: 0\n",
      "Row 9582 => Predicted: 1\n",
      "Row 9583 => Predicted: 0\n",
      "Row 9584 => Predicted: 0\n",
      "Row 9585 => Predicted: 0\n",
      "Row 9586 => Predicted: 1\n",
      "Row 9587 => Predicted: 1\n",
      "Row 9588 => Predicted: 0\n",
      "Row 9589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9580 to 9589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9590 => Predicted: 1\n",
      "Row 9591 => Predicted: 0\n",
      "Row 9592 => Predicted: 1\n",
      "Row 9593 => Predicted: 1\n",
      "Row 9594 => Predicted: 1\n",
      "Row 9595 => Predicted: 0\n",
      "Row 9596 => Predicted: 1\n",
      "Row 9597 => Predicted: 1\n",
      "Row 9598 => Predicted: 1\n",
      "Row 9599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9590 to 9599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9600 => Predicted: 0\n",
      "Row 9601 => Predicted: 0\n",
      "Row 9602 => Predicted: 1\n",
      "Row 9603 => Predicted: 1\n",
      "Row 9604 => Predicted: 0\n",
      "Row 9605 => Predicted: 1\n",
      "Row 9606 => Predicted: 0\n",
      "Row 9607 => Predicted: 0\n",
      "Row 9608 => Predicted: 0\n",
      "Row 9609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9600 to 9609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9610 => Predicted: 0\n",
      "Row 9611 => Predicted: 1\n",
      "Row 9612 => Predicted: 0\n",
      "Row 9613 => Predicted: 1\n",
      "Row 9614 => Predicted: 0\n",
      "Row 9615 => Predicted: 1\n",
      "Row 9616 => Predicted: 1\n",
      "Row 9617 => Predicted: 1\n",
      "Row 9618 => Predicted: 0\n",
      "Row 9619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9610 to 9619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9620 => Predicted: 1\n",
      "Row 9621 => Predicted: 1\n",
      "Row 9622 => Predicted: 1\n",
      "Row 9623 => Predicted: 0\n",
      "Row 9624 => Predicted: 0\n",
      "Row 9625 => Predicted: 1\n",
      "Row 9626 => Predicted: 1\n",
      "Row 9627 => Predicted: 0\n",
      "Row 9628 => Predicted: 1\n",
      "Row 9629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9620 to 9629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9630 => Predicted: 0\n",
      "Row 9631 => Predicted: 0\n",
      "Row 9632 => Predicted: 1\n",
      "Row 9633 => Predicted: 0\n",
      "Row 9634 => Predicted: 1\n",
      "Row 9635 => Predicted: 0\n",
      "Row 9636 => Predicted: 0\n",
      "Row 9637 => Predicted: 1\n",
      "Row 9638 => Predicted: 1\n",
      "Row 9639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9630 to 9639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9640 => Predicted: 1\n",
      "Row 9641 => Predicted: 1\n",
      "Row 9642 => Predicted: 1\n",
      "Row 9643 => Predicted: 1\n",
      "Row 9644 => Predicted: 1\n",
      "Row 9645 => Predicted: 0\n",
      "Row 9646 => Predicted: 1\n",
      "Row 9647 => Predicted: 0\n",
      "Row 9648 => Predicted: 1\n",
      "Row 9649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9640 to 9649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9650 => Predicted: 0\n",
      "Row 9651 => Predicted: 1\n",
      "Row 9652 => Predicted: 0\n",
      "Row 9653 => Predicted: 0\n",
      "Row 9654 => Predicted: 0\n",
      "Row 9655 => Predicted: 1\n",
      "Row 9656 => Predicted: 1\n",
      "Row 9657 => Predicted: 1\n",
      "Row 9658 => Predicted: 1\n",
      "Row 9659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9650 to 9659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9660 => Predicted: 0\n",
      "Row 9661 => Predicted: 0\n",
      "Row 9662 => Predicted: 1\n",
      "Row 9663 => Predicted: 0\n",
      "Row 9664 => Predicted: 1\n",
      "Row 9665 => Predicted: 0\n",
      "Row 9666 => Predicted: 0\n",
      "Row 9667 => Predicted: 0\n",
      "Row 9668 => Predicted: 0\n",
      "Row 9669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9660 to 9669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9670 => Predicted: 1\n",
      "Row 9671 => Predicted: 1\n",
      "Row 9672 => Predicted: 0\n",
      "Row 9673 => Predicted: 0\n",
      "Row 9674 => Predicted: 0\n",
      "Row 9675 => Predicted: 1\n",
      "Row 9676 => Predicted: 0\n",
      "Row 9677 => Predicted: 0\n",
      "Row 9678 => Predicted: 1\n",
      "Row 9679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9670 to 9679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9680 => Predicted: 0\n",
      "Row 9681 => Predicted: 0\n",
      "Row 9682 => Predicted: 1\n",
      "Row 9683 => Predicted: 1\n",
      "Row 9684 => Predicted: 0\n",
      "Row 9685 => Predicted: 1\n",
      "Row 9686 => Predicted: 0\n",
      "Row 9687 => Predicted: 0\n",
      "Row 9688 => Predicted: 1\n",
      "Row 9689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9680 to 9689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9690 => Predicted: 0\n",
      "Row 9691 => Predicted: 0\n",
      "Row 9692 => Predicted: 1\n",
      "Row 9693 => Predicted: 1\n",
      "Row 9694 => Predicted: 1\n",
      "Row 9695 => Predicted: 1\n",
      "Row 9696 => Predicted: 1\n",
      "Row 9697 => Predicted: 1\n",
      "Row 9698 => Predicted: 0\n",
      "Row 9699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9690 to 9699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9700 => Predicted: 0\n",
      "Row 9701 => Predicted: 1\n",
      "Row 9702 => Predicted: 0\n",
      "Row 9703 => Predicted: 0\n",
      "Row 9704 => Predicted: 0\n",
      "Row 9705 => Predicted: 0\n",
      "Row 9706 => Predicted: 1\n",
      "Row 9707 => Predicted: 0\n",
      "Row 9708 => Predicted: 0\n",
      "Row 9709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9700 to 9709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9710 => Predicted: 1\n",
      "Row 9711 => Predicted: 1\n",
      "Row 9712 => Predicted: 1\n",
      "Row 9713 => Predicted: 1\n",
      "Row 9714 => Predicted: 0\n",
      "Row 9715 => Predicted: 1\n",
      "Row 9716 => Predicted: 1\n",
      "Row 9717 => Predicted: 1\n",
      "Row 9718 => Predicted: 0\n",
      "Row 9719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9710 to 9719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9720 => Predicted: 0\n",
      "Row 9721 => Predicted: 1\n",
      "Row 9722 => Predicted: 1\n",
      "Row 9723 => Predicted: 1\n",
      "Row 9724 => Predicted: 1\n",
      "Row 9725 => Predicted: 1\n",
      "Row 9726 => Predicted: 1\n",
      "Row 9727 => Predicted: 0\n",
      "Row 9728 => Predicted: 1\n",
      "Row 9729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9720 to 9729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9730 => Predicted: 1\n",
      "Row 9731 => Predicted: 0\n",
      "Row 9732 => Predicted: 0\n",
      "Row 9733 => Predicted: 1\n",
      "Row 9734 => Predicted: 0\n",
      "Row 9735 => Predicted: 0\n",
      "Row 9736 => Predicted: 0\n",
      "Row 9737 => Predicted: 1\n",
      "Row 9738 => Predicted: 0\n",
      "Row 9739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9730 to 9739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9740 => Predicted: 0\n",
      "Row 9741 => Predicted: 1\n",
      "Row 9742 => Predicted: 1\n",
      "Row 9743 => Predicted: 0\n",
      "Row 9744 => Predicted: 1\n",
      "Row 9745 => Predicted: 0\n",
      "Row 9746 => Predicted: 1\n",
      "Row 9747 => Predicted: 0\n",
      "Row 9748 => Predicted: 1\n",
      "Row 9749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9740 to 9749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9750 => Predicted: 1\n",
      "Row 9751 => Predicted: 0\n",
      "Row 9752 => Predicted: 1\n",
      "Row 9753 => Predicted: 1\n",
      "Row 9754 => Predicted: 0\n",
      "Row 9755 => Predicted: 1\n",
      "Row 9756 => Predicted: 0\n",
      "Row 9757 => Predicted: 0\n",
      "Row 9758 => Predicted: 0\n",
      "Row 9759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9750 to 9759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9760 => Predicted: 0\n",
      "Row 9761 => Predicted: 0\n",
      "Row 9762 => Predicted: 0\n",
      "Row 9763 => Predicted: 0\n",
      "Row 9764 => Predicted: 0\n",
      "Row 9765 => Predicted: 0\n",
      "Row 9766 => Predicted: 1\n",
      "Row 9767 => Predicted: 1\n",
      "Row 9768 => Predicted: 1\n",
      "Row 9769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9760 to 9769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9770 => Predicted: 1\n",
      "Row 9771 => Predicted: 1\n",
      "Row 9772 => Predicted: 0\n",
      "Row 9773 => Predicted: 0\n",
      "Row 9774 => Predicted: 0\n",
      "Row 9775 => Predicted: 1\n",
      "Row 9776 => Predicted: 1\n",
      "Row 9777 => Predicted: 0\n",
      "Row 9778 => Predicted: 0\n",
      "Row 9779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9770 to 9779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9780 => Predicted: 1\n",
      "Row 9781 => Predicted: 1\n",
      "Row 9782 => Predicted: 0\n",
      "Row 9783 => Predicted: 1\n",
      "Row 9784 => Predicted: 0\n",
      "Row 9785 => Predicted: 0\n",
      "Row 9786 => Predicted: 0\n",
      "Row 9787 => Predicted: 0\n",
      "Row 9788 => Predicted: 0\n",
      "Row 9789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9780 to 9789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9790 => Predicted: 0\n",
      "Row 9791 => Predicted: 1\n",
      "Row 9792 => Predicted: 0\n",
      "Row 9793 => Predicted: 0\n",
      "Row 9794 => Predicted: 0\n",
      "Row 9795 => Predicted: 1\n",
      "Row 9796 => Predicted: 0\n",
      "Row 9797 => Predicted: 1\n",
      "Row 9798 => Predicted: 0\n",
      "Row 9799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9790 to 9799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9800 => Predicted: 0\n",
      "Row 9801 => Predicted: 0\n",
      "Row 9802 => Predicted: 1\n",
      "Row 9803 => Predicted: 0\n",
      "Row 9804 => Predicted: 0\n",
      "Row 9805 => Predicted: 0\n",
      "Row 9806 => Predicted: 1\n",
      "Row 9807 => Predicted: 1\n",
      "Row 9808 => Predicted: 1\n",
      "Row 9809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9800 to 9809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9810 => Predicted: 1\n",
      "Row 9811 => Predicted: 1\n",
      "Row 9812 => Predicted: 0\n",
      "Row 9813 => Predicted: 0\n",
      "Row 9814 => Predicted: 1\n",
      "Row 9815 => Predicted: 1\n",
      "Row 9816 => Predicted: 1\n",
      "Row 9817 => Predicted: 0\n",
      "Row 9818 => Predicted: 1\n",
      "Row 9819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9810 to 9819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9820 => Predicted: 0\n",
      "Row 9821 => Predicted: 0\n",
      "Row 9822 => Predicted: 0\n",
      "Row 9823 => Predicted: 1\n",
      "Row 9824 => Predicted: 1\n",
      "Row 9825 => Predicted: 1\n",
      "Row 9826 => Predicted: 1\n",
      "Row 9827 => Predicted: 0\n",
      "Row 9828 => Predicted: 1\n",
      "Row 9829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9820 to 9829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9830 => Predicted: 0\n",
      "Row 9831 => Predicted: 1\n",
      "Row 9832 => Predicted: 1\n",
      "Row 9833 => Predicted: 1\n",
      "Row 9834 => Predicted: 1\n",
      "Row 9835 => Predicted: 0\n",
      "Row 9836 => Predicted: 0\n",
      "Row 9837 => Predicted: 1\n",
      "Row 9838 => Predicted: 0\n",
      "Row 9839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9830 to 9839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9840 => Predicted: 0\n",
      "Row 9841 => Predicted: 1\n",
      "Row 9842 => Predicted: 1\n",
      "Row 9843 => Predicted: 0\n",
      "Row 9844 => Predicted: 0\n",
      "Row 9845 => Predicted: 0\n",
      "Row 9846 => Predicted: 1\n",
      "Row 9847 => Predicted: 1\n",
      "Row 9848 => Predicted: 1\n",
      "Row 9849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9840 to 9849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9850 => Predicted: 0\n",
      "Row 9851 => Predicted: 0\n",
      "Row 9852 => Predicted: 0\n",
      "Row 9853 => Predicted: 0\n",
      "Row 9854 => Predicted: 0\n",
      "Row 9855 => Predicted: 1\n",
      "Row 9856 => Predicted: 0\n",
      "Row 9857 => Predicted: 1\n",
      "Row 9858 => Predicted: 1\n",
      "Row 9859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9850 to 9859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9860 => Predicted: 0\n",
      "Row 9861 => Predicted: 1\n",
      "Row 9862 => Predicted: 1\n",
      "Row 9863 => Predicted: 1\n",
      "Row 9864 => Predicted: 1\n",
      "Row 9865 => Predicted: 1\n",
      "Row 9866 => Predicted: 1\n",
      "Row 9867 => Predicted: 0\n",
      "Row 9868 => Predicted: 1\n",
      "Row 9869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9860 to 9869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9870 => Predicted: 1\n",
      "Row 9871 => Predicted: 1\n",
      "Row 9872 => Predicted: 1\n",
      "Row 9873 => Predicted: 0\n",
      "Row 9874 => Predicted: 1\n",
      "Row 9875 => Predicted: 1\n",
      "Row 9876 => Predicted: 1\n",
      "Row 9877 => Predicted: 1\n",
      "Row 9878 => Predicted: 1\n",
      "Row 9879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9870 to 9879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9880 => Predicted: 1\n",
      "Row 9881 => Predicted: 1\n",
      "Row 9882 => Predicted: 0\n",
      "Row 9883 => Predicted: 0\n",
      "Row 9884 => Predicted: 1\n",
      "Row 9885 => Predicted: 1\n",
      "Row 9886 => Predicted: 1\n",
      "Row 9887 => Predicted: 0\n",
      "Row 9888 => Predicted: 1\n",
      "Row 9889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9880 to 9889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9890 => Predicted: 0\n",
      "Row 9891 => Predicted: 1\n",
      "Row 9892 => Predicted: 0\n",
      "Row 9893 => Predicted: 0\n",
      "Row 9894 => Predicted: 1\n",
      "Row 9895 => Predicted: 1\n",
      "Row 9896 => Predicted: 0\n",
      "Row 9897 => Predicted: 1\n",
      "Row 9898 => Predicted: 1\n",
      "Row 9899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9890 to 9899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9900 => Predicted: 1\n",
      "Row 9901 => Predicted: 1\n",
      "Row 9902 => Predicted: 0\n",
      "Row 9903 => Predicted: 0\n",
      "Row 9904 => Predicted: 1\n",
      "Row 9905 => Predicted: 1\n",
      "Row 9906 => Predicted: 1\n",
      "Row 9907 => Predicted: 0\n",
      "Row 9908 => Predicted: 1\n",
      "Row 9909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9900 to 9909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9910 => Predicted: 1\n",
      "Row 9911 => Predicted: 1\n",
      "Row 9912 => Predicted: 1\n",
      "Row 9913 => Predicted: 1\n",
      "Row 9914 => Predicted: 0\n",
      "Row 9915 => Predicted: 0\n",
      "Row 9916 => Predicted: 1\n",
      "Row 9917 => Predicted: 0\n",
      "Row 9918 => Predicted: 1\n",
      "Row 9919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9910 to 9919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9920 => Predicted: 1\n",
      "Row 9921 => Predicted: 1\n",
      "Row 9922 => Predicted: 1\n",
      "Row 9923 => Predicted: 1\n",
      "Row 9924 => Predicted: 1\n",
      "Row 9925 => Predicted: 1\n",
      "Row 9926 => Predicted: 0\n",
      "Row 9927 => Predicted: 0\n",
      "Row 9928 => Predicted: 0\n",
      "Row 9929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9920 to 9929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9930 => Predicted: 0\n",
      "Row 9931 => Predicted: 0\n",
      "Row 9932 => Predicted: 0\n",
      "Row 9933 => Predicted: 1\n",
      "Row 9934 => Predicted: 1\n",
      "Row 9935 => Predicted: 0\n",
      "Row 9936 => Predicted: 1\n",
      "Row 9937 => Predicted: 0\n",
      "Row 9938 => Predicted: 1\n",
      "Row 9939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9930 to 9939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9940 => Predicted: 1\n",
      "Row 9941 => Predicted: 0\n",
      "Row 9942 => Predicted: 1\n",
      "Row 9943 => Predicted: 1\n",
      "Row 9944 => Predicted: 1\n",
      "Row 9945 => Predicted: 0\n",
      "Row 9946 => Predicted: 1\n",
      "Row 9947 => Predicted: 0\n",
      "Row 9948 => Predicted: 0\n",
      "Row 9949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9940 to 9949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9950 => Predicted: 0\n",
      "Row 9951 => Predicted: 0\n",
      "Row 9952 => Predicted: 0\n",
      "Row 9953 => Predicted: 1\n",
      "Row 9954 => Predicted: 1\n",
      "Row 9955 => Predicted: 1\n",
      "Row 9956 => Predicted: 1\n",
      "Row 9957 => Predicted: 1\n",
      "Row 9958 => Predicted: 1\n",
      "Row 9959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9950 to 9959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9960 => Predicted: 0\n",
      "Row 9961 => Predicted: 0\n",
      "Row 9962 => Predicted: 1\n",
      "Row 9963 => Predicted: 0\n",
      "Row 9964 => Predicted: 1\n",
      "Row 9965 => Predicted: 1\n",
      "Row 9966 => Predicted: 0\n",
      "Row 9967 => Predicted: 1\n",
      "Row 9968 => Predicted: 0\n",
      "Row 9969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9960 to 9969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9970 => Predicted: 1\n",
      "Row 9971 => Predicted: 1\n",
      "Row 9972 => Predicted: 1\n",
      "Row 9973 => Predicted: 0\n",
      "Row 9974 => Predicted: 0\n",
      "Row 9975 => Predicted: 0\n",
      "Row 9976 => Predicted: 0\n",
      "Row 9977 => Predicted: 0\n",
      "Row 9978 => Predicted: 0\n",
      "Row 9979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9970 to 9979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9980 => Predicted: 1\n",
      "Row 9981 => Predicted: 0\n",
      "Row 9982 => Predicted: 1\n",
      "Row 9983 => Predicted: 0\n",
      "Row 9984 => Predicted: 0\n",
      "Row 9985 => Predicted: 0\n",
      "Row 9986 => Predicted: 0\n",
      "Row 9987 => Predicted: 1\n",
      "Row 9988 => Predicted: 0\n",
      "Row 9989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 9980 to 9989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9990 => Predicted: 0\n",
      "Row 9991 => Predicted: 0\n",
      "Row 9992 => Predicted: 1\n",
      "Row 9993 => Predicted: 1\n",
      "Row 9994 => Predicted: 1\n",
      "Row 9995 => Predicted: 0\n",
      "Row 9996 => Predicted: 0\n",
      "Row 9997 => Predicted: 1\n",
      "Row 9998 => Predicted: 0\n",
      "Row 9999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 9990 to 9999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10000 => Predicted: 0\n",
      "Row 10001 => Predicted: 1\n",
      "Row 10002 => Predicted: 1\n",
      "Row 10003 => Predicted: 1\n",
      "Row 10004 => Predicted: 0\n",
      "Row 10005 => Predicted: 0\n",
      "Row 10006 => Predicted: 1\n",
      "Row 10007 => Predicted: 1\n",
      "Row 10008 => Predicted: 0\n",
      "Row 10009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10000 to 10009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10010 => Predicted: 1\n",
      "Row 10011 => Predicted: 1\n",
      "Row 10012 => Predicted: 1\n",
      "Row 10013 => Predicted: 0\n",
      "Row 10014 => Predicted: 1\n",
      "Row 10015 => Predicted: 1\n",
      "Row 10016 => Predicted: 0\n",
      "Row 10017 => Predicted: 1\n",
      "Row 10018 => Predicted: 0\n",
      "Row 10019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10010 to 10019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10020 => Predicted: 1\n",
      "Row 10021 => Predicted: 0\n",
      "Row 10022 => Predicted: 1\n",
      "Row 10023 => Predicted: 0\n",
      "Row 10024 => Predicted: 1\n",
      "Row 10025 => Predicted: 1\n",
      "Row 10026 => Predicted: 1\n",
      "Row 10027 => Predicted: 1\n",
      "Row 10028 => Predicted: 0\n",
      "Row 10029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10020 to 10029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10030 => Predicted: 1\n",
      "Row 10031 => Predicted: 0\n",
      "Row 10032 => Predicted: 1\n",
      "Row 10033 => Predicted: 0\n",
      "Row 10034 => Predicted: 0\n",
      "Row 10035 => Predicted: 1\n",
      "Row 10036 => Predicted: 1\n",
      "Row 10037 => Predicted: 1\n",
      "Row 10038 => Predicted: 0\n",
      "Row 10039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10030 to 10039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10040 => Predicted: 1\n",
      "Row 10041 => Predicted: 0\n",
      "Row 10042 => Predicted: 0\n",
      "Row 10043 => Predicted: 0\n",
      "Row 10044 => Predicted: 1\n",
      "Row 10045 => Predicted: 1\n",
      "Row 10046 => Predicted: 0\n",
      "Row 10047 => Predicted: 0\n",
      "Row 10048 => Predicted: 0\n",
      "Row 10049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10040 to 10049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10050 => Predicted: 1\n",
      "Row 10051 => Predicted: 1\n",
      "Row 10052 => Predicted: 0\n",
      "Row 10053 => Predicted: 0\n",
      "Row 10054 => Predicted: 0\n",
      "Row 10055 => Predicted: 0\n",
      "Row 10056 => Predicted: 1\n",
      "Row 10057 => Predicted: 1\n",
      "Row 10058 => Predicted: 0\n",
      "Row 10059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10050 to 10059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10060 => Predicted: 0\n",
      "Row 10061 => Predicted: 1\n",
      "Row 10062 => Predicted: 1\n",
      "Row 10063 => Predicted: 1\n",
      "Row 10064 => Predicted: 0\n",
      "Row 10065 => Predicted: 1\n",
      "Row 10066 => Predicted: 0\n",
      "Row 10067 => Predicted: 0\n",
      "Row 10068 => Predicted: 1\n",
      "Row 10069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10060 to 10069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10070 => Predicted: 1\n",
      "Row 10071 => Predicted: 1\n",
      "Row 10072 => Predicted: 1\n",
      "Row 10073 => Predicted: 0\n",
      "Row 10074 => Predicted: 1\n",
      "Row 10075 => Predicted: 1\n",
      "Row 10076 => Predicted: 0\n",
      "Row 10077 => Predicted: 1\n",
      "Row 10078 => Predicted: 1\n",
      "Row 10079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10070 to 10079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10080 => Predicted: 1\n",
      "Row 10081 => Predicted: 0\n",
      "Row 10082 => Predicted: 1\n",
      "Row 10083 => Predicted: 0\n",
      "Row 10084 => Predicted: 1\n",
      "Row 10085 => Predicted: 1\n",
      "Row 10086 => Predicted: 1\n",
      "Row 10087 => Predicted: 0\n",
      "Row 10088 => Predicted: 0\n",
      "Row 10089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10080 to 10089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10090 => Predicted: 1\n",
      "Row 10091 => Predicted: 1\n",
      "Row 10092 => Predicted: 0\n",
      "Row 10093 => Predicted: 0\n",
      "Row 10094 => Predicted: 1\n",
      "Row 10095 => Predicted: 0\n",
      "Row 10096 => Predicted: 1\n",
      "Row 10097 => Predicted: 1\n",
      "Row 10098 => Predicted: 1\n",
      "Row 10099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10090 to 10099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10100 => Predicted: 0\n",
      "Row 10101 => Predicted: 1\n",
      "Row 10102 => Predicted: 1\n",
      "Row 10103 => Predicted: 0\n",
      "Row 10104 => Predicted: 0\n",
      "Row 10105 => Predicted: 1\n",
      "Row 10106 => Predicted: 0\n",
      "Row 10107 => Predicted: 1\n",
      "Row 10108 => Predicted: 0\n",
      "Row 10109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10100 to 10109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10110 => Predicted: 1\n",
      "Row 10111 => Predicted: 0\n",
      "Row 10112 => Predicted: 1\n",
      "Row 10113 => Predicted: 0\n",
      "Row 10114 => Predicted: 0\n",
      "Row 10115 => Predicted: 1\n",
      "Row 10116 => Predicted: 1\n",
      "Row 10117 => Predicted: 0\n",
      "Row 10118 => Predicted: 1\n",
      "Row 10119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10110 to 10119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10120 => Predicted: 0\n",
      "Row 10121 => Predicted: 0\n",
      "Row 10122 => Predicted: 0\n",
      "Row 10123 => Predicted: 1\n",
      "Row 10124 => Predicted: 0\n",
      "Row 10125 => Predicted: 1\n",
      "Row 10126 => Predicted: 1\n",
      "Row 10127 => Predicted: 1\n",
      "Row 10128 => Predicted: 0\n",
      "Row 10129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10120 to 10129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10130 => Predicted: 1\n",
      "Row 10131 => Predicted: 1\n",
      "Row 10132 => Predicted: 1\n",
      "Row 10133 => Predicted: 1\n",
      "Row 10134 => Predicted: 0\n",
      "Row 10135 => Predicted: 0\n",
      "Row 10136 => Predicted: 1\n",
      "Row 10137 => Predicted: 0\n",
      "Row 10138 => Predicted: 0\n",
      "Row 10139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10130 to 10139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10140 => Predicted: 0\n",
      "Row 10141 => Predicted: 1\n",
      "Row 10142 => Predicted: 1\n",
      "Row 10143 => Predicted: 1\n",
      "Row 10144 => Predicted: 0\n",
      "Row 10145 => Predicted: 0\n",
      "Row 10146 => Predicted: 1\n",
      "Row 10147 => Predicted: 1\n",
      "Row 10148 => Predicted: 0\n",
      "Row 10149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10140 to 10149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10150 => Predicted: 1\n",
      "Row 10151 => Predicted: 0\n",
      "Row 10152 => Predicted: 1\n",
      "Row 10153 => Predicted: 1\n",
      "Row 10154 => Predicted: 1\n",
      "Row 10155 => Predicted: 1\n",
      "Row 10156 => Predicted: 1\n",
      "Row 10157 => Predicted: 0\n",
      "Row 10158 => Predicted: 1\n",
      "Row 10159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10150 to 10159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10160 => Predicted: 1\n",
      "Row 10161 => Predicted: 1\n",
      "Row 10162 => Predicted: 0\n",
      "Row 10163 => Predicted: 1\n",
      "Row 10164 => Predicted: 1\n",
      "Row 10165 => Predicted: 1\n",
      "Row 10166 => Predicted: 1\n",
      "Row 10167 => Predicted: 1\n",
      "Row 10168 => Predicted: 1\n",
      "Row 10169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10160 to 10169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10170 => Predicted: 0\n",
      "Row 10171 => Predicted: 1\n",
      "Row 10172 => Predicted: 1\n",
      "Row 10173 => Predicted: 0\n",
      "Row 10174 => Predicted: 0\n",
      "Row 10175 => Predicted: 0\n",
      "Row 10176 => Predicted: 1\n",
      "Row 10177 => Predicted: 1\n",
      "Row 10178 => Predicted: 1\n",
      "Row 10179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10170 to 10179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10180 => Predicted: 1\n",
      "Row 10181 => Predicted: 0\n",
      "Row 10182 => Predicted: 0\n",
      "Row 10183 => Predicted: 1\n",
      "Row 10184 => Predicted: 1\n",
      "Row 10185 => Predicted: 1\n",
      "Row 10186 => Predicted: 0\n",
      "Row 10187 => Predicted: 1\n",
      "Row 10188 => Predicted: 0\n",
      "Row 10189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10180 to 10189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10190 => Predicted: 0\n",
      "Row 10191 => Predicted: 1\n",
      "Row 10192 => Predicted: 1\n",
      "Row 10193 => Predicted: 1\n",
      "Row 10194 => Predicted: 1\n",
      "Row 10195 => Predicted: 0\n",
      "Row 10196 => Predicted: 1\n",
      "Row 10197 => Predicted: 0\n",
      "Row 10198 => Predicted: 0\n",
      "Row 10199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10190 to 10199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10200 => Predicted: 1\n",
      "Row 10201 => Predicted: 1\n",
      "Row 10202 => Predicted: 0\n",
      "Row 10203 => Predicted: 0\n",
      "Row 10204 => Predicted: 0\n",
      "Row 10205 => Predicted: 0\n",
      "Row 10206 => Predicted: 1\n",
      "Row 10207 => Predicted: 0\n",
      "Row 10208 => Predicted: 1\n",
      "Row 10209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10200 to 10209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10210 => Predicted: 1\n",
      "Row 10211 => Predicted: 0\n",
      "Row 10212 => Predicted: 1\n",
      "Row 10213 => Predicted: 1\n",
      "Row 10214 => Predicted: 0\n",
      "Row 10215 => Predicted: 0\n",
      "Row 10216 => Predicted: 1\n",
      "Row 10217 => Predicted: 1\n",
      "Row 10218 => Predicted: 0\n",
      "Row 10219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10210 to 10219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10220 => Predicted: 1\n",
      "Row 10221 => Predicted: 1\n",
      "Row 10222 => Predicted: 1\n",
      "Row 10223 => Predicted: 0\n",
      "Row 10224 => Predicted: 1\n",
      "Row 10225 => Predicted: 1\n",
      "Row 10226 => Predicted: 1\n",
      "Row 10227 => Predicted: 1\n",
      "Row 10228 => Predicted: 1\n",
      "Row 10229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10220 to 10229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10230 => Predicted: 0\n",
      "Row 10231 => Predicted: 0\n",
      "Row 10232 => Predicted: 0\n",
      "Row 10233 => Predicted: 1\n",
      "Row 10234 => Predicted: 1\n",
      "Row 10235 => Predicted: 0\n",
      "Row 10236 => Predicted: 1\n",
      "Row 10237 => Predicted: 1\n",
      "Row 10238 => Predicted: 0\n",
      "Row 10239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10230 to 10239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10240 => Predicted: 1\n",
      "Row 10241 => Predicted: 1\n",
      "Row 10242 => Predicted: 1\n",
      "Row 10243 => Predicted: 1\n",
      "Row 10244 => Predicted: 0\n",
      "Row 10245 => Predicted: 1\n",
      "Row 10246 => Predicted: 0\n",
      "Row 10247 => Predicted: 0\n",
      "Row 10248 => Predicted: 0\n",
      "Row 10249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10240 to 10249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10250 => Predicted: 0\n",
      "Row 10251 => Predicted: 1\n",
      "Row 10252 => Predicted: 1\n",
      "Row 10253 => Predicted: 0\n",
      "Row 10254 => Predicted: 1\n",
      "Row 10255 => Predicted: 1\n",
      "Row 10256 => Predicted: 1\n",
      "Row 10257 => Predicted: 1\n",
      "Row 10258 => Predicted: 0\n",
      "Row 10259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10250 to 10259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10260 => Predicted: 1\n",
      "Row 10261 => Predicted: 0\n",
      "Row 10262 => Predicted: 1\n",
      "Row 10263 => Predicted: 0\n",
      "Row 10264 => Predicted: 1\n",
      "Row 10265 => Predicted: 1\n",
      "Row 10266 => Predicted: 0\n",
      "Row 10267 => Predicted: 1\n",
      "Row 10268 => Predicted: 0\n",
      "Row 10269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10260 to 10269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10270 => Predicted: 1\n",
      "Row 10271 => Predicted: 0\n",
      "Row 10272 => Predicted: 1\n",
      "Row 10273 => Predicted: 1\n",
      "Row 10274 => Predicted: 0\n",
      "Row 10275 => Predicted: 1\n",
      "Row 10276 => Predicted: 1\n",
      "Row 10277 => Predicted: 1\n",
      "Row 10278 => Predicted: 1\n",
      "Row 10279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10270 to 10279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10280 => Predicted: 1\n",
      "Row 10281 => Predicted: 1\n",
      "Row 10282 => Predicted: 0\n",
      "Row 10283 => Predicted: 1\n",
      "Row 10284 => Predicted: 1\n",
      "Row 10285 => Predicted: 1\n",
      "Row 10286 => Predicted: 1\n",
      "Row 10287 => Predicted: 1\n",
      "Row 10288 => Predicted: 1\n",
      "Row 10289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10280 to 10289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10290 => Predicted: 0\n",
      "Row 10291 => Predicted: 1\n",
      "Row 10292 => Predicted: 0\n",
      "Row 10293 => Predicted: 1\n",
      "Row 10294 => Predicted: 0\n",
      "Row 10295 => Predicted: 1\n",
      "Row 10296 => Predicted: 1\n",
      "Row 10297 => Predicted: 0\n",
      "Row 10298 => Predicted: 1\n",
      "Row 10299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10290 to 10299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10300 => Predicted: 1\n",
      "Row 10301 => Predicted: 1\n",
      "Row 10302 => Predicted: 0\n",
      "Row 10303 => Predicted: 1\n",
      "Row 10304 => Predicted: 1\n",
      "Row 10305 => Predicted: 0\n",
      "Row 10306 => Predicted: 1\n",
      "Row 10307 => Predicted: 1\n",
      "Row 10308 => Predicted: 1\n",
      "Row 10309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10300 to 10309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10310 => Predicted: 1\n",
      "Row 10311 => Predicted: 1\n",
      "Row 10312 => Predicted: 1\n",
      "Row 10313 => Predicted: 1\n",
      "Row 10314 => Predicted: 1\n",
      "Row 10315 => Predicted: 1\n",
      "Row 10316 => Predicted: 1\n",
      "Row 10317 => Predicted: 1\n",
      "Row 10318 => Predicted: 0\n",
      "Row 10319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10310 to 10319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10320 => Predicted: 0\n",
      "Row 10321 => Predicted: 1\n",
      "Row 10322 => Predicted: 1\n",
      "Row 10323 => Predicted: 0\n",
      "Row 10324 => Predicted: 1\n",
      "Row 10325 => Predicted: 1\n",
      "Row 10326 => Predicted: 0\n",
      "Row 10327 => Predicted: 1\n",
      "Row 10328 => Predicted: 0\n",
      "Row 10329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10320 to 10329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10330 => Predicted: 1\n",
      "Row 10331 => Predicted: 0\n",
      "Row 10332 => Predicted: 1\n",
      "Row 10333 => Predicted: 1\n",
      "Row 10334 => Predicted: 1\n",
      "Row 10335 => Predicted: 1\n",
      "Row 10336 => Predicted: 0\n",
      "Row 10337 => Predicted: 1\n",
      "Row 10338 => Predicted: 1\n",
      "Row 10339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10330 to 10339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10340 => Predicted: 0\n",
      "Row 10341 => Predicted: 1\n",
      "Row 10342 => Predicted: 1\n",
      "Row 10343 => Predicted: 1\n",
      "Row 10344 => Predicted: 0\n",
      "Row 10345 => Predicted: 1\n",
      "Row 10346 => Predicted: 0\n",
      "Row 10347 => Predicted: 1\n",
      "Row 10348 => Predicted: 0\n",
      "Row 10349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10340 to 10349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10350 => Predicted: 1\n",
      "Row 10351 => Predicted: 1\n",
      "Row 10352 => Predicted: 1\n",
      "Row 10353 => Predicted: 1\n",
      "Row 10354 => Predicted: 0\n",
      "Row 10355 => Predicted: 0\n",
      "Row 10356 => Predicted: 0\n",
      "Row 10357 => Predicted: 0\n",
      "Row 10358 => Predicted: 1\n",
      "Row 10359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10350 to 10359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10360 => Predicted: 1\n",
      "Row 10361 => Predicted: 1\n",
      "Row 10362 => Predicted: 1\n",
      "Row 10363 => Predicted: 0\n",
      "Row 10364 => Predicted: 1\n",
      "Row 10365 => Predicted: 1\n",
      "Row 10366 => Predicted: 1\n",
      "Row 10367 => Predicted: 1\n",
      "Row 10368 => Predicted: 1\n",
      "Row 10369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10360 to 10369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10370 => Predicted: 1\n",
      "Row 10371 => Predicted: 1\n",
      "Row 10372 => Predicted: 1\n",
      "Row 10373 => Predicted: 1\n",
      "Row 10374 => Predicted: 0\n",
      "Row 10375 => Predicted: 1\n",
      "Row 10376 => Predicted: 1\n",
      "Row 10377 => Predicted: 0\n",
      "Row 10378 => Predicted: 0\n",
      "Row 10379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10370 to 10379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10380 => Predicted: 1\n",
      "Row 10381 => Predicted: 0\n",
      "Row 10382 => Predicted: 0\n",
      "Row 10383 => Predicted: 1\n",
      "Row 10384 => Predicted: 0\n",
      "Row 10385 => Predicted: 1\n",
      "Row 10386 => Predicted: 1\n",
      "Row 10387 => Predicted: 0\n",
      "Row 10388 => Predicted: 1\n",
      "Row 10389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10380 to 10389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10390 => Predicted: 0\n",
      "Row 10391 => Predicted: 1\n",
      "Row 10392 => Predicted: 0\n",
      "Row 10393 => Predicted: 1\n",
      "Row 10394 => Predicted: 1\n",
      "Row 10395 => Predicted: 1\n",
      "Row 10396 => Predicted: 1\n",
      "Row 10397 => Predicted: 1\n",
      "Row 10398 => Predicted: 0\n",
      "Row 10399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10390 to 10399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10400 => Predicted: 1\n",
      "Row 10401 => Predicted: 1\n",
      "Row 10402 => Predicted: 0\n",
      "Row 10403 => Predicted: 0\n",
      "Row 10404 => Predicted: 0\n",
      "Row 10405 => Predicted: 1\n",
      "Row 10406 => Predicted: 1\n",
      "Row 10407 => Predicted: 0\n",
      "Row 10408 => Predicted: 0\n",
      "Row 10409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10400 to 10409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10410 => Predicted: 1\n",
      "Row 10411 => Predicted: 1\n",
      "Row 10412 => Predicted: 1\n",
      "Row 10413 => Predicted: 1\n",
      "Row 10414 => Predicted: 0\n",
      "Row 10415 => Predicted: 0\n",
      "Row 10416 => Predicted: 0\n",
      "Row 10417 => Predicted: 1\n",
      "Row 10418 => Predicted: 1\n",
      "Row 10419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10410 to 10419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10420 => Predicted: 1\n",
      "Row 10421 => Predicted: 1\n",
      "Row 10422 => Predicted: 0\n",
      "Row 10423 => Predicted: 0\n",
      "Row 10424 => Predicted: 1\n",
      "Row 10425 => Predicted: 0\n",
      "Row 10426 => Predicted: 0\n",
      "Row 10427 => Predicted: 1\n",
      "Row 10428 => Predicted: 0\n",
      "Row 10429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10420 to 10429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10430 => Predicted: 1\n",
      "Row 10431 => Predicted: 0\n",
      "Row 10432 => Predicted: 0\n",
      "Row 10433 => Predicted: 1\n",
      "Row 10434 => Predicted: 0\n",
      "Row 10435 => Predicted: 1\n",
      "Row 10436 => Predicted: 1\n",
      "Row 10437 => Predicted: 0\n",
      "Row 10438 => Predicted: 0\n",
      "Row 10439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10430 to 10439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10440 => Predicted: 0\n",
      "Row 10441 => Predicted: 0\n",
      "Row 10442 => Predicted: 0\n",
      "Row 10443 => Predicted: 1\n",
      "Row 10444 => Predicted: 0\n",
      "Row 10445 => Predicted: 1\n",
      "Row 10446 => Predicted: 0\n",
      "Row 10447 => Predicted: 0\n",
      "Row 10448 => Predicted: 1\n",
      "Row 10449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10440 to 10449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10450 => Predicted: 1\n",
      "Row 10451 => Predicted: 0\n",
      "Row 10452 => Predicted: 0\n",
      "Row 10453 => Predicted: 0\n",
      "Row 10454 => Predicted: 1\n",
      "Row 10455 => Predicted: 1\n",
      "Row 10456 => Predicted: 0\n",
      "Row 10457 => Predicted: 1\n",
      "Row 10458 => Predicted: 1\n",
      "Row 10459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10450 to 10459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10460 => Predicted: 1\n",
      "Row 10461 => Predicted: 0\n",
      "Row 10462 => Predicted: 0\n",
      "Row 10463 => Predicted: 1\n",
      "Row 10464 => Predicted: 1\n",
      "Row 10465 => Predicted: 0\n",
      "Row 10466 => Predicted: 0\n",
      "Row 10467 => Predicted: 1\n",
      "Row 10468 => Predicted: 0\n",
      "Row 10469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10460 to 10469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10470 => Predicted: 1\n",
      "Row 10471 => Predicted: 1\n",
      "Row 10472 => Predicted: 0\n",
      "Row 10473 => Predicted: 1\n",
      "Row 10474 => Predicted: 0\n",
      "Row 10475 => Predicted: 1\n",
      "Row 10476 => Predicted: 0\n",
      "Row 10477 => Predicted: 0\n",
      "Row 10478 => Predicted: 0\n",
      "Row 10479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10470 to 10479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10480 => Predicted: 1\n",
      "Row 10481 => Predicted: 1\n",
      "Row 10482 => Predicted: 1\n",
      "Row 10483 => Predicted: 0\n",
      "Row 10484 => Predicted: 0\n",
      "Row 10485 => Predicted: 0\n",
      "Row 10486 => Predicted: 0\n",
      "Row 10487 => Predicted: 1\n",
      "Row 10488 => Predicted: 0\n",
      "Row 10489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10480 to 10489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10490 => Predicted: 0\n",
      "Row 10491 => Predicted: 1\n",
      "Row 10492 => Predicted: 1\n",
      "Row 10493 => Predicted: 1\n",
      "Row 10494 => Predicted: 0\n",
      "Row 10495 => Predicted: 1\n",
      "Row 10496 => Predicted: 1\n",
      "Row 10497 => Predicted: 0\n",
      "Row 10498 => Predicted: 1\n",
      "Row 10499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10490 to 10499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10500 => Predicted: 0\n",
      "Row 10501 => Predicted: 1\n",
      "Row 10502 => Predicted: 1\n",
      "Row 10503 => Predicted: 1\n",
      "Row 10504 => Predicted: 0\n",
      "Row 10505 => Predicted: 0\n",
      "Row 10506 => Predicted: 0\n",
      "Row 10507 => Predicted: 1\n",
      "Row 10508 => Predicted: 1\n",
      "Row 10509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10500 to 10509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10510 => Predicted: 1\n",
      "Row 10511 => Predicted: 0\n",
      "Row 10512 => Predicted: 0\n",
      "Row 10513 => Predicted: 0\n",
      "Row 10514 => Predicted: 1\n",
      "Row 10515 => Predicted: 0\n",
      "Row 10516 => Predicted: 0\n",
      "Row 10517 => Predicted: 0\n",
      "Row 10518 => Predicted: 0\n",
      "Row 10519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10510 to 10519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10520 => Predicted: 0\n",
      "Row 10521 => Predicted: 0\n",
      "Row 10522 => Predicted: 1\n",
      "Row 10523 => Predicted: 1\n",
      "Row 10524 => Predicted: 1\n",
      "Row 10525 => Predicted: 0\n",
      "Row 10526 => Predicted: 0\n",
      "Row 10527 => Predicted: 1\n",
      "Row 10528 => Predicted: 0\n",
      "Row 10529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10520 to 10529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10530 => Predicted: 0\n",
      "Row 10531 => Predicted: 1\n",
      "Row 10532 => Predicted: 0\n",
      "Row 10533 => Predicted: 1\n",
      "Row 10534 => Predicted: 0\n",
      "Row 10535 => Predicted: 0\n",
      "Row 10536 => Predicted: 1\n",
      "Row 10537 => Predicted: 0\n",
      "Row 10538 => Predicted: 1\n",
      "Row 10539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10530 to 10539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10540 => Predicted: 0\n",
      "Row 10541 => Predicted: 0\n",
      "Row 10542 => Predicted: 1\n",
      "Row 10543 => Predicted: 0\n",
      "Row 10544 => Predicted: 1\n",
      "Row 10545 => Predicted: 1\n",
      "Row 10546 => Predicted: 1\n",
      "Row 10547 => Predicted: 0\n",
      "Row 10548 => Predicted: 1\n",
      "Row 10549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10540 to 10549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10550 => Predicted: 0\n",
      "Row 10551 => Predicted: 0\n",
      "Row 10552 => Predicted: 1\n",
      "Row 10553 => Predicted: 1\n",
      "Row 10554 => Predicted: 1\n",
      "Row 10555 => Predicted: 0\n",
      "Row 10556 => Predicted: 0\n",
      "Row 10557 => Predicted: 1\n",
      "Row 10558 => Predicted: 1\n",
      "Row 10559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10550 to 10559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10560 => Predicted: 1\n",
      "Row 10561 => Predicted: 0\n",
      "Row 10562 => Predicted: 0\n",
      "Row 10563 => Predicted: 1\n",
      "Row 10564 => Predicted: 0\n",
      "Row 10565 => Predicted: 1\n",
      "Row 10566 => Predicted: 0\n",
      "Row 10567 => Predicted: 0\n",
      "Row 10568 => Predicted: 1\n",
      "Row 10569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10560 to 10569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10570 => Predicted: 1\n",
      "Row 10571 => Predicted: 0\n",
      "Row 10572 => Predicted: 0\n",
      "Row 10573 => Predicted: 1\n",
      "Row 10574 => Predicted: 0\n",
      "Row 10575 => Predicted: 0\n",
      "Row 10576 => Predicted: 0\n",
      "Row 10577 => Predicted: 1\n",
      "Row 10578 => Predicted: 0\n",
      "Row 10579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10570 to 10579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10580 => Predicted: 1\n",
      "Row 10581 => Predicted: 0\n",
      "Row 10582 => Predicted: 1\n",
      "Row 10583 => Predicted: 1\n",
      "Row 10584 => Predicted: 1\n",
      "Row 10585 => Predicted: 0\n",
      "Row 10586 => Predicted: 0\n",
      "Row 10587 => Predicted: 1\n",
      "Row 10588 => Predicted: 1\n",
      "Row 10589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10580 to 10589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10590 => Predicted: 1\n",
      "Row 10591 => Predicted: 1\n",
      "Row 10592 => Predicted: 1\n",
      "Row 10593 => Predicted: 0\n",
      "Row 10594 => Predicted: 0\n",
      "Row 10595 => Predicted: 0\n",
      "Row 10596 => Predicted: 1\n",
      "Row 10597 => Predicted: 1\n",
      "Row 10598 => Predicted: 1\n",
      "Row 10599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10590 to 10599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10600 => Predicted: 0\n",
      "Row 10601 => Predicted: 0\n",
      "Row 10602 => Predicted: 0\n",
      "Row 10603 => Predicted: 1\n",
      "Row 10604 => Predicted: 0\n",
      "Row 10605 => Predicted: 0\n",
      "Row 10606 => Predicted: 1\n",
      "Row 10607 => Predicted: 0\n",
      "Row 10608 => Predicted: 0\n",
      "Row 10609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10600 to 10609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10610 => Predicted: 1\n",
      "Row 10611 => Predicted: 1\n",
      "Row 10612 => Predicted: 0\n",
      "Row 10613 => Predicted: 0\n",
      "Row 10614 => Predicted: 1\n",
      "Row 10615 => Predicted: 0\n",
      "Row 10616 => Predicted: 1\n",
      "Row 10617 => Predicted: 0\n",
      "Row 10618 => Predicted: 1\n",
      "Row 10619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10610 to 10619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10620 => Predicted: 1\n",
      "Row 10621 => Predicted: 0\n",
      "Row 10622 => Predicted: 0\n",
      "Row 10623 => Predicted: 1\n",
      "Row 10624 => Predicted: 1\n",
      "Row 10625 => Predicted: 0\n",
      "Row 10626 => Predicted: 0\n",
      "Row 10627 => Predicted: 0\n",
      "Row 10628 => Predicted: 0\n",
      "Row 10629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10620 to 10629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10630 => Predicted: 1\n",
      "Row 10631 => Predicted: 1\n",
      "Row 10632 => Predicted: 0\n",
      "Row 10633 => Predicted: 1\n",
      "Row 10634 => Predicted: 0\n",
      "Row 10635 => Predicted: 1\n",
      "Row 10636 => Predicted: 1\n",
      "Row 10637 => Predicted: 1\n",
      "Row 10638 => Predicted: 0\n",
      "Row 10639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10630 to 10639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10640 => Predicted: 1\n",
      "Row 10641 => Predicted: 0\n",
      "Row 10642 => Predicted: 1\n",
      "Row 10643 => Predicted: 1\n",
      "Row 10644 => Predicted: 1\n",
      "Row 10645 => Predicted: 1\n",
      "Row 10646 => Predicted: 0\n",
      "Row 10647 => Predicted: 0\n",
      "Row 10648 => Predicted: 0\n",
      "Row 10649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10640 to 10649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10650 => Predicted: 0\n",
      "Row 10651 => Predicted: 1\n",
      "Row 10652 => Predicted: 0\n",
      "Row 10653 => Predicted: 0\n",
      "Row 10654 => Predicted: 0\n",
      "Row 10655 => Predicted: 0\n",
      "Row 10656 => Predicted: 1\n",
      "Row 10657 => Predicted: 0\n",
      "Row 10658 => Predicted: 1\n",
      "Row 10659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10650 to 10659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10660 => Predicted: 1\n",
      "Row 10661 => Predicted: 1\n",
      "Row 10662 => Predicted: 0\n",
      "Row 10663 => Predicted: 0\n",
      "Row 10664 => Predicted: 1\n",
      "Row 10665 => Predicted: 0\n",
      "Row 10666 => Predicted: 1\n",
      "Row 10667 => Predicted: 0\n",
      "Row 10668 => Predicted: 1\n",
      "Row 10669 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10660 to 10669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10670 => Predicted: 1\n",
      "Row 10671 => Predicted: 0\n",
      "Row 10672 => Predicted: 0\n",
      "Row 10673 => Predicted: 0\n",
      "Row 10674 => Predicted: 0\n",
      "Row 10675 => Predicted: 0\n",
      "Row 10676 => Predicted: 0\n",
      "Row 10677 => Predicted: 1\n",
      "Row 10678 => Predicted: 1\n",
      "Row 10679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10670 to 10679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10680 => Predicted: 0\n",
      "Row 10681 => Predicted: 1\n",
      "Row 10682 => Predicted: 0\n",
      "Row 10683 => Predicted: 0\n",
      "Row 10684 => Predicted: 1\n",
      "Row 10685 => Predicted: 1\n",
      "Row 10686 => Predicted: 1\n",
      "Row 10687 => Predicted: 1\n",
      "Row 10688 => Predicted: 1\n",
      "Row 10689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10680 to 10689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10690 => Predicted: 0\n",
      "Row 10691 => Predicted: 1\n",
      "Row 10692 => Predicted: 1\n",
      "Row 10693 => Predicted: 1\n",
      "Row 10694 => Predicted: 0\n",
      "Row 10695 => Predicted: 1\n",
      "Row 10696 => Predicted: 1\n",
      "Row 10697 => Predicted: 1\n",
      "Row 10698 => Predicted: 1\n",
      "Row 10699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10690 to 10699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10700 => Predicted: 0\n",
      "Row 10701 => Predicted: 0\n",
      "Row 10702 => Predicted: 0\n",
      "Row 10703 => Predicted: 1\n",
      "Row 10704 => Predicted: 1\n",
      "Row 10705 => Predicted: 0\n",
      "Row 10706 => Predicted: 1\n",
      "Row 10707 => Predicted: 0\n",
      "Row 10708 => Predicted: 0\n",
      "Row 10709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10700 to 10709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10710 => Predicted: 1\n",
      "Row 10711 => Predicted: 1\n",
      "Row 10712 => Predicted: 1\n",
      "Row 10713 => Predicted: 0\n",
      "Row 10714 => Predicted: 0\n",
      "Row 10715 => Predicted: 1\n",
      "Row 10716 => Predicted: 0\n",
      "Row 10717 => Predicted: 0\n",
      "Row 10718 => Predicted: 0\n",
      "Row 10719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10710 to 10719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10720 => Predicted: 1\n",
      "Row 10721 => Predicted: 0\n",
      "Row 10722 => Predicted: 1\n",
      "Row 10723 => Predicted: 1\n",
      "Row 10724 => Predicted: 0\n",
      "Row 10725 => Predicted: 0\n",
      "Row 10726 => Predicted: 1\n",
      "Row 10727 => Predicted: 0\n",
      "Row 10728 => Predicted: 1\n",
      "Row 10729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10720 to 10729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10730 => Predicted: 1\n",
      "Row 10731 => Predicted: 1\n",
      "Row 10732 => Predicted: 1\n",
      "Row 10733 => Predicted: 1\n",
      "Row 10734 => Predicted: 0\n",
      "Row 10735 => Predicted: 1\n",
      "Row 10736 => Predicted: 1\n",
      "Row 10737 => Predicted: 1\n",
      "Row 10738 => Predicted: 0\n",
      "Row 10739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10730 to 10739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10740 => Predicted: 1\n",
      "Row 10741 => Predicted: 0\n",
      "Row 10742 => Predicted: 1\n",
      "Row 10743 => Predicted: 1\n",
      "Row 10744 => Predicted: 1\n",
      "Row 10745 => Predicted: 0\n",
      "Row 10746 => Predicted: 0\n",
      "Row 10747 => Predicted: 1\n",
      "Row 10748 => Predicted: 0\n",
      "Row 10749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10740 to 10749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10750 => Predicted: 0\n",
      "Row 10751 => Predicted: 0\n",
      "Row 10752 => Predicted: 1\n",
      "Row 10753 => Predicted: 0\n",
      "Row 10754 => Predicted: 1\n",
      "Row 10755 => Predicted: 0\n",
      "Row 10756 => Predicted: 1\n",
      "Row 10757 => Predicted: 1\n",
      "Row 10758 => Predicted: 0\n",
      "Row 10759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10750 to 10759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10760 => Predicted: 0\n",
      "Row 10761 => Predicted: 1\n",
      "Row 10762 => Predicted: 1\n",
      "Row 10763 => Predicted: 0\n",
      "Row 10764 => Predicted: 0\n",
      "Row 10765 => Predicted: 0\n",
      "Row 10766 => Predicted: 0\n",
      "Row 10767 => Predicted: 1\n",
      "Row 10768 => Predicted: 1\n",
      "Row 10769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10760 to 10769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10770 => Predicted: 0\n",
      "Row 10771 => Predicted: 0\n",
      "Row 10772 => Predicted: 1\n",
      "Row 10773 => Predicted: 1\n",
      "Row 10774 => Predicted: 0\n",
      "Row 10775 => Predicted: 0\n",
      "Row 10776 => Predicted: 1\n",
      "Row 10777 => Predicted: 0\n",
      "Row 10778 => Predicted: 1\n",
      "Row 10779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10770 to 10779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10780 => Predicted: 0\n",
      "Row 10781 => Predicted: 1\n",
      "Row 10782 => Predicted: 0\n",
      "Row 10783 => Predicted: 1\n",
      "Row 10784 => Predicted: 1\n",
      "Row 10785 => Predicted: 0\n",
      "Row 10786 => Predicted: 1\n",
      "Row 10787 => Predicted: 0\n",
      "Row 10788 => Predicted: 1\n",
      "Row 10789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10780 to 10789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10790 => Predicted: 1\n",
      "Row 10791 => Predicted: 1\n",
      "Row 10792 => Predicted: 1\n",
      "Row 10793 => Predicted: 1\n",
      "Row 10794 => Predicted: 1\n",
      "Row 10795 => Predicted: 1\n",
      "Row 10796 => Predicted: 1\n",
      "Row 10797 => Predicted: 0\n",
      "Row 10798 => Predicted: 1\n",
      "Row 10799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10790 to 10799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10800 => Predicted: 1\n",
      "Row 10801 => Predicted: 1\n",
      "Row 10802 => Predicted: 1\n",
      "Row 10803 => Predicted: 0\n",
      "Row 10804 => Predicted: 1\n",
      "Row 10805 => Predicted: 0\n",
      "Row 10806 => Predicted: 0\n",
      "Row 10807 => Predicted: 0\n",
      "Row 10808 => Predicted: 1\n",
      "Row 10809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10800 to 10809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10810 => Predicted: 1\n",
      "Row 10811 => Predicted: 1\n",
      "Row 10812 => Predicted: 1\n",
      "Row 10813 => Predicted: 1\n",
      "Row 10814 => Predicted: 0\n",
      "Row 10815 => Predicted: 1\n",
      "Row 10816 => Predicted: 1\n",
      "Row 10817 => Predicted: 1\n",
      "Row 10818 => Predicted: 1\n",
      "Row 10819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10810 to 10819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10820 => Predicted: 0\n",
      "Row 10821 => Predicted: 1\n",
      "Row 10822 => Predicted: 1\n",
      "Row 10823 => Predicted: 0\n",
      "Row 10824 => Predicted: 0\n",
      "Row 10825 => Predicted: 0\n",
      "Row 10826 => Predicted: 0\n",
      "Row 10827 => Predicted: 1\n",
      "Row 10828 => Predicted: 0\n",
      "Row 10829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10820 to 10829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10830 => Predicted: 0\n",
      "Row 10831 => Predicted: 1\n",
      "Row 10832 => Predicted: 1\n",
      "Row 10833 => Predicted: 1\n",
      "Row 10834 => Predicted: 1\n",
      "Row 10835 => Predicted: 1\n",
      "Row 10836 => Predicted: 0\n",
      "Row 10837 => Predicted: 0\n",
      "Row 10838 => Predicted: 1\n",
      "Row 10839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10830 to 10839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10840 => Predicted: 1\n",
      "Row 10841 => Predicted: 0\n",
      "Row 10842 => Predicted: 1\n",
      "Row 10843 => Predicted: 0\n",
      "Row 10844 => Predicted: 0\n",
      "Row 10845 => Predicted: 0\n",
      "Row 10846 => Predicted: 1\n",
      "Row 10847 => Predicted: 0\n",
      "Row 10848 => Predicted: 1\n",
      "Row 10849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10840 to 10849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10850 => Predicted: 0\n",
      "Row 10851 => Predicted: 0\n",
      "Row 10852 => Predicted: 1\n",
      "Row 10853 => Predicted: 1\n",
      "Row 10854 => Predicted: 1\n",
      "Row 10855 => Predicted: 1\n",
      "Row 10856 => Predicted: 0\n",
      "Row 10857 => Predicted: 1\n",
      "Row 10858 => Predicted: 1\n",
      "Row 10859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10850 to 10859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10860 => Predicted: 1\n",
      "Row 10861 => Predicted: 1\n",
      "Row 10862 => Predicted: 0\n",
      "Row 10863 => Predicted: 0\n",
      "Row 10864 => Predicted: 1\n",
      "Row 10865 => Predicted: 1\n",
      "Row 10866 => Predicted: 1\n",
      "Row 10867 => Predicted: 0\n",
      "Row 10868 => Predicted: 1\n",
      "Row 10869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10860 to 10869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10870 => Predicted: 0\n",
      "Row 10871 => Predicted: 0\n",
      "Row 10872 => Predicted: 0\n",
      "Row 10873 => Predicted: 0\n",
      "Row 10874 => Predicted: 1\n",
      "Row 10875 => Predicted: 0\n",
      "Row 10876 => Predicted: 1\n",
      "Row 10877 => Predicted: 0\n",
      "Row 10878 => Predicted: 1\n",
      "Row 10879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10870 to 10879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10880 => Predicted: 0\n",
      "Row 10881 => Predicted: 1\n",
      "Row 10882 => Predicted: 0\n",
      "Row 10883 => Predicted: 0\n",
      "Row 10884 => Predicted: 1\n",
      "Row 10885 => Predicted: 1\n",
      "Row 10886 => Predicted: 0\n",
      "Row 10887 => Predicted: 1\n",
      "Row 10888 => Predicted: 1\n",
      "Row 10889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10880 to 10889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10890 => Predicted: 0\n",
      "Row 10891 => Predicted: 1\n",
      "Row 10892 => Predicted: 1\n",
      "Row 10893 => Predicted: 1\n",
      "Row 10894 => Predicted: 0\n",
      "Row 10895 => Predicted: 0\n",
      "Row 10896 => Predicted: 0\n",
      "Row 10897 => Predicted: 0\n",
      "Row 10898 => Predicted: 0\n",
      "Row 10899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10890 to 10899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10900 => Predicted: 1\n",
      "Row 10901 => Predicted: 0\n",
      "Row 10902 => Predicted: 0\n",
      "Row 10903 => Predicted: 0\n",
      "Row 10904 => Predicted: 0\n",
      "Row 10905 => Predicted: 0\n",
      "Row 10906 => Predicted: 0\n",
      "Row 10907 => Predicted: 1\n",
      "Row 10908 => Predicted: 0\n",
      "Row 10909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10900 to 10909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10910 => Predicted: 0\n",
      "Row 10911 => Predicted: 1\n",
      "Row 10912 => Predicted: 1\n",
      "Row 10913 => Predicted: 1\n",
      "Row 10914 => Predicted: 1\n",
      "Row 10915 => Predicted: 0\n",
      "Row 10916 => Predicted: 1\n",
      "Row 10917 => Predicted: 0\n",
      "Row 10918 => Predicted: 0\n",
      "Row 10919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10910 to 10919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10920 => Predicted: 0\n",
      "Row 10921 => Predicted: 1\n",
      "Row 10922 => Predicted: 0\n",
      "Row 10923 => Predicted: 0\n",
      "Row 10924 => Predicted: 0\n",
      "Row 10925 => Predicted: 0\n",
      "Row 10926 => Predicted: 1\n",
      "Row 10927 => Predicted: 1\n",
      "Row 10928 => Predicted: 0\n",
      "Row 10929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10920 to 10929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10930 => Predicted: 0\n",
      "Row 10931 => Predicted: 0\n",
      "Row 10932 => Predicted: 1\n",
      "Row 10933 => Predicted: 0\n",
      "Row 10934 => Predicted: 0\n",
      "Row 10935 => Predicted: 0\n",
      "Row 10936 => Predicted: 0\n",
      "Row 10937 => Predicted: 1\n",
      "Row 10938 => Predicted: 0\n",
      "Row 10939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10930 to 10939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10940 => Predicted: 0\n",
      "Row 10941 => Predicted: 1\n",
      "Row 10942 => Predicted: 1\n",
      "Row 10943 => Predicted: 0\n",
      "Row 10944 => Predicted: 0\n",
      "Row 10945 => Predicted: 1\n",
      "Row 10946 => Predicted: 0\n",
      "Row 10947 => Predicted: 1\n",
      "Row 10948 => Predicted: 1\n",
      "Row 10949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10940 to 10949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10950 => Predicted: 1\n",
      "Row 10951 => Predicted: 1\n",
      "Row 10952 => Predicted: 1\n",
      "Row 10953 => Predicted: 1\n",
      "Row 10954 => Predicted: 1\n",
      "Row 10955 => Predicted: 1\n",
      "Row 10956 => Predicted: 1\n",
      "Row 10957 => Predicted: 1\n",
      "Row 10958 => Predicted: 1\n",
      "Row 10959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10950 to 10959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10960 => Predicted: 0\n",
      "Row 10961 => Predicted: 0\n",
      "Row 10962 => Predicted: 1\n",
      "Row 10963 => Predicted: 1\n",
      "Row 10964 => Predicted: 0\n",
      "Row 10965 => Predicted: 1\n",
      "Row 10966 => Predicted: 0\n",
      "Row 10967 => Predicted: 0\n",
      "Row 10968 => Predicted: 1\n",
      "Row 10969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 10960 to 10969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10970 => Predicted: 0\n",
      "Row 10971 => Predicted: 1\n",
      "Row 10972 => Predicted: 1\n",
      "Row 10973 => Predicted: 1\n",
      "Row 10974 => Predicted: 0\n",
      "Row 10975 => Predicted: 0\n",
      "Row 10976 => Predicted: 1\n",
      "Row 10977 => Predicted: 0\n",
      "Row 10978 => Predicted: 1\n",
      "Row 10979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10970 to 10979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10980 => Predicted: 1\n",
      "Row 10981 => Predicted: 0\n",
      "Row 10982 => Predicted: 0\n",
      "Row 10983 => Predicted: 0\n",
      "Row 10984 => Predicted: 0\n",
      "Row 10985 => Predicted: 0\n",
      "Row 10986 => Predicted: 0\n",
      "Row 10987 => Predicted: 0\n",
      "Row 10988 => Predicted: 1\n",
      "Row 10989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10980 to 10989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10990 => Predicted: 0\n",
      "Row 10991 => Predicted: 0\n",
      "Row 10992 => Predicted: 1\n",
      "Row 10993 => Predicted: 1\n",
      "Row 10994 => Predicted: 1\n",
      "Row 10995 => Predicted: 1\n",
      "Row 10996 => Predicted: 1\n",
      "Row 10997 => Predicted: 1\n",
      "Row 10998 => Predicted: 1\n",
      "Row 10999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 10990 to 10999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11000 => Predicted: 1\n",
      "Row 11001 => Predicted: 0\n",
      "Row 11002 => Predicted: 1\n",
      "Row 11003 => Predicted: 0\n",
      "Row 11004 => Predicted: 0\n",
      "Row 11005 => Predicted: 1\n",
      "Row 11006 => Predicted: 0\n",
      "Row 11007 => Predicted: 0\n",
      "Row 11008 => Predicted: 0\n",
      "Row 11009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11000 to 11009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11010 => Predicted: 1\n",
      "Row 11011 => Predicted: 1\n",
      "Row 11012 => Predicted: 0\n",
      "Row 11013 => Predicted: 1\n",
      "Row 11014 => Predicted: 0\n",
      "Row 11015 => Predicted: 1\n",
      "Row 11016 => Predicted: 0\n",
      "Row 11017 => Predicted: 0\n",
      "Row 11018 => Predicted: 0\n",
      "Row 11019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11010 to 11019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11020 => Predicted: 1\n",
      "Row 11021 => Predicted: 0\n",
      "Row 11022 => Predicted: 0\n",
      "Row 11023 => Predicted: 0\n",
      "Row 11024 => Predicted: 0\n",
      "Row 11025 => Predicted: 0\n",
      "Row 11026 => Predicted: 1\n",
      "Row 11027 => Predicted: 0\n",
      "Row 11028 => Predicted: 0\n",
      "Row 11029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11020 to 11029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11030 => Predicted: 0\n",
      "Row 11031 => Predicted: 0\n",
      "Row 11032 => Predicted: 1\n",
      "Row 11033 => Predicted: 0\n",
      "Row 11034 => Predicted: 1\n",
      "Row 11035 => Predicted: 1\n",
      "Row 11036 => Predicted: 0\n",
      "Row 11037 => Predicted: 0\n",
      "Row 11038 => Predicted: 1\n",
      "Row 11039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11030 to 11039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11040 => Predicted: 0\n",
      "Row 11041 => Predicted: 1\n",
      "Row 11042 => Predicted: 0\n",
      "Row 11043 => Predicted: 0\n",
      "Row 11044 => Predicted: 1\n",
      "Row 11045 => Predicted: 1\n",
      "Row 11046 => Predicted: 1\n",
      "Row 11047 => Predicted: 0\n",
      "Row 11048 => Predicted: 1\n",
      "Row 11049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11040 to 11049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11050 => Predicted: 0\n",
      "Row 11051 => Predicted: 0\n",
      "Row 11052 => Predicted: 0\n",
      "Row 11053 => Predicted: 0\n",
      "Row 11054 => Predicted: 1\n",
      "Row 11055 => Predicted: 0\n",
      "Row 11056 => Predicted: 1\n",
      "Row 11057 => Predicted: 0\n",
      "Row 11058 => Predicted: 1\n",
      "Row 11059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11050 to 11059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11060 => Predicted: 1\n",
      "Row 11061 => Predicted: 0\n",
      "Row 11062 => Predicted: 1\n",
      "Row 11063 => Predicted: 1\n",
      "Row 11064 => Predicted: 1\n",
      "Row 11065 => Predicted: 0\n",
      "Row 11066 => Predicted: 1\n",
      "Row 11067 => Predicted: 0\n",
      "Row 11068 => Predicted: 0\n",
      "Row 11069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11060 to 11069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11070 => Predicted: 0\n",
      "Row 11071 => Predicted: 0\n",
      "Row 11072 => Predicted: 1\n",
      "Row 11073 => Predicted: 0\n",
      "Row 11074 => Predicted: 1\n",
      "Row 11075 => Predicted: 1\n",
      "Row 11076 => Predicted: 1\n",
      "Row 11077 => Predicted: 0\n",
      "Row 11078 => Predicted: 0\n",
      "Row 11079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11070 to 11079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11080 => Predicted: 1\n",
      "Row 11081 => Predicted: 0\n",
      "Row 11082 => Predicted: 0\n",
      "Row 11083 => Predicted: 1\n",
      "Row 11084 => Predicted: 0\n",
      "Row 11085 => Predicted: 1\n",
      "Row 11086 => Predicted: 0\n",
      "Row 11087 => Predicted: 1\n",
      "Row 11088 => Predicted: 0\n",
      "Row 11089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11080 to 11089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11090 => Predicted: 1\n",
      "Row 11091 => Predicted: 1\n",
      "Row 11092 => Predicted: 1\n",
      "Row 11093 => Predicted: 1\n",
      "Row 11094 => Predicted: 0\n",
      "Row 11095 => Predicted: 0\n",
      "Row 11096 => Predicted: 1\n",
      "Row 11097 => Predicted: 0\n",
      "Row 11098 => Predicted: 0\n",
      "Row 11099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11090 to 11099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11100 => Predicted: 0\n",
      "Row 11101 => Predicted: 0\n",
      "Row 11102 => Predicted: 1\n",
      "Row 11103 => Predicted: 1\n",
      "Row 11104 => Predicted: 1\n",
      "Row 11105 => Predicted: 1\n",
      "Row 11106 => Predicted: 0\n",
      "Row 11107 => Predicted: 0\n",
      "Row 11108 => Predicted: 1\n",
      "Row 11109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11100 to 11109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11110 => Predicted: 0\n",
      "Row 11111 => Predicted: 1\n",
      "Row 11112 => Predicted: 1\n",
      "Row 11113 => Predicted: 0\n",
      "Row 11114 => Predicted: 0\n",
      "Row 11115 => Predicted: 0\n",
      "Row 11116 => Predicted: 1\n",
      "Row 11117 => Predicted: 0\n",
      "Row 11118 => Predicted: 1\n",
      "Row 11119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11110 to 11119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11120 => Predicted: 0\n",
      "Row 11121 => Predicted: 1\n",
      "Row 11122 => Predicted: 0\n",
      "Row 11123 => Predicted: 1\n",
      "Row 11124 => Predicted: 1\n",
      "Row 11125 => Predicted: 0\n",
      "Row 11126 => Predicted: 0\n",
      "Row 11127 => Predicted: 0\n",
      "Row 11128 => Predicted: 0\n",
      "Row 11129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11120 to 11129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11130 => Predicted: 1\n",
      "Row 11131 => Predicted: 0\n",
      "Row 11132 => Predicted: 0\n",
      "Row 11133 => Predicted: 1\n",
      "Row 11134 => Predicted: 0\n",
      "Row 11135 => Predicted: 0\n",
      "Row 11136 => Predicted: 0\n",
      "Row 11137 => Predicted: 1\n",
      "Row 11138 => Predicted: 1\n",
      "Row 11139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11130 to 11139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11140 => Predicted: 0\n",
      "Row 11141 => Predicted: 1\n",
      "Row 11142 => Predicted: 0\n",
      "Row 11143 => Predicted: 0\n",
      "Row 11144 => Predicted: 1\n",
      "Row 11145 => Predicted: 0\n",
      "Row 11146 => Predicted: 1\n",
      "Row 11147 => Predicted: 1\n",
      "Row 11148 => Predicted: 0\n",
      "Row 11149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11140 to 11149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11150 => Predicted: 0\n",
      "Row 11151 => Predicted: 1\n",
      "Row 11152 => Predicted: 1\n",
      "Row 11153 => Predicted: 1\n",
      "Row 11154 => Predicted: 0\n",
      "Row 11155 => Predicted: 1\n",
      "Row 11156 => Predicted: 1\n",
      "Row 11157 => Predicted: 1\n",
      "Row 11158 => Predicted: 0\n",
      "Row 11159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11150 to 11159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11160 => Predicted: 1\n",
      "Row 11161 => Predicted: 0\n",
      "Row 11162 => Predicted: 1\n",
      "Row 11163 => Predicted: 0\n",
      "Row 11164 => Predicted: 0\n",
      "Row 11165 => Predicted: 1\n",
      "Row 11166 => Predicted: 1\n",
      "Row 11167 => Predicted: 0\n",
      "Row 11168 => Predicted: 1\n",
      "Row 11169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11160 to 11169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11170 => Predicted: 1\n",
      "Row 11171 => Predicted: 1\n",
      "Row 11172 => Predicted: 0\n",
      "Row 11173 => Predicted: 0\n",
      "Row 11174 => Predicted: 1\n",
      "Row 11175 => Predicted: 0\n",
      "Row 11176 => Predicted: 1\n",
      "Row 11177 => Predicted: 1\n",
      "Row 11178 => Predicted: 1\n",
      "Row 11179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11170 to 11179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11180 => Predicted: 0\n",
      "Row 11181 => Predicted: 1\n",
      "Row 11182 => Predicted: 1\n",
      "Row 11183 => Predicted: 0\n",
      "Row 11184 => Predicted: 0\n",
      "Row 11185 => Predicted: 1\n",
      "Row 11186 => Predicted: 0\n",
      "Row 11187 => Predicted: 0\n",
      "Row 11188 => Predicted: 1\n",
      "Row 11189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11180 to 11189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11190 => Predicted: 0\n",
      "Row 11191 => Predicted: 1\n",
      "Row 11192 => Predicted: 1\n",
      "Row 11193 => Predicted: 0\n",
      "Row 11194 => Predicted: 0\n",
      "Row 11195 => Predicted: 1\n",
      "Row 11196 => Predicted: 1\n",
      "Row 11197 => Predicted: 1\n",
      "Row 11198 => Predicted: 1\n",
      "Row 11199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11190 to 11199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11200 => Predicted: 1\n",
      "Row 11201 => Predicted: 1\n",
      "Row 11202 => Predicted: 1\n",
      "Row 11203 => Predicted: 0\n",
      "Row 11204 => Predicted: 1\n",
      "Row 11205 => Predicted: 1\n",
      "Row 11206 => Predicted: 0\n",
      "Row 11207 => Predicted: 1\n",
      "Row 11208 => Predicted: 0\n",
      "Row 11209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11200 to 11209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11210 => Predicted: 1\n",
      "Row 11211 => Predicted: 0\n",
      "Row 11212 => Predicted: 0\n",
      "Row 11213 => Predicted: 1\n",
      "Row 11214 => Predicted: 0\n",
      "Row 11215 => Predicted: 0\n",
      "Row 11216 => Predicted: 1\n",
      "Row 11217 => Predicted: 1\n",
      "Row 11218 => Predicted: 1\n",
      "Row 11219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11210 to 11219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11220 => Predicted: 1\n",
      "Row 11221 => Predicted: 0\n",
      "Row 11222 => Predicted: 0\n",
      "Row 11223 => Predicted: 0\n",
      "Row 11224 => Predicted: 1\n",
      "Row 11225 => Predicted: 0\n",
      "Row 11226 => Predicted: 0\n",
      "Row 11227 => Predicted: 0\n",
      "Row 11228 => Predicted: 1\n",
      "Row 11229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11220 to 11229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11230 => Predicted: 1\n",
      "Row 11231 => Predicted: 1\n",
      "Row 11232 => Predicted: 1\n",
      "Row 11233 => Predicted: 1\n",
      "Row 11234 => Predicted: 1\n",
      "Row 11235 => Predicted: 0\n",
      "Row 11236 => Predicted: 1\n",
      "Row 11237 => Predicted: 1\n",
      "Row 11238 => Predicted: 1\n",
      "Row 11239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11230 to 11239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11240 => Predicted: 0\n",
      "Row 11241 => Predicted: 0\n",
      "Row 11242 => Predicted: 0\n",
      "Row 11243 => Predicted: 0\n",
      "Row 11244 => Predicted: 1\n",
      "Row 11245 => Predicted: 0\n",
      "Row 11246 => Predicted: 1\n",
      "Row 11247 => Predicted: 1\n",
      "Row 11248 => Predicted: 0\n",
      "Row 11249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11240 to 11249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11250 => Predicted: 0\n",
      "Row 11251 => Predicted: 1\n",
      "Row 11252 => Predicted: 1\n",
      "Row 11253 => Predicted: 0\n",
      "Row 11254 => Predicted: 1\n",
      "Row 11255 => Predicted: 0\n",
      "Row 11256 => Predicted: 0\n",
      "Row 11257 => Predicted: 1\n",
      "Row 11258 => Predicted: 1\n",
      "Row 11259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11250 to 11259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11260 => Predicted: 1\n",
      "Row 11261 => Predicted: 1\n",
      "Row 11262 => Predicted: 1\n",
      "Row 11263 => Predicted: 1\n",
      "Row 11264 => Predicted: 0\n",
      "Row 11265 => Predicted: 1\n",
      "Row 11266 => Predicted: 1\n",
      "Row 11267 => Predicted: 0\n",
      "Row 11268 => Predicted: 1\n",
      "Row 11269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11260 to 11269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11270 => Predicted: 0\n",
      "Row 11271 => Predicted: 1\n",
      "Row 11272 => Predicted: 1\n",
      "Row 11273 => Predicted: 1\n",
      "Row 11274 => Predicted: 0\n",
      "Row 11275 => Predicted: 0\n",
      "Row 11276 => Predicted: 0\n",
      "Row 11277 => Predicted: 1\n",
      "Row 11278 => Predicted: 1\n",
      "Row 11279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11270 to 11279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11280 => Predicted: 1\n",
      "Row 11281 => Predicted: 0\n",
      "Row 11282 => Predicted: 0\n",
      "Row 11283 => Predicted: 1\n",
      "Row 11284 => Predicted: 1\n",
      "Row 11285 => Predicted: 0\n",
      "Row 11286 => Predicted: 1\n",
      "Row 11287 => Predicted: 1\n",
      "Row 11288 => Predicted: 0\n",
      "Row 11289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11280 to 11289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11290 => Predicted: 1\n",
      "Row 11291 => Predicted: 0\n",
      "Row 11292 => Predicted: 0\n",
      "Row 11293 => Predicted: 1\n",
      "Row 11294 => Predicted: 1\n",
      "Row 11295 => Predicted: 1\n",
      "Row 11296 => Predicted: 0\n",
      "Row 11297 => Predicted: 0\n",
      "Row 11298 => Predicted: 1\n",
      "Row 11299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11290 to 11299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11300 => Predicted: 1\n",
      "Row 11301 => Predicted: 0\n",
      "Row 11302 => Predicted: 1\n",
      "Row 11303 => Predicted: 0\n",
      "Row 11304 => Predicted: 1\n",
      "Row 11305 => Predicted: 0\n",
      "Row 11306 => Predicted: 1\n",
      "Row 11307 => Predicted: 0\n",
      "Row 11308 => Predicted: 0\n",
      "Row 11309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11300 to 11309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11310 => Predicted: 0\n",
      "Row 11311 => Predicted: 1\n",
      "Row 11312 => Predicted: 1\n",
      "Row 11313 => Predicted: 1\n",
      "Row 11314 => Predicted: 1\n",
      "Row 11315 => Predicted: 1\n",
      "Row 11316 => Predicted: 0\n",
      "Row 11317 => Predicted: 1\n",
      "Row 11318 => Predicted: 0\n",
      "Row 11319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11310 to 11319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11320 => Predicted: 1\n",
      "Row 11321 => Predicted: 0\n",
      "Row 11322 => Predicted: 0\n",
      "Row 11323 => Predicted: 1\n",
      "Row 11324 => Predicted: 0\n",
      "Row 11325 => Predicted: 0\n",
      "Row 11326 => Predicted: 0\n",
      "Row 11327 => Predicted: 0\n",
      "Row 11328 => Predicted: 0\n",
      "Row 11329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11320 to 11329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11330 => Predicted: 1\n",
      "Row 11331 => Predicted: 1\n",
      "Row 11332 => Predicted: 0\n",
      "Row 11333 => Predicted: 1\n",
      "Row 11334 => Predicted: 1\n",
      "Row 11335 => Predicted: 1\n",
      "Row 11336 => Predicted: 0\n",
      "Row 11337 => Predicted: 1\n",
      "Row 11338 => Predicted: 1\n",
      "Row 11339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11330 to 11339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11340 => Predicted: 1\n",
      "Row 11341 => Predicted: 1\n",
      "Row 11342 => Predicted: 0\n",
      "Row 11343 => Predicted: 1\n",
      "Row 11344 => Predicted: 1\n",
      "Row 11345 => Predicted: 0\n",
      "Row 11346 => Predicted: 1\n",
      "Row 11347 => Predicted: 1\n",
      "Row 11348 => Predicted: 1\n",
      "Row 11349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11340 to 11349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11350 => Predicted: 0\n",
      "Row 11351 => Predicted: 1\n",
      "Row 11352 => Predicted: 0\n",
      "Row 11353 => Predicted: 1\n",
      "Row 11354 => Predicted: 1\n",
      "Row 11355 => Predicted: 0\n",
      "Row 11356 => Predicted: 0\n",
      "Row 11357 => Predicted: 1\n",
      "Row 11358 => Predicted: 1\n",
      "Row 11359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11350 to 11359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11360 => Predicted: 1\n",
      "Row 11361 => Predicted: 0\n",
      "Row 11362 => Predicted: 0\n",
      "Row 11363 => Predicted: 1\n",
      "Row 11364 => Predicted: 1\n",
      "Row 11365 => Predicted: 0\n",
      "Row 11366 => Predicted: 1\n",
      "Row 11367 => Predicted: 1\n",
      "Row 11368 => Predicted: 1\n",
      "Row 11369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11360 to 11369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11370 => Predicted: 1\n",
      "Row 11371 => Predicted: 1\n",
      "Row 11372 => Predicted: 0\n",
      "Row 11373 => Predicted: 1\n",
      "Row 11374 => Predicted: 0\n",
      "Row 11375 => Predicted: 1\n",
      "Row 11376 => Predicted: 0\n",
      "Row 11377 => Predicted: 1\n",
      "Row 11378 => Predicted: 0\n",
      "Row 11379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11370 to 11379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11380 => Predicted: 1\n",
      "Row 11381 => Predicted: 1\n",
      "Row 11382 => Predicted: 1\n",
      "Row 11383 => Predicted: 0\n",
      "Row 11384 => Predicted: 1\n",
      "Row 11385 => Predicted: 1\n",
      "Row 11386 => Predicted: 0\n",
      "Row 11387 => Predicted: 1\n",
      "Row 11388 => Predicted: 0\n",
      "Row 11389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11380 to 11389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11390 => Predicted: 0\n",
      "Row 11391 => Predicted: 0\n",
      "Row 11392 => Predicted: 0\n",
      "Row 11393 => Predicted: 1\n",
      "Row 11394 => Predicted: 0\n",
      "Row 11395 => Predicted: 1\n",
      "Row 11396 => Predicted: 1\n",
      "Row 11397 => Predicted: 1\n",
      "Row 11398 => Predicted: 1\n",
      "Row 11399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11390 to 11399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11400 => Predicted: 0\n",
      "Row 11401 => Predicted: 0\n",
      "Row 11402 => Predicted: 0\n",
      "Row 11403 => Predicted: 1\n",
      "Row 11404 => Predicted: 1\n",
      "Row 11405 => Predicted: 1\n",
      "Row 11406 => Predicted: 0\n",
      "Row 11407 => Predicted: 0\n",
      "Row 11408 => Predicted: 1\n",
      "Row 11409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11400 to 11409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11410 => Predicted: 0\n",
      "Row 11411 => Predicted: 0\n",
      "Row 11412 => Predicted: 0\n",
      "Row 11413 => Predicted: 1\n",
      "Row 11414 => Predicted: 0\n",
      "Row 11415 => Predicted: 0\n",
      "Row 11416 => Predicted: 1\n",
      "Row 11417 => Predicted: 1\n",
      "Row 11418 => Predicted: 0\n",
      "Row 11419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11410 to 11419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11420 => Predicted: 0\n",
      "Row 11421 => Predicted: 1\n",
      "Row 11422 => Predicted: 1\n",
      "Row 11423 => Predicted: 0\n",
      "Row 11424 => Predicted: 0\n",
      "Row 11425 => Predicted: 0\n",
      "Row 11426 => Predicted: 1\n",
      "Row 11427 => Predicted: 1\n",
      "Row 11428 => Predicted: 0\n",
      "Row 11429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11420 to 11429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11430 => Predicted: 0\n",
      "Row 11431 => Predicted: 1\n",
      "Row 11432 => Predicted: 0\n",
      "Row 11433 => Predicted: 0\n",
      "Row 11434 => Predicted: 1\n",
      "Row 11435 => Predicted: 1\n",
      "Row 11436 => Predicted: 1\n",
      "Row 11437 => Predicted: 1\n",
      "Row 11438 => Predicted: 0\n",
      "Row 11439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11430 to 11439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11440 => Predicted: 0\n",
      "Row 11441 => Predicted: 0\n",
      "Row 11442 => Predicted: 1\n",
      "Row 11443 => Predicted: 1\n",
      "Row 11444 => Predicted: 0\n",
      "Row 11445 => Predicted: 0\n",
      "Row 11446 => Predicted: 1\n",
      "Row 11447 => Predicted: 0\n",
      "Row 11448 => Predicted: 1\n",
      "Row 11449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11440 to 11449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11450 => Predicted: 1\n",
      "Row 11451 => Predicted: 1\n",
      "Row 11452 => Predicted: 0\n",
      "Row 11453 => Predicted: 1\n",
      "Row 11454 => Predicted: 0\n",
      "Row 11455 => Predicted: 0\n",
      "Row 11456 => Predicted: 0\n",
      "Row 11457 => Predicted: 1\n",
      "Row 11458 => Predicted: 1\n",
      "Row 11459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11450 to 11459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11460 => Predicted: 0\n",
      "Row 11461 => Predicted: 1\n",
      "Row 11462 => Predicted: 0\n",
      "Row 11463 => Predicted: 0\n",
      "Row 11464 => Predicted: 1\n",
      "Row 11465 => Predicted: 0\n",
      "Row 11466 => Predicted: 0\n",
      "Row 11467 => Predicted: 1\n",
      "Row 11468 => Predicted: 1\n",
      "Row 11469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11460 to 11469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11470 => Predicted: 1\n",
      "Row 11471 => Predicted: 0\n",
      "Row 11472 => Predicted: 0\n",
      "Row 11473 => Predicted: 0\n",
      "Row 11474 => Predicted: 1\n",
      "Row 11475 => Predicted: 0\n",
      "Row 11476 => Predicted: 0\n",
      "Row 11477 => Predicted: 0\n",
      "Row 11478 => Predicted: 1\n",
      "Row 11479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11470 to 11479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11480 => Predicted: 1\n",
      "Row 11481 => Predicted: 0\n",
      "Row 11482 => Predicted: 1\n",
      "Row 11483 => Predicted: 0\n",
      "Row 11484 => Predicted: 1\n",
      "Row 11485 => Predicted: 0\n",
      "Row 11486 => Predicted: 0\n",
      "Row 11487 => Predicted: 0\n",
      "Row 11488 => Predicted: 1\n",
      "Row 11489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11480 to 11489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11490 => Predicted: 1\n",
      "Row 11491 => Predicted: 1\n",
      "Row 11492 => Predicted: 1\n",
      "Row 11493 => Predicted: 1\n",
      "Row 11494 => Predicted: 0\n",
      "Row 11495 => Predicted: 0\n",
      "Row 11496 => Predicted: 1\n",
      "Row 11497 => Predicted: 0\n",
      "Row 11498 => Predicted: 1\n",
      "Row 11499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11490 to 11499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11500 => Predicted: 1\n",
      "Row 11501 => Predicted: 0\n",
      "Row 11502 => Predicted: 1\n",
      "Row 11503 => Predicted: 1\n",
      "Row 11504 => Predicted: 0\n",
      "Row 11505 => Predicted: 0\n",
      "Row 11506 => Predicted: 1\n",
      "Row 11507 => Predicted: 1\n",
      "Row 11508 => Predicted: 1\n",
      "Row 11509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11500 to 11509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11510 => Predicted: 0\n",
      "Row 11511 => Predicted: 0\n",
      "Row 11512 => Predicted: 0\n",
      "Row 11513 => Predicted: 0\n",
      "Row 11514 => Predicted: 1\n",
      "Row 11515 => Predicted: 1\n",
      "Row 11516 => Predicted: 0\n",
      "Row 11517 => Predicted: 1\n",
      "Row 11518 => Predicted: 0\n",
      "Row 11519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11510 to 11519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11520 => Predicted: 0\n",
      "Row 11521 => Predicted: 1\n",
      "Row 11522 => Predicted: 0\n",
      "Row 11523 => Predicted: 0\n",
      "Row 11524 => Predicted: 1\n",
      "Row 11525 => Predicted: 0\n",
      "Row 11526 => Predicted: 0\n",
      "Row 11527 => Predicted: 1\n",
      "Row 11528 => Predicted: 0\n",
      "Row 11529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11520 to 11529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11530 => Predicted: 0\n",
      "Row 11531 => Predicted: 0\n",
      "Row 11532 => Predicted: 0\n",
      "Row 11533 => Predicted: 0\n",
      "Row 11534 => Predicted: 0\n",
      "Row 11535 => Predicted: 0\n",
      "Row 11536 => Predicted: 1\n",
      "Row 11537 => Predicted: 0\n",
      "Row 11538 => Predicted: 0\n",
      "Row 11539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11530 to 11539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11540 => Predicted: 1\n",
      "Row 11541 => Predicted: 0\n",
      "Row 11542 => Predicted: 0\n",
      "Row 11543 => Predicted: 1\n",
      "Row 11544 => Predicted: 0\n",
      "Row 11545 => Predicted: 0\n",
      "Row 11546 => Predicted: 1\n",
      "Row 11547 => Predicted: 0\n",
      "Row 11548 => Predicted: 1\n",
      "Row 11549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11540 to 11549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11550 => Predicted: 0\n",
      "Row 11551 => Predicted: 1\n",
      "Row 11552 => Predicted: 0\n",
      "Row 11553 => Predicted: 1\n",
      "Row 11554 => Predicted: 1\n",
      "Row 11555 => Predicted: 0\n",
      "Row 11556 => Predicted: 0\n",
      "Row 11557 => Predicted: 1\n",
      "Row 11558 => Predicted: 0\n",
      "Row 11559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11550 to 11559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11560 => Predicted: 1\n",
      "Row 11561 => Predicted: 0\n",
      "Row 11562 => Predicted: 0\n",
      "Row 11563 => Predicted: 0\n",
      "Row 11564 => Predicted: 0\n",
      "Row 11565 => Predicted: 0\n",
      "Row 11566 => Predicted: 1\n",
      "Row 11567 => Predicted: 0\n",
      "Row 11568 => Predicted: 1\n",
      "Row 11569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11560 to 11569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11570 => Predicted: 0\n",
      "Row 11571 => Predicted: 0\n",
      "Row 11572 => Predicted: 1\n",
      "Row 11573 => Predicted: 0\n",
      "Row 11574 => Predicted: 1\n",
      "Row 11575 => Predicted: 1\n",
      "Row 11576 => Predicted: 0\n",
      "Row 11577 => Predicted: 0\n",
      "Row 11578 => Predicted: 1\n",
      "Row 11579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11570 to 11579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11580 => Predicted: 0\n",
      "Row 11581 => Predicted: 0\n",
      "Row 11582 => Predicted: 1\n",
      "Row 11583 => Predicted: 0\n",
      "Row 11584 => Predicted: 0\n",
      "Row 11585 => Predicted: 1\n",
      "Row 11586 => Predicted: 1\n",
      "Row 11587 => Predicted: 1\n",
      "Row 11588 => Predicted: 0\n",
      "Row 11589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11580 to 11589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11590 => Predicted: 0\n",
      "Row 11591 => Predicted: 1\n",
      "Row 11592 => Predicted: 0\n",
      "Row 11593 => Predicted: 0\n",
      "Row 11594 => Predicted: 1\n",
      "Row 11595 => Predicted: 0\n",
      "Row 11596 => Predicted: 1\n",
      "Row 11597 => Predicted: 0\n",
      "Row 11598 => Predicted: 0\n",
      "Row 11599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11590 to 11599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11600 => Predicted: 0\n",
      "Row 11601 => Predicted: 1\n",
      "Row 11602 => Predicted: 0\n",
      "Row 11603 => Predicted: 1\n",
      "Row 11604 => Predicted: 1\n",
      "Row 11605 => Predicted: 0\n",
      "Row 11606 => Predicted: 1\n",
      "Row 11607 => Predicted: 1\n",
      "Row 11608 => Predicted: 1\n",
      "Row 11609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11600 to 11609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11610 => Predicted: 1\n",
      "Row 11611 => Predicted: 1\n",
      "Row 11612 => Predicted: 0\n",
      "Row 11613 => Predicted: 0\n",
      "Row 11614 => Predicted: 1\n",
      "Row 11615 => Predicted: 0\n",
      "Row 11616 => Predicted: 1\n",
      "Row 11617 => Predicted: 0\n",
      "Row 11618 => Predicted: 1\n",
      "Row 11619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11610 to 11619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11620 => Predicted: 0\n",
      "Row 11621 => Predicted: 0\n",
      "Row 11622 => Predicted: 1\n",
      "Row 11623 => Predicted: 1\n",
      "Row 11624 => Predicted: 0\n",
      "Row 11625 => Predicted: 1\n",
      "Row 11626 => Predicted: 1\n",
      "Row 11627 => Predicted: 0\n",
      "Row 11628 => Predicted: 1\n",
      "Row 11629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11620 to 11629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11630 => Predicted: 0\n",
      "Row 11631 => Predicted: 0\n",
      "Row 11632 => Predicted: 0\n",
      "Row 11633 => Predicted: 1\n",
      "Row 11634 => Predicted: 1\n",
      "Row 11635 => Predicted: 0\n",
      "Row 11636 => Predicted: 1\n",
      "Row 11637 => Predicted: 1\n",
      "Row 11638 => Predicted: 1\n",
      "Row 11639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11630 to 11639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11640 => Predicted: 1\n",
      "Row 11641 => Predicted: 1\n",
      "Row 11642 => Predicted: 1\n",
      "Row 11643 => Predicted: 1\n",
      "Row 11644 => Predicted: 0\n",
      "Row 11645 => Predicted: 1\n",
      "Row 11646 => Predicted: 1\n",
      "Row 11647 => Predicted: 0\n",
      "Row 11648 => Predicted: 0\n",
      "Row 11649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11640 to 11649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11650 => Predicted: 1\n",
      "Row 11651 => Predicted: 0\n",
      "Row 11652 => Predicted: 1\n",
      "Row 11653 => Predicted: 0\n",
      "Row 11654 => Predicted: 0\n",
      "Row 11655 => Predicted: 1\n",
      "Row 11656 => Predicted: 1\n",
      "Row 11657 => Predicted: 0\n",
      "Row 11658 => Predicted: 0\n",
      "Row 11659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11650 to 11659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11660 => Predicted: 0\n",
      "Row 11661 => Predicted: 1\n",
      "Row 11662 => Predicted: 0\n",
      "Row 11663 => Predicted: 0\n",
      "Row 11664 => Predicted: 1\n",
      "Row 11665 => Predicted: 0\n",
      "Row 11666 => Predicted: 1\n",
      "Row 11667 => Predicted: 1\n",
      "Row 11668 => Predicted: 0\n",
      "Row 11669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11660 to 11669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11670 => Predicted: 0\n",
      "Row 11671 => Predicted: 1\n",
      "Row 11672 => Predicted: 0\n",
      "Row 11673 => Predicted: 0\n",
      "Row 11674 => Predicted: 0\n",
      "Row 11675 => Predicted: 0\n",
      "Row 11676 => Predicted: 0\n",
      "Row 11677 => Predicted: 1\n",
      "Row 11678 => Predicted: 0\n",
      "Row 11679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11670 to 11679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11680 => Predicted: 1\n",
      "Row 11681 => Predicted: 0\n",
      "Row 11682 => Predicted: 0\n",
      "Row 11683 => Predicted: 0\n",
      "Row 11684 => Predicted: 1\n",
      "Row 11685 => Predicted: 1\n",
      "Row 11686 => Predicted: 1\n",
      "Row 11687 => Predicted: 0\n",
      "Row 11688 => Predicted: 0\n",
      "Row 11689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11680 to 11689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11690 => Predicted: 0\n",
      "Row 11691 => Predicted: 1\n",
      "Row 11692 => Predicted: 0\n",
      "Row 11693 => Predicted: 1\n",
      "Row 11694 => Predicted: 1\n",
      "Row 11695 => Predicted: 1\n",
      "Row 11696 => Predicted: 1\n",
      "Row 11697 => Predicted: 0\n",
      "Row 11698 => Predicted: 1\n",
      "Row 11699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11690 to 11699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11700 => Predicted: 0\n",
      "Row 11701 => Predicted: 1\n",
      "Row 11702 => Predicted: 1\n",
      "Row 11703 => Predicted: 1\n",
      "Row 11704 => Predicted: 1\n",
      "Row 11705 => Predicted: 0\n",
      "Row 11706 => Predicted: 1\n",
      "Row 11707 => Predicted: 1\n",
      "Row 11708 => Predicted: 1\n",
      "Row 11709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11700 to 11709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11710 => Predicted: 1\n",
      "Row 11711 => Predicted: 1\n",
      "Row 11712 => Predicted: 1\n",
      "Row 11713 => Predicted: 1\n",
      "Row 11714 => Predicted: 1\n",
      "Row 11715 => Predicted: 1\n",
      "Row 11716 => Predicted: 0\n",
      "Row 11717 => Predicted: 1\n",
      "Row 11718 => Predicted: 1\n",
      "Row 11719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11710 to 11719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11720 => Predicted: 0\n",
      "Row 11721 => Predicted: 1\n",
      "Row 11722 => Predicted: 0\n",
      "Row 11723 => Predicted: 1\n",
      "Row 11724 => Predicted: 0\n",
      "Row 11725 => Predicted: 1\n",
      "Row 11726 => Predicted: 0\n",
      "Row 11727 => Predicted: 1\n",
      "Row 11728 => Predicted: 0\n",
      "Row 11729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11720 to 11729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11730 => Predicted: 0\n",
      "Row 11731 => Predicted: 0\n",
      "Row 11732 => Predicted: 0\n",
      "Row 11733 => Predicted: 0\n",
      "Row 11734 => Predicted: 0\n",
      "Row 11735 => Predicted: 1\n",
      "Row 11736 => Predicted: 0\n",
      "Row 11737 => Predicted: 0\n",
      "Row 11738 => Predicted: 0\n",
      "Row 11739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11730 to 11739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11740 => Predicted: 1\n",
      "Row 11741 => Predicted: 1\n",
      "Row 11742 => Predicted: 1\n",
      "Row 11743 => Predicted: 0\n",
      "Row 11744 => Predicted: 1\n",
      "Row 11745 => Predicted: 0\n",
      "Row 11746 => Predicted: 0\n",
      "Row 11747 => Predicted: 0\n",
      "Row 11748 => Predicted: 0\n",
      "Row 11749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11740 to 11749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11750 => Predicted: 0\n",
      "Row 11751 => Predicted: 0\n",
      "Row 11752 => Predicted: 0\n",
      "Row 11753 => Predicted: 1\n",
      "Row 11754 => Predicted: 1\n",
      "Row 11755 => Predicted: 0\n",
      "Row 11756 => Predicted: 1\n",
      "Row 11757 => Predicted: 0\n",
      "Row 11758 => Predicted: 1\n",
      "Row 11759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11750 to 11759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11760 => Predicted: 0\n",
      "Row 11761 => Predicted: 0\n",
      "Row 11762 => Predicted: 1\n",
      "Row 11763 => Predicted: 1\n",
      "Row 11764 => Predicted: 0\n",
      "Row 11765 => Predicted: 1\n",
      "Row 11766 => Predicted: 1\n",
      "Row 11767 => Predicted: 1\n",
      "Row 11768 => Predicted: 1\n",
      "Row 11769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11760 to 11769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11770 => Predicted: 0\n",
      "Row 11771 => Predicted: 0\n",
      "Row 11772 => Predicted: 0\n",
      "Row 11773 => Predicted: 0\n",
      "Row 11774 => Predicted: 0\n",
      "Row 11775 => Predicted: 0\n",
      "Row 11776 => Predicted: 1\n",
      "Row 11777 => Predicted: 0\n",
      "Row 11778 => Predicted: 0\n",
      "Row 11779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11770 to 11779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11780 => Predicted: 1\n",
      "Row 11781 => Predicted: 0\n",
      "Row 11782 => Predicted: 0\n",
      "Row 11783 => Predicted: 1\n",
      "Row 11784 => Predicted: 1\n",
      "Row 11785 => Predicted: 1\n",
      "Row 11786 => Predicted: 0\n",
      "Row 11787 => Predicted: 1\n",
      "Row 11788 => Predicted: 0\n",
      "Row 11789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11780 to 11789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11790 => Predicted: 0\n",
      "Row 11791 => Predicted: 1\n",
      "Row 11792 => Predicted: 0\n",
      "Row 11793 => Predicted: 0\n",
      "Row 11794 => Predicted: 1\n",
      "Row 11795 => Predicted: 1\n",
      "Row 11796 => Predicted: 1\n",
      "Row 11797 => Predicted: 1\n",
      "Row 11798 => Predicted: 0\n",
      "Row 11799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11790 to 11799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11800 => Predicted: 1\n",
      "Row 11801 => Predicted: 0\n",
      "Row 11802 => Predicted: 0\n",
      "Row 11803 => Predicted: 0\n",
      "Row 11804 => Predicted: 0\n",
      "Row 11805 => Predicted: 0\n",
      "Row 11806 => Predicted: 1\n",
      "Row 11807 => Predicted: 0\n",
      "Row 11808 => Predicted: 0\n",
      "Row 11809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11800 to 11809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11810 => Predicted: 1\n",
      "Row 11811 => Predicted: 0\n",
      "Row 11812 => Predicted: 1\n",
      "Row 11813 => Predicted: 1\n",
      "Row 11814 => Predicted: 1\n",
      "Row 11815 => Predicted: 0\n",
      "Row 11816 => Predicted: 1\n",
      "Row 11817 => Predicted: 1\n",
      "Row 11818 => Predicted: 1\n",
      "Row 11819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11810 to 11819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11820 => Predicted: 1\n",
      "Row 11821 => Predicted: 1\n",
      "Row 11822 => Predicted: 0\n",
      "Row 11823 => Predicted: 1\n",
      "Row 11824 => Predicted: 1\n",
      "Row 11825 => Predicted: 1\n",
      "Row 11826 => Predicted: 0\n",
      "Row 11827 => Predicted: 1\n",
      "Row 11828 => Predicted: 1\n",
      "Row 11829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11820 to 11829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11830 => Predicted: 1\n",
      "Row 11831 => Predicted: 0\n",
      "Row 11832 => Predicted: 0\n",
      "Row 11833 => Predicted: 0\n",
      "Row 11834 => Predicted: 1\n",
      "Row 11835 => Predicted: 0\n",
      "Row 11836 => Predicted: 1\n",
      "Row 11837 => Predicted: 1\n",
      "Row 11838 => Predicted: 1\n",
      "Row 11839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11830 to 11839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11840 => Predicted: 1\n",
      "Row 11841 => Predicted: 1\n",
      "Row 11842 => Predicted: 1\n",
      "Row 11843 => Predicted: 1\n",
      "Row 11844 => Predicted: 1\n",
      "Row 11845 => Predicted: 1\n",
      "Row 11846 => Predicted: 1\n",
      "Row 11847 => Predicted: 1\n",
      "Row 11848 => Predicted: 0\n",
      "Row 11849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11840 to 11849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11850 => Predicted: 0\n",
      "Row 11851 => Predicted: 1\n",
      "Row 11852 => Predicted: 1\n",
      "Row 11853 => Predicted: 0\n",
      "Row 11854 => Predicted: 0\n",
      "Row 11855 => Predicted: 1\n",
      "Row 11856 => Predicted: 1\n",
      "Row 11857 => Predicted: 0\n",
      "Row 11858 => Predicted: 1\n",
      "Row 11859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11850 to 11859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11860 => Predicted: 1\n",
      "Row 11861 => Predicted: 0\n",
      "Row 11862 => Predicted: 1\n",
      "Row 11863 => Predicted: 0\n",
      "Row 11864 => Predicted: 0\n",
      "Row 11865 => Predicted: 0\n",
      "Row 11866 => Predicted: 1\n",
      "Row 11867 => Predicted: 0\n",
      "Row 11868 => Predicted: 1\n",
      "Row 11869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11860 to 11869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11870 => Predicted: 0\n",
      "Row 11871 => Predicted: 0\n",
      "Row 11872 => Predicted: 0\n",
      "Row 11873 => Predicted: 0\n",
      "Row 11874 => Predicted: 0\n",
      "Row 11875 => Predicted: 1\n",
      "Row 11876 => Predicted: 1\n",
      "Row 11877 => Predicted: 1\n",
      "Row 11878 => Predicted: 0\n",
      "Row 11879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11870 to 11879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11880 => Predicted: 1\n",
      "Row 11881 => Predicted: 1\n",
      "Row 11882 => Predicted: 0\n",
      "Row 11883 => Predicted: 0\n",
      "Row 11884 => Predicted: 0\n",
      "Row 11885 => Predicted: 0\n",
      "Row 11886 => Predicted: 1\n",
      "Row 11887 => Predicted: 1\n",
      "Row 11888 => Predicted: 0\n",
      "Row 11889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11880 to 11889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11890 => Predicted: 1\n",
      "Row 11891 => Predicted: 0\n",
      "Row 11892 => Predicted: 0\n",
      "Row 11893 => Predicted: 1\n",
      "Row 11894 => Predicted: 1\n",
      "Row 11895 => Predicted: 0\n",
      "Row 11896 => Predicted: 0\n",
      "Row 11897 => Predicted: 0\n",
      "Row 11898 => Predicted: 1\n",
      "Row 11899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11890 to 11899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11900 => Predicted: 0\n",
      "Row 11901 => Predicted: 0\n",
      "Row 11902 => Predicted: 1\n",
      "Row 11903 => Predicted: 0\n",
      "Row 11904 => Predicted: 0\n",
      "Row 11905 => Predicted: 1\n",
      "Row 11906 => Predicted: 1\n",
      "Row 11907 => Predicted: 1\n",
      "Row 11908 => Predicted: 1\n",
      "Row 11909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11900 to 11909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11910 => Predicted: 0\n",
      "Row 11911 => Predicted: 1\n",
      "Row 11912 => Predicted: 0\n",
      "Row 11913 => Predicted: 0\n",
      "Row 11914 => Predicted: 0\n",
      "Row 11915 => Predicted: 1\n",
      "Row 11916 => Predicted: 1\n",
      "Row 11917 => Predicted: 1\n",
      "Row 11918 => Predicted: 1\n",
      "Row 11919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11910 to 11919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11920 => Predicted: 1\n",
      "Row 11921 => Predicted: 0\n",
      "Row 11922 => Predicted: 1\n",
      "Row 11923 => Predicted: 1\n",
      "Row 11924 => Predicted: 1\n",
      "Row 11925 => Predicted: 1\n",
      "Row 11926 => Predicted: 0\n",
      "Row 11927 => Predicted: 0\n",
      "Row 11928 => Predicted: 0\n",
      "Row 11929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11920 to 11929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11930 => Predicted: 0\n",
      "Row 11931 => Predicted: 0\n",
      "Row 11932 => Predicted: 1\n",
      "Row 11933 => Predicted: 1\n",
      "Row 11934 => Predicted: 0\n",
      "Row 11935 => Predicted: 0\n",
      "Row 11936 => Predicted: 1\n",
      "Row 11937 => Predicted: 1\n",
      "Row 11938 => Predicted: 0\n",
      "Row 11939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11930 to 11939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11940 => Predicted: 1\n",
      "Row 11941 => Predicted: 1\n",
      "Row 11942 => Predicted: 0\n",
      "Row 11943 => Predicted: 0\n",
      "Row 11944 => Predicted: 1\n",
      "Row 11945 => Predicted: 0\n",
      "Row 11946 => Predicted: 0\n",
      "Row 11947 => Predicted: 1\n",
      "Row 11948 => Predicted: 1\n",
      "Row 11949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11940 to 11949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11950 => Predicted: 1\n",
      "Row 11951 => Predicted: 1\n",
      "Row 11952 => Predicted: 1\n",
      "Row 11953 => Predicted: 1\n",
      "Row 11954 => Predicted: 1\n",
      "Row 11955 => Predicted: 1\n",
      "Row 11956 => Predicted: 1\n",
      "Row 11957 => Predicted: 0\n",
      "Row 11958 => Predicted: 1\n",
      "Row 11959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11950 to 11959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11960 => Predicted: 1\n",
      "Row 11961 => Predicted: 1\n",
      "Row 11962 => Predicted: 0\n",
      "Row 11963 => Predicted: 1\n",
      "Row 11964 => Predicted: 1\n",
      "Row 11965 => Predicted: 1\n",
      "Row 11966 => Predicted: 0\n",
      "Row 11967 => Predicted: 0\n",
      "Row 11968 => Predicted: 1\n",
      "Row 11969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11960 to 11969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11970 => Predicted: 0\n",
      "Row 11971 => Predicted: 1\n",
      "Row 11972 => Predicted: 1\n",
      "Row 11973 => Predicted: 0\n",
      "Row 11974 => Predicted: 0\n",
      "Row 11975 => Predicted: 1\n",
      "Row 11976 => Predicted: 1\n",
      "Row 11977 => Predicted: 1\n",
      "Row 11978 => Predicted: 1\n",
      "Row 11979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 11970 to 11979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11980 => Predicted: 1\n",
      "Row 11981 => Predicted: 1\n",
      "Row 11982 => Predicted: 1\n",
      "Row 11983 => Predicted: 1\n",
      "Row 11984 => Predicted: 0\n",
      "Row 11985 => Predicted: 0\n",
      "Row 11986 => Predicted: 0\n",
      "Row 11987 => Predicted: 1\n",
      "Row 11988 => Predicted: 1\n",
      "Row 11989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11980 to 11989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11990 => Predicted: 1\n",
      "Row 11991 => Predicted: 1\n",
      "Row 11992 => Predicted: 0\n",
      "Row 11993 => Predicted: 1\n",
      "Row 11994 => Predicted: 0\n",
      "Row 11995 => Predicted: 1\n",
      "Row 11996 => Predicted: 1\n",
      "Row 11997 => Predicted: 0\n",
      "Row 11998 => Predicted: 1\n",
      "Row 11999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 11990 to 11999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12000 => Predicted: 0\n",
      "Row 12001 => Predicted: 1\n",
      "Row 12002 => Predicted: 0\n",
      "Row 12003 => Predicted: 0\n",
      "Row 12004 => Predicted: 0\n",
      "Row 12005 => Predicted: 1\n",
      "Row 12006 => Predicted: 0\n",
      "Row 12007 => Predicted: 0\n",
      "Row 12008 => Predicted: 0\n",
      "Row 12009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12000 to 12009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12010 => Predicted: 1\n",
      "Row 12011 => Predicted: 0\n",
      "Row 12012 => Predicted: 0\n",
      "Row 12013 => Predicted: 1\n",
      "Row 12014 => Predicted: 1\n",
      "Row 12015 => Predicted: 0\n",
      "Row 12016 => Predicted: 1\n",
      "Row 12017 => Predicted: 1\n",
      "Row 12018 => Predicted: 1\n",
      "Row 12019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12010 to 12019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12020 => Predicted: 0\n",
      "Row 12021 => Predicted: 0\n",
      "Row 12022 => Predicted: 0\n",
      "Row 12023 => Predicted: 1\n",
      "Row 12024 => Predicted: 0\n",
      "Row 12025 => Predicted: 1\n",
      "Row 12026 => Predicted: 0\n",
      "Row 12027 => Predicted: 0\n",
      "Row 12028 => Predicted: 1\n",
      "Row 12029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12020 to 12029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12030 => Predicted: 1\n",
      "Row 12031 => Predicted: 1\n",
      "Row 12032 => Predicted: 1\n",
      "Row 12033 => Predicted: 1\n",
      "Row 12034 => Predicted: 0\n",
      "Row 12035 => Predicted: 1\n",
      "Row 12036 => Predicted: 1\n",
      "Row 12037 => Predicted: 1\n",
      "Row 12038 => Predicted: 1\n",
      "Row 12039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12030 to 12039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12040 => Predicted: 0\n",
      "Row 12041 => Predicted: 0\n",
      "Row 12042 => Predicted: 0\n",
      "Row 12043 => Predicted: 0\n",
      "Row 12044 => Predicted: 0\n",
      "Row 12045 => Predicted: 1\n",
      "Row 12046 => Predicted: 1\n",
      "Row 12047 => Predicted: 1\n",
      "Row 12048 => Predicted: 1\n",
      "Row 12049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12040 to 12049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12050 => Predicted: 1\n",
      "Row 12051 => Predicted: 0\n",
      "Row 12052 => Predicted: 1\n",
      "Row 12053 => Predicted: 0\n",
      "Row 12054 => Predicted: 1\n",
      "Row 12055 => Predicted: 1\n",
      "Row 12056 => Predicted: 0\n",
      "Row 12057 => Predicted: 1\n",
      "Row 12058 => Predicted: 1\n",
      "Row 12059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12050 to 12059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12060 => Predicted: 1\n",
      "Row 12061 => Predicted: 0\n",
      "Row 12062 => Predicted: 1\n",
      "Row 12063 => Predicted: 1\n",
      "Row 12064 => Predicted: 1\n",
      "Row 12065 => Predicted: 0\n",
      "Row 12066 => Predicted: 0\n",
      "Row 12067 => Predicted: 0\n",
      "Row 12068 => Predicted: 1\n",
      "Row 12069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12060 to 12069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12070 => Predicted: 0\n",
      "Row 12071 => Predicted: 1\n",
      "Row 12072 => Predicted: 1\n",
      "Row 12073 => Predicted: 1\n",
      "Row 12074 => Predicted: 1\n",
      "Row 12075 => Predicted: 0\n",
      "Row 12076 => Predicted: 0\n",
      "Row 12077 => Predicted: 0\n",
      "Row 12078 => Predicted: 1\n",
      "Row 12079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12070 to 12079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12080 => Predicted: 1\n",
      "Row 12081 => Predicted: 1\n",
      "Row 12082 => Predicted: 0\n",
      "Row 12083 => Predicted: 0\n",
      "Row 12084 => Predicted: 1\n",
      "Row 12085 => Predicted: 1\n",
      "Row 12086 => Predicted: 1\n",
      "Row 12087 => Predicted: 0\n",
      "Row 12088 => Predicted: 0\n",
      "Row 12089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12080 to 12089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12090 => Predicted: 0\n",
      "Row 12091 => Predicted: 0\n",
      "Row 12092 => Predicted: 0\n",
      "Row 12093 => Predicted: 1\n",
      "Row 12094 => Predicted: 1\n",
      "Row 12095 => Predicted: 1\n",
      "Row 12096 => Predicted: 0\n",
      "Row 12097 => Predicted: 0\n",
      "Row 12098 => Predicted: 0\n",
      "Row 12099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12090 to 12099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12100 => Predicted: 0\n",
      "Row 12101 => Predicted: 0\n",
      "Row 12102 => Predicted: 0\n",
      "Row 12103 => Predicted: 0\n",
      "Row 12104 => Predicted: 1\n",
      "Row 12105 => Predicted: 0\n",
      "Row 12106 => Predicted: 0\n",
      "Row 12107 => Predicted: 1\n",
      "Row 12108 => Predicted: 0\n",
      "Row 12109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12100 to 12109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12110 => Predicted: 1\n",
      "Row 12111 => Predicted: 1\n",
      "Row 12112 => Predicted: 1\n",
      "Row 12113 => Predicted: 1\n",
      "Row 12114 => Predicted: 0\n",
      "Row 12115 => Predicted: 1\n",
      "Row 12116 => Predicted: 1\n",
      "Row 12117 => Predicted: 1\n",
      "Row 12118 => Predicted: 1\n",
      "Row 12119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12110 to 12119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12120 => Predicted: 0\n",
      "Row 12121 => Predicted: 1\n",
      "Row 12122 => Predicted: 0\n",
      "Row 12123 => Predicted: 0\n",
      "Row 12124 => Predicted: 1\n",
      "Row 12125 => Predicted: 1\n",
      "Row 12126 => Predicted: 1\n",
      "Row 12127 => Predicted: 0\n",
      "Row 12128 => Predicted: 0\n",
      "Row 12129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12120 to 12129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12130 => Predicted: 0\n",
      "Row 12131 => Predicted: 0\n",
      "Row 12132 => Predicted: 1\n",
      "Row 12133 => Predicted: 0\n",
      "Row 12134 => Predicted: 0\n",
      "Row 12135 => Predicted: 0\n",
      "Row 12136 => Predicted: 0\n",
      "Row 12137 => Predicted: 1\n",
      "Row 12138 => Predicted: 0\n",
      "Row 12139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12130 to 12139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12140 => Predicted: 1\n",
      "Row 12141 => Predicted: 1\n",
      "Row 12142 => Predicted: 1\n",
      "Row 12143 => Predicted: 1\n",
      "Row 12144 => Predicted: 1\n",
      "Row 12145 => Predicted: 0\n",
      "Row 12146 => Predicted: 1\n",
      "Row 12147 => Predicted: 1\n",
      "Row 12148 => Predicted: 1\n",
      "Row 12149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12140 to 12149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12150 => Predicted: 0\n",
      "Row 12151 => Predicted: 0\n",
      "Row 12152 => Predicted: 1\n",
      "Row 12153 => Predicted: 1\n",
      "Row 12154 => Predicted: 1\n",
      "Row 12155 => Predicted: 0\n",
      "Row 12156 => Predicted: 1\n",
      "Row 12157 => Predicted: 0\n",
      "Row 12158 => Predicted: 0\n",
      "Row 12159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12150 to 12159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12160 => Predicted: 1\n",
      "Row 12161 => Predicted: 1\n",
      "Row 12162 => Predicted: 0\n",
      "Row 12163 => Predicted: 0\n",
      "Row 12164 => Predicted: 1\n",
      "Row 12165 => Predicted: 0\n",
      "Row 12166 => Predicted: 1\n",
      "Row 12167 => Predicted: 1\n",
      "Row 12168 => Predicted: 1\n",
      "Row 12169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12160 to 12169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12170 => Predicted: 0\n",
      "Row 12171 => Predicted: 1\n",
      "Row 12172 => Predicted: 1\n",
      "Row 12173 => Predicted: 0\n",
      "Row 12174 => Predicted: 0\n",
      "Row 12175 => Predicted: 1\n",
      "Row 12176 => Predicted: 0\n",
      "Row 12177 => Predicted: 1\n",
      "Row 12178 => Predicted: 1\n",
      "Row 12179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12170 to 12179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12180 => Predicted: 1\n",
      "Row 12181 => Predicted: 0\n",
      "Row 12182 => Predicted: 0\n",
      "Row 12183 => Predicted: 0\n",
      "Row 12184 => Predicted: 1\n",
      "Row 12185 => Predicted: 0\n",
      "Row 12186 => Predicted: 0\n",
      "Row 12187 => Predicted: 1\n",
      "Row 12188 => Predicted: 1\n",
      "Row 12189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12180 to 12189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12190 => Predicted: 0\n",
      "Row 12191 => Predicted: 0\n",
      "Row 12192 => Predicted: 0\n",
      "Row 12193 => Predicted: 1\n",
      "Row 12194 => Predicted: 1\n",
      "Row 12195 => Predicted: 0\n",
      "Row 12196 => Predicted: 1\n",
      "Row 12197 => Predicted: 1\n",
      "Row 12198 => Predicted: 1\n",
      "Row 12199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12190 to 12199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12200 => Predicted: 0\n",
      "Row 12201 => Predicted: 0\n",
      "Row 12202 => Predicted: 0\n",
      "Row 12203 => Predicted: 0\n",
      "Row 12204 => Predicted: 1\n",
      "Row 12205 => Predicted: 0\n",
      "Row 12206 => Predicted: 0\n",
      "Row 12207 => Predicted: 0\n",
      "Row 12208 => Predicted: 1\n",
      "Row 12209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12200 to 12209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12210 => Predicted: 1\n",
      "Row 12211 => Predicted: 0\n",
      "Row 12212 => Predicted: 1\n",
      "Row 12213 => Predicted: 0\n",
      "Row 12214 => Predicted: 0\n",
      "Row 12215 => Predicted: 1\n",
      "Row 12216 => Predicted: 0\n",
      "Row 12217 => Predicted: 1\n",
      "Row 12218 => Predicted: 0\n",
      "Row 12219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12210 to 12219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12220 => Predicted: 1\n",
      "Row 12221 => Predicted: 1\n",
      "Row 12222 => Predicted: 1\n",
      "Row 12223 => Predicted: 1\n",
      "Row 12224 => Predicted: 0\n",
      "Row 12225 => Predicted: 1\n",
      "Row 12226 => Predicted: 0\n",
      "Row 12227 => Predicted: 0\n",
      "Row 12228 => Predicted: 1\n",
      "Row 12229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12220 to 12229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12230 => Predicted: 1\n",
      "Row 12231 => Predicted: 0\n",
      "Row 12232 => Predicted: 1\n",
      "Row 12233 => Predicted: 1\n",
      "Row 12234 => Predicted: 0\n",
      "Row 12235 => Predicted: 1\n",
      "Row 12236 => Predicted: 1\n",
      "Row 12237 => Predicted: 1\n",
      "Row 12238 => Predicted: 0\n",
      "Row 12239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12230 to 12239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12240 => Predicted: 1\n",
      "Row 12241 => Predicted: 1\n",
      "Row 12242 => Predicted: 0\n",
      "Row 12243 => Predicted: 1\n",
      "Row 12244 => Predicted: 1\n",
      "Row 12245 => Predicted: 0\n",
      "Row 12246 => Predicted: 0\n",
      "Row 12247 => Predicted: 0\n",
      "Row 12248 => Predicted: 1\n",
      "Row 12249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12240 to 12249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12250 => Predicted: 1\n",
      "Row 12251 => Predicted: 0\n",
      "Row 12252 => Predicted: 1\n",
      "Row 12253 => Predicted: 1\n",
      "Row 12254 => Predicted: 0\n",
      "Row 12255 => Predicted: 1\n",
      "Row 12256 => Predicted: 0\n",
      "Row 12257 => Predicted: 1\n",
      "Row 12258 => Predicted: 1\n",
      "Row 12259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12250 to 12259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12260 => Predicted: 1\n",
      "Row 12261 => Predicted: 0\n",
      "Row 12262 => Predicted: 0\n",
      "Row 12263 => Predicted: 1\n",
      "Row 12264 => Predicted: 1\n",
      "Row 12265 => Predicted: 1\n",
      "Row 12266 => Predicted: 0\n",
      "Row 12267 => Predicted: 0\n",
      "Row 12268 => Predicted: 1\n",
      "Row 12269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12260 to 12269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12270 => Predicted: 1\n",
      "Row 12271 => Predicted: 0\n",
      "Row 12272 => Predicted: 0\n",
      "Row 12273 => Predicted: 1\n",
      "Row 12274 => Predicted: 1\n",
      "Row 12275 => Predicted: 1\n",
      "Row 12276 => Predicted: 1\n",
      "Row 12277 => Predicted: 1\n",
      "Row 12278 => Predicted: 0\n",
      "Row 12279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12270 to 12279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12280 => Predicted: 0\n",
      "Row 12281 => Predicted: 0\n",
      "Row 12282 => Predicted: 1\n",
      "Row 12283 => Predicted: 1\n",
      "Row 12284 => Predicted: 1\n",
      "Row 12285 => Predicted: 0\n",
      "Row 12286 => Predicted: 0\n",
      "Row 12287 => Predicted: 0\n",
      "Row 12288 => Predicted: 1\n",
      "Row 12289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12280 to 12289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12290 => Predicted: 0\n",
      "Row 12291 => Predicted: 0\n",
      "Row 12292 => Predicted: 1\n",
      "Row 12293 => Predicted: 1\n",
      "Row 12294 => Predicted: 0\n",
      "Row 12295 => Predicted: 1\n",
      "Row 12296 => Predicted: 0\n",
      "Row 12297 => Predicted: 1\n",
      "Row 12298 => Predicted: 1\n",
      "Row 12299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12290 to 12299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12300 => Predicted: 0\n",
      "Row 12301 => Predicted: 1\n",
      "Row 12302 => Predicted: 1\n",
      "Row 12303 => Predicted: 1\n",
      "Row 12304 => Predicted: 0\n",
      "Row 12305 => Predicted: 1\n",
      "Row 12306 => Predicted: 0\n",
      "Row 12307 => Predicted: 1\n",
      "Row 12308 => Predicted: 0\n",
      "Row 12309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12300 to 12309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12310 => Predicted: 0\n",
      "Row 12311 => Predicted: 0\n",
      "Row 12312 => Predicted: 1\n",
      "Row 12313 => Predicted: 0\n",
      "Row 12314 => Predicted: 1\n",
      "Row 12315 => Predicted: 1\n",
      "Row 12316 => Predicted: 1\n",
      "Row 12317 => Predicted: 1\n",
      "Row 12318 => Predicted: 1\n",
      "Row 12319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12310 to 12319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12320 => Predicted: 0\n",
      "Row 12321 => Predicted: 1\n",
      "Row 12322 => Predicted: 0\n",
      "Row 12323 => Predicted: 0\n",
      "Row 12324 => Predicted: 0\n",
      "Row 12325 => Predicted: 0\n",
      "Row 12326 => Predicted: 1\n",
      "Row 12327 => Predicted: 1\n",
      "Row 12328 => Predicted: 1\n",
      "Row 12329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12320 to 12329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12330 => Predicted: 0\n",
      "Row 12331 => Predicted: 1\n",
      "Row 12332 => Predicted: 1\n",
      "Row 12333 => Predicted: 1\n",
      "Row 12334 => Predicted: 1\n",
      "Row 12335 => Predicted: 0\n",
      "Row 12336 => Predicted: 1\n",
      "Row 12337 => Predicted: 1\n",
      "Row 12338 => Predicted: 0\n",
      "Row 12339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12330 to 12339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12340 => Predicted: 1\n",
      "Row 12341 => Predicted: 0\n",
      "Row 12342 => Predicted: 1\n",
      "Row 12343 => Predicted: 0\n",
      "Row 12344 => Predicted: 0\n",
      "Row 12345 => Predicted: 1\n",
      "Row 12346 => Predicted: 0\n",
      "Row 12347 => Predicted: 0\n",
      "Row 12348 => Predicted: 1\n",
      "Row 12349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12340 to 12349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12350 => Predicted: 1\n",
      "Row 12351 => Predicted: 0\n",
      "Row 12352 => Predicted: 1\n",
      "Row 12353 => Predicted: 1\n",
      "Row 12354 => Predicted: 1\n",
      "Row 12355 => Predicted: 1\n",
      "Row 12356 => Predicted: 0\n",
      "Row 12357 => Predicted: 0\n",
      "Row 12358 => Predicted: 1\n",
      "Row 12359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12350 to 12359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12360 => Predicted: 0\n",
      "Row 12361 => Predicted: 1\n",
      "Row 12362 => Predicted: 1\n",
      "Row 12363 => Predicted: 0\n",
      "Row 12364 => Predicted: 1\n",
      "Row 12365 => Predicted: 1\n",
      "Row 12366 => Predicted: 0\n",
      "Row 12367 => Predicted: 1\n",
      "Row 12368 => Predicted: 1\n",
      "Row 12369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12360 to 12369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12370 => Predicted: 1\n",
      "Row 12371 => Predicted: 0\n",
      "Row 12372 => Predicted: 0\n",
      "Row 12373 => Predicted: 0\n",
      "Row 12374 => Predicted: 0\n",
      "Row 12375 => Predicted: 0\n",
      "Row 12376 => Predicted: 0\n",
      "Row 12377 => Predicted: 1\n",
      "Row 12378 => Predicted: 1\n",
      "Row 12379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12370 to 12379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12380 => Predicted: 1\n",
      "Row 12381 => Predicted: 0\n",
      "Row 12382 => Predicted: 0\n",
      "Row 12383 => Predicted: 1\n",
      "Row 12384 => Predicted: 1\n",
      "Row 12385 => Predicted: 0\n",
      "Row 12386 => Predicted: 0\n",
      "Row 12387 => Predicted: 0\n",
      "Row 12388 => Predicted: 0\n",
      "Row 12389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12380 to 12389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12390 => Predicted: 0\n",
      "Row 12391 => Predicted: 0\n",
      "Row 12392 => Predicted: 1\n",
      "Row 12393 => Predicted: 1\n",
      "Row 12394 => Predicted: 0\n",
      "Row 12395 => Predicted: 1\n",
      "Row 12396 => Predicted: 0\n",
      "Row 12397 => Predicted: 1\n",
      "Row 12398 => Predicted: 1\n",
      "Row 12399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12390 to 12399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12400 => Predicted: 1\n",
      "Row 12401 => Predicted: 1\n",
      "Row 12402 => Predicted: 0\n",
      "Row 12403 => Predicted: 1\n",
      "Row 12404 => Predicted: 1\n",
      "Row 12405 => Predicted: 0\n",
      "Row 12406 => Predicted: 1\n",
      "Row 12407 => Predicted: 1\n",
      "Row 12408 => Predicted: 0\n",
      "Row 12409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12400 to 12409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12410 => Predicted: 1\n",
      "Row 12411 => Predicted: 1\n",
      "Row 12412 => Predicted: 0\n",
      "Row 12413 => Predicted: 0\n",
      "Row 12414 => Predicted: 0\n",
      "Row 12415 => Predicted: 1\n",
      "Row 12416 => Predicted: 0\n",
      "Row 12417 => Predicted: 0\n",
      "Row 12418 => Predicted: 1\n",
      "Row 12419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12410 to 12419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12420 => Predicted: 0\n",
      "Row 12421 => Predicted: 1\n",
      "Row 12422 => Predicted: 1\n",
      "Row 12423 => Predicted: 1\n",
      "Row 12424 => Predicted: 1\n",
      "Row 12425 => Predicted: 0\n",
      "Row 12426 => Predicted: 1\n",
      "Row 12427 => Predicted: 1\n",
      "Row 12428 => Predicted: 0\n",
      "Row 12429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12420 to 12429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12430 => Predicted: 0\n",
      "Row 12431 => Predicted: 0\n",
      "Row 12432 => Predicted: 0\n",
      "Row 12433 => Predicted: 0\n",
      "Row 12434 => Predicted: 0\n",
      "Row 12435 => Predicted: 0\n",
      "Row 12436 => Predicted: 1\n",
      "Row 12437 => Predicted: 1\n",
      "Row 12438 => Predicted: 1\n",
      "Row 12439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12430 to 12439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12440 => Predicted: 0\n",
      "Row 12441 => Predicted: 0\n",
      "Row 12442 => Predicted: 1\n",
      "Row 12443 => Predicted: 1\n",
      "Row 12444 => Predicted: 0\n",
      "Row 12445 => Predicted: 1\n",
      "Row 12446 => Predicted: 1\n",
      "Row 12447 => Predicted: 0\n",
      "Row 12448 => Predicted: 1\n",
      "Row 12449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12440 to 12449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12450 => Predicted: 1\n",
      "Row 12451 => Predicted: 0\n",
      "Row 12452 => Predicted: 0\n",
      "Row 12453 => Predicted: 1\n",
      "Row 12454 => Predicted: 1\n",
      "Row 12455 => Predicted: 1\n",
      "Row 12456 => Predicted: 0\n",
      "Row 12457 => Predicted: 0\n",
      "Row 12458 => Predicted: 0\n",
      "Row 12459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12450 to 12459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12460 => Predicted: 1\n",
      "Row 12461 => Predicted: 1\n",
      "Row 12462 => Predicted: 1\n",
      "Row 12463 => Predicted: 0\n",
      "Row 12464 => Predicted: 1\n",
      "Row 12465 => Predicted: 1\n",
      "Row 12466 => Predicted: 1\n",
      "Row 12467 => Predicted: 1\n",
      "Row 12468 => Predicted: 1\n",
      "Row 12469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12460 to 12469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12470 => Predicted: 0\n",
      "Row 12471 => Predicted: 1\n",
      "Row 12472 => Predicted: 1\n",
      "Row 12473 => Predicted: 1\n",
      "Row 12474 => Predicted: 0\n",
      "Row 12475 => Predicted: 1\n",
      "Row 12476 => Predicted: 1\n",
      "Row 12477 => Predicted: 0\n",
      "Row 12478 => Predicted: 1\n",
      "Row 12479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12470 to 12479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12480 => Predicted: 0\n",
      "Row 12481 => Predicted: 0\n",
      "Row 12482 => Predicted: 0\n",
      "Row 12483 => Predicted: 0\n",
      "Row 12484 => Predicted: 1\n",
      "Row 12485 => Predicted: 1\n",
      "Row 12486 => Predicted: 0\n",
      "Row 12487 => Predicted: 0\n",
      "Row 12488 => Predicted: 1\n",
      "Row 12489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12480 to 12489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12490 => Predicted: 0\n",
      "Row 12491 => Predicted: 1\n",
      "Row 12492 => Predicted: 1\n",
      "Row 12493 => Predicted: 0\n",
      "Row 12494 => Predicted: 1\n",
      "Row 12495 => Predicted: 1\n",
      "Row 12496 => Predicted: 1\n",
      "Row 12497 => Predicted: 1\n",
      "Row 12498 => Predicted: 0\n",
      "Row 12499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12490 to 12499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12500 => Predicted: 0\n",
      "Row 12501 => Predicted: 1\n",
      "Row 12502 => Predicted: 0\n",
      "Row 12503 => Predicted: 0\n",
      "Row 12504 => Predicted: 0\n",
      "Row 12505 => Predicted: 1\n",
      "Row 12506 => Predicted: 1\n",
      "Row 12507 => Predicted: 0\n",
      "Row 12508 => Predicted: 1\n",
      "Row 12509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12500 to 12509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12510 => Predicted: 0\n",
      "Row 12511 => Predicted: 1\n",
      "Row 12512 => Predicted: 1\n",
      "Row 12513 => Predicted: 0\n",
      "Row 12514 => Predicted: 0\n",
      "Row 12515 => Predicted: 1\n",
      "Row 12516 => Predicted: 0\n",
      "Row 12517 => Predicted: 0\n",
      "Row 12518 => Predicted: 1\n",
      "Row 12519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12510 to 12519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12520 => Predicted: 1\n",
      "Row 12521 => Predicted: 1\n",
      "Row 12522 => Predicted: 1\n",
      "Row 12523 => Predicted: 0\n",
      "Row 12524 => Predicted: 1\n",
      "Row 12525 => Predicted: 0\n",
      "Row 12526 => Predicted: 1\n",
      "Row 12527 => Predicted: 1\n",
      "Row 12528 => Predicted: 1\n",
      "Row 12529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12520 to 12529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12530 => Predicted: 1\n",
      "Row 12531 => Predicted: 1\n",
      "Row 12532 => Predicted: 0\n",
      "Row 12533 => Predicted: 0\n",
      "Row 12534 => Predicted: 0\n",
      "Row 12535 => Predicted: 1\n",
      "Row 12536 => Predicted: 0\n",
      "Row 12537 => Predicted: 1\n",
      "Row 12538 => Predicted: 0\n",
      "Row 12539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12530 to 12539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12540 => Predicted: 0\n",
      "Row 12541 => Predicted: 1\n",
      "Row 12542 => Predicted: 1\n",
      "Row 12543 => Predicted: 1\n",
      "Row 12544 => Predicted: 0\n",
      "Row 12545 => Predicted: 1\n",
      "Row 12546 => Predicted: 1\n",
      "Row 12547 => Predicted: 0\n",
      "Row 12548 => Predicted: 1\n",
      "Row 12549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12540 to 12549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12550 => Predicted: 1\n",
      "Row 12551 => Predicted: 1\n",
      "Row 12552 => Predicted: 0\n",
      "Row 12553 => Predicted: 0\n",
      "Row 12554 => Predicted: 0\n",
      "Row 12555 => Predicted: 0\n",
      "Row 12556 => Predicted: 0\n",
      "Row 12557 => Predicted: 0\n",
      "Row 12558 => Predicted: 1\n",
      "Row 12559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12550 to 12559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12560 => Predicted: 1\n",
      "Row 12561 => Predicted: 0\n",
      "Row 12562 => Predicted: 1\n",
      "Row 12563 => Predicted: 0\n",
      "Row 12564 => Predicted: 0\n",
      "Row 12565 => Predicted: 0\n",
      "Row 12566 => Predicted: 0\n",
      "Row 12567 => Predicted: 0\n",
      "Row 12568 => Predicted: 0\n",
      "Row 12569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12560 to 12569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12570 => Predicted: 0\n",
      "Row 12571 => Predicted: 1\n",
      "Row 12572 => Predicted: 0\n",
      "Row 12573 => Predicted: 1\n",
      "Row 12574 => Predicted: 1\n",
      "Row 12575 => Predicted: 1\n",
      "Row 12576 => Predicted: 1\n",
      "Row 12577 => Predicted: 1\n",
      "Row 12578 => Predicted: 1\n",
      "Row 12579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12570 to 12579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12580 => Predicted: 0\n",
      "Row 12581 => Predicted: 1\n",
      "Row 12582 => Predicted: 1\n",
      "Row 12583 => Predicted: 0\n",
      "Row 12584 => Predicted: 1\n",
      "Row 12585 => Predicted: 1\n",
      "Row 12586 => Predicted: 0\n",
      "Row 12587 => Predicted: 0\n",
      "Row 12588 => Predicted: 0\n",
      "Row 12589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12580 to 12589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12590 => Predicted: 1\n",
      "Row 12591 => Predicted: 1\n",
      "Row 12592 => Predicted: 0\n",
      "Row 12593 => Predicted: 0\n",
      "Row 12594 => Predicted: 1\n",
      "Row 12595 => Predicted: 0\n",
      "Row 12596 => Predicted: 1\n",
      "Row 12597 => Predicted: 0\n",
      "Row 12598 => Predicted: 0\n",
      "Row 12599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12590 to 12599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12600 => Predicted: 1\n",
      "Row 12601 => Predicted: 0\n",
      "Row 12602 => Predicted: 1\n",
      "Row 12603 => Predicted: 0\n",
      "Row 12604 => Predicted: 1\n",
      "Row 12605 => Predicted: 1\n",
      "Row 12606 => Predicted: 1\n",
      "Row 12607 => Predicted: 0\n",
      "Row 12608 => Predicted: 0\n",
      "Row 12609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12600 to 12609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12610 => Predicted: 1\n",
      "Row 12611 => Predicted: 0\n",
      "Row 12612 => Predicted: 1\n",
      "Row 12613 => Predicted: 0\n",
      "Row 12614 => Predicted: 1\n",
      "Row 12615 => Predicted: 1\n",
      "Row 12616 => Predicted: 0\n",
      "Row 12617 => Predicted: 0\n",
      "Row 12618 => Predicted: 1\n",
      "Row 12619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12610 to 12619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12620 => Predicted: 0\n",
      "Row 12621 => Predicted: 0\n",
      "Row 12622 => Predicted: 0\n",
      "Row 12623 => Predicted: 0\n",
      "Row 12624 => Predicted: 1\n",
      "Row 12625 => Predicted: 1\n",
      "Row 12626 => Predicted: 0\n",
      "Row 12627 => Predicted: 1\n",
      "Row 12628 => Predicted: 1\n",
      "Row 12629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12620 to 12629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12630 => Predicted: 1\n",
      "Row 12631 => Predicted: 1\n",
      "Row 12632 => Predicted: 1\n",
      "Row 12633 => Predicted: 1\n",
      "Row 12634 => Predicted: 1\n",
      "Row 12635 => Predicted: 1\n",
      "Row 12636 => Predicted: 0\n",
      "Row 12637 => Predicted: 0\n",
      "Row 12638 => Predicted: 1\n",
      "Row 12639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12630 to 12639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12640 => Predicted: 0\n",
      "Row 12641 => Predicted: 1\n",
      "Row 12642 => Predicted: 1\n",
      "Row 12643 => Predicted: 0\n",
      "Row 12644 => Predicted: 0\n",
      "Row 12645 => Predicted: 1\n",
      "Row 12646 => Predicted: 1\n",
      "Row 12647 => Predicted: 1\n",
      "Row 12648 => Predicted: 0\n",
      "Row 12649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12640 to 12649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12650 => Predicted: 0\n",
      "Row 12651 => Predicted: 1\n",
      "Row 12652 => Predicted: 0\n",
      "Row 12653 => Predicted: 1\n",
      "Row 12654 => Predicted: 0\n",
      "Row 12655 => Predicted: 0\n",
      "Row 12656 => Predicted: 0\n",
      "Row 12657 => Predicted: 1\n",
      "Row 12658 => Predicted: 1\n",
      "Row 12659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12650 to 12659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12660 => Predicted: 0\n",
      "Row 12661 => Predicted: 1\n",
      "Row 12662 => Predicted: 1\n",
      "Row 12663 => Predicted: 0\n",
      "Row 12664 => Predicted: 1\n",
      "Row 12665 => Predicted: 1\n",
      "Row 12666 => Predicted: 0\n",
      "Row 12667 => Predicted: 1\n",
      "Row 12668 => Predicted: 0\n",
      "Row 12669 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12660 to 12669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12670 => Predicted: 0\n",
      "Row 12671 => Predicted: 0\n",
      "Row 12672 => Predicted: 0\n",
      "Row 12673 => Predicted: 0\n",
      "Row 12674 => Predicted: 1\n",
      "Row 12675 => Predicted: 1\n",
      "Row 12676 => Predicted: 0\n",
      "Row 12677 => Predicted: 0\n",
      "Row 12678 => Predicted: 0\n",
      "Row 12679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12670 to 12679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12680 => Predicted: 1\n",
      "Row 12681 => Predicted: 0\n",
      "Row 12682 => Predicted: 0\n",
      "Row 12683 => Predicted: 1\n",
      "Row 12684 => Predicted: 0\n",
      "Row 12685 => Predicted: 1\n",
      "Row 12686 => Predicted: 0\n",
      "Row 12687 => Predicted: 1\n",
      "Row 12688 => Predicted: 0\n",
      "Row 12689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12680 to 12689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12690 => Predicted: 0\n",
      "Row 12691 => Predicted: 0\n",
      "Row 12692 => Predicted: 1\n",
      "Row 12693 => Predicted: 1\n",
      "Row 12694 => Predicted: 0\n",
      "Row 12695 => Predicted: 1\n",
      "Row 12696 => Predicted: 0\n",
      "Row 12697 => Predicted: 0\n",
      "Row 12698 => Predicted: 0\n",
      "Row 12699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12690 to 12699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12700 => Predicted: 1\n",
      "Row 12701 => Predicted: 0\n",
      "Row 12702 => Predicted: 0\n",
      "Row 12703 => Predicted: 1\n",
      "Row 12704 => Predicted: 0\n",
      "Row 12705 => Predicted: 0\n",
      "Row 12706 => Predicted: 1\n",
      "Row 12707 => Predicted: 1\n",
      "Row 12708 => Predicted: 0\n",
      "Row 12709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12700 to 12709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12710 => Predicted: 1\n",
      "Row 12711 => Predicted: 0\n",
      "Row 12712 => Predicted: 0\n",
      "Row 12713 => Predicted: 1\n",
      "Row 12714 => Predicted: 1\n",
      "Row 12715 => Predicted: 1\n",
      "Row 12716 => Predicted: 0\n",
      "Row 12717 => Predicted: 0\n",
      "Row 12718 => Predicted: 1\n",
      "Row 12719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12710 to 12719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12720 => Predicted: 1\n",
      "Row 12721 => Predicted: 0\n",
      "Row 12722 => Predicted: 0\n",
      "Row 12723 => Predicted: 1\n",
      "Row 12724 => Predicted: 1\n",
      "Row 12725 => Predicted: 1\n",
      "Row 12726 => Predicted: 1\n",
      "Row 12727 => Predicted: 1\n",
      "Row 12728 => Predicted: 1\n",
      "Row 12729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12720 to 12729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12730 => Predicted: 1\n",
      "Row 12731 => Predicted: 1\n",
      "Row 12732 => Predicted: 1\n",
      "Row 12733 => Predicted: 1\n",
      "Row 12734 => Predicted: 1\n",
      "Row 12735 => Predicted: 1\n",
      "Row 12736 => Predicted: 0\n",
      "Row 12737 => Predicted: 1\n",
      "Row 12738 => Predicted: 1\n",
      "Row 12739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12730 to 12739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12740 => Predicted: 0\n",
      "Row 12741 => Predicted: 0\n",
      "Row 12742 => Predicted: 0\n",
      "Row 12743 => Predicted: 1\n",
      "Row 12744 => Predicted: 0\n",
      "Row 12745 => Predicted: 0\n",
      "Row 12746 => Predicted: 0\n",
      "Row 12747 => Predicted: 1\n",
      "Row 12748 => Predicted: 0\n",
      "Row 12749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12740 to 12749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12750 => Predicted: 0\n",
      "Row 12751 => Predicted: 0\n",
      "Row 12752 => Predicted: 1\n",
      "Row 12753 => Predicted: 0\n",
      "Row 12754 => Predicted: 1\n",
      "Row 12755 => Predicted: 1\n",
      "Row 12756 => Predicted: 1\n",
      "Row 12757 => Predicted: 1\n",
      "Row 12758 => Predicted: 1\n",
      "Row 12759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12750 to 12759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12760 => Predicted: 1\n",
      "Row 12761 => Predicted: 1\n",
      "Row 12762 => Predicted: 0\n",
      "Row 12763 => Predicted: 1\n",
      "Row 12764 => Predicted: 0\n",
      "Row 12765 => Predicted: 1\n",
      "Row 12766 => Predicted: 0\n",
      "Row 12767 => Predicted: 1\n",
      "Row 12768 => Predicted: 1\n",
      "Row 12769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12760 to 12769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12770 => Predicted: 1\n",
      "Row 12771 => Predicted: 0\n",
      "Row 12772 => Predicted: 0\n",
      "Row 12773 => Predicted: 0\n",
      "Row 12774 => Predicted: 1\n",
      "Row 12775 => Predicted: 0\n",
      "Row 12776 => Predicted: 0\n",
      "Row 12777 => Predicted: 0\n",
      "Row 12778 => Predicted: 0\n",
      "Row 12779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12770 to 12779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12780 => Predicted: 1\n",
      "Row 12781 => Predicted: 1\n",
      "Row 12782 => Predicted: 1\n",
      "Row 12783 => Predicted: 1\n",
      "Row 12784 => Predicted: 0\n",
      "Row 12785 => Predicted: 1\n",
      "Row 12786 => Predicted: 1\n",
      "Row 12787 => Predicted: 1\n",
      "Row 12788 => Predicted: 1\n",
      "Row 12789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12780 to 12789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12790 => Predicted: 1\n",
      "Row 12791 => Predicted: 1\n",
      "Row 12792 => Predicted: 0\n",
      "Row 12793 => Predicted: 0\n",
      "Row 12794 => Predicted: 1\n",
      "Row 12795 => Predicted: 1\n",
      "Row 12796 => Predicted: 1\n",
      "Row 12797 => Predicted: 0\n",
      "Row 12798 => Predicted: 0\n",
      "Row 12799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12790 to 12799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12800 => Predicted: 1\n",
      "Row 12801 => Predicted: 0\n",
      "Row 12802 => Predicted: 1\n",
      "Row 12803 => Predicted: 1\n",
      "Row 12804 => Predicted: 1\n",
      "Row 12805 => Predicted: 1\n",
      "Row 12806 => Predicted: 0\n",
      "Row 12807 => Predicted: 0\n",
      "Row 12808 => Predicted: 1\n",
      "Row 12809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12800 to 12809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12810 => Predicted: 0\n",
      "Row 12811 => Predicted: 1\n",
      "Row 12812 => Predicted: 1\n",
      "Row 12813 => Predicted: 1\n",
      "Row 12814 => Predicted: 1\n",
      "Row 12815 => Predicted: 0\n",
      "Row 12816 => Predicted: 1\n",
      "Row 12817 => Predicted: 1\n",
      "Row 12818 => Predicted: 1\n",
      "Row 12819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12810 to 12819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12820 => Predicted: 1\n",
      "Row 12821 => Predicted: 0\n",
      "Row 12822 => Predicted: 0\n",
      "Row 12823 => Predicted: 1\n",
      "Row 12824 => Predicted: 0\n",
      "Row 12825 => Predicted: 1\n",
      "Row 12826 => Predicted: 0\n",
      "Row 12827 => Predicted: 0\n",
      "Row 12828 => Predicted: 0\n",
      "Row 12829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12820 to 12829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12830 => Predicted: 1\n",
      "Row 12831 => Predicted: 1\n",
      "Row 12832 => Predicted: 1\n",
      "Row 12833 => Predicted: 0\n",
      "Row 12834 => Predicted: 1\n",
      "Row 12835 => Predicted: 1\n",
      "Row 12836 => Predicted: 0\n",
      "Row 12837 => Predicted: 0\n",
      "Row 12838 => Predicted: 0\n",
      "Row 12839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12830 to 12839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12840 => Predicted: 1\n",
      "Row 12841 => Predicted: 1\n",
      "Row 12842 => Predicted: 0\n",
      "Row 12843 => Predicted: 1\n",
      "Row 12844 => Predicted: 0\n",
      "Row 12845 => Predicted: 1\n",
      "Row 12846 => Predicted: 1\n",
      "Row 12847 => Predicted: 0\n",
      "Row 12848 => Predicted: 0\n",
      "Row 12849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12840 to 12849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12850 => Predicted: 0\n",
      "Row 12851 => Predicted: 0\n",
      "Row 12852 => Predicted: 1\n",
      "Row 12853 => Predicted: 1\n",
      "Row 12854 => Predicted: 1\n",
      "Row 12855 => Predicted: 1\n",
      "Row 12856 => Predicted: 1\n",
      "Row 12857 => Predicted: 0\n",
      "Row 12858 => Predicted: 0\n",
      "Row 12859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12850 to 12859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12860 => Predicted: 1\n",
      "Row 12861 => Predicted: 0\n",
      "Row 12862 => Predicted: 0\n",
      "Row 12863 => Predicted: 0\n",
      "Row 12864 => Predicted: 0\n",
      "Row 12865 => Predicted: 1\n",
      "Row 12866 => Predicted: 0\n",
      "Row 12867 => Predicted: 1\n",
      "Row 12868 => Predicted: 1\n",
      "Row 12869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12860 to 12869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12870 => Predicted: 1\n",
      "Row 12871 => Predicted: 1\n",
      "Row 12872 => Predicted: 1\n",
      "Row 12873 => Predicted: 1\n",
      "Row 12874 => Predicted: 0\n",
      "Row 12875 => Predicted: 1\n",
      "Row 12876 => Predicted: 0\n",
      "Row 12877 => Predicted: 1\n",
      "Row 12878 => Predicted: 1\n",
      "Row 12879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12870 to 12879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12880 => Predicted: 0\n",
      "Row 12881 => Predicted: 1\n",
      "Row 12882 => Predicted: 0\n",
      "Row 12883 => Predicted: 1\n",
      "Row 12884 => Predicted: 1\n",
      "Row 12885 => Predicted: 0\n",
      "Row 12886 => Predicted: 1\n",
      "Row 12887 => Predicted: 0\n",
      "Row 12888 => Predicted: 0\n",
      "Row 12889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12880 to 12889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12890 => Predicted: 1\n",
      "Row 12891 => Predicted: 1\n",
      "Row 12892 => Predicted: 0\n",
      "Row 12893 => Predicted: 1\n",
      "Row 12894 => Predicted: 0\n",
      "Row 12895 => Predicted: 1\n",
      "Row 12896 => Predicted: 0\n",
      "Row 12897 => Predicted: 0\n",
      "Row 12898 => Predicted: 1\n",
      "Row 12899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12890 to 12899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12900 => Predicted: 0\n",
      "Row 12901 => Predicted: 1\n",
      "Row 12902 => Predicted: 1\n",
      "Row 12903 => Predicted: 0\n",
      "Row 12904 => Predicted: 0\n",
      "Row 12905 => Predicted: 1\n",
      "Row 12906 => Predicted: 1\n",
      "Row 12907 => Predicted: 1\n",
      "Row 12908 => Predicted: 0\n",
      "Row 12909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12900 to 12909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12910 => Predicted: 1\n",
      "Row 12911 => Predicted: 1\n",
      "Row 12912 => Predicted: 0\n",
      "Row 12913 => Predicted: 0\n",
      "Row 12914 => Predicted: 1\n",
      "Row 12915 => Predicted: 0\n",
      "Row 12916 => Predicted: 0\n",
      "Row 12917 => Predicted: 0\n",
      "Row 12918 => Predicted: 0\n",
      "Row 12919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12910 to 12919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12920 => Predicted: 1\n",
      "Row 12921 => Predicted: 1\n",
      "Row 12922 => Predicted: 0\n",
      "Row 12923 => Predicted: 1\n",
      "Row 12924 => Predicted: 0\n",
      "Row 12925 => Predicted: 1\n",
      "Row 12926 => Predicted: 0\n",
      "Row 12927 => Predicted: 0\n",
      "Row 12928 => Predicted: 1\n",
      "Row 12929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12920 to 12929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12930 => Predicted: 0\n",
      "Row 12931 => Predicted: 1\n",
      "Row 12932 => Predicted: 0\n",
      "Row 12933 => Predicted: 1\n",
      "Row 12934 => Predicted: 0\n",
      "Row 12935 => Predicted: 0\n",
      "Row 12936 => Predicted: 1\n",
      "Row 12937 => Predicted: 0\n",
      "Row 12938 => Predicted: 1\n",
      "Row 12939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12930 to 12939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12940 => Predicted: 0\n",
      "Row 12941 => Predicted: 0\n",
      "Row 12942 => Predicted: 1\n",
      "Row 12943 => Predicted: 1\n",
      "Row 12944 => Predicted: 1\n",
      "Row 12945 => Predicted: 1\n",
      "Row 12946 => Predicted: 1\n",
      "Row 12947 => Predicted: 1\n",
      "Row 12948 => Predicted: 1\n",
      "Row 12949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12940 to 12949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12950 => Predicted: 0\n",
      "Row 12951 => Predicted: 0\n",
      "Row 12952 => Predicted: 1\n",
      "Row 12953 => Predicted: 1\n",
      "Row 12954 => Predicted: 1\n",
      "Row 12955 => Predicted: 1\n",
      "Row 12956 => Predicted: 0\n",
      "Row 12957 => Predicted: 0\n",
      "Row 12958 => Predicted: 0\n",
      "Row 12959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12950 to 12959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12960 => Predicted: 0\n",
      "Row 12961 => Predicted: 0\n",
      "Row 12962 => Predicted: 0\n",
      "Row 12963 => Predicted: 0\n",
      "Row 12964 => Predicted: 0\n",
      "Row 12965 => Predicted: 1\n",
      "Row 12966 => Predicted: 0\n",
      "Row 12967 => Predicted: 0\n",
      "Row 12968 => Predicted: 0\n",
      "Row 12969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12960 to 12969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12970 => Predicted: 1\n",
      "Row 12971 => Predicted: 1\n",
      "Row 12972 => Predicted: 0\n",
      "Row 12973 => Predicted: 0\n",
      "Row 12974 => Predicted: 1\n",
      "Row 12975 => Predicted: 0\n",
      "Row 12976 => Predicted: 0\n",
      "Row 12977 => Predicted: 0\n",
      "Row 12978 => Predicted: 1\n",
      "Row 12979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12970 to 12979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12980 => Predicted: 0\n",
      "Row 12981 => Predicted: 0\n",
      "Row 12982 => Predicted: 0\n",
      "Row 12983 => Predicted: 1\n",
      "Row 12984 => Predicted: 1\n",
      "Row 12985 => Predicted: 1\n",
      "Row 12986 => Predicted: 0\n",
      "Row 12987 => Predicted: 0\n",
      "Row 12988 => Predicted: 1\n",
      "Row 12989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 12980 to 12989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12990 => Predicted: 0\n",
      "Row 12991 => Predicted: 1\n",
      "Row 12992 => Predicted: 1\n",
      "Row 12993 => Predicted: 0\n",
      "Row 12994 => Predicted: 0\n",
      "Row 12995 => Predicted: 1\n",
      "Row 12996 => Predicted: 1\n",
      "Row 12997 => Predicted: 1\n",
      "Row 12998 => Predicted: 1\n",
      "Row 12999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 12990 to 12999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13000 => Predicted: 0\n",
      "Row 13001 => Predicted: 0\n",
      "Row 13002 => Predicted: 0\n",
      "Row 13003 => Predicted: 0\n",
      "Row 13004 => Predicted: 1\n",
      "Row 13005 => Predicted: 1\n",
      "Row 13006 => Predicted: 1\n",
      "Row 13007 => Predicted: 0\n",
      "Row 13008 => Predicted: 1\n",
      "Row 13009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13000 to 13009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13010 => Predicted: 1\n",
      "Row 13011 => Predicted: 1\n",
      "Row 13012 => Predicted: 0\n",
      "Row 13013 => Predicted: 1\n",
      "Row 13014 => Predicted: 1\n",
      "Row 13015 => Predicted: 0\n",
      "Row 13016 => Predicted: 1\n",
      "Row 13017 => Predicted: 1\n",
      "Row 13018 => Predicted: 0\n",
      "Row 13019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13010 to 13019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13020 => Predicted: 1\n",
      "Row 13021 => Predicted: 1\n",
      "Row 13022 => Predicted: 1\n",
      "Row 13023 => Predicted: 1\n",
      "Row 13024 => Predicted: 0\n",
      "Row 13025 => Predicted: 1\n",
      "Row 13026 => Predicted: 0\n",
      "Row 13027 => Predicted: 0\n",
      "Row 13028 => Predicted: 0\n",
      "Row 13029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13020 to 13029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13030 => Predicted: 0\n",
      "Row 13031 => Predicted: 0\n",
      "Row 13032 => Predicted: 1\n",
      "Row 13033 => Predicted: 0\n",
      "Row 13034 => Predicted: 0\n",
      "Row 13035 => Predicted: 0\n",
      "Row 13036 => Predicted: 0\n",
      "Row 13037 => Predicted: 0\n",
      "Row 13038 => Predicted: 1\n",
      "Row 13039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13030 to 13039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13040 => Predicted: 1\n",
      "Row 13041 => Predicted: 0\n",
      "Row 13042 => Predicted: 1\n",
      "Row 13043 => Predicted: 0\n",
      "Row 13044 => Predicted: 0\n",
      "Row 13045 => Predicted: 0\n",
      "Row 13046 => Predicted: 0\n",
      "Row 13047 => Predicted: 0\n",
      "Row 13048 => Predicted: 1\n",
      "Row 13049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13040 to 13049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13050 => Predicted: 1\n",
      "Row 13051 => Predicted: 1\n",
      "Row 13052 => Predicted: 0\n",
      "Row 13053 => Predicted: 1\n",
      "Row 13054 => Predicted: 1\n",
      "Row 13055 => Predicted: 1\n",
      "Row 13056 => Predicted: 1\n",
      "Row 13057 => Predicted: 1\n",
      "Row 13058 => Predicted: 0\n",
      "Row 13059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13050 to 13059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13060 => Predicted: 0\n",
      "Row 13061 => Predicted: 0\n",
      "Row 13062 => Predicted: 0\n",
      "Row 13063 => Predicted: 1\n",
      "Row 13064 => Predicted: 0\n",
      "Row 13065 => Predicted: 0\n",
      "Row 13066 => Predicted: 1\n",
      "Row 13067 => Predicted: 0\n",
      "Row 13068 => Predicted: 0\n",
      "Row 13069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13060 to 13069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13070 => Predicted: 0\n",
      "Row 13071 => Predicted: 1\n",
      "Row 13072 => Predicted: 0\n",
      "Row 13073 => Predicted: 0\n",
      "Row 13074 => Predicted: 1\n",
      "Row 13075 => Predicted: 1\n",
      "Row 13076 => Predicted: 1\n",
      "Row 13077 => Predicted: 0\n",
      "Row 13078 => Predicted: 1\n",
      "Row 13079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13070 to 13079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13080 => Predicted: 0\n",
      "Row 13081 => Predicted: 1\n",
      "Row 13082 => Predicted: 0\n",
      "Row 13083 => Predicted: 1\n",
      "Row 13084 => Predicted: 0\n",
      "Row 13085 => Predicted: 1\n",
      "Row 13086 => Predicted: 0\n",
      "Row 13087 => Predicted: 0\n",
      "Row 13088 => Predicted: 1\n",
      "Row 13089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13080 to 13089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13090 => Predicted: 1\n",
      "Row 13091 => Predicted: 0\n",
      "Row 13092 => Predicted: 1\n",
      "Row 13093 => Predicted: 1\n",
      "Row 13094 => Predicted: 1\n",
      "Row 13095 => Predicted: 1\n",
      "Row 13096 => Predicted: 0\n",
      "Row 13097 => Predicted: 1\n",
      "Row 13098 => Predicted: 0\n",
      "Row 13099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13090 to 13099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13100 => Predicted: 0\n",
      "Row 13101 => Predicted: 1\n",
      "Row 13102 => Predicted: 0\n",
      "Row 13103 => Predicted: 1\n",
      "Row 13104 => Predicted: 1\n",
      "Row 13105 => Predicted: 0\n",
      "Row 13106 => Predicted: 0\n",
      "Row 13107 => Predicted: 0\n",
      "Row 13108 => Predicted: 0\n",
      "Row 13109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13100 to 13109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13110 => Predicted: 0\n",
      "Row 13111 => Predicted: 0\n",
      "Row 13112 => Predicted: 1\n",
      "Row 13113 => Predicted: 0\n",
      "Row 13114 => Predicted: 0\n",
      "Row 13115 => Predicted: 0\n",
      "Row 13116 => Predicted: 1\n",
      "Row 13117 => Predicted: 1\n",
      "Row 13118 => Predicted: 1\n",
      "Row 13119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13110 to 13119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13120 => Predicted: 1\n",
      "Row 13121 => Predicted: 0\n",
      "Row 13122 => Predicted: 1\n",
      "Row 13123 => Predicted: 1\n",
      "Row 13124 => Predicted: 0\n",
      "Row 13125 => Predicted: 0\n",
      "Row 13126 => Predicted: 0\n",
      "Row 13127 => Predicted: 0\n",
      "Row 13128 => Predicted: 1\n",
      "Row 13129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13120 to 13129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13130 => Predicted: 1\n",
      "Row 13131 => Predicted: 0\n",
      "Row 13132 => Predicted: 0\n",
      "Row 13133 => Predicted: 1\n",
      "Row 13134 => Predicted: 1\n",
      "Row 13135 => Predicted: 0\n",
      "Row 13136 => Predicted: 1\n",
      "Row 13137 => Predicted: 0\n",
      "Row 13138 => Predicted: 0\n",
      "Row 13139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13130 to 13139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13140 => Predicted: 1\n",
      "Row 13141 => Predicted: 0\n",
      "Row 13142 => Predicted: 1\n",
      "Row 13143 => Predicted: 0\n",
      "Row 13144 => Predicted: 1\n",
      "Row 13145 => Predicted: 1\n",
      "Row 13146 => Predicted: 1\n",
      "Row 13147 => Predicted: 1\n",
      "Row 13148 => Predicted: 0\n",
      "Row 13149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13140 to 13149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13150 => Predicted: 0\n",
      "Row 13151 => Predicted: 0\n",
      "Row 13152 => Predicted: 1\n",
      "Row 13153 => Predicted: 0\n",
      "Row 13154 => Predicted: 1\n",
      "Row 13155 => Predicted: 0\n",
      "Row 13156 => Predicted: 1\n",
      "Row 13157 => Predicted: 1\n",
      "Row 13158 => Predicted: 1\n",
      "Row 13159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13150 to 13159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13160 => Predicted: 0\n",
      "Row 13161 => Predicted: 0\n",
      "Row 13162 => Predicted: 0\n",
      "Row 13163 => Predicted: 1\n",
      "Row 13164 => Predicted: 1\n",
      "Row 13165 => Predicted: 1\n",
      "Row 13166 => Predicted: 0\n",
      "Row 13167 => Predicted: 0\n",
      "Row 13168 => Predicted: 0\n",
      "Row 13169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13160 to 13169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13170 => Predicted: 0\n",
      "Row 13171 => Predicted: 1\n",
      "Row 13172 => Predicted: 1\n",
      "Row 13173 => Predicted: 0\n",
      "Row 13174 => Predicted: 0\n",
      "Row 13175 => Predicted: 1\n",
      "Row 13176 => Predicted: 0\n",
      "Row 13177 => Predicted: 0\n",
      "Row 13178 => Predicted: 1\n",
      "Row 13179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13170 to 13179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13180 => Predicted: 1\n",
      "Row 13181 => Predicted: 1\n",
      "Row 13182 => Predicted: 0\n",
      "Row 13183 => Predicted: 0\n",
      "Row 13184 => Predicted: 0\n",
      "Row 13185 => Predicted: 0\n",
      "Row 13186 => Predicted: 0\n",
      "Row 13187 => Predicted: 1\n",
      "Row 13188 => Predicted: 0\n",
      "Row 13189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13180 to 13189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13190 => Predicted: 0\n",
      "Row 13191 => Predicted: 1\n",
      "Row 13192 => Predicted: 0\n",
      "Row 13193 => Predicted: 1\n",
      "Row 13194 => Predicted: 0\n",
      "Row 13195 => Predicted: 1\n",
      "Row 13196 => Predicted: 1\n",
      "Row 13197 => Predicted: 0\n",
      "Row 13198 => Predicted: 1\n",
      "Row 13199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13190 to 13199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13200 => Predicted: 0\n",
      "Row 13201 => Predicted: 1\n",
      "Row 13202 => Predicted: 1\n",
      "Row 13203 => Predicted: 0\n",
      "Row 13204 => Predicted: 1\n",
      "Row 13205 => Predicted: 1\n",
      "Row 13206 => Predicted: 0\n",
      "Row 13207 => Predicted: 0\n",
      "Row 13208 => Predicted: 1\n",
      "Row 13209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13200 to 13209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13210 => Predicted: 0\n",
      "Row 13211 => Predicted: 1\n",
      "Row 13212 => Predicted: 0\n",
      "Row 13213 => Predicted: 0\n",
      "Row 13214 => Predicted: 1\n",
      "Row 13215 => Predicted: 1\n",
      "Row 13216 => Predicted: 0\n",
      "Row 13217 => Predicted: 1\n",
      "Row 13218 => Predicted: 0\n",
      "Row 13219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13210 to 13219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13220 => Predicted: 1\n",
      "Row 13221 => Predicted: 0\n",
      "Row 13222 => Predicted: 0\n",
      "Row 13223 => Predicted: 0\n",
      "Row 13224 => Predicted: 0\n",
      "Row 13225 => Predicted: 1\n",
      "Row 13226 => Predicted: 1\n",
      "Row 13227 => Predicted: 0\n",
      "Row 13228 => Predicted: 0\n",
      "Row 13229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13220 to 13229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13230 => Predicted: 0\n",
      "Row 13231 => Predicted: 1\n",
      "Row 13232 => Predicted: 0\n",
      "Row 13233 => Predicted: 1\n",
      "Row 13234 => Predicted: 1\n",
      "Row 13235 => Predicted: 0\n",
      "Row 13236 => Predicted: 1\n",
      "Row 13237 => Predicted: 1\n",
      "Row 13238 => Predicted: 0\n",
      "Row 13239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13230 to 13239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13240 => Predicted: 1\n",
      "Row 13241 => Predicted: 0\n",
      "Row 13242 => Predicted: 1\n",
      "Row 13243 => Predicted: 0\n",
      "Row 13244 => Predicted: 0\n",
      "Row 13245 => Predicted: 0\n",
      "Row 13246 => Predicted: 1\n",
      "Row 13247 => Predicted: 1\n",
      "Row 13248 => Predicted: 1\n",
      "Row 13249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13240 to 13249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13250 => Predicted: 0\n",
      "Row 13251 => Predicted: 0\n",
      "Row 13252 => Predicted: 1\n",
      "Row 13253 => Predicted: 1\n",
      "Row 13254 => Predicted: 1\n",
      "Row 13255 => Predicted: 0\n",
      "Row 13256 => Predicted: 0\n",
      "Row 13257 => Predicted: 0\n",
      "Row 13258 => Predicted: 1\n",
      "Row 13259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13250 to 13259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13260 => Predicted: 0\n",
      "Row 13261 => Predicted: 1\n",
      "Row 13262 => Predicted: 1\n",
      "Row 13263 => Predicted: 1\n",
      "Row 13264 => Predicted: 0\n",
      "Row 13265 => Predicted: 1\n",
      "Row 13266 => Predicted: 0\n",
      "Row 13267 => Predicted: 1\n",
      "Row 13268 => Predicted: 1\n",
      "Row 13269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13260 to 13269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13270 => Predicted: 0\n",
      "Row 13271 => Predicted: 1\n",
      "Row 13272 => Predicted: 0\n",
      "Row 13273 => Predicted: 1\n",
      "Row 13274 => Predicted: 0\n",
      "Row 13275 => Predicted: 0\n",
      "Row 13276 => Predicted: 1\n",
      "Row 13277 => Predicted: 1\n",
      "Row 13278 => Predicted: 1\n",
      "Row 13279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13270 to 13279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13280 => Predicted: 1\n",
      "Row 13281 => Predicted: 1\n",
      "Row 13282 => Predicted: 0\n",
      "Row 13283 => Predicted: 1\n",
      "Row 13284 => Predicted: 0\n",
      "Row 13285 => Predicted: 1\n",
      "Row 13286 => Predicted: 0\n",
      "Row 13287 => Predicted: 1\n",
      "Row 13288 => Predicted: 1\n",
      "Row 13289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13280 to 13289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13290 => Predicted: 0\n",
      "Row 13291 => Predicted: 1\n",
      "Row 13292 => Predicted: 0\n",
      "Row 13293 => Predicted: 0\n",
      "Row 13294 => Predicted: 1\n",
      "Row 13295 => Predicted: 0\n",
      "Row 13296 => Predicted: 0\n",
      "Row 13297 => Predicted: 1\n",
      "Row 13298 => Predicted: 1\n",
      "Row 13299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13290 to 13299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13300 => Predicted: 1\n",
      "Row 13301 => Predicted: 1\n",
      "Row 13302 => Predicted: 0\n",
      "Row 13303 => Predicted: 0\n",
      "Row 13304 => Predicted: 1\n",
      "Row 13305 => Predicted: 0\n",
      "Row 13306 => Predicted: 0\n",
      "Row 13307 => Predicted: 0\n",
      "Row 13308 => Predicted: 0\n",
      "Row 13309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13300 to 13309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13310 => Predicted: 0\n",
      "Row 13311 => Predicted: 1\n",
      "Row 13312 => Predicted: 0\n",
      "Row 13313 => Predicted: 1\n",
      "Row 13314 => Predicted: 0\n",
      "Row 13315 => Predicted: 1\n",
      "Row 13316 => Predicted: 1\n",
      "Row 13317 => Predicted: 0\n",
      "Row 13318 => Predicted: 1\n",
      "Row 13319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13310 to 13319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13320 => Predicted: 1\n",
      "Row 13321 => Predicted: 0\n",
      "Row 13322 => Predicted: 1\n",
      "Row 13323 => Predicted: 0\n",
      "Row 13324 => Predicted: 0\n",
      "Row 13325 => Predicted: 0\n",
      "Row 13326 => Predicted: 1\n",
      "Row 13327 => Predicted: 1\n",
      "Row 13328 => Predicted: 1\n",
      "Row 13329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13320 to 13329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13330 => Predicted: 1\n",
      "Row 13331 => Predicted: 0\n",
      "Row 13332 => Predicted: 0\n",
      "Row 13333 => Predicted: 0\n",
      "Row 13334 => Predicted: 1\n",
      "Row 13335 => Predicted: 1\n",
      "Row 13336 => Predicted: 1\n",
      "Row 13337 => Predicted: 0\n",
      "Row 13338 => Predicted: 0\n",
      "Row 13339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13330 to 13339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13340 => Predicted: 1\n",
      "Row 13341 => Predicted: 0\n",
      "Row 13342 => Predicted: 0\n",
      "Row 13343 => Predicted: 0\n",
      "Row 13344 => Predicted: 0\n",
      "Row 13345 => Predicted: 0\n",
      "Row 13346 => Predicted: 0\n",
      "Row 13347 => Predicted: 0\n",
      "Row 13348 => Predicted: 0\n",
      "Row 13349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13340 to 13349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13350 => Predicted: 1\n",
      "Row 13351 => Predicted: 0\n",
      "Row 13352 => Predicted: 1\n",
      "Row 13353 => Predicted: 1\n",
      "Row 13354 => Predicted: 1\n",
      "Row 13355 => Predicted: 0\n",
      "Row 13356 => Predicted: 0\n",
      "Row 13357 => Predicted: 1\n",
      "Row 13358 => Predicted: 1\n",
      "Row 13359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13350 to 13359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13360 => Predicted: 0\n",
      "Row 13361 => Predicted: 1\n",
      "Row 13362 => Predicted: 1\n",
      "Row 13363 => Predicted: 1\n",
      "Row 13364 => Predicted: 0\n",
      "Row 13365 => Predicted: 0\n",
      "Row 13366 => Predicted: 0\n",
      "Row 13367 => Predicted: 0\n",
      "Row 13368 => Predicted: 1\n",
      "Row 13369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13360 to 13369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13370 => Predicted: 0\n",
      "Row 13371 => Predicted: 0\n",
      "Row 13372 => Predicted: 0\n",
      "Row 13373 => Predicted: 1\n",
      "Row 13374 => Predicted: 0\n",
      "Row 13375 => Predicted: 0\n",
      "Row 13376 => Predicted: 1\n",
      "Row 13377 => Predicted: 1\n",
      "Row 13378 => Predicted: 0\n",
      "Row 13379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13370 to 13379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13380 => Predicted: 1\n",
      "Row 13381 => Predicted: 1\n",
      "Row 13382 => Predicted: 0\n",
      "Row 13383 => Predicted: 1\n",
      "Row 13384 => Predicted: 0\n",
      "Row 13385 => Predicted: 1\n",
      "Row 13386 => Predicted: 1\n",
      "Row 13387 => Predicted: 0\n",
      "Row 13388 => Predicted: 0\n",
      "Row 13389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13380 to 13389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13390 => Predicted: 1\n",
      "Row 13391 => Predicted: 1\n",
      "Row 13392 => Predicted: 0\n",
      "Row 13393 => Predicted: 1\n",
      "Row 13394 => Predicted: 1\n",
      "Row 13395 => Predicted: 0\n",
      "Row 13396 => Predicted: 1\n",
      "Row 13397 => Predicted: 0\n",
      "Row 13398 => Predicted: 0\n",
      "Row 13399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13390 to 13399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13400 => Predicted: 0\n",
      "Row 13401 => Predicted: 1\n",
      "Row 13402 => Predicted: 1\n",
      "Row 13403 => Predicted: 1\n",
      "Row 13404 => Predicted: 1\n",
      "Row 13405 => Predicted: 0\n",
      "Row 13406 => Predicted: 1\n",
      "Row 13407 => Predicted: 1\n",
      "Row 13408 => Predicted: 1\n",
      "Row 13409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13400 to 13409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13410 => Predicted: 1\n",
      "Row 13411 => Predicted: 0\n",
      "Row 13412 => Predicted: 0\n",
      "Row 13413 => Predicted: 0\n",
      "Row 13414 => Predicted: 0\n",
      "Row 13415 => Predicted: 1\n",
      "Row 13416 => Predicted: 0\n",
      "Row 13417 => Predicted: 0\n",
      "Row 13418 => Predicted: 0\n",
      "Row 13419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13410 to 13419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13420 => Predicted: 1\n",
      "Row 13421 => Predicted: 0\n",
      "Row 13422 => Predicted: 1\n",
      "Row 13423 => Predicted: 0\n",
      "Row 13424 => Predicted: 1\n",
      "Row 13425 => Predicted: 1\n",
      "Row 13426 => Predicted: 1\n",
      "Row 13427 => Predicted: 0\n",
      "Row 13428 => Predicted: 0\n",
      "Row 13429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13420 to 13429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13430 => Predicted: 0\n",
      "Row 13431 => Predicted: 1\n",
      "Row 13432 => Predicted: 1\n",
      "Row 13433 => Predicted: 1\n",
      "Row 13434 => Predicted: 1\n",
      "Row 13435 => Predicted: 1\n",
      "Row 13436 => Predicted: 0\n",
      "Row 13437 => Predicted: 0\n",
      "Row 13438 => Predicted: 1\n",
      "Row 13439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13430 to 13439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13440 => Predicted: 0\n",
      "Row 13441 => Predicted: 0\n",
      "Row 13442 => Predicted: 0\n",
      "Row 13443 => Predicted: 0\n",
      "Row 13444 => Predicted: 0\n",
      "Row 13445 => Predicted: 1\n",
      "Row 13446 => Predicted: 0\n",
      "Row 13447 => Predicted: 0\n",
      "Row 13448 => Predicted: 1\n",
      "Row 13449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13440 to 13449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13450 => Predicted: 1\n",
      "Row 13451 => Predicted: 0\n",
      "Row 13452 => Predicted: 1\n",
      "Row 13453 => Predicted: 0\n",
      "Row 13454 => Predicted: 0\n",
      "Row 13455 => Predicted: 1\n",
      "Row 13456 => Predicted: 0\n",
      "Row 13457 => Predicted: 1\n",
      "Row 13458 => Predicted: 1\n",
      "Row 13459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13450 to 13459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13460 => Predicted: 0\n",
      "Row 13461 => Predicted: 1\n",
      "Row 13462 => Predicted: 0\n",
      "Row 13463 => Predicted: 0\n",
      "Row 13464 => Predicted: 1\n",
      "Row 13465 => Predicted: 1\n",
      "Row 13466 => Predicted: 1\n",
      "Row 13467 => Predicted: 1\n",
      "Row 13468 => Predicted: 1\n",
      "Row 13469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13460 to 13469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13470 => Predicted: 0\n",
      "Row 13471 => Predicted: 1\n",
      "Row 13472 => Predicted: 1\n",
      "Row 13473 => Predicted: 0\n",
      "Row 13474 => Predicted: 0\n",
      "Row 13475 => Predicted: 1\n",
      "Row 13476 => Predicted: 1\n",
      "Row 13477 => Predicted: 1\n",
      "Row 13478 => Predicted: 1\n",
      "Row 13479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13470 to 13479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13480 => Predicted: 1\n",
      "Row 13481 => Predicted: 1\n",
      "Row 13482 => Predicted: 1\n",
      "Row 13483 => Predicted: 1\n",
      "Row 13484 => Predicted: 0\n",
      "Row 13485 => Predicted: 1\n",
      "Row 13486 => Predicted: 0\n",
      "Row 13487 => Predicted: 0\n",
      "Row 13488 => Predicted: 0\n",
      "Row 13489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13480 to 13489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13490 => Predicted: 1\n",
      "Row 13491 => Predicted: 1\n",
      "Row 13492 => Predicted: 0\n",
      "Row 13493 => Predicted: 0\n",
      "Row 13494 => Predicted: 0\n",
      "Row 13495 => Predicted: 0\n",
      "Row 13496 => Predicted: 1\n",
      "Row 13497 => Predicted: 1\n",
      "Row 13498 => Predicted: 0\n",
      "Row 13499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13490 to 13499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13500 => Predicted: 1\n",
      "Row 13501 => Predicted: 1\n",
      "Row 13502 => Predicted: 0\n",
      "Row 13503 => Predicted: 1\n",
      "Row 13504 => Predicted: 0\n",
      "Row 13505 => Predicted: 0\n",
      "Row 13506 => Predicted: 0\n",
      "Row 13507 => Predicted: 0\n",
      "Row 13508 => Predicted: 1\n",
      "Row 13509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13500 to 13509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13510 => Predicted: 1\n",
      "Row 13511 => Predicted: 0\n",
      "Row 13512 => Predicted: 1\n",
      "Row 13513 => Predicted: 1\n",
      "Row 13514 => Predicted: 1\n",
      "Row 13515 => Predicted: 0\n",
      "Row 13516 => Predicted: 1\n",
      "Row 13517 => Predicted: 0\n",
      "Row 13518 => Predicted: 1\n",
      "Row 13519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13510 to 13519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13520 => Predicted: 1\n",
      "Row 13521 => Predicted: 1\n",
      "Row 13522 => Predicted: 0\n",
      "Row 13523 => Predicted: 1\n",
      "Row 13524 => Predicted: 1\n",
      "Row 13525 => Predicted: 0\n",
      "Row 13526 => Predicted: 0\n",
      "Row 13527 => Predicted: 1\n",
      "Row 13528 => Predicted: 1\n",
      "Row 13529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13520 to 13529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13530 => Predicted: 1\n",
      "Row 13531 => Predicted: 0\n",
      "Row 13532 => Predicted: 1\n",
      "Row 13533 => Predicted: 1\n",
      "Row 13534 => Predicted: 1\n",
      "Row 13535 => Predicted: 1\n",
      "Row 13536 => Predicted: 1\n",
      "Row 13537 => Predicted: 1\n",
      "Row 13538 => Predicted: 1\n",
      "Row 13539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13530 to 13539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13540 => Predicted: 0\n",
      "Row 13541 => Predicted: 1\n",
      "Row 13542 => Predicted: 1\n",
      "Row 13543 => Predicted: 1\n",
      "Row 13544 => Predicted: 0\n",
      "Row 13545 => Predicted: 0\n",
      "Row 13546 => Predicted: 0\n",
      "Row 13547 => Predicted: 0\n",
      "Row 13548 => Predicted: 1\n",
      "Row 13549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13540 to 13549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13550 => Predicted: 0\n",
      "Row 13551 => Predicted: 1\n",
      "Row 13552 => Predicted: 1\n",
      "Row 13553 => Predicted: 1\n",
      "Row 13554 => Predicted: 0\n",
      "Row 13555 => Predicted: 1\n",
      "Row 13556 => Predicted: 1\n",
      "Row 13557 => Predicted: 1\n",
      "Row 13558 => Predicted: 1\n",
      "Row 13559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13550 to 13559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13560 => Predicted: 1\n",
      "Row 13561 => Predicted: 0\n",
      "Row 13562 => Predicted: 0\n",
      "Row 13563 => Predicted: 0\n",
      "Row 13564 => Predicted: 1\n",
      "Row 13565 => Predicted: 1\n",
      "Row 13566 => Predicted: 0\n",
      "Row 13567 => Predicted: 0\n",
      "Row 13568 => Predicted: 1\n",
      "Row 13569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13560 to 13569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13570 => Predicted: 0\n",
      "Row 13571 => Predicted: 0\n",
      "Row 13572 => Predicted: 1\n",
      "Row 13573 => Predicted: 0\n",
      "Row 13574 => Predicted: 1\n",
      "Row 13575 => Predicted: 1\n",
      "Row 13576 => Predicted: 0\n",
      "Row 13577 => Predicted: 0\n",
      "Row 13578 => Predicted: 1\n",
      "Row 13579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13570 to 13579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13580 => Predicted: 1\n",
      "Row 13581 => Predicted: 0\n",
      "Row 13582 => Predicted: 1\n",
      "Row 13583 => Predicted: 0\n",
      "Row 13584 => Predicted: 0\n",
      "Row 13585 => Predicted: 0\n",
      "Row 13586 => Predicted: 0\n",
      "Row 13587 => Predicted: 0\n",
      "Row 13588 => Predicted: 1\n",
      "Row 13589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13580 to 13589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13590 => Predicted: 1\n",
      "Row 13591 => Predicted: 0\n",
      "Row 13592 => Predicted: 1\n",
      "Row 13593 => Predicted: 1\n",
      "Row 13594 => Predicted: 0\n",
      "Row 13595 => Predicted: 0\n",
      "Row 13596 => Predicted: 1\n",
      "Row 13597 => Predicted: 1\n",
      "Row 13598 => Predicted: 1\n",
      "Row 13599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13590 to 13599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13600 => Predicted: 0\n",
      "Row 13601 => Predicted: 0\n",
      "Row 13602 => Predicted: 0\n",
      "Row 13603 => Predicted: 1\n",
      "Row 13604 => Predicted: 1\n",
      "Row 13605 => Predicted: 1\n",
      "Row 13606 => Predicted: 0\n",
      "Row 13607 => Predicted: 0\n",
      "Row 13608 => Predicted: 1\n",
      "Row 13609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13600 to 13609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13610 => Predicted: 1\n",
      "Row 13611 => Predicted: 1\n",
      "Row 13612 => Predicted: 0\n",
      "Row 13613 => Predicted: 1\n",
      "Row 13614 => Predicted: 1\n",
      "Row 13615 => Predicted: 0\n",
      "Row 13616 => Predicted: 1\n",
      "Row 13617 => Predicted: 1\n",
      "Row 13618 => Predicted: 0\n",
      "Row 13619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13610 to 13619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13620 => Predicted: 1\n",
      "Row 13621 => Predicted: 1\n",
      "Row 13622 => Predicted: 1\n",
      "Row 13623 => Predicted: 0\n",
      "Row 13624 => Predicted: 0\n",
      "Row 13625 => Predicted: 1\n",
      "Row 13626 => Predicted: 1\n",
      "Row 13627 => Predicted: 0\n",
      "Row 13628 => Predicted: 0\n",
      "Row 13629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13620 to 13629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13630 => Predicted: 0\n",
      "Row 13631 => Predicted: 1\n",
      "Row 13632 => Predicted: 0\n",
      "Row 13633 => Predicted: 0\n",
      "Row 13634 => Predicted: 1\n",
      "Row 13635 => Predicted: 1\n",
      "Row 13636 => Predicted: 0\n",
      "Row 13637 => Predicted: 0\n",
      "Row 13638 => Predicted: 0\n",
      "Row 13639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13630 to 13639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13640 => Predicted: 0\n",
      "Row 13641 => Predicted: 1\n",
      "Row 13642 => Predicted: 1\n",
      "Row 13643 => Predicted: 0\n",
      "Row 13644 => Predicted: 0\n",
      "Row 13645 => Predicted: 0\n",
      "Row 13646 => Predicted: 1\n",
      "Row 13647 => Predicted: 0\n",
      "Row 13648 => Predicted: 1\n",
      "Row 13649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13640 to 13649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13650 => Predicted: 0\n",
      "Row 13651 => Predicted: 0\n",
      "Row 13652 => Predicted: 0\n",
      "Row 13653 => Predicted: 0\n",
      "Row 13654 => Predicted: 1\n",
      "Row 13655 => Predicted: 1\n",
      "Row 13656 => Predicted: 0\n",
      "Row 13657 => Predicted: 1\n",
      "Row 13658 => Predicted: 0\n",
      "Row 13659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13650 to 13659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13660 => Predicted: 0\n",
      "Row 13661 => Predicted: 1\n",
      "Row 13662 => Predicted: 1\n",
      "Row 13663 => Predicted: 1\n",
      "Row 13664 => Predicted: 1\n",
      "Row 13665 => Predicted: 1\n",
      "Row 13666 => Predicted: 1\n",
      "Row 13667 => Predicted: 0\n",
      "Row 13668 => Predicted: 1\n",
      "Row 13669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13660 to 13669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13670 => Predicted: 1\n",
      "Row 13671 => Predicted: 1\n",
      "Row 13672 => Predicted: 1\n",
      "Row 13673 => Predicted: 1\n",
      "Row 13674 => Predicted: 0\n",
      "Row 13675 => Predicted: 1\n",
      "Row 13676 => Predicted: 1\n",
      "Row 13677 => Predicted: 0\n",
      "Row 13678 => Predicted: 0\n",
      "Row 13679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13670 to 13679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13680 => Predicted: 1\n",
      "Row 13681 => Predicted: 0\n",
      "Row 13682 => Predicted: 0\n",
      "Row 13683 => Predicted: 1\n",
      "Row 13684 => Predicted: 0\n",
      "Row 13685 => Predicted: 0\n",
      "Row 13686 => Predicted: 1\n",
      "Row 13687 => Predicted: 1\n",
      "Row 13688 => Predicted: 0\n",
      "Row 13689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13680 to 13689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13690 => Predicted: 0\n",
      "Row 13691 => Predicted: 0\n",
      "Row 13692 => Predicted: 0\n",
      "Row 13693 => Predicted: 0\n",
      "Row 13694 => Predicted: 0\n",
      "Row 13695 => Predicted: 0\n",
      "Row 13696 => Predicted: 1\n",
      "Row 13697 => Predicted: 1\n",
      "Row 13698 => Predicted: 0\n",
      "Row 13699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13690 to 13699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13700 => Predicted: 0\n",
      "Row 13701 => Predicted: 0\n",
      "Row 13702 => Predicted: 0\n",
      "Row 13703 => Predicted: 1\n",
      "Row 13704 => Predicted: 1\n",
      "Row 13705 => Predicted: 1\n",
      "Row 13706 => Predicted: 0\n",
      "Row 13707 => Predicted: 1\n",
      "Row 13708 => Predicted: 0\n",
      "Row 13709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13700 to 13709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13710 => Predicted: 0\n",
      "Row 13711 => Predicted: 0\n",
      "Row 13712 => Predicted: 1\n",
      "Row 13713 => Predicted: 0\n",
      "Row 13714 => Predicted: 0\n",
      "Row 13715 => Predicted: 0\n",
      "Row 13716 => Predicted: 1\n",
      "Row 13717 => Predicted: 1\n",
      "Row 13718 => Predicted: 0\n",
      "Row 13719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13710 to 13719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13720 => Predicted: 1\n",
      "Row 13721 => Predicted: 0\n",
      "Row 13722 => Predicted: 0\n",
      "Row 13723 => Predicted: 1\n",
      "Row 13724 => Predicted: 1\n",
      "Row 13725 => Predicted: 1\n",
      "Row 13726 => Predicted: 1\n",
      "Row 13727 => Predicted: 0\n",
      "Row 13728 => Predicted: 0\n",
      "Row 13729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13720 to 13729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13730 => Predicted: 1\n",
      "Row 13731 => Predicted: 1\n",
      "Row 13732 => Predicted: 0\n",
      "Row 13733 => Predicted: 1\n",
      "Row 13734 => Predicted: 0\n",
      "Row 13735 => Predicted: 1\n",
      "Row 13736 => Predicted: 0\n",
      "Row 13737 => Predicted: 1\n",
      "Row 13738 => Predicted: 1\n",
      "Row 13739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13730 to 13739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13740 => Predicted: 1\n",
      "Row 13741 => Predicted: 1\n",
      "Row 13742 => Predicted: 1\n",
      "Row 13743 => Predicted: 1\n",
      "Row 13744 => Predicted: 1\n",
      "Row 13745 => Predicted: 1\n",
      "Row 13746 => Predicted: 1\n",
      "Row 13747 => Predicted: 1\n",
      "Row 13748 => Predicted: 1\n",
      "Row 13749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13740 to 13749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13750 => Predicted: 1\n",
      "Row 13751 => Predicted: 1\n",
      "Row 13752 => Predicted: 1\n",
      "Row 13753 => Predicted: 1\n",
      "Row 13754 => Predicted: 1\n",
      "Row 13755 => Predicted: 0\n",
      "Row 13756 => Predicted: 1\n",
      "Row 13757 => Predicted: 0\n",
      "Row 13758 => Predicted: 0\n",
      "Row 13759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13750 to 13759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13760 => Predicted: 0\n",
      "Row 13761 => Predicted: 0\n",
      "Row 13762 => Predicted: 0\n",
      "Row 13763 => Predicted: 0\n",
      "Row 13764 => Predicted: 1\n",
      "Row 13765 => Predicted: 0\n",
      "Row 13766 => Predicted: 0\n",
      "Row 13767 => Predicted: 1\n",
      "Row 13768 => Predicted: 1\n",
      "Row 13769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13760 to 13769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13770 => Predicted: 0\n",
      "Row 13771 => Predicted: 1\n",
      "Row 13772 => Predicted: 1\n",
      "Row 13773 => Predicted: 0\n",
      "Row 13774 => Predicted: 1\n",
      "Row 13775 => Predicted: 1\n",
      "Row 13776 => Predicted: 1\n",
      "Row 13777 => Predicted: 0\n",
      "Row 13778 => Predicted: 0\n",
      "Row 13779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13770 to 13779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13780 => Predicted: 1\n",
      "Row 13781 => Predicted: 1\n",
      "Row 13782 => Predicted: 1\n",
      "Row 13783 => Predicted: 0\n",
      "Row 13784 => Predicted: 1\n",
      "Row 13785 => Predicted: 0\n",
      "Row 13786 => Predicted: 0\n",
      "Row 13787 => Predicted: 1\n",
      "Row 13788 => Predicted: 1\n",
      "Row 13789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13780 to 13789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13790 => Predicted: 0\n",
      "Row 13791 => Predicted: 1\n",
      "Row 13792 => Predicted: 0\n",
      "Row 13793 => Predicted: 0\n",
      "Row 13794 => Predicted: 1\n",
      "Row 13795 => Predicted: 0\n",
      "Row 13796 => Predicted: 0\n",
      "Row 13797 => Predicted: 1\n",
      "Row 13798 => Predicted: 0\n",
      "Row 13799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13790 to 13799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13800 => Predicted: 0\n",
      "Row 13801 => Predicted: 0\n",
      "Row 13802 => Predicted: 1\n",
      "Row 13803 => Predicted: 0\n",
      "Row 13804 => Predicted: 0\n",
      "Row 13805 => Predicted: 0\n",
      "Row 13806 => Predicted: 0\n",
      "Row 13807 => Predicted: 1\n",
      "Row 13808 => Predicted: 1\n",
      "Row 13809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13800 to 13809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13810 => Predicted: 0\n",
      "Row 13811 => Predicted: 1\n",
      "Row 13812 => Predicted: 1\n",
      "Row 13813 => Predicted: 1\n",
      "Row 13814 => Predicted: 0\n",
      "Row 13815 => Predicted: 1\n",
      "Row 13816 => Predicted: 1\n",
      "Row 13817 => Predicted: 1\n",
      "Row 13818 => Predicted: 0\n",
      "Row 13819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13810 to 13819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13820 => Predicted: 1\n",
      "Row 13821 => Predicted: 0\n",
      "Row 13822 => Predicted: 0\n",
      "Row 13823 => Predicted: 1\n",
      "Row 13824 => Predicted: 0\n",
      "Row 13825 => Predicted: 1\n",
      "Row 13826 => Predicted: 0\n",
      "Row 13827 => Predicted: 1\n",
      "Row 13828 => Predicted: 0\n",
      "Row 13829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13820 to 13829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13830 => Predicted: 1\n",
      "Row 13831 => Predicted: 1\n",
      "Row 13832 => Predicted: 0\n",
      "Row 13833 => Predicted: 0\n",
      "Row 13834 => Predicted: 0\n",
      "Row 13835 => Predicted: 1\n",
      "Row 13836 => Predicted: 1\n",
      "Row 13837 => Predicted: 0\n",
      "Row 13838 => Predicted: 0\n",
      "Row 13839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13830 to 13839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13840 => Predicted: 1\n",
      "Row 13841 => Predicted: 1\n",
      "Row 13842 => Predicted: 1\n",
      "Row 13843 => Predicted: 0\n",
      "Row 13844 => Predicted: 0\n",
      "Row 13845 => Predicted: 0\n",
      "Row 13846 => Predicted: 1\n",
      "Row 13847 => Predicted: 1\n",
      "Row 13848 => Predicted: 0\n",
      "Row 13849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13840 to 13849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13850 => Predicted: 0\n",
      "Row 13851 => Predicted: 0\n",
      "Row 13852 => Predicted: 0\n",
      "Row 13853 => Predicted: 1\n",
      "Row 13854 => Predicted: 1\n",
      "Row 13855 => Predicted: 0\n",
      "Row 13856 => Predicted: 1\n",
      "Row 13857 => Predicted: 0\n",
      "Row 13858 => Predicted: 1\n",
      "Row 13859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13850 to 13859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13860 => Predicted: 0\n",
      "Row 13861 => Predicted: 1\n",
      "Row 13862 => Predicted: 0\n",
      "Row 13863 => Predicted: 1\n",
      "Row 13864 => Predicted: 0\n",
      "Row 13865 => Predicted: 0\n",
      "Row 13866 => Predicted: 1\n",
      "Row 13867 => Predicted: 0\n",
      "Row 13868 => Predicted: 0\n",
      "Row 13869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13860 to 13869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13870 => Predicted: 1\n",
      "Row 13871 => Predicted: 1\n",
      "Row 13872 => Predicted: 0\n",
      "Row 13873 => Predicted: 1\n",
      "Row 13874 => Predicted: 1\n",
      "Row 13875 => Predicted: 1\n",
      "Row 13876 => Predicted: 0\n",
      "Row 13877 => Predicted: 1\n",
      "Row 13878 => Predicted: 1\n",
      "Row 13879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13870 to 13879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13880 => Predicted: 1\n",
      "Row 13881 => Predicted: 0\n",
      "Row 13882 => Predicted: 0\n",
      "Row 13883 => Predicted: 1\n",
      "Row 13884 => Predicted: 1\n",
      "Row 13885 => Predicted: 0\n",
      "Row 13886 => Predicted: 1\n",
      "Row 13887 => Predicted: 1\n",
      "Row 13888 => Predicted: 0\n",
      "Row 13889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13880 to 13889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13890 => Predicted: 0\n",
      "Row 13891 => Predicted: 0\n",
      "Row 13892 => Predicted: 0\n",
      "Row 13893 => Predicted: 0\n",
      "Row 13894 => Predicted: 0\n",
      "Row 13895 => Predicted: 1\n",
      "Row 13896 => Predicted: 1\n",
      "Row 13897 => Predicted: 0\n",
      "Row 13898 => Predicted: 0\n",
      "Row 13899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13890 to 13899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13900 => Predicted: 0\n",
      "Row 13901 => Predicted: 0\n",
      "Row 13902 => Predicted: 1\n",
      "Row 13903 => Predicted: 0\n",
      "Row 13904 => Predicted: 1\n",
      "Row 13905 => Predicted: 1\n",
      "Row 13906 => Predicted: 0\n",
      "Row 13907 => Predicted: 1\n",
      "Row 13908 => Predicted: 1\n",
      "Row 13909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13900 to 13909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13910 => Predicted: 0\n",
      "Row 13911 => Predicted: 1\n",
      "Row 13912 => Predicted: 0\n",
      "Row 13913 => Predicted: 1\n",
      "Row 13914 => Predicted: 0\n",
      "Row 13915 => Predicted: 0\n",
      "Row 13916 => Predicted: 0\n",
      "Row 13917 => Predicted: 0\n",
      "Row 13918 => Predicted: 1\n",
      "Row 13919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13910 to 13919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13920 => Predicted: 1\n",
      "Row 13921 => Predicted: 1\n",
      "Row 13922 => Predicted: 1\n",
      "Row 13923 => Predicted: 1\n",
      "Row 13924 => Predicted: 0\n",
      "Row 13925 => Predicted: 0\n",
      "Row 13926 => Predicted: 0\n",
      "Row 13927 => Predicted: 0\n",
      "Row 13928 => Predicted: 0\n",
      "Row 13929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13920 to 13929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13930 => Predicted: 0\n",
      "Row 13931 => Predicted: 1\n",
      "Row 13932 => Predicted: 1\n",
      "Row 13933 => Predicted: 1\n",
      "Row 13934 => Predicted: 1\n",
      "Row 13935 => Predicted: 0\n",
      "Row 13936 => Predicted: 0\n",
      "Row 13937 => Predicted: 0\n",
      "Row 13938 => Predicted: 1\n",
      "Row 13939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13930 to 13939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13940 => Predicted: 0\n",
      "Row 13941 => Predicted: 1\n",
      "Row 13942 => Predicted: 0\n",
      "Row 13943 => Predicted: 1\n",
      "Row 13944 => Predicted: 0\n",
      "Row 13945 => Predicted: 0\n",
      "Row 13946 => Predicted: 0\n",
      "Row 13947 => Predicted: 0\n",
      "Row 13948 => Predicted: 1\n",
      "Row 13949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13940 to 13949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13950 => Predicted: 0\n",
      "Row 13951 => Predicted: 0\n",
      "Row 13952 => Predicted: 0\n",
      "Row 13953 => Predicted: 1\n",
      "Row 13954 => Predicted: 0\n",
      "Row 13955 => Predicted: 1\n",
      "Row 13956 => Predicted: 1\n",
      "Row 13957 => Predicted: 1\n",
      "Row 13958 => Predicted: 0\n",
      "Row 13959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13950 to 13959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13960 => Predicted: 1\n",
      "Row 13961 => Predicted: 0\n",
      "Row 13962 => Predicted: 0\n",
      "Row 13963 => Predicted: 1\n",
      "Row 13964 => Predicted: 1\n",
      "Row 13965 => Predicted: 1\n",
      "Row 13966 => Predicted: 0\n",
      "Row 13967 => Predicted: 1\n",
      "Row 13968 => Predicted: 0\n",
      "Row 13969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13960 to 13969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13970 => Predicted: 1\n",
      "Row 13971 => Predicted: 1\n",
      "Row 13972 => Predicted: 0\n",
      "Row 13973 => Predicted: 0\n",
      "Row 13974 => Predicted: 0\n",
      "Row 13975 => Predicted: 0\n",
      "Row 13976 => Predicted: 1\n",
      "Row 13977 => Predicted: 0\n",
      "Row 13978 => Predicted: 0\n",
      "Row 13979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13970 to 13979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13980 => Predicted: 1\n",
      "Row 13981 => Predicted: 0\n",
      "Row 13982 => Predicted: 1\n",
      "Row 13983 => Predicted: 0\n",
      "Row 13984 => Predicted: 0\n",
      "Row 13985 => Predicted: 0\n",
      "Row 13986 => Predicted: 0\n",
      "Row 13987 => Predicted: 0\n",
      "Row 13988 => Predicted: 0\n",
      "Row 13989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 13980 to 13989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13990 => Predicted: 1\n",
      "Row 13991 => Predicted: 1\n",
      "Row 13992 => Predicted: 1\n",
      "Row 13993 => Predicted: 0\n",
      "Row 13994 => Predicted: 1\n",
      "Row 13995 => Predicted: 0\n",
      "Row 13996 => Predicted: 0\n",
      "Row 13997 => Predicted: 1\n",
      "Row 13998 => Predicted: 1\n",
      "Row 13999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 13990 to 13999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14000 => Predicted: 1\n",
      "Row 14001 => Predicted: 0\n",
      "Row 14002 => Predicted: 1\n",
      "Row 14003 => Predicted: 0\n",
      "Row 14004 => Predicted: 0\n",
      "Row 14005 => Predicted: 0\n",
      "Row 14006 => Predicted: 0\n",
      "Row 14007 => Predicted: 0\n",
      "Row 14008 => Predicted: 0\n",
      "Row 14009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14000 to 14009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14010 => Predicted: 1\n",
      "Row 14011 => Predicted: 0\n",
      "Row 14012 => Predicted: 1\n",
      "Row 14013 => Predicted: 0\n",
      "Row 14014 => Predicted: 0\n",
      "Row 14015 => Predicted: 0\n",
      "Row 14016 => Predicted: 1\n",
      "Row 14017 => Predicted: 1\n",
      "Row 14018 => Predicted: 0\n",
      "Row 14019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14010 to 14019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14020 => Predicted: 1\n",
      "Row 14021 => Predicted: 1\n",
      "Row 14022 => Predicted: 0\n",
      "Row 14023 => Predicted: 0\n",
      "Row 14024 => Predicted: 0\n",
      "Row 14025 => Predicted: 1\n",
      "Row 14026 => Predicted: 0\n",
      "Row 14027 => Predicted: 1\n",
      "Row 14028 => Predicted: 1\n",
      "Row 14029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14020 to 14029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14030 => Predicted: 0\n",
      "Row 14031 => Predicted: 1\n",
      "Row 14032 => Predicted: 0\n",
      "Row 14033 => Predicted: 0\n",
      "Row 14034 => Predicted: 0\n",
      "Row 14035 => Predicted: 0\n",
      "Row 14036 => Predicted: 1\n",
      "Row 14037 => Predicted: 0\n",
      "Row 14038 => Predicted: 1\n",
      "Row 14039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14030 to 14039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14040 => Predicted: 0\n",
      "Row 14041 => Predicted: 0\n",
      "Row 14042 => Predicted: 0\n",
      "Row 14043 => Predicted: 0\n",
      "Row 14044 => Predicted: 1\n",
      "Row 14045 => Predicted: 1\n",
      "Row 14046 => Predicted: 0\n",
      "Row 14047 => Predicted: 1\n",
      "Row 14048 => Predicted: 0\n",
      "Row 14049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14040 to 14049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14050 => Predicted: 1\n",
      "Row 14051 => Predicted: 1\n",
      "Row 14052 => Predicted: 0\n",
      "Row 14053 => Predicted: 1\n",
      "Row 14054 => Predicted: 1\n",
      "Row 14055 => Predicted: 0\n",
      "Row 14056 => Predicted: 1\n",
      "Row 14057 => Predicted: 1\n",
      "Row 14058 => Predicted: 1\n",
      "Row 14059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14050 to 14059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14060 => Predicted: 1\n",
      "Row 14061 => Predicted: 0\n",
      "Row 14062 => Predicted: 1\n",
      "Row 14063 => Predicted: 1\n",
      "Row 14064 => Predicted: 0\n",
      "Row 14065 => Predicted: 0\n",
      "Row 14066 => Predicted: 0\n",
      "Row 14067 => Predicted: 1\n",
      "Row 14068 => Predicted: 1\n",
      "Row 14069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14060 to 14069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14070 => Predicted: 1\n",
      "Row 14071 => Predicted: 1\n",
      "Row 14072 => Predicted: 0\n",
      "Row 14073 => Predicted: 1\n",
      "Row 14074 => Predicted: 1\n",
      "Row 14075 => Predicted: 1\n",
      "Row 14076 => Predicted: 0\n",
      "Row 14077 => Predicted: 1\n",
      "Row 14078 => Predicted: 1\n",
      "Row 14079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14070 to 14079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14080 => Predicted: 1\n",
      "Row 14081 => Predicted: 0\n",
      "Row 14082 => Predicted: 1\n",
      "Row 14083 => Predicted: 0\n",
      "Row 14084 => Predicted: 0\n",
      "Row 14085 => Predicted: 1\n",
      "Row 14086 => Predicted: 0\n",
      "Row 14087 => Predicted: 0\n",
      "Row 14088 => Predicted: 1\n",
      "Row 14089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14080 to 14089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14090 => Predicted: 0\n",
      "Row 14091 => Predicted: 0\n",
      "Row 14092 => Predicted: 0\n",
      "Row 14093 => Predicted: 0\n",
      "Row 14094 => Predicted: 0\n",
      "Row 14095 => Predicted: 1\n",
      "Row 14096 => Predicted: 1\n",
      "Row 14097 => Predicted: 0\n",
      "Row 14098 => Predicted: 0\n",
      "Row 14099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14090 to 14099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14100 => Predicted: 0\n",
      "Row 14101 => Predicted: 0\n",
      "Row 14102 => Predicted: 0\n",
      "Row 14103 => Predicted: 0\n",
      "Row 14104 => Predicted: 0\n",
      "Row 14105 => Predicted: 1\n",
      "Row 14106 => Predicted: 1\n",
      "Row 14107 => Predicted: 0\n",
      "Row 14108 => Predicted: 1\n",
      "Row 14109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14100 to 14109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14110 => Predicted: 0\n",
      "Row 14111 => Predicted: 0\n",
      "Row 14112 => Predicted: 1\n",
      "Row 14113 => Predicted: 0\n",
      "Row 14114 => Predicted: 0\n",
      "Row 14115 => Predicted: 1\n",
      "Row 14116 => Predicted: 0\n",
      "Row 14117 => Predicted: 1\n",
      "Row 14118 => Predicted: 0\n",
      "Row 14119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14110 to 14119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14120 => Predicted: 1\n",
      "Row 14121 => Predicted: 1\n",
      "Row 14122 => Predicted: 1\n",
      "Row 14123 => Predicted: 0\n",
      "Row 14124 => Predicted: 1\n",
      "Row 14125 => Predicted: 1\n",
      "Row 14126 => Predicted: 0\n",
      "Row 14127 => Predicted: 1\n",
      "Row 14128 => Predicted: 0\n",
      "Row 14129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14120 to 14129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14130 => Predicted: 0\n",
      "Row 14131 => Predicted: 0\n",
      "Row 14132 => Predicted: 0\n",
      "Row 14133 => Predicted: 1\n",
      "Row 14134 => Predicted: 1\n",
      "Row 14135 => Predicted: 0\n",
      "Row 14136 => Predicted: 1\n",
      "Row 14137 => Predicted: 1\n",
      "Row 14138 => Predicted: 0\n",
      "Row 14139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14130 to 14139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14140 => Predicted: 1\n",
      "Row 14141 => Predicted: 0\n",
      "Row 14142 => Predicted: 1\n",
      "Row 14143 => Predicted: 1\n",
      "Row 14144 => Predicted: 0\n",
      "Row 14145 => Predicted: 1\n",
      "Row 14146 => Predicted: 0\n",
      "Row 14147 => Predicted: 1\n",
      "Row 14148 => Predicted: 0\n",
      "Row 14149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14140 to 14149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14150 => Predicted: 1\n",
      "Row 14151 => Predicted: 1\n",
      "Row 14152 => Predicted: 0\n",
      "Row 14153 => Predicted: 1\n",
      "Row 14154 => Predicted: 1\n",
      "Row 14155 => Predicted: 1\n",
      "Row 14156 => Predicted: 0\n",
      "Row 14157 => Predicted: 0\n",
      "Row 14158 => Predicted: 1\n",
      "Row 14159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14150 to 14159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14160 => Predicted: 0\n",
      "Row 14161 => Predicted: 0\n",
      "Row 14162 => Predicted: 1\n",
      "Row 14163 => Predicted: 1\n",
      "Row 14164 => Predicted: 1\n",
      "Row 14165 => Predicted: 0\n",
      "Row 14166 => Predicted: 1\n",
      "Row 14167 => Predicted: 1\n",
      "Row 14168 => Predicted: 0\n",
      "Row 14169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14160 to 14169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14170 => Predicted: 1\n",
      "Row 14171 => Predicted: 1\n",
      "Row 14172 => Predicted: 1\n",
      "Row 14173 => Predicted: 0\n",
      "Row 14174 => Predicted: 1\n",
      "Row 14175 => Predicted: 1\n",
      "Row 14176 => Predicted: 0\n",
      "Row 14177 => Predicted: 0\n",
      "Row 14178 => Predicted: 1\n",
      "Row 14179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14170 to 14179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14180 => Predicted: 0\n",
      "Row 14181 => Predicted: 1\n",
      "Row 14182 => Predicted: 0\n",
      "Row 14183 => Predicted: 0\n",
      "Row 14184 => Predicted: 1\n",
      "Row 14185 => Predicted: 0\n",
      "Row 14186 => Predicted: 1\n",
      "Row 14187 => Predicted: 1\n",
      "Row 14188 => Predicted: 1\n",
      "Row 14189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14180 to 14189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14190 => Predicted: 1\n",
      "Row 14191 => Predicted: 0\n",
      "Row 14192 => Predicted: 1\n",
      "Row 14193 => Predicted: 1\n",
      "Row 14194 => Predicted: 1\n",
      "Row 14195 => Predicted: 1\n",
      "Row 14196 => Predicted: 1\n",
      "Row 14197 => Predicted: 1\n",
      "Row 14198 => Predicted: 0\n",
      "Row 14199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14190 to 14199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14200 => Predicted: 1\n",
      "Row 14201 => Predicted: 1\n",
      "Row 14202 => Predicted: 0\n",
      "Row 14203 => Predicted: 0\n",
      "Row 14204 => Predicted: 1\n",
      "Row 14205 => Predicted: 0\n",
      "Row 14206 => Predicted: 1\n",
      "Row 14207 => Predicted: 1\n",
      "Row 14208 => Predicted: 0\n",
      "Row 14209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14200 to 14209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14210 => Predicted: 0\n",
      "Row 14211 => Predicted: 0\n",
      "Row 14212 => Predicted: 1\n",
      "Row 14213 => Predicted: 1\n",
      "Row 14214 => Predicted: 0\n",
      "Row 14215 => Predicted: 0\n",
      "Row 14216 => Predicted: 1\n",
      "Row 14217 => Predicted: 1\n",
      "Row 14218 => Predicted: 0\n",
      "Row 14219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14210 to 14219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14220 => Predicted: 1\n",
      "Row 14221 => Predicted: 1\n",
      "Row 14222 => Predicted: 1\n",
      "Row 14223 => Predicted: 1\n",
      "Row 14224 => Predicted: 1\n",
      "Row 14225 => Predicted: 0\n",
      "Row 14226 => Predicted: 0\n",
      "Row 14227 => Predicted: 1\n",
      "Row 14228 => Predicted: 0\n",
      "Row 14229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14220 to 14229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14230 => Predicted: 0\n",
      "Row 14231 => Predicted: 1\n",
      "Row 14232 => Predicted: 1\n",
      "Row 14233 => Predicted: 0\n",
      "Row 14234 => Predicted: 0\n",
      "Row 14235 => Predicted: 1\n",
      "Row 14236 => Predicted: 1\n",
      "Row 14237 => Predicted: 0\n",
      "Row 14238 => Predicted: 0\n",
      "Row 14239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14230 to 14239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14240 => Predicted: 0\n",
      "Row 14241 => Predicted: 1\n",
      "Row 14242 => Predicted: 0\n",
      "Row 14243 => Predicted: 0\n",
      "Row 14244 => Predicted: 0\n",
      "Row 14245 => Predicted: 1\n",
      "Row 14246 => Predicted: 0\n",
      "Row 14247 => Predicted: 1\n",
      "Row 14248 => Predicted: 0\n",
      "Row 14249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14240 to 14249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14250 => Predicted: 1\n",
      "Row 14251 => Predicted: 1\n",
      "Row 14252 => Predicted: 1\n",
      "Row 14253 => Predicted: 0\n",
      "Row 14254 => Predicted: 0\n",
      "Row 14255 => Predicted: 1\n",
      "Row 14256 => Predicted: 0\n",
      "Row 14257 => Predicted: 0\n",
      "Row 14258 => Predicted: 0\n",
      "Row 14259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14250 to 14259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14260 => Predicted: 0\n",
      "Row 14261 => Predicted: 1\n",
      "Row 14262 => Predicted: 0\n",
      "Row 14263 => Predicted: 1\n",
      "Row 14264 => Predicted: 1\n",
      "Row 14265 => Predicted: 1\n",
      "Row 14266 => Predicted: 0\n",
      "Row 14267 => Predicted: 1\n",
      "Row 14268 => Predicted: 1\n",
      "Row 14269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14260 to 14269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14270 => Predicted: 0\n",
      "Row 14271 => Predicted: 1\n",
      "Row 14272 => Predicted: 1\n",
      "Row 14273 => Predicted: 0\n",
      "Row 14274 => Predicted: 0\n",
      "Row 14275 => Predicted: 0\n",
      "Row 14276 => Predicted: 0\n",
      "Row 14277 => Predicted: 1\n",
      "Row 14278 => Predicted: 1\n",
      "Row 14279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14270 to 14279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14280 => Predicted: 0\n",
      "Row 14281 => Predicted: 1\n",
      "Row 14282 => Predicted: 1\n",
      "Row 14283 => Predicted: 1\n",
      "Row 14284 => Predicted: 0\n",
      "Row 14285 => Predicted: 0\n",
      "Row 14286 => Predicted: 1\n",
      "Row 14287 => Predicted: 0\n",
      "Row 14288 => Predicted: 1\n",
      "Row 14289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14280 to 14289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14290 => Predicted: 1\n",
      "Row 14291 => Predicted: 1\n",
      "Row 14292 => Predicted: 1\n",
      "Row 14293 => Predicted: 1\n",
      "Row 14294 => Predicted: 1\n",
      "Row 14295 => Predicted: 0\n",
      "Row 14296 => Predicted: 0\n",
      "Row 14297 => Predicted: 0\n",
      "Row 14298 => Predicted: 0\n",
      "Row 14299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14290 to 14299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14300 => Predicted: 0\n",
      "Row 14301 => Predicted: 1\n",
      "Row 14302 => Predicted: 0\n",
      "Row 14303 => Predicted: 1\n",
      "Row 14304 => Predicted: 0\n",
      "Row 14305 => Predicted: 0\n",
      "Row 14306 => Predicted: 0\n",
      "Row 14307 => Predicted: 0\n",
      "Row 14308 => Predicted: 0\n",
      "Row 14309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14300 to 14309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14310 => Predicted: 1\n",
      "Row 14311 => Predicted: 1\n",
      "Row 14312 => Predicted: 1\n",
      "Row 14313 => Predicted: 1\n",
      "Row 14314 => Predicted: 1\n",
      "Row 14315 => Predicted: 1\n",
      "Row 14316 => Predicted: 0\n",
      "Row 14317 => Predicted: 0\n",
      "Row 14318 => Predicted: 1\n",
      "Row 14319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14310 to 14319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14320 => Predicted: 0\n",
      "Row 14321 => Predicted: 1\n",
      "Row 14322 => Predicted: 1\n",
      "Row 14323 => Predicted: 0\n",
      "Row 14324 => Predicted: 0\n",
      "Row 14325 => Predicted: 0\n",
      "Row 14326 => Predicted: 1\n",
      "Row 14327 => Predicted: 0\n",
      "Row 14328 => Predicted: 0\n",
      "Row 14329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14320 to 14329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14330 => Predicted: 0\n",
      "Row 14331 => Predicted: 1\n",
      "Row 14332 => Predicted: 0\n",
      "Row 14333 => Predicted: 1\n",
      "Row 14334 => Predicted: 1\n",
      "Row 14335 => Predicted: 1\n",
      "Row 14336 => Predicted: 1\n",
      "Row 14337 => Predicted: 1\n",
      "Row 14338 => Predicted: 1\n",
      "Row 14339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14330 to 14339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14340 => Predicted: 0\n",
      "Row 14341 => Predicted: 0\n",
      "Row 14342 => Predicted: 1\n",
      "Row 14343 => Predicted: 0\n",
      "Row 14344 => Predicted: 1\n",
      "Row 14345 => Predicted: 0\n",
      "Row 14346 => Predicted: 0\n",
      "Row 14347 => Predicted: 0\n",
      "Row 14348 => Predicted: 0\n",
      "Row 14349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14340 to 14349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14350 => Predicted: 0\n",
      "Row 14351 => Predicted: 1\n",
      "Row 14352 => Predicted: 1\n",
      "Row 14353 => Predicted: 1\n",
      "Row 14354 => Predicted: 1\n",
      "Row 14355 => Predicted: 1\n",
      "Row 14356 => Predicted: 1\n",
      "Row 14357 => Predicted: 0\n",
      "Row 14358 => Predicted: 1\n",
      "Row 14359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14350 to 14359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14360 => Predicted: 0\n",
      "Row 14361 => Predicted: 1\n",
      "Row 14362 => Predicted: 0\n",
      "Row 14363 => Predicted: 0\n",
      "Row 14364 => Predicted: 0\n",
      "Row 14365 => Predicted: 0\n",
      "Row 14366 => Predicted: 1\n",
      "Row 14367 => Predicted: 1\n",
      "Row 14368 => Predicted: 0\n",
      "Row 14369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14360 to 14369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14370 => Predicted: 1\n",
      "Row 14371 => Predicted: 1\n",
      "Row 14372 => Predicted: 1\n",
      "Row 14373 => Predicted: 0\n",
      "Row 14374 => Predicted: 1\n",
      "Row 14375 => Predicted: 0\n",
      "Row 14376 => Predicted: 1\n",
      "Row 14377 => Predicted: 0\n",
      "Row 14378 => Predicted: 0\n",
      "Row 14379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14370 to 14379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14380 => Predicted: 0\n",
      "Row 14381 => Predicted: 0\n",
      "Row 14382 => Predicted: 1\n",
      "Row 14383 => Predicted: 1\n",
      "Row 14384 => Predicted: 0\n",
      "Row 14385 => Predicted: 0\n",
      "Row 14386 => Predicted: 1\n",
      "Row 14387 => Predicted: 0\n",
      "Row 14388 => Predicted: 1\n",
      "Row 14389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14380 to 14389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14390 => Predicted: 0\n",
      "Row 14391 => Predicted: 0\n",
      "Row 14392 => Predicted: 1\n",
      "Row 14393 => Predicted: 0\n",
      "Row 14394 => Predicted: 0\n",
      "Row 14395 => Predicted: 1\n",
      "Row 14396 => Predicted: 0\n",
      "Row 14397 => Predicted: 1\n",
      "Row 14398 => Predicted: 0\n",
      "Row 14399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14390 to 14399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14400 => Predicted: 1\n",
      "Row 14401 => Predicted: 0\n",
      "Row 14402 => Predicted: 0\n",
      "Row 14403 => Predicted: 0\n",
      "Row 14404 => Predicted: 1\n",
      "Row 14405 => Predicted: 0\n",
      "Row 14406 => Predicted: 0\n",
      "Row 14407 => Predicted: 0\n",
      "Row 14408 => Predicted: 0\n",
      "Row 14409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14400 to 14409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14410 => Predicted: 1\n",
      "Row 14411 => Predicted: 1\n",
      "Row 14412 => Predicted: 0\n",
      "Row 14413 => Predicted: 0\n",
      "Row 14414 => Predicted: 0\n",
      "Row 14415 => Predicted: 1\n",
      "Row 14416 => Predicted: 0\n",
      "Row 14417 => Predicted: 0\n",
      "Row 14418 => Predicted: 1\n",
      "Row 14419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14410 to 14419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14420 => Predicted: 1\n",
      "Row 14421 => Predicted: 1\n",
      "Row 14422 => Predicted: 0\n",
      "Row 14423 => Predicted: 0\n",
      "Row 14424 => Predicted: 0\n",
      "Row 14425 => Predicted: 0\n",
      "Row 14426 => Predicted: 1\n",
      "Row 14427 => Predicted: 1\n",
      "Row 14428 => Predicted: 1\n",
      "Row 14429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14420 to 14429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14430 => Predicted: 1\n",
      "Row 14431 => Predicted: 1\n",
      "Row 14432 => Predicted: 1\n",
      "Row 14433 => Predicted: 1\n",
      "Row 14434 => Predicted: 0\n",
      "Row 14435 => Predicted: 0\n",
      "Row 14436 => Predicted: 0\n",
      "Row 14437 => Predicted: 0\n",
      "Row 14438 => Predicted: 0\n",
      "Row 14439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14430 to 14439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14440 => Predicted: 0\n",
      "Row 14441 => Predicted: 1\n",
      "Row 14442 => Predicted: 1\n",
      "Row 14443 => Predicted: 1\n",
      "Row 14444 => Predicted: 0\n",
      "Row 14445 => Predicted: 0\n",
      "Row 14446 => Predicted: 1\n",
      "Row 14447 => Predicted: 1\n",
      "Row 14448 => Predicted: 0\n",
      "Row 14449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14440 to 14449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14450 => Predicted: 0\n",
      "Row 14451 => Predicted: 1\n",
      "Row 14452 => Predicted: 1\n",
      "Row 14453 => Predicted: 0\n",
      "Row 14454 => Predicted: 1\n",
      "Row 14455 => Predicted: 1\n",
      "Row 14456 => Predicted: 1\n",
      "Row 14457 => Predicted: 0\n",
      "Row 14458 => Predicted: 0\n",
      "Row 14459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14450 to 14459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14460 => Predicted: 0\n",
      "Row 14461 => Predicted: 0\n",
      "Row 14462 => Predicted: 0\n",
      "Row 14463 => Predicted: 1\n",
      "Row 14464 => Predicted: 0\n",
      "Row 14465 => Predicted: 1\n",
      "Row 14466 => Predicted: 1\n",
      "Row 14467 => Predicted: 0\n",
      "Row 14468 => Predicted: 0\n",
      "Row 14469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14460 to 14469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14470 => Predicted: 0\n",
      "Row 14471 => Predicted: 0\n",
      "Row 14472 => Predicted: 0\n",
      "Row 14473 => Predicted: 0\n",
      "Row 14474 => Predicted: 0\n",
      "Row 14475 => Predicted: 0\n",
      "Row 14476 => Predicted: 1\n",
      "Row 14477 => Predicted: 0\n",
      "Row 14478 => Predicted: 0\n",
      "Row 14479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14470 to 14479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14480 => Predicted: 0\n",
      "Row 14481 => Predicted: 0\n",
      "Row 14482 => Predicted: 1\n",
      "Row 14483 => Predicted: 0\n",
      "Row 14484 => Predicted: 0\n",
      "Row 14485 => Predicted: 0\n",
      "Row 14486 => Predicted: 1\n",
      "Row 14487 => Predicted: 1\n",
      "Row 14488 => Predicted: 0\n",
      "Row 14489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14480 to 14489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14490 => Predicted: 1\n",
      "Row 14491 => Predicted: 1\n",
      "Row 14492 => Predicted: 0\n",
      "Row 14493 => Predicted: 0\n",
      "Row 14494 => Predicted: 0\n",
      "Row 14495 => Predicted: 0\n",
      "Row 14496 => Predicted: 0\n",
      "Row 14497 => Predicted: 1\n",
      "Row 14498 => Predicted: 0\n",
      "Row 14499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14490 to 14499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14500 => Predicted: 0\n",
      "Row 14501 => Predicted: 0\n",
      "Row 14502 => Predicted: 1\n",
      "Row 14503 => Predicted: 0\n",
      "Row 14504 => Predicted: 0\n",
      "Row 14505 => Predicted: 0\n",
      "Row 14506 => Predicted: 1\n",
      "Row 14507 => Predicted: 1\n",
      "Row 14508 => Predicted: 0\n",
      "Row 14509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14500 to 14509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14510 => Predicted: 1\n",
      "Row 14511 => Predicted: 0\n",
      "Row 14512 => Predicted: 1\n",
      "Row 14513 => Predicted: 0\n",
      "Row 14514 => Predicted: 1\n",
      "Row 14515 => Predicted: 1\n",
      "Row 14516 => Predicted: 1\n",
      "Row 14517 => Predicted: 1\n",
      "Row 14518 => Predicted: 0\n",
      "Row 14519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14510 to 14519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14520 => Predicted: 1\n",
      "Row 14521 => Predicted: 1\n",
      "Row 14522 => Predicted: 0\n",
      "Row 14523 => Predicted: 0\n",
      "Row 14524 => Predicted: 1\n",
      "Row 14525 => Predicted: 0\n",
      "Row 14526 => Predicted: 1\n",
      "Row 14527 => Predicted: 1\n",
      "Row 14528 => Predicted: 1\n",
      "Row 14529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14520 to 14529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14530 => Predicted: 0\n",
      "Row 14531 => Predicted: 1\n",
      "Row 14532 => Predicted: 1\n",
      "Row 14533 => Predicted: 0\n",
      "Row 14534 => Predicted: 1\n",
      "Row 14535 => Predicted: 1\n",
      "Row 14536 => Predicted: 0\n",
      "Row 14537 => Predicted: 0\n",
      "Row 14538 => Predicted: 1\n",
      "Row 14539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14530 to 14539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14540 => Predicted: 0\n",
      "Row 14541 => Predicted: 0\n",
      "Row 14542 => Predicted: 0\n",
      "Row 14543 => Predicted: 0\n",
      "Row 14544 => Predicted: 0\n",
      "Row 14545 => Predicted: 0\n",
      "Row 14546 => Predicted: 1\n",
      "Row 14547 => Predicted: 0\n",
      "Row 14548 => Predicted: 1\n",
      "Row 14549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14540 to 14549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14550 => Predicted: 1\n",
      "Row 14551 => Predicted: 0\n",
      "Row 14552 => Predicted: 0\n",
      "Row 14553 => Predicted: 1\n",
      "Row 14554 => Predicted: 1\n",
      "Row 14555 => Predicted: 1\n",
      "Row 14556 => Predicted: 1\n",
      "Row 14557 => Predicted: 1\n",
      "Row 14558 => Predicted: 0\n",
      "Row 14559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14550 to 14559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14560 => Predicted: 1\n",
      "Row 14561 => Predicted: 0\n",
      "Row 14562 => Predicted: 0\n",
      "Row 14563 => Predicted: 0\n",
      "Row 14564 => Predicted: 0\n",
      "Row 14565 => Predicted: 0\n",
      "Row 14566 => Predicted: 0\n",
      "Row 14567 => Predicted: 1\n",
      "Row 14568 => Predicted: 0\n",
      "Row 14569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14560 to 14569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14570 => Predicted: 0\n",
      "Row 14571 => Predicted: 1\n",
      "Row 14572 => Predicted: 1\n",
      "Row 14573 => Predicted: 1\n",
      "Row 14574 => Predicted: 0\n",
      "Row 14575 => Predicted: 1\n",
      "Row 14576 => Predicted: 1\n",
      "Row 14577 => Predicted: 1\n",
      "Row 14578 => Predicted: 0\n",
      "Row 14579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14570 to 14579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14580 => Predicted: 0\n",
      "Row 14581 => Predicted: 1\n",
      "Row 14582 => Predicted: 1\n",
      "Row 14583 => Predicted: 1\n",
      "Row 14584 => Predicted: 0\n",
      "Row 14585 => Predicted: 0\n",
      "Row 14586 => Predicted: 0\n",
      "Row 14587 => Predicted: 0\n",
      "Row 14588 => Predicted: 1\n",
      "Row 14589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14580 to 14589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14590 => Predicted: 0\n",
      "Row 14591 => Predicted: 0\n",
      "Row 14592 => Predicted: 1\n",
      "Row 14593 => Predicted: 1\n",
      "Row 14594 => Predicted: 1\n",
      "Row 14595 => Predicted: 1\n",
      "Row 14596 => Predicted: 0\n",
      "Row 14597 => Predicted: 0\n",
      "Row 14598 => Predicted: 1\n",
      "Row 14599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14590 to 14599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14600 => Predicted: 1\n",
      "Row 14601 => Predicted: 0\n",
      "Row 14602 => Predicted: 1\n",
      "Row 14603 => Predicted: 0\n",
      "Row 14604 => Predicted: 1\n",
      "Row 14605 => Predicted: 1\n",
      "Row 14606 => Predicted: 1\n",
      "Row 14607 => Predicted: 0\n",
      "Row 14608 => Predicted: 1\n",
      "Row 14609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14600 to 14609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14610 => Predicted: 0\n",
      "Row 14611 => Predicted: 1\n",
      "Row 14612 => Predicted: 1\n",
      "Row 14613 => Predicted: 0\n",
      "Row 14614 => Predicted: 1\n",
      "Row 14615 => Predicted: 0\n",
      "Row 14616 => Predicted: 0\n",
      "Row 14617 => Predicted: 1\n",
      "Row 14618 => Predicted: 0\n",
      "Row 14619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14610 to 14619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14620 => Predicted: 0\n",
      "Row 14621 => Predicted: 1\n",
      "Row 14622 => Predicted: 1\n",
      "Row 14623 => Predicted: 0\n",
      "Row 14624 => Predicted: 1\n",
      "Row 14625 => Predicted: 0\n",
      "Row 14626 => Predicted: 0\n",
      "Row 14627 => Predicted: 0\n",
      "Row 14628 => Predicted: 1\n",
      "Row 14629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14620 to 14629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14630 => Predicted: 0\n",
      "Row 14631 => Predicted: 0\n",
      "Row 14632 => Predicted: 0\n",
      "Row 14633 => Predicted: 1\n",
      "Row 14634 => Predicted: 0\n",
      "Row 14635 => Predicted: 0\n",
      "Row 14636 => Predicted: 0\n",
      "Row 14637 => Predicted: 0\n",
      "Row 14638 => Predicted: 1\n",
      "Row 14639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14630 to 14639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14640 => Predicted: 1\n",
      "Row 14641 => Predicted: 0\n",
      "Row 14642 => Predicted: 1\n",
      "Row 14643 => Predicted: 1\n",
      "Row 14644 => Predicted: 1\n",
      "Row 14645 => Predicted: 0\n",
      "Row 14646 => Predicted: 0\n",
      "Row 14647 => Predicted: 1\n",
      "Row 14648 => Predicted: 0\n",
      "Row 14649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14640 to 14649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14650 => Predicted: 0\n",
      "Row 14651 => Predicted: 0\n",
      "Row 14652 => Predicted: 0\n",
      "Row 14653 => Predicted: 1\n",
      "Row 14654 => Predicted: 1\n",
      "Row 14655 => Predicted: 0\n",
      "Row 14656 => Predicted: 1\n",
      "Row 14657 => Predicted: 1\n",
      "Row 14658 => Predicted: 1\n",
      "Row 14659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14650 to 14659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14660 => Predicted: 1\n",
      "Row 14661 => Predicted: 0\n",
      "Row 14662 => Predicted: 1\n",
      "Row 14663 => Predicted: 1\n",
      "Row 14664 => Predicted: 1\n",
      "Row 14665 => Predicted: 1\n",
      "Row 14666 => Predicted: 1\n",
      "Row 14667 => Predicted: 0\n",
      "Row 14668 => Predicted: 0\n",
      "Row 14669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14660 to 14669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14670 => Predicted: 0\n",
      "Row 14671 => Predicted: 1\n",
      "Row 14672 => Predicted: 1\n",
      "Row 14673 => Predicted: 0\n",
      "Row 14674 => Predicted: 1\n",
      "Row 14675 => Predicted: 0\n",
      "Row 14676 => Predicted: 0\n",
      "Row 14677 => Predicted: 0\n",
      "Row 14678 => Predicted: 0\n",
      "Row 14679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14670 to 14679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14680 => Predicted: 0\n",
      "Row 14681 => Predicted: 1\n",
      "Row 14682 => Predicted: 0\n",
      "Row 14683 => Predicted: 0\n",
      "Row 14684 => Predicted: 0\n",
      "Row 14685 => Predicted: 0\n",
      "Row 14686 => Predicted: 0\n",
      "Row 14687 => Predicted: 0\n",
      "Row 14688 => Predicted: 1\n",
      "Row 14689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14680 to 14689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14690 => Predicted: 1\n",
      "Row 14691 => Predicted: 0\n",
      "Row 14692 => Predicted: 1\n",
      "Row 14693 => Predicted: 0\n",
      "Row 14694 => Predicted: 1\n",
      "Row 14695 => Predicted: 1\n",
      "Row 14696 => Predicted: 0\n",
      "Row 14697 => Predicted: 0\n",
      "Row 14698 => Predicted: 0\n",
      "Row 14699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14690 to 14699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14700 => Predicted: 0\n",
      "Row 14701 => Predicted: 1\n",
      "Row 14702 => Predicted: 1\n",
      "Row 14703 => Predicted: 0\n",
      "Row 14704 => Predicted: 0\n",
      "Row 14705 => Predicted: 0\n",
      "Row 14706 => Predicted: 1\n",
      "Row 14707 => Predicted: 0\n",
      "Row 14708 => Predicted: 1\n",
      "Row 14709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14700 to 14709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14710 => Predicted: 1\n",
      "Row 14711 => Predicted: 1\n",
      "Row 14712 => Predicted: 1\n",
      "Row 14713 => Predicted: 0\n",
      "Row 14714 => Predicted: 0\n",
      "Row 14715 => Predicted: 0\n",
      "Row 14716 => Predicted: 0\n",
      "Row 14717 => Predicted: 1\n",
      "Row 14718 => Predicted: 0\n",
      "Row 14719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14710 to 14719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14720 => Predicted: 1\n",
      "Row 14721 => Predicted: 0\n",
      "Row 14722 => Predicted: 0\n",
      "Row 14723 => Predicted: 0\n",
      "Row 14724 => Predicted: 0\n",
      "Row 14725 => Predicted: 1\n",
      "Row 14726 => Predicted: 1\n",
      "Row 14727 => Predicted: 1\n",
      "Row 14728 => Predicted: 0\n",
      "Row 14729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14720 to 14729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14730 => Predicted: 0\n",
      "Row 14731 => Predicted: 0\n",
      "Row 14732 => Predicted: 1\n",
      "Row 14733 => Predicted: 0\n",
      "Row 14734 => Predicted: 0\n",
      "Row 14735 => Predicted: 0\n",
      "Row 14736 => Predicted: 1\n",
      "Row 14737 => Predicted: 0\n",
      "Row 14738 => Predicted: 1\n",
      "Row 14739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14730 to 14739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14740 => Predicted: 1\n",
      "Row 14741 => Predicted: 0\n",
      "Row 14742 => Predicted: 0\n",
      "Row 14743 => Predicted: 1\n",
      "Row 14744 => Predicted: 1\n",
      "Row 14745 => Predicted: 1\n",
      "Row 14746 => Predicted: 1\n",
      "Row 14747 => Predicted: 1\n",
      "Row 14748 => Predicted: 0\n",
      "Row 14749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14740 to 14749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14750 => Predicted: 0\n",
      "Row 14751 => Predicted: 0\n",
      "Row 14752 => Predicted: 1\n",
      "Row 14753 => Predicted: 0\n",
      "Row 14754 => Predicted: 0\n",
      "Row 14755 => Predicted: 1\n",
      "Row 14756 => Predicted: 1\n",
      "Row 14757 => Predicted: 1\n",
      "Row 14758 => Predicted: 0\n",
      "Row 14759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14750 to 14759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14760 => Predicted: 1\n",
      "Row 14761 => Predicted: 1\n",
      "Row 14762 => Predicted: 0\n",
      "Row 14763 => Predicted: 0\n",
      "Row 14764 => Predicted: 1\n",
      "Row 14765 => Predicted: 0\n",
      "Row 14766 => Predicted: 0\n",
      "Row 14767 => Predicted: 0\n",
      "Row 14768 => Predicted: 1\n",
      "Row 14769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14760 to 14769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14770 => Predicted: 0\n",
      "Row 14771 => Predicted: 0\n",
      "Row 14772 => Predicted: 0\n",
      "Row 14773 => Predicted: 1\n",
      "Row 14774 => Predicted: 1\n",
      "Row 14775 => Predicted: 0\n",
      "Row 14776 => Predicted: 1\n",
      "Row 14777 => Predicted: 1\n",
      "Row 14778 => Predicted: 1\n",
      "Row 14779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14770 to 14779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14780 => Predicted: 0\n",
      "Row 14781 => Predicted: 0\n",
      "Row 14782 => Predicted: 0\n",
      "Row 14783 => Predicted: 1\n",
      "Row 14784 => Predicted: 1\n",
      "Row 14785 => Predicted: 0\n",
      "Row 14786 => Predicted: 0\n",
      "Row 14787 => Predicted: 1\n",
      "Row 14788 => Predicted: 0\n",
      "Row 14789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14780 to 14789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14790 => Predicted: 1\n",
      "Row 14791 => Predicted: 0\n",
      "Row 14792 => Predicted: 1\n",
      "Row 14793 => Predicted: 1\n",
      "Row 14794 => Predicted: 1\n",
      "Row 14795 => Predicted: 1\n",
      "Row 14796 => Predicted: 1\n",
      "Row 14797 => Predicted: 0\n",
      "Row 14798 => Predicted: 1\n",
      "Row 14799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14790 to 14799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14800 => Predicted: 1\n",
      "Row 14801 => Predicted: 0\n",
      "Row 14802 => Predicted: 0\n",
      "Row 14803 => Predicted: 1\n",
      "Row 14804 => Predicted: 1\n",
      "Row 14805 => Predicted: 1\n",
      "Row 14806 => Predicted: 1\n",
      "Row 14807 => Predicted: 0\n",
      "Row 14808 => Predicted: 1\n",
      "Row 14809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14800 to 14809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14810 => Predicted: 0\n",
      "Row 14811 => Predicted: 1\n",
      "Row 14812 => Predicted: 1\n",
      "Row 14813 => Predicted: 1\n",
      "Row 14814 => Predicted: 1\n",
      "Row 14815 => Predicted: 1\n",
      "Row 14816 => Predicted: 1\n",
      "Row 14817 => Predicted: 0\n",
      "Row 14818 => Predicted: 0\n",
      "Row 14819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14810 to 14819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14820 => Predicted: 1\n",
      "Row 14821 => Predicted: 1\n",
      "Row 14822 => Predicted: 1\n",
      "Row 14823 => Predicted: 0\n",
      "Row 14824 => Predicted: 0\n",
      "Row 14825 => Predicted: 0\n",
      "Row 14826 => Predicted: 0\n",
      "Row 14827 => Predicted: 0\n",
      "Row 14828 => Predicted: 1\n",
      "Row 14829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14820 to 14829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14830 => Predicted: 1\n",
      "Row 14831 => Predicted: 0\n",
      "Row 14832 => Predicted: 1\n",
      "Row 14833 => Predicted: 1\n",
      "Row 14834 => Predicted: 0\n",
      "Row 14835 => Predicted: 0\n",
      "Row 14836 => Predicted: 0\n",
      "Row 14837 => Predicted: 1\n",
      "Row 14838 => Predicted: 0\n",
      "Row 14839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14830 to 14839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14840 => Predicted: 1\n",
      "Row 14841 => Predicted: 1\n",
      "Row 14842 => Predicted: 1\n",
      "Row 14843 => Predicted: 1\n",
      "Row 14844 => Predicted: 1\n",
      "Row 14845 => Predicted: 1\n",
      "Row 14846 => Predicted: 0\n",
      "Row 14847 => Predicted: 1\n",
      "Row 14848 => Predicted: 1\n",
      "Row 14849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14840 to 14849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14850 => Predicted: 0\n",
      "Row 14851 => Predicted: 1\n",
      "Row 14852 => Predicted: 1\n",
      "Row 14853 => Predicted: 1\n",
      "Row 14854 => Predicted: 0\n",
      "Row 14855 => Predicted: 1\n",
      "Row 14856 => Predicted: 1\n",
      "Row 14857 => Predicted: 0\n",
      "Row 14858 => Predicted: 0\n",
      "Row 14859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14850 to 14859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14860 => Predicted: 1\n",
      "Row 14861 => Predicted: 1\n",
      "Row 14862 => Predicted: 0\n",
      "Row 14863 => Predicted: 1\n",
      "Row 14864 => Predicted: 1\n",
      "Row 14865 => Predicted: 1\n",
      "Row 14866 => Predicted: 1\n",
      "Row 14867 => Predicted: 0\n",
      "Row 14868 => Predicted: 0\n",
      "Row 14869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14860 to 14869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14870 => Predicted: 0\n",
      "Row 14871 => Predicted: 0\n",
      "Row 14872 => Predicted: 0\n",
      "Row 14873 => Predicted: 0\n",
      "Row 14874 => Predicted: 0\n",
      "Row 14875 => Predicted: 0\n",
      "Row 14876 => Predicted: 0\n",
      "Row 14877 => Predicted: 1\n",
      "Row 14878 => Predicted: 0\n",
      "Row 14879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14870 to 14879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14880 => Predicted: 0\n",
      "Row 14881 => Predicted: 1\n",
      "Row 14882 => Predicted: 1\n",
      "Row 14883 => Predicted: 0\n",
      "Row 14884 => Predicted: 0\n",
      "Row 14885 => Predicted: 1\n",
      "Row 14886 => Predicted: 1\n",
      "Row 14887 => Predicted: 0\n",
      "Row 14888 => Predicted: 1\n",
      "Row 14889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14880 to 14889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14890 => Predicted: 1\n",
      "Row 14891 => Predicted: 0\n",
      "Row 14892 => Predicted: 1\n",
      "Row 14893 => Predicted: 1\n",
      "Row 14894 => Predicted: 1\n",
      "Row 14895 => Predicted: 0\n",
      "Row 14896 => Predicted: 0\n",
      "Row 14897 => Predicted: 1\n",
      "Row 14898 => Predicted: 0\n",
      "Row 14899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14890 to 14899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14900 => Predicted: 0\n",
      "Row 14901 => Predicted: 1\n",
      "Row 14902 => Predicted: 1\n",
      "Row 14903 => Predicted: 0\n",
      "Row 14904 => Predicted: 0\n",
      "Row 14905 => Predicted: 1\n",
      "Row 14906 => Predicted: 1\n",
      "Row 14907 => Predicted: 0\n",
      "Row 14908 => Predicted: 0\n",
      "Row 14909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14900 to 14909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14910 => Predicted: 0\n",
      "Row 14911 => Predicted: 1\n",
      "Row 14912 => Predicted: 1\n",
      "Row 14913 => Predicted: 1\n",
      "Row 14914 => Predicted: 1\n",
      "Row 14915 => Predicted: 1\n",
      "Row 14916 => Predicted: 0\n",
      "Row 14917 => Predicted: 0\n",
      "Row 14918 => Predicted: 1\n",
      "Row 14919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14910 to 14919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14920 => Predicted: 1\n",
      "Row 14921 => Predicted: 0\n",
      "Row 14922 => Predicted: 0\n",
      "Row 14923 => Predicted: 0\n",
      "Row 14924 => Predicted: 1\n",
      "Row 14925 => Predicted: 1\n",
      "Row 14926 => Predicted: 0\n",
      "Row 14927 => Predicted: 0\n",
      "Row 14928 => Predicted: 1\n",
      "Row 14929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14920 to 14929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14930 => Predicted: 1\n",
      "Row 14931 => Predicted: 0\n",
      "Row 14932 => Predicted: 1\n",
      "Row 14933 => Predicted: 0\n",
      "Row 14934 => Predicted: 0\n",
      "Row 14935 => Predicted: 1\n",
      "Row 14936 => Predicted: 0\n",
      "Row 14937 => Predicted: 1\n",
      "Row 14938 => Predicted: 1\n",
      "Row 14939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14930 to 14939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14940 => Predicted: 1\n",
      "Row 14941 => Predicted: 1\n",
      "Row 14942 => Predicted: 0\n",
      "Row 14943 => Predicted: 1\n",
      "Row 14944 => Predicted: 0\n",
      "Row 14945 => Predicted: 0\n",
      "Row 14946 => Predicted: 1\n",
      "Row 14947 => Predicted: 1\n",
      "Row 14948 => Predicted: 0\n",
      "Row 14949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14940 to 14949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14950 => Predicted: 0\n",
      "Row 14951 => Predicted: 1\n",
      "Row 14952 => Predicted: 0\n",
      "Row 14953 => Predicted: 1\n",
      "Row 14954 => Predicted: 1\n",
      "Row 14955 => Predicted: 0\n",
      "Row 14956 => Predicted: 1\n",
      "Row 14957 => Predicted: 0\n",
      "Row 14958 => Predicted: 0\n",
      "Row 14959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14950 to 14959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14960 => Predicted: 0\n",
      "Row 14961 => Predicted: 1\n",
      "Row 14962 => Predicted: 1\n",
      "Row 14963 => Predicted: 0\n",
      "Row 14964 => Predicted: 1\n",
      "Row 14965 => Predicted: 0\n",
      "Row 14966 => Predicted: 1\n",
      "Row 14967 => Predicted: 0\n",
      "Row 14968 => Predicted: 1\n",
      "Row 14969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14960 to 14969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14970 => Predicted: 0\n",
      "Row 14971 => Predicted: 0\n",
      "Row 14972 => Predicted: 0\n",
      "Row 14973 => Predicted: 0\n",
      "Row 14974 => Predicted: 0\n",
      "Row 14975 => Predicted: 1\n",
      "Row 14976 => Predicted: 0\n",
      "Row 14977 => Predicted: 0\n",
      "Row 14978 => Predicted: 0\n",
      "Row 14979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14970 to 14979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14980 => Predicted: 1\n",
      "Row 14981 => Predicted: 0\n",
      "Row 14982 => Predicted: 0\n",
      "Row 14983 => Predicted: 1\n",
      "Row 14984 => Predicted: 0\n",
      "Row 14985 => Predicted: 1\n",
      "Row 14986 => Predicted: 0\n",
      "Row 14987 => Predicted: 0\n",
      "Row 14988 => Predicted: 0\n",
      "Row 14989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 14980 to 14989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14990 => Predicted: 1\n",
      "Row 14991 => Predicted: 0\n",
      "Row 14992 => Predicted: 1\n",
      "Row 14993 => Predicted: 1\n",
      "Row 14994 => Predicted: 1\n",
      "Row 14995 => Predicted: 0\n",
      "Row 14996 => Predicted: 0\n",
      "Row 14997 => Predicted: 1\n",
      "Row 14998 => Predicted: 0\n",
      "Row 14999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 14990 to 14999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15000 => Predicted: 1\n",
      "Row 15001 => Predicted: 0\n",
      "Row 15002 => Predicted: 1\n",
      "Row 15003 => Predicted: 1\n",
      "Row 15004 => Predicted: 1\n",
      "Row 15005 => Predicted: 1\n",
      "Row 15006 => Predicted: 1\n",
      "Row 15007 => Predicted: 1\n",
      "Row 15008 => Predicted: 0\n",
      "Row 15009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15000 to 15009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15010 => Predicted: 1\n",
      "Row 15011 => Predicted: 1\n",
      "Row 15012 => Predicted: 0\n",
      "Row 15013 => Predicted: 0\n",
      "Row 15014 => Predicted: 0\n",
      "Row 15015 => Predicted: 1\n",
      "Row 15016 => Predicted: 1\n",
      "Row 15017 => Predicted: 0\n",
      "Row 15018 => Predicted: 0\n",
      "Row 15019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15010 to 15019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15020 => Predicted: 0\n",
      "Row 15021 => Predicted: 1\n",
      "Row 15022 => Predicted: 0\n",
      "Row 15023 => Predicted: 1\n",
      "Row 15024 => Predicted: 0\n",
      "Row 15025 => Predicted: 1\n",
      "Row 15026 => Predicted: 0\n",
      "Row 15027 => Predicted: 0\n",
      "Row 15028 => Predicted: 1\n",
      "Row 15029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15020 to 15029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15030 => Predicted: 1\n",
      "Row 15031 => Predicted: 1\n",
      "Row 15032 => Predicted: 0\n",
      "Row 15033 => Predicted: 0\n",
      "Row 15034 => Predicted: 1\n",
      "Row 15035 => Predicted: 0\n",
      "Row 15036 => Predicted: 1\n",
      "Row 15037 => Predicted: 1\n",
      "Row 15038 => Predicted: 1\n",
      "Row 15039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15030 to 15039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15040 => Predicted: 1\n",
      "Row 15041 => Predicted: 1\n",
      "Row 15042 => Predicted: 0\n",
      "Row 15043 => Predicted: 0\n",
      "Row 15044 => Predicted: 0\n",
      "Row 15045 => Predicted: 1\n",
      "Row 15046 => Predicted: 1\n",
      "Row 15047 => Predicted: 1\n",
      "Row 15048 => Predicted: 1\n",
      "Row 15049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15040 to 15049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15050 => Predicted: 0\n",
      "Row 15051 => Predicted: 0\n",
      "Row 15052 => Predicted: 0\n",
      "Row 15053 => Predicted: 1\n",
      "Row 15054 => Predicted: 1\n",
      "Row 15055 => Predicted: 0\n",
      "Row 15056 => Predicted: 1\n",
      "Row 15057 => Predicted: 1\n",
      "Row 15058 => Predicted: 1\n",
      "Row 15059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15050 to 15059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15060 => Predicted: 1\n",
      "Row 15061 => Predicted: 1\n",
      "Row 15062 => Predicted: 0\n",
      "Row 15063 => Predicted: 1\n",
      "Row 15064 => Predicted: 1\n",
      "Row 15065 => Predicted: 0\n",
      "Row 15066 => Predicted: 1\n",
      "Row 15067 => Predicted: 1\n",
      "Row 15068 => Predicted: 0\n",
      "Row 15069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15060 to 15069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15070 => Predicted: 1\n",
      "Row 15071 => Predicted: 0\n",
      "Row 15072 => Predicted: 0\n",
      "Row 15073 => Predicted: 0\n",
      "Row 15074 => Predicted: 0\n",
      "Row 15075 => Predicted: 1\n",
      "Row 15076 => Predicted: 1\n",
      "Row 15077 => Predicted: 0\n",
      "Row 15078 => Predicted: 0\n",
      "Row 15079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15070 to 15079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15080 => Predicted: 1\n",
      "Row 15081 => Predicted: 1\n",
      "Row 15082 => Predicted: 1\n",
      "Row 15083 => Predicted: 1\n",
      "Row 15084 => Predicted: 1\n",
      "Row 15085 => Predicted: 0\n",
      "Row 15086 => Predicted: 0\n",
      "Row 15087 => Predicted: 1\n",
      "Row 15088 => Predicted: 1\n",
      "Row 15089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15080 to 15089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15090 => Predicted: 1\n",
      "Row 15091 => Predicted: 1\n",
      "Row 15092 => Predicted: 1\n",
      "Row 15093 => Predicted: 0\n",
      "Row 15094 => Predicted: 0\n",
      "Row 15095 => Predicted: 1\n",
      "Row 15096 => Predicted: 0\n",
      "Row 15097 => Predicted: 1\n",
      "Row 15098 => Predicted: 0\n",
      "Row 15099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15090 to 15099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15100 => Predicted: 0\n",
      "Row 15101 => Predicted: 0\n",
      "Row 15102 => Predicted: 0\n",
      "Row 15103 => Predicted: 0\n",
      "Row 15104 => Predicted: 1\n",
      "Row 15105 => Predicted: 0\n",
      "Row 15106 => Predicted: 0\n",
      "Row 15107 => Predicted: 0\n",
      "Row 15108 => Predicted: 0\n",
      "Row 15109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15100 to 15109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15110 => Predicted: 0\n",
      "Row 15111 => Predicted: 1\n",
      "Row 15112 => Predicted: 1\n",
      "Row 15113 => Predicted: 0\n",
      "Row 15114 => Predicted: 1\n",
      "Row 15115 => Predicted: 1\n",
      "Row 15116 => Predicted: 0\n",
      "Row 15117 => Predicted: 1\n",
      "Row 15118 => Predicted: 1\n",
      "Row 15119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15110 to 15119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15120 => Predicted: 0\n",
      "Row 15121 => Predicted: 0\n",
      "Row 15122 => Predicted: 0\n",
      "Row 15123 => Predicted: 1\n",
      "Row 15124 => Predicted: 1\n",
      "Row 15125 => Predicted: 0\n",
      "Row 15126 => Predicted: 1\n",
      "Row 15127 => Predicted: 0\n",
      "Row 15128 => Predicted: 0\n",
      "Row 15129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15120 to 15129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15130 => Predicted: 1\n",
      "Row 15131 => Predicted: 0\n",
      "Row 15132 => Predicted: 0\n",
      "Row 15133 => Predicted: 0\n",
      "Row 15134 => Predicted: 1\n",
      "Row 15135 => Predicted: 1\n",
      "Row 15136 => Predicted: 1\n",
      "Row 15137 => Predicted: 0\n",
      "Row 15138 => Predicted: 0\n",
      "Row 15139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15130 to 15139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15140 => Predicted: 0\n",
      "Row 15141 => Predicted: 0\n",
      "Row 15142 => Predicted: 0\n",
      "Row 15143 => Predicted: 1\n",
      "Row 15144 => Predicted: 0\n",
      "Row 15145 => Predicted: 0\n",
      "Row 15146 => Predicted: 1\n",
      "Row 15147 => Predicted: 0\n",
      "Row 15148 => Predicted: 0\n",
      "Row 15149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15140 to 15149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15150 => Predicted: 1\n",
      "Row 15151 => Predicted: 1\n",
      "Row 15152 => Predicted: 0\n",
      "Row 15153 => Predicted: 0\n",
      "Row 15154 => Predicted: 1\n",
      "Row 15155 => Predicted: 0\n",
      "Row 15156 => Predicted: 1\n",
      "Row 15157 => Predicted: 1\n",
      "Row 15158 => Predicted: 1\n",
      "Row 15159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15150 to 15159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15160 => Predicted: 1\n",
      "Row 15161 => Predicted: 1\n",
      "Row 15162 => Predicted: 1\n",
      "Row 15163 => Predicted: 0\n",
      "Row 15164 => Predicted: 0\n",
      "Row 15165 => Predicted: 0\n",
      "Row 15166 => Predicted: 0\n",
      "Row 15167 => Predicted: 1\n",
      "Row 15168 => Predicted: 0\n",
      "Row 15169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15160 to 15169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15170 => Predicted: 0\n",
      "Row 15171 => Predicted: 1\n",
      "Row 15172 => Predicted: 1\n",
      "Row 15173 => Predicted: 1\n",
      "Row 15174 => Predicted: 1\n",
      "Row 15175 => Predicted: 0\n",
      "Row 15176 => Predicted: 1\n",
      "Row 15177 => Predicted: 1\n",
      "Row 15178 => Predicted: 0\n",
      "Row 15179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15170 to 15179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15180 => Predicted: 1\n",
      "Row 15181 => Predicted: 1\n",
      "Row 15182 => Predicted: 0\n",
      "Row 15183 => Predicted: 0\n",
      "Row 15184 => Predicted: 1\n",
      "Row 15185 => Predicted: 1\n",
      "Row 15186 => Predicted: 0\n",
      "Row 15187 => Predicted: 0\n",
      "Row 15188 => Predicted: 1\n",
      "Row 15189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15180 to 15189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15190 => Predicted: 0\n",
      "Row 15191 => Predicted: 1\n",
      "Row 15192 => Predicted: 0\n",
      "Row 15193 => Predicted: 1\n",
      "Row 15194 => Predicted: 1\n",
      "Row 15195 => Predicted: 1\n",
      "Row 15196 => Predicted: 1\n",
      "Row 15197 => Predicted: 1\n",
      "Row 15198 => Predicted: 0\n",
      "Row 15199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15190 to 15199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15200 => Predicted: 0\n",
      "Row 15201 => Predicted: 0\n",
      "Row 15202 => Predicted: 0\n",
      "Row 15203 => Predicted: 1\n",
      "Row 15204 => Predicted: 1\n",
      "Row 15205 => Predicted: 1\n",
      "Row 15206 => Predicted: 0\n",
      "Row 15207 => Predicted: 1\n",
      "Row 15208 => Predicted: 1\n",
      "Row 15209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15200 to 15209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15210 => Predicted: 0\n",
      "Row 15211 => Predicted: 1\n",
      "Row 15212 => Predicted: 1\n",
      "Row 15213 => Predicted: 0\n",
      "Row 15214 => Predicted: 1\n",
      "Row 15215 => Predicted: 0\n",
      "Row 15216 => Predicted: 1\n",
      "Row 15217 => Predicted: 1\n",
      "Row 15218 => Predicted: 0\n",
      "Row 15219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15210 to 15219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15220 => Predicted: 1\n",
      "Row 15221 => Predicted: 1\n",
      "Row 15222 => Predicted: 1\n",
      "Row 15223 => Predicted: 0\n",
      "Row 15224 => Predicted: 0\n",
      "Row 15225 => Predicted: 0\n",
      "Row 15226 => Predicted: 1\n",
      "Row 15227 => Predicted: 1\n",
      "Row 15228 => Predicted: 1\n",
      "Row 15229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15220 to 15229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15230 => Predicted: 1\n",
      "Row 15231 => Predicted: 0\n",
      "Row 15232 => Predicted: 1\n",
      "Row 15233 => Predicted: 1\n",
      "Row 15234 => Predicted: 0\n",
      "Row 15235 => Predicted: 0\n",
      "Row 15236 => Predicted: 0\n",
      "Row 15237 => Predicted: 0\n",
      "Row 15238 => Predicted: 0\n",
      "Row 15239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15230 to 15239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15240 => Predicted: 1\n",
      "Row 15241 => Predicted: 1\n",
      "Row 15242 => Predicted: 1\n",
      "Row 15243 => Predicted: 0\n",
      "Row 15244 => Predicted: 0\n",
      "Row 15245 => Predicted: 0\n",
      "Row 15246 => Predicted: 1\n",
      "Row 15247 => Predicted: 1\n",
      "Row 15248 => Predicted: 1\n",
      "Row 15249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15240 to 15249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15250 => Predicted: 0\n",
      "Row 15251 => Predicted: 0\n",
      "Row 15252 => Predicted: 1\n",
      "Row 15253 => Predicted: 0\n",
      "Row 15254 => Predicted: 1\n",
      "Row 15255 => Predicted: 1\n",
      "Row 15256 => Predicted: 1\n",
      "Row 15257 => Predicted: 1\n",
      "Row 15258 => Predicted: 1\n",
      "Row 15259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15250 to 15259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15260 => Predicted: 1\n",
      "Row 15261 => Predicted: 1\n",
      "Row 15262 => Predicted: 1\n",
      "Row 15263 => Predicted: 1\n",
      "Row 15264 => Predicted: 1\n",
      "Row 15265 => Predicted: 1\n",
      "Row 15266 => Predicted: 1\n",
      "Row 15267 => Predicted: 0\n",
      "Row 15268 => Predicted: 0\n",
      "Row 15269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15260 to 15269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15270 => Predicted: 0\n",
      "Row 15271 => Predicted: 0\n",
      "Row 15272 => Predicted: 0\n",
      "Row 15273 => Predicted: 0\n",
      "Row 15274 => Predicted: 0\n",
      "Row 15275 => Predicted: 1\n",
      "Row 15276 => Predicted: 0\n",
      "Row 15277 => Predicted: 0\n",
      "Row 15278 => Predicted: 1\n",
      "Row 15279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15270 to 15279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15280 => Predicted: 1\n",
      "Row 15281 => Predicted: 0\n",
      "Row 15282 => Predicted: 1\n",
      "Row 15283 => Predicted: 0\n",
      "Row 15284 => Predicted: 1\n",
      "Row 15285 => Predicted: 1\n",
      "Row 15286 => Predicted: 1\n",
      "Row 15287 => Predicted: 0\n",
      "Row 15288 => Predicted: 0\n",
      "Row 15289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15280 to 15289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15290 => Predicted: 1\n",
      "Row 15291 => Predicted: 0\n",
      "Row 15292 => Predicted: 1\n",
      "Row 15293 => Predicted: 1\n",
      "Row 15294 => Predicted: 0\n",
      "Row 15295 => Predicted: 0\n",
      "Row 15296 => Predicted: 1\n",
      "Row 15297 => Predicted: 1\n",
      "Row 15298 => Predicted: 0\n",
      "Row 15299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15290 to 15299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15300 => Predicted: 0\n",
      "Row 15301 => Predicted: 1\n",
      "Row 15302 => Predicted: 0\n",
      "Row 15303 => Predicted: 1\n",
      "Row 15304 => Predicted: 0\n",
      "Row 15305 => Predicted: 1\n",
      "Row 15306 => Predicted: 0\n",
      "Row 15307 => Predicted: 1\n",
      "Row 15308 => Predicted: 1\n",
      "Row 15309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15300 to 15309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15310 => Predicted: 0\n",
      "Row 15311 => Predicted: 0\n",
      "Row 15312 => Predicted: 0\n",
      "Row 15313 => Predicted: 0\n",
      "Row 15314 => Predicted: 0\n",
      "Row 15315 => Predicted: 1\n",
      "Row 15316 => Predicted: 1\n",
      "Row 15317 => Predicted: 1\n",
      "Row 15318 => Predicted: 0\n",
      "Row 15319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15310 to 15319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15320 => Predicted: 1\n",
      "Row 15321 => Predicted: 0\n",
      "Row 15322 => Predicted: 0\n",
      "Row 15323 => Predicted: 0\n",
      "Row 15324 => Predicted: 1\n",
      "Row 15325 => Predicted: 0\n",
      "Row 15326 => Predicted: 0\n",
      "Row 15327 => Predicted: 1\n",
      "Row 15328 => Predicted: 1\n",
      "Row 15329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15320 to 15329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15330 => Predicted: 0\n",
      "Row 15331 => Predicted: 1\n",
      "Row 15332 => Predicted: 1\n",
      "Row 15333 => Predicted: 0\n",
      "Row 15334 => Predicted: 0\n",
      "Row 15335 => Predicted: 1\n",
      "Row 15336 => Predicted: 1\n",
      "Row 15337 => Predicted: 0\n",
      "Row 15338 => Predicted: 1\n",
      "Row 15339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15330 to 15339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15340 => Predicted: 0\n",
      "Row 15341 => Predicted: 1\n",
      "Row 15342 => Predicted: 1\n",
      "Row 15343 => Predicted: 1\n",
      "Row 15344 => Predicted: 1\n",
      "Row 15345 => Predicted: 1\n",
      "Row 15346 => Predicted: 1\n",
      "Row 15347 => Predicted: 1\n",
      "Row 15348 => Predicted: 1\n",
      "Row 15349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15340 to 15349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15350 => Predicted: 1\n",
      "Row 15351 => Predicted: 0\n",
      "Row 15352 => Predicted: 1\n",
      "Row 15353 => Predicted: 0\n",
      "Row 15354 => Predicted: 1\n",
      "Row 15355 => Predicted: 0\n",
      "Row 15356 => Predicted: 1\n",
      "Row 15357 => Predicted: 0\n",
      "Row 15358 => Predicted: 0\n",
      "Row 15359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15350 to 15359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15360 => Predicted: 0\n",
      "Row 15361 => Predicted: 1\n",
      "Row 15362 => Predicted: 1\n",
      "Row 15363 => Predicted: 0\n",
      "Row 15364 => Predicted: 0\n",
      "Row 15365 => Predicted: 0\n",
      "Row 15366 => Predicted: 1\n",
      "Row 15367 => Predicted: 1\n",
      "Row 15368 => Predicted: 0\n",
      "Row 15369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15360 to 15369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15370 => Predicted: 1\n",
      "Row 15371 => Predicted: 0\n",
      "Row 15372 => Predicted: 0\n",
      "Row 15373 => Predicted: 0\n",
      "Row 15374 => Predicted: 1\n",
      "Row 15375 => Predicted: 1\n",
      "Row 15376 => Predicted: 1\n",
      "Row 15377 => Predicted: 1\n",
      "Row 15378 => Predicted: 1\n",
      "Row 15379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15370 to 15379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15380 => Predicted: 1\n",
      "Row 15381 => Predicted: 1\n",
      "Row 15382 => Predicted: 0\n",
      "Row 15383 => Predicted: 1\n",
      "Row 15384 => Predicted: 0\n",
      "Row 15385 => Predicted: 1\n",
      "Row 15386 => Predicted: 1\n",
      "Row 15387 => Predicted: 1\n",
      "Row 15388 => Predicted: 1\n",
      "Row 15389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15380 to 15389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15390 => Predicted: 0\n",
      "Row 15391 => Predicted: 1\n",
      "Row 15392 => Predicted: 0\n",
      "Row 15393 => Predicted: 1\n",
      "Row 15394 => Predicted: 1\n",
      "Row 15395 => Predicted: 1\n",
      "Row 15396 => Predicted: 1\n",
      "Row 15397 => Predicted: 0\n",
      "Row 15398 => Predicted: 1\n",
      "Row 15399 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15390 to 15399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15400 => Predicted: 0\n",
      "Row 15401 => Predicted: 0\n",
      "Row 15402 => Predicted: 0\n",
      "Row 15403 => Predicted: 0\n",
      "Row 15404 => Predicted: 1\n",
      "Row 15405 => Predicted: 1\n",
      "Row 15406 => Predicted: 0\n",
      "Row 15407 => Predicted: 1\n",
      "Row 15408 => Predicted: 0\n",
      "Row 15409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15400 to 15409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15410 => Predicted: 1\n",
      "Row 15411 => Predicted: 1\n",
      "Row 15412 => Predicted: 1\n",
      "Row 15413 => Predicted: 0\n",
      "Row 15414 => Predicted: 1\n",
      "Row 15415 => Predicted: 0\n",
      "Row 15416 => Predicted: 0\n",
      "Row 15417 => Predicted: 0\n",
      "Row 15418 => Predicted: 0\n",
      "Row 15419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15410 to 15419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15420 => Predicted: 1\n",
      "Row 15421 => Predicted: 0\n",
      "Row 15422 => Predicted: 1\n",
      "Row 15423 => Predicted: 0\n",
      "Row 15424 => Predicted: 0\n",
      "Row 15425 => Predicted: 0\n",
      "Row 15426 => Predicted: 1\n",
      "Row 15427 => Predicted: 1\n",
      "Row 15428 => Predicted: 1\n",
      "Row 15429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15420 to 15429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15430 => Predicted: 0\n",
      "Row 15431 => Predicted: 0\n",
      "Row 15432 => Predicted: 0\n",
      "Row 15433 => Predicted: 1\n",
      "Row 15434 => Predicted: 0\n",
      "Row 15435 => Predicted: 1\n",
      "Row 15436 => Predicted: 1\n",
      "Row 15437 => Predicted: 0\n",
      "Row 15438 => Predicted: 1\n",
      "Row 15439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15430 to 15439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15440 => Predicted: 1\n",
      "Row 15441 => Predicted: 1\n",
      "Row 15442 => Predicted: 0\n",
      "Row 15443 => Predicted: 0\n",
      "Row 15444 => Predicted: 0\n",
      "Row 15445 => Predicted: 1\n",
      "Row 15446 => Predicted: 0\n",
      "Row 15447 => Predicted: 1\n",
      "Row 15448 => Predicted: 1\n",
      "Row 15449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15440 to 15449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15450 => Predicted: 0\n",
      "Row 15451 => Predicted: 0\n",
      "Row 15452 => Predicted: 0\n",
      "Row 15453 => Predicted: 0\n",
      "Row 15454 => Predicted: 1\n",
      "Row 15455 => Predicted: 0\n",
      "Row 15456 => Predicted: 0\n",
      "Row 15457 => Predicted: 0\n",
      "Row 15458 => Predicted: 1\n",
      "Row 15459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15450 to 15459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15460 => Predicted: 0\n",
      "Row 15461 => Predicted: 1\n",
      "Row 15462 => Predicted: 0\n",
      "Row 15463 => Predicted: 1\n",
      "Row 15464 => Predicted: 0\n",
      "Row 15465 => Predicted: 1\n",
      "Row 15466 => Predicted: 1\n",
      "Row 15467 => Predicted: 1\n",
      "Row 15468 => Predicted: 1\n",
      "Row 15469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15460 to 15469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15470 => Predicted: 1\n",
      "Row 15471 => Predicted: 1\n",
      "Row 15472 => Predicted: 1\n",
      "Row 15473 => Predicted: 1\n",
      "Row 15474 => Predicted: 0\n",
      "Row 15475 => Predicted: 0\n",
      "Row 15476 => Predicted: 0\n",
      "Row 15477 => Predicted: 0\n",
      "Row 15478 => Predicted: 0\n",
      "Row 15479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15470 to 15479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15480 => Predicted: 1\n",
      "Row 15481 => Predicted: 0\n",
      "Row 15482 => Predicted: 0\n",
      "Row 15483 => Predicted: 0\n",
      "Row 15484 => Predicted: 0\n",
      "Row 15485 => Predicted: 0\n",
      "Row 15486 => Predicted: 1\n",
      "Row 15487 => Predicted: 1\n",
      "Row 15488 => Predicted: 0\n",
      "Row 15489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15480 to 15489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15490 => Predicted: 0\n",
      "Row 15491 => Predicted: 0\n",
      "Row 15492 => Predicted: 1\n",
      "Row 15493 => Predicted: 1\n",
      "Row 15494 => Predicted: 0\n",
      "Row 15495 => Predicted: 1\n",
      "Row 15496 => Predicted: 1\n",
      "Row 15497 => Predicted: 0\n",
      "Row 15498 => Predicted: 1\n",
      "Row 15499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15490 to 15499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15500 => Predicted: 1\n",
      "Row 15501 => Predicted: 1\n",
      "Row 15502 => Predicted: 0\n",
      "Row 15503 => Predicted: 0\n",
      "Row 15504 => Predicted: 1\n",
      "Row 15505 => Predicted: 1\n",
      "Row 15506 => Predicted: 1\n",
      "Row 15507 => Predicted: 0\n",
      "Row 15508 => Predicted: 0\n",
      "Row 15509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15500 to 15509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15510 => Predicted: 0\n",
      "Row 15511 => Predicted: 0\n",
      "Row 15512 => Predicted: 1\n",
      "Row 15513 => Predicted: 0\n",
      "Row 15514 => Predicted: 1\n",
      "Row 15515 => Predicted: 1\n",
      "Row 15516 => Predicted: 1\n",
      "Row 15517 => Predicted: 1\n",
      "Row 15518 => Predicted: 1\n",
      "Row 15519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15510 to 15519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15520 => Predicted: 1\n",
      "Row 15521 => Predicted: 0\n",
      "Row 15522 => Predicted: 1\n",
      "Row 15523 => Predicted: 0\n",
      "Row 15524 => Predicted: 0\n",
      "Row 15525 => Predicted: 1\n",
      "Row 15526 => Predicted: 0\n",
      "Row 15527 => Predicted: 1\n",
      "Row 15528 => Predicted: 1\n",
      "Row 15529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15520 to 15529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15530 => Predicted: 1\n",
      "Row 15531 => Predicted: 0\n",
      "Row 15532 => Predicted: 1\n",
      "Row 15533 => Predicted: 1\n",
      "Row 15534 => Predicted: 0\n",
      "Row 15535 => Predicted: 0\n",
      "Row 15536 => Predicted: 1\n",
      "Row 15537 => Predicted: 1\n",
      "Row 15538 => Predicted: 0\n",
      "Row 15539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15530 to 15539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15540 => Predicted: 1\n",
      "Row 15541 => Predicted: 1\n",
      "Row 15542 => Predicted: 1\n",
      "Row 15543 => Predicted: 0\n",
      "Row 15544 => Predicted: 1\n",
      "Row 15545 => Predicted: 1\n",
      "Row 15546 => Predicted: 0\n",
      "Row 15547 => Predicted: 1\n",
      "Row 15548 => Predicted: 0\n",
      "Row 15549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15540 to 15549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15550 => Predicted: 0\n",
      "Row 15551 => Predicted: 0\n",
      "Row 15552 => Predicted: 1\n",
      "Row 15553 => Predicted: 1\n",
      "Row 15554 => Predicted: 0\n",
      "Row 15555 => Predicted: 1\n",
      "Row 15556 => Predicted: 1\n",
      "Row 15557 => Predicted: 0\n",
      "Row 15558 => Predicted: 0\n",
      "Row 15559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15550 to 15559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15560 => Predicted: 1\n",
      "Row 15561 => Predicted: 0\n",
      "Row 15562 => Predicted: 1\n",
      "Row 15563 => Predicted: 0\n",
      "Row 15564 => Predicted: 0\n",
      "Row 15565 => Predicted: 0\n",
      "Row 15566 => Predicted: 1\n",
      "Row 15567 => Predicted: 0\n",
      "Row 15568 => Predicted: 0\n",
      "Row 15569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15560 to 15569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15570 => Predicted: 1\n",
      "Row 15571 => Predicted: 1\n",
      "Row 15572 => Predicted: 1\n",
      "Row 15573 => Predicted: 0\n",
      "Row 15574 => Predicted: 1\n",
      "Row 15575 => Predicted: 0\n",
      "Row 15576 => Predicted: 0\n",
      "Row 15577 => Predicted: 0\n",
      "Row 15578 => Predicted: 0\n",
      "Row 15579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15570 to 15579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15580 => Predicted: 1\n",
      "Row 15581 => Predicted: 0\n",
      "Row 15582 => Predicted: 1\n",
      "Row 15583 => Predicted: 0\n",
      "Row 15584 => Predicted: 1\n",
      "Row 15585 => Predicted: 0\n",
      "Row 15586 => Predicted: 0\n",
      "Row 15587 => Predicted: 1\n",
      "Row 15588 => Predicted: 1\n",
      "Row 15589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15580 to 15589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15590 => Predicted: 1\n",
      "Row 15591 => Predicted: 1\n",
      "Row 15592 => Predicted: 0\n",
      "Row 15593 => Predicted: 0\n",
      "Row 15594 => Predicted: 0\n",
      "Row 15595 => Predicted: 0\n",
      "Row 15596 => Predicted: 1\n",
      "Row 15597 => Predicted: 1\n",
      "Row 15598 => Predicted: 0\n",
      "Row 15599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15590 to 15599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15600 => Predicted: 0\n",
      "Row 15601 => Predicted: 0\n",
      "Row 15602 => Predicted: 1\n",
      "Row 15603 => Predicted: 0\n",
      "Row 15604 => Predicted: 0\n",
      "Row 15605 => Predicted: 1\n",
      "Row 15606 => Predicted: 0\n",
      "Row 15607 => Predicted: 0\n",
      "Row 15608 => Predicted: 1\n",
      "Row 15609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15600 to 15609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15610 => Predicted: 0\n",
      "Row 15611 => Predicted: 0\n",
      "Row 15612 => Predicted: 1\n",
      "Row 15613 => Predicted: 1\n",
      "Row 15614 => Predicted: 1\n",
      "Row 15615 => Predicted: 1\n",
      "Row 15616 => Predicted: 0\n",
      "Row 15617 => Predicted: 1\n",
      "Row 15618 => Predicted: 1\n",
      "Row 15619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15610 to 15619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15620 => Predicted: 1\n",
      "Row 15621 => Predicted: 0\n",
      "Row 15622 => Predicted: 0\n",
      "Row 15623 => Predicted: 1\n",
      "Row 15624 => Predicted: 1\n",
      "Row 15625 => Predicted: 1\n",
      "Row 15626 => Predicted: 0\n",
      "Row 15627 => Predicted: 1\n",
      "Row 15628 => Predicted: 1\n",
      "Row 15629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15620 to 15629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15630 => Predicted: 0\n",
      "Row 15631 => Predicted: 0\n",
      "Row 15632 => Predicted: 0\n",
      "Row 15633 => Predicted: 1\n",
      "Row 15634 => Predicted: 1\n",
      "Row 15635 => Predicted: 1\n",
      "Row 15636 => Predicted: 0\n",
      "Row 15637 => Predicted: 1\n",
      "Row 15638 => Predicted: 0\n",
      "Row 15639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15630 to 15639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15640 => Predicted: 0\n",
      "Row 15641 => Predicted: 1\n",
      "Row 15642 => Predicted: 1\n",
      "Row 15643 => Predicted: 1\n",
      "Row 15644 => Predicted: 0\n",
      "Row 15645 => Predicted: 1\n",
      "Row 15646 => Predicted: 0\n",
      "Row 15647 => Predicted: 0\n",
      "Row 15648 => Predicted: 1\n",
      "Row 15649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15640 to 15649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15650 => Predicted: 1\n",
      "Row 15651 => Predicted: 1\n",
      "Row 15652 => Predicted: 0\n",
      "Row 15653 => Predicted: 0\n",
      "Row 15654 => Predicted: 0\n",
      "Row 15655 => Predicted: 0\n",
      "Row 15656 => Predicted: 0\n",
      "Row 15657 => Predicted: 0\n",
      "Row 15658 => Predicted: 0\n",
      "Row 15659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15650 to 15659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15660 => Predicted: 1\n",
      "Row 15661 => Predicted: 0\n",
      "Row 15662 => Predicted: 1\n",
      "Row 15663 => Predicted: 0\n",
      "Row 15664 => Predicted: 0\n",
      "Row 15665 => Predicted: 0\n",
      "Row 15666 => Predicted: 1\n",
      "Row 15667 => Predicted: 1\n",
      "Row 15668 => Predicted: 1\n",
      "Row 15669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15660 to 15669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15670 => Predicted: 0\n",
      "Row 15671 => Predicted: 0\n",
      "Row 15672 => Predicted: 1\n",
      "Row 15673 => Predicted: 0\n",
      "Row 15674 => Predicted: 1\n",
      "Row 15675 => Predicted: 1\n",
      "Row 15676 => Predicted: 1\n",
      "Row 15677 => Predicted: 1\n",
      "Row 15678 => Predicted: 1\n",
      "Row 15679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15670 to 15679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15680 => Predicted: 0\n",
      "Row 15681 => Predicted: 1\n",
      "Row 15682 => Predicted: 0\n",
      "Row 15683 => Predicted: 0\n",
      "Row 15684 => Predicted: 1\n",
      "Row 15685 => Predicted: 1\n",
      "Row 15686 => Predicted: 0\n",
      "Row 15687 => Predicted: 0\n",
      "Row 15688 => Predicted: 0\n",
      "Row 15689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15680 to 15689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15690 => Predicted: 0\n",
      "Row 15691 => Predicted: 0\n",
      "Row 15692 => Predicted: 1\n",
      "Row 15693 => Predicted: 0\n",
      "Row 15694 => Predicted: 0\n",
      "Row 15695 => Predicted: 1\n",
      "Row 15696 => Predicted: 0\n",
      "Row 15697 => Predicted: 0\n",
      "Row 15698 => Predicted: 1\n",
      "Row 15699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15690 to 15699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15700 => Predicted: 0\n",
      "Row 15701 => Predicted: 0\n",
      "Row 15702 => Predicted: 1\n",
      "Row 15703 => Predicted: 1\n",
      "Row 15704 => Predicted: 0\n",
      "Row 15705 => Predicted: 1\n",
      "Row 15706 => Predicted: 1\n",
      "Row 15707 => Predicted: 0\n",
      "Row 15708 => Predicted: 1\n",
      "Row 15709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15700 to 15709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15710 => Predicted: 1\n",
      "Row 15711 => Predicted: 0\n",
      "Row 15712 => Predicted: 0\n",
      "Row 15713 => Predicted: 1\n",
      "Row 15714 => Predicted: 1\n",
      "Row 15715 => Predicted: 1\n",
      "Row 15716 => Predicted: 1\n",
      "Row 15717 => Predicted: 0\n",
      "Row 15718 => Predicted: 0\n",
      "Row 15719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15710 to 15719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15720 => Predicted: 1\n",
      "Row 15721 => Predicted: 0\n",
      "Row 15722 => Predicted: 1\n",
      "Row 15723 => Predicted: 1\n",
      "Row 15724 => Predicted: 1\n",
      "Row 15725 => Predicted: 1\n",
      "Row 15726 => Predicted: 1\n",
      "Row 15727 => Predicted: 0\n",
      "Row 15728 => Predicted: 0\n",
      "Row 15729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15720 to 15729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15730 => Predicted: 1\n",
      "Row 15731 => Predicted: 0\n",
      "Row 15732 => Predicted: 1\n",
      "Row 15733 => Predicted: 1\n",
      "Row 15734 => Predicted: 1\n",
      "Row 15735 => Predicted: 1\n",
      "Row 15736 => Predicted: 1\n",
      "Row 15737 => Predicted: 1\n",
      "Row 15738 => Predicted: 1\n",
      "Row 15739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15730 to 15739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15740 => Predicted: 0\n",
      "Row 15741 => Predicted: 1\n",
      "Row 15742 => Predicted: 0\n",
      "Row 15743 => Predicted: 1\n",
      "Row 15744 => Predicted: 1\n",
      "Row 15745 => Predicted: 0\n",
      "Row 15746 => Predicted: 0\n",
      "Row 15747 => Predicted: 0\n",
      "Row 15748 => Predicted: 1\n",
      "Row 15749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15740 to 15749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15750 => Predicted: 0\n",
      "Row 15751 => Predicted: 1\n",
      "Row 15752 => Predicted: 0\n",
      "Row 15753 => Predicted: 0\n",
      "Row 15754 => Predicted: 1\n",
      "Row 15755 => Predicted: 0\n",
      "Row 15756 => Predicted: 1\n",
      "Row 15757 => Predicted: 1\n",
      "Row 15758 => Predicted: 0\n",
      "Row 15759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15750 to 15759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15760 => Predicted: 1\n",
      "Row 15761 => Predicted: 1\n",
      "Row 15762 => Predicted: 0\n",
      "Row 15763 => Predicted: 1\n",
      "Row 15764 => Predicted: 1\n",
      "Row 15765 => Predicted: 0\n",
      "Row 15766 => Predicted: 0\n",
      "Row 15767 => Predicted: 1\n",
      "Row 15768 => Predicted: 1\n",
      "Row 15769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15760 to 15769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15770 => Predicted: 0\n",
      "Row 15771 => Predicted: 0\n",
      "Row 15772 => Predicted: 0\n",
      "Row 15773 => Predicted: 1\n",
      "Row 15774 => Predicted: 1\n",
      "Row 15775 => Predicted: 1\n",
      "Row 15776 => Predicted: 1\n",
      "Row 15777 => Predicted: 0\n",
      "Row 15778 => Predicted: 1\n",
      "Row 15779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15770 to 15779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15780 => Predicted: 0\n",
      "Row 15781 => Predicted: 1\n",
      "Row 15782 => Predicted: 0\n",
      "Row 15783 => Predicted: 1\n",
      "Row 15784 => Predicted: 0\n",
      "Row 15785 => Predicted: 1\n",
      "Row 15786 => Predicted: 1\n",
      "Row 15787 => Predicted: 0\n",
      "Row 15788 => Predicted: 1\n",
      "Row 15789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15780 to 15789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15790 => Predicted: 0\n",
      "Row 15791 => Predicted: 1\n",
      "Row 15792 => Predicted: 0\n",
      "Row 15793 => Predicted: 0\n",
      "Row 15794 => Predicted: 1\n",
      "Row 15795 => Predicted: 1\n",
      "Row 15796 => Predicted: 0\n",
      "Row 15797 => Predicted: 0\n",
      "Row 15798 => Predicted: 1\n",
      "Row 15799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15790 to 15799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15800 => Predicted: 0\n",
      "Row 15801 => Predicted: 1\n",
      "Row 15802 => Predicted: 0\n",
      "Row 15803 => Predicted: 0\n",
      "Row 15804 => Predicted: 1\n",
      "Row 15805 => Predicted: 0\n",
      "Row 15806 => Predicted: 1\n",
      "Row 15807 => Predicted: 1\n",
      "Row 15808 => Predicted: 0\n",
      "Row 15809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15800 to 15809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15810 => Predicted: 1\n",
      "Row 15811 => Predicted: 1\n",
      "Row 15812 => Predicted: 1\n",
      "Row 15813 => Predicted: 1\n",
      "Row 15814 => Predicted: 0\n",
      "Row 15815 => Predicted: 0\n",
      "Row 15816 => Predicted: 0\n",
      "Row 15817 => Predicted: 1\n",
      "Row 15818 => Predicted: 1\n",
      "Row 15819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15810 to 15819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15820 => Predicted: 0\n",
      "Row 15821 => Predicted: 1\n",
      "Row 15822 => Predicted: 0\n",
      "Row 15823 => Predicted: 0\n",
      "Row 15824 => Predicted: 1\n",
      "Row 15825 => Predicted: 0\n",
      "Row 15826 => Predicted: 1\n",
      "Row 15827 => Predicted: 0\n",
      "Row 15828 => Predicted: 1\n",
      "Row 15829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15820 to 15829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15830 => Predicted: 1\n",
      "Row 15831 => Predicted: 1\n",
      "Row 15832 => Predicted: 1\n",
      "Row 15833 => Predicted: 1\n",
      "Row 15834 => Predicted: 1\n",
      "Row 15835 => Predicted: 0\n",
      "Row 15836 => Predicted: 0\n",
      "Row 15837 => Predicted: 1\n",
      "Row 15838 => Predicted: 0\n",
      "Row 15839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15830 to 15839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15840 => Predicted: 1\n",
      "Row 15841 => Predicted: 0\n",
      "Row 15842 => Predicted: 1\n",
      "Row 15843 => Predicted: 1\n",
      "Row 15844 => Predicted: 1\n",
      "Row 15845 => Predicted: 1\n",
      "Row 15846 => Predicted: 0\n",
      "Row 15847 => Predicted: 1\n",
      "Row 15848 => Predicted: 0\n",
      "Row 15849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15840 to 15849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15850 => Predicted: 0\n",
      "Row 15851 => Predicted: 1\n",
      "Row 15852 => Predicted: 1\n",
      "Row 15853 => Predicted: 1\n",
      "Row 15854 => Predicted: 1\n",
      "Row 15855 => Predicted: 1\n",
      "Row 15856 => Predicted: 0\n",
      "Row 15857 => Predicted: 1\n",
      "Row 15858 => Predicted: 0\n",
      "Row 15859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15850 to 15859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15860 => Predicted: 0\n",
      "Row 15861 => Predicted: 1\n",
      "Row 15862 => Predicted: 1\n",
      "Row 15863 => Predicted: 1\n",
      "Row 15864 => Predicted: 1\n",
      "Row 15865 => Predicted: 0\n",
      "Row 15866 => Predicted: 1\n",
      "Row 15867 => Predicted: 0\n",
      "Row 15868 => Predicted: 1\n",
      "Row 15869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15860 to 15869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15870 => Predicted: 1\n",
      "Row 15871 => Predicted: 1\n",
      "Row 15872 => Predicted: 1\n",
      "Row 15873 => Predicted: 1\n",
      "Row 15874 => Predicted: 0\n",
      "Row 15875 => Predicted: 0\n",
      "Row 15876 => Predicted: 0\n",
      "Row 15877 => Predicted: 1\n",
      "Row 15878 => Predicted: 0\n",
      "Row 15879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15870 to 15879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15880 => Predicted: 1\n",
      "Row 15881 => Predicted: 1\n",
      "Row 15882 => Predicted: 1\n",
      "Row 15883 => Predicted: 0\n",
      "Row 15884 => Predicted: 0\n",
      "Row 15885 => Predicted: 1\n",
      "Row 15886 => Predicted: 0\n",
      "Row 15887 => Predicted: 1\n",
      "Row 15888 => Predicted: 1\n",
      "Row 15889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15880 to 15889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15890 => Predicted: 1\n",
      "Row 15891 => Predicted: 0\n",
      "Row 15892 => Predicted: 1\n",
      "Row 15893 => Predicted: 0\n",
      "Row 15894 => Predicted: 1\n",
      "Row 15895 => Predicted: 1\n",
      "Row 15896 => Predicted: 1\n",
      "Row 15897 => Predicted: 1\n",
      "Row 15898 => Predicted: 1\n",
      "Row 15899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15890 to 15899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15900 => Predicted: 0\n",
      "Row 15901 => Predicted: 1\n",
      "Row 15902 => Predicted: 1\n",
      "Row 15903 => Predicted: 0\n",
      "Row 15904 => Predicted: 1\n",
      "Row 15905 => Predicted: 0\n",
      "Row 15906 => Predicted: 0\n",
      "Row 15907 => Predicted: 1\n",
      "Row 15908 => Predicted: 0\n",
      "Row 15909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15900 to 15909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15910 => Predicted: 1\n",
      "Row 15911 => Predicted: 1\n",
      "Row 15912 => Predicted: 1\n",
      "Row 15913 => Predicted: 1\n",
      "Row 15914 => Predicted: 1\n",
      "Row 15915 => Predicted: 0\n",
      "Row 15916 => Predicted: 0\n",
      "Row 15917 => Predicted: 1\n",
      "Row 15918 => Predicted: 0\n",
      "Row 15919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15910 to 15919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15920 => Predicted: 0\n",
      "Row 15921 => Predicted: 1\n",
      "Row 15922 => Predicted: 1\n",
      "Row 15923 => Predicted: 1\n",
      "Row 15924 => Predicted: 1\n",
      "Row 15925 => Predicted: 1\n",
      "Row 15926 => Predicted: 0\n",
      "Row 15927 => Predicted: 0\n",
      "Row 15928 => Predicted: 0\n",
      "Row 15929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15920 to 15929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15930 => Predicted: 0\n",
      "Row 15931 => Predicted: 1\n",
      "Row 15932 => Predicted: 0\n",
      "Row 15933 => Predicted: 1\n",
      "Row 15934 => Predicted: 1\n",
      "Row 15935 => Predicted: 0\n",
      "Row 15936 => Predicted: 0\n",
      "Row 15937 => Predicted: 0\n",
      "Row 15938 => Predicted: 0\n",
      "Row 15939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15930 to 15939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15940 => Predicted: 1\n",
      "Row 15941 => Predicted: 0\n",
      "Row 15942 => Predicted: 0\n",
      "Row 15943 => Predicted: 0\n",
      "Row 15944 => Predicted: 0\n",
      "Row 15945 => Predicted: 0\n",
      "Row 15946 => Predicted: 1\n",
      "Row 15947 => Predicted: 0\n",
      "Row 15948 => Predicted: 1\n",
      "Row 15949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15940 to 15949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15950 => Predicted: 0\n",
      "Row 15951 => Predicted: 0\n",
      "Row 15952 => Predicted: 0\n",
      "Row 15953 => Predicted: 1\n",
      "Row 15954 => Predicted: 0\n",
      "Row 15955 => Predicted: 1\n",
      "Row 15956 => Predicted: 0\n",
      "Row 15957 => Predicted: 1\n",
      "Row 15958 => Predicted: 1\n",
      "Row 15959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15950 to 15959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15960 => Predicted: 0\n",
      "Row 15961 => Predicted: 0\n",
      "Row 15962 => Predicted: 0\n",
      "Row 15963 => Predicted: 1\n",
      "Row 15964 => Predicted: 1\n",
      "Row 15965 => Predicted: 0\n",
      "Row 15966 => Predicted: 1\n",
      "Row 15967 => Predicted: 0\n",
      "Row 15968 => Predicted: 0\n",
      "Row 15969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 15960 to 15969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15970 => Predicted: 1\n",
      "Row 15971 => Predicted: 0\n",
      "Row 15972 => Predicted: 0\n",
      "Row 15973 => Predicted: 1\n",
      "Row 15974 => Predicted: 1\n",
      "Row 15975 => Predicted: 1\n",
      "Row 15976 => Predicted: 1\n",
      "Row 15977 => Predicted: 0\n",
      "Row 15978 => Predicted: 0\n",
      "Row 15979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15970 to 15979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15980 => Predicted: 1\n",
      "Row 15981 => Predicted: 0\n",
      "Row 15982 => Predicted: 1\n",
      "Row 15983 => Predicted: 1\n",
      "Row 15984 => Predicted: 1\n",
      "Row 15985 => Predicted: 1\n",
      "Row 15986 => Predicted: 1\n",
      "Row 15987 => Predicted: 1\n",
      "Row 15988 => Predicted: 0\n",
      "Row 15989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15980 to 15989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15990 => Predicted: 1\n",
      "Row 15991 => Predicted: 0\n",
      "Row 15992 => Predicted: 0\n",
      "Row 15993 => Predicted: 1\n",
      "Row 15994 => Predicted: 0\n",
      "Row 15995 => Predicted: 0\n",
      "Row 15996 => Predicted: 1\n",
      "Row 15997 => Predicted: 0\n",
      "Row 15998 => Predicted: 0\n",
      "Row 15999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 15990 to 15999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16000 => Predicted: 0\n",
      "Row 16001 => Predicted: 1\n",
      "Row 16002 => Predicted: 1\n",
      "Row 16003 => Predicted: 1\n",
      "Row 16004 => Predicted: 1\n",
      "Row 16005 => Predicted: 1\n",
      "Row 16006 => Predicted: 0\n",
      "Row 16007 => Predicted: 0\n",
      "Row 16008 => Predicted: 0\n",
      "Row 16009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16000 to 16009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16010 => Predicted: 0\n",
      "Row 16011 => Predicted: 0\n",
      "Row 16012 => Predicted: 1\n",
      "Row 16013 => Predicted: 1\n",
      "Row 16014 => Predicted: 1\n",
      "Row 16015 => Predicted: 0\n",
      "Row 16016 => Predicted: 1\n",
      "Row 16017 => Predicted: 0\n",
      "Row 16018 => Predicted: 1\n",
      "Row 16019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16010 to 16019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16020 => Predicted: 0\n",
      "Row 16021 => Predicted: 0\n",
      "Row 16022 => Predicted: 1\n",
      "Row 16023 => Predicted: 0\n",
      "Row 16024 => Predicted: 1\n",
      "Row 16025 => Predicted: 0\n",
      "Row 16026 => Predicted: 0\n",
      "Row 16027 => Predicted: 1\n",
      "Row 16028 => Predicted: 0\n",
      "Row 16029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16020 to 16029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16030 => Predicted: 0\n",
      "Row 16031 => Predicted: 0\n",
      "Row 16032 => Predicted: 0\n",
      "Row 16033 => Predicted: 0\n",
      "Row 16034 => Predicted: 1\n",
      "Row 16035 => Predicted: 0\n",
      "Row 16036 => Predicted: 0\n",
      "Row 16037 => Predicted: 1\n",
      "Row 16038 => Predicted: 0\n",
      "Row 16039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16030 to 16039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16040 => Predicted: 0\n",
      "Row 16041 => Predicted: 1\n",
      "Row 16042 => Predicted: 0\n",
      "Row 16043 => Predicted: 1\n",
      "Row 16044 => Predicted: 0\n",
      "Row 16045 => Predicted: 1\n",
      "Row 16046 => Predicted: 1\n",
      "Row 16047 => Predicted: 1\n",
      "Row 16048 => Predicted: 0\n",
      "Row 16049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16040 to 16049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16050 => Predicted: 0\n",
      "Row 16051 => Predicted: 0\n",
      "Row 16052 => Predicted: 1\n",
      "Row 16053 => Predicted: 1\n",
      "Row 16054 => Predicted: 0\n",
      "Row 16055 => Predicted: 0\n",
      "Row 16056 => Predicted: 0\n",
      "Row 16057 => Predicted: 1\n",
      "Row 16058 => Predicted: 1\n",
      "Row 16059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16050 to 16059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16060 => Predicted: 0\n",
      "Row 16061 => Predicted: 0\n",
      "Row 16062 => Predicted: 0\n",
      "Row 16063 => Predicted: 1\n",
      "Row 16064 => Predicted: 1\n",
      "Row 16065 => Predicted: 0\n",
      "Row 16066 => Predicted: 1\n",
      "Row 16067 => Predicted: 1\n",
      "Row 16068 => Predicted: 0\n",
      "Row 16069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16060 to 16069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16070 => Predicted: 0\n",
      "Row 16071 => Predicted: 0\n",
      "Row 16072 => Predicted: 0\n",
      "Row 16073 => Predicted: 0\n",
      "Row 16074 => Predicted: 1\n",
      "Row 16075 => Predicted: 1\n",
      "Row 16076 => Predicted: 1\n",
      "Row 16077 => Predicted: 1\n",
      "Row 16078 => Predicted: 0\n",
      "Row 16079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16070 to 16079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16080 => Predicted: 0\n",
      "Row 16081 => Predicted: 1\n",
      "Row 16082 => Predicted: 1\n",
      "Row 16083 => Predicted: 0\n",
      "Row 16084 => Predicted: 1\n",
      "Row 16085 => Predicted: 0\n",
      "Row 16086 => Predicted: 0\n",
      "Row 16087 => Predicted: 1\n",
      "Row 16088 => Predicted: 0\n",
      "Row 16089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16080 to 16089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16090 => Predicted: 0\n",
      "Row 16091 => Predicted: 1\n",
      "Row 16092 => Predicted: 0\n",
      "Row 16093 => Predicted: 1\n",
      "Row 16094 => Predicted: 0\n",
      "Row 16095 => Predicted: 1\n",
      "Row 16096 => Predicted: 0\n",
      "Row 16097 => Predicted: 1\n",
      "Row 16098 => Predicted: 1\n",
      "Row 16099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16090 to 16099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16100 => Predicted: 1\n",
      "Row 16101 => Predicted: 0\n",
      "Row 16102 => Predicted: 1\n",
      "Row 16103 => Predicted: 0\n",
      "Row 16104 => Predicted: 1\n",
      "Row 16105 => Predicted: 0\n",
      "Row 16106 => Predicted: 0\n",
      "Row 16107 => Predicted: 1\n",
      "Row 16108 => Predicted: 0\n",
      "Row 16109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16100 to 16109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16110 => Predicted: 0\n",
      "Row 16111 => Predicted: 1\n",
      "Row 16112 => Predicted: 1\n",
      "Row 16113 => Predicted: 0\n",
      "Row 16114 => Predicted: 1\n",
      "Row 16115 => Predicted: 1\n",
      "Row 16116 => Predicted: 1\n",
      "Row 16117 => Predicted: 1\n",
      "Row 16118 => Predicted: 1\n",
      "Row 16119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16110 to 16119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16120 => Predicted: 1\n",
      "Row 16121 => Predicted: 0\n",
      "Row 16122 => Predicted: 1\n",
      "Row 16123 => Predicted: 1\n",
      "Row 16124 => Predicted: 1\n",
      "Row 16125 => Predicted: 1\n",
      "Row 16126 => Predicted: 1\n",
      "Row 16127 => Predicted: 0\n",
      "Row 16128 => Predicted: 0\n",
      "Row 16129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16120 to 16129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16130 => Predicted: 1\n",
      "Row 16131 => Predicted: 1\n",
      "Row 16132 => Predicted: 1\n",
      "Row 16133 => Predicted: 1\n",
      "Row 16134 => Predicted: 1\n",
      "Row 16135 => Predicted: 0\n",
      "Row 16136 => Predicted: 1\n",
      "Row 16137 => Predicted: 0\n",
      "Row 16138 => Predicted: 1\n",
      "Row 16139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16130 to 16139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16140 => Predicted: 0\n",
      "Row 16141 => Predicted: 1\n",
      "Row 16142 => Predicted: 1\n",
      "Row 16143 => Predicted: 1\n",
      "Row 16144 => Predicted: 0\n",
      "Row 16145 => Predicted: 1\n",
      "Row 16146 => Predicted: 0\n",
      "Row 16147 => Predicted: 1\n",
      "Row 16148 => Predicted: 1\n",
      "Row 16149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16140 to 16149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16150 => Predicted: 1\n",
      "Row 16151 => Predicted: 1\n",
      "Row 16152 => Predicted: 1\n",
      "Row 16153 => Predicted: 0\n",
      "Row 16154 => Predicted: 0\n",
      "Row 16155 => Predicted: 1\n",
      "Row 16156 => Predicted: 0\n",
      "Row 16157 => Predicted: 1\n",
      "Row 16158 => Predicted: 1\n",
      "Row 16159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16150 to 16159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16160 => Predicted: 1\n",
      "Row 16161 => Predicted: 0\n",
      "Row 16162 => Predicted: 1\n",
      "Row 16163 => Predicted: 1\n",
      "Row 16164 => Predicted: 1\n",
      "Row 16165 => Predicted: 1\n",
      "Row 16166 => Predicted: 0\n",
      "Row 16167 => Predicted: 1\n",
      "Row 16168 => Predicted: 0\n",
      "Row 16169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16160 to 16169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16170 => Predicted: 0\n",
      "Row 16171 => Predicted: 0\n",
      "Row 16172 => Predicted: 1\n",
      "Row 16173 => Predicted: 1\n",
      "Row 16174 => Predicted: 1\n",
      "Row 16175 => Predicted: 0\n",
      "Row 16176 => Predicted: 1\n",
      "Row 16177 => Predicted: 0\n",
      "Row 16178 => Predicted: 0\n",
      "Row 16179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16170 to 16179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16180 => Predicted: 1\n",
      "Row 16181 => Predicted: 1\n",
      "Row 16182 => Predicted: 1\n",
      "Row 16183 => Predicted: 1\n",
      "Row 16184 => Predicted: 1\n",
      "Row 16185 => Predicted: 0\n",
      "Row 16186 => Predicted: 1\n",
      "Row 16187 => Predicted: 1\n",
      "Row 16188 => Predicted: 0\n",
      "Row 16189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16180 to 16189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16190 => Predicted: 1\n",
      "Row 16191 => Predicted: 0\n",
      "Row 16192 => Predicted: 0\n",
      "Row 16193 => Predicted: 0\n",
      "Row 16194 => Predicted: 1\n",
      "Row 16195 => Predicted: 1\n",
      "Row 16196 => Predicted: 1\n",
      "Row 16197 => Predicted: 1\n",
      "Row 16198 => Predicted: 0\n",
      "Row 16199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16190 to 16199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16200 => Predicted: 1\n",
      "Row 16201 => Predicted: 1\n",
      "Row 16202 => Predicted: 0\n",
      "Row 16203 => Predicted: 1\n",
      "Row 16204 => Predicted: 1\n",
      "Row 16205 => Predicted: 0\n",
      "Row 16206 => Predicted: 1\n",
      "Row 16207 => Predicted: 0\n",
      "Row 16208 => Predicted: 1\n",
      "Row 16209 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16200 to 16209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16210 => Predicted: 1\n",
      "Row 16211 => Predicted: 0\n",
      "Row 16212 => Predicted: 0\n",
      "Row 16213 => Predicted: 0\n",
      "Row 16214 => Predicted: 1\n",
      "Row 16215 => Predicted: 0\n",
      "Row 16216 => Predicted: 1\n",
      "Row 16217 => Predicted: 0\n",
      "Row 16218 => Predicted: 0\n",
      "Row 16219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16210 to 16219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16220 => Predicted: 0\n",
      "Row 16221 => Predicted: 1\n",
      "Row 16222 => Predicted: 1\n",
      "Row 16223 => Predicted: 0\n",
      "Row 16224 => Predicted: 0\n",
      "Row 16225 => Predicted: 1\n",
      "Row 16226 => Predicted: 1\n",
      "Row 16227 => Predicted: 1\n",
      "Row 16228 => Predicted: 1\n",
      "Row 16229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16220 to 16229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16230 => Predicted: 0\n",
      "Row 16231 => Predicted: 0\n",
      "Row 16232 => Predicted: 1\n",
      "Row 16233 => Predicted: 0\n",
      "Row 16234 => Predicted: 0\n",
      "Row 16235 => Predicted: 0\n",
      "Row 16236 => Predicted: 0\n",
      "Row 16237 => Predicted: 1\n",
      "Row 16238 => Predicted: 1\n",
      "Row 16239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16230 to 16239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16240 => Predicted: 1\n",
      "Row 16241 => Predicted: 1\n",
      "Row 16242 => Predicted: 1\n",
      "Row 16243 => Predicted: 1\n",
      "Row 16244 => Predicted: 1\n",
      "Row 16245 => Predicted: 1\n",
      "Row 16246 => Predicted: 1\n",
      "Row 16247 => Predicted: 0\n",
      "Row 16248 => Predicted: 1\n",
      "Row 16249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16240 to 16249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16250 => Predicted: 1\n",
      "Row 16251 => Predicted: 0\n",
      "Row 16252 => Predicted: 0\n",
      "Row 16253 => Predicted: 1\n",
      "Row 16254 => Predicted: 0\n",
      "Row 16255 => Predicted: 1\n",
      "Row 16256 => Predicted: 1\n",
      "Row 16257 => Predicted: 0\n",
      "Row 16258 => Predicted: 1\n",
      "Row 16259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16250 to 16259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16260 => Predicted: 1\n",
      "Row 16261 => Predicted: 0\n",
      "Row 16262 => Predicted: 1\n",
      "Row 16263 => Predicted: 1\n",
      "Row 16264 => Predicted: 1\n",
      "Row 16265 => Predicted: 0\n",
      "Row 16266 => Predicted: 1\n",
      "Row 16267 => Predicted: 0\n",
      "Row 16268 => Predicted: 0\n",
      "Row 16269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16260 to 16269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16270 => Predicted: 1\n",
      "Row 16271 => Predicted: 0\n",
      "Row 16272 => Predicted: 1\n",
      "Row 16273 => Predicted: 1\n",
      "Row 16274 => Predicted: 1\n",
      "Row 16275 => Predicted: 0\n",
      "Row 16276 => Predicted: 1\n",
      "Row 16277 => Predicted: 1\n",
      "Row 16278 => Predicted: 0\n",
      "Row 16279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16270 to 16279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16280 => Predicted: 0\n",
      "Row 16281 => Predicted: 0\n",
      "Row 16282 => Predicted: 0\n",
      "Row 16283 => Predicted: 1\n",
      "Row 16284 => Predicted: 1\n",
      "Row 16285 => Predicted: 0\n",
      "Row 16286 => Predicted: 0\n",
      "Row 16287 => Predicted: 1\n",
      "Row 16288 => Predicted: 1\n",
      "Row 16289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16280 to 16289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16290 => Predicted: 1\n",
      "Row 16291 => Predicted: 0\n",
      "Row 16292 => Predicted: 1\n",
      "Row 16293 => Predicted: 1\n",
      "Row 16294 => Predicted: 0\n",
      "Row 16295 => Predicted: 0\n",
      "Row 16296 => Predicted: 1\n",
      "Row 16297 => Predicted: 1\n",
      "Row 16298 => Predicted: 0\n",
      "Row 16299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16290 to 16299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16300 => Predicted: 1\n",
      "Row 16301 => Predicted: 0\n",
      "Row 16302 => Predicted: 1\n",
      "Row 16303 => Predicted: 1\n",
      "Row 16304 => Predicted: 0\n",
      "Row 16305 => Predicted: 1\n",
      "Row 16306 => Predicted: 1\n",
      "Row 16307 => Predicted: 1\n",
      "Row 16308 => Predicted: 1\n",
      "Row 16309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16300 to 16309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16310 => Predicted: 1\n",
      "Row 16311 => Predicted: 0\n",
      "Row 16312 => Predicted: 0\n",
      "Row 16313 => Predicted: 1\n",
      "Row 16314 => Predicted: 0\n",
      "Row 16315 => Predicted: 1\n",
      "Row 16316 => Predicted: 0\n",
      "Row 16317 => Predicted: 1\n",
      "Row 16318 => Predicted: 1\n",
      "Row 16319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16310 to 16319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16320 => Predicted: 1\n",
      "Row 16321 => Predicted: 0\n",
      "Row 16322 => Predicted: 0\n",
      "Row 16323 => Predicted: 1\n",
      "Row 16324 => Predicted: 1\n",
      "Row 16325 => Predicted: 1\n",
      "Row 16326 => Predicted: 1\n",
      "Row 16327 => Predicted: 0\n",
      "Row 16328 => Predicted: 1\n",
      "Row 16329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16320 to 16329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16330 => Predicted: 1\n",
      "Row 16331 => Predicted: 1\n",
      "Row 16332 => Predicted: 1\n",
      "Row 16333 => Predicted: 1\n",
      "Row 16334 => Predicted: 0\n",
      "Row 16335 => Predicted: 0\n",
      "Row 16336 => Predicted: 0\n",
      "Row 16337 => Predicted: 0\n",
      "Row 16338 => Predicted: 0\n",
      "Row 16339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16330 to 16339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16340 => Predicted: 0\n",
      "Row 16341 => Predicted: 0\n",
      "Row 16342 => Predicted: 0\n",
      "Row 16343 => Predicted: 1\n",
      "Row 16344 => Predicted: 0\n",
      "Row 16345 => Predicted: 1\n",
      "Row 16346 => Predicted: 0\n",
      "Row 16347 => Predicted: 1\n",
      "Row 16348 => Predicted: 1\n",
      "Row 16349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16340 to 16349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16350 => Predicted: 0\n",
      "Row 16351 => Predicted: 0\n",
      "Row 16352 => Predicted: 0\n",
      "Row 16353 => Predicted: 1\n",
      "Row 16354 => Predicted: 0\n",
      "Row 16355 => Predicted: 0\n",
      "Row 16356 => Predicted: 1\n",
      "Row 16357 => Predicted: 1\n",
      "Row 16358 => Predicted: 0\n",
      "Row 16359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16350 to 16359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16360 => Predicted: 1\n",
      "Row 16361 => Predicted: 0\n",
      "Row 16362 => Predicted: 1\n",
      "Row 16363 => Predicted: 1\n",
      "Row 16364 => Predicted: 1\n",
      "Row 16365 => Predicted: 0\n",
      "Row 16366 => Predicted: 1\n",
      "Row 16367 => Predicted: 0\n",
      "Row 16368 => Predicted: 1\n",
      "Row 16369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16360 to 16369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16370 => Predicted: 1\n",
      "Row 16371 => Predicted: 0\n",
      "Row 16372 => Predicted: 1\n",
      "Row 16373 => Predicted: 1\n",
      "Row 16374 => Predicted: 1\n",
      "Row 16375 => Predicted: 0\n",
      "Row 16376 => Predicted: 1\n",
      "Row 16377 => Predicted: 0\n",
      "Row 16378 => Predicted: 1\n",
      "Row 16379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16370 to 16379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16380 => Predicted: 1\n",
      "Row 16381 => Predicted: 0\n",
      "Row 16382 => Predicted: 1\n",
      "Row 16383 => Predicted: 0\n",
      "Row 16384 => Predicted: 1\n",
      "Row 16385 => Predicted: 0\n",
      "Row 16386 => Predicted: 0\n",
      "Row 16387 => Predicted: 0\n",
      "Row 16388 => Predicted: 0\n",
      "Row 16389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16380 to 16389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16390 => Predicted: 1\n",
      "Row 16391 => Predicted: 0\n",
      "Row 16392 => Predicted: 0\n",
      "Row 16393 => Predicted: 1\n",
      "Row 16394 => Predicted: 1\n",
      "Row 16395 => Predicted: 1\n",
      "Row 16396 => Predicted: 1\n",
      "Row 16397 => Predicted: 0\n",
      "Row 16398 => Predicted: 1\n",
      "Row 16399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16390 to 16399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16400 => Predicted: 0\n",
      "Row 16401 => Predicted: 1\n",
      "Row 16402 => Predicted: 0\n",
      "Row 16403 => Predicted: 1\n",
      "Row 16404 => Predicted: 0\n",
      "Row 16405 => Predicted: 1\n",
      "Row 16406 => Predicted: 1\n",
      "Row 16407 => Predicted: 0\n",
      "Row 16408 => Predicted: 0\n",
      "Row 16409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16400 to 16409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16410 => Predicted: 0\n",
      "Row 16411 => Predicted: 0\n",
      "Row 16412 => Predicted: 0\n",
      "Row 16413 => Predicted: 1\n",
      "Row 16414 => Predicted: 0\n",
      "Row 16415 => Predicted: 0\n",
      "Row 16416 => Predicted: 1\n",
      "Row 16417 => Predicted: 0\n",
      "Row 16418 => Predicted: 0\n",
      "Row 16419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16410 to 16419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16420 => Predicted: 1\n",
      "Row 16421 => Predicted: 0\n",
      "Row 16422 => Predicted: 0\n",
      "Row 16423 => Predicted: 0\n",
      "Row 16424 => Predicted: 1\n",
      "Row 16425 => Predicted: 1\n",
      "Row 16426 => Predicted: 1\n",
      "Row 16427 => Predicted: 0\n",
      "Row 16428 => Predicted: 0\n",
      "Row 16429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16420 to 16429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16430 => Predicted: 1\n",
      "Row 16431 => Predicted: 1\n",
      "Row 16432 => Predicted: 1\n",
      "Row 16433 => Predicted: 1\n",
      "Row 16434 => Predicted: 0\n",
      "Row 16435 => Predicted: 1\n",
      "Row 16436 => Predicted: 0\n",
      "Row 16437 => Predicted: 0\n",
      "Row 16438 => Predicted: 1\n",
      "Row 16439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16430 to 16439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16440 => Predicted: 1\n",
      "Row 16441 => Predicted: 1\n",
      "Row 16442 => Predicted: 1\n",
      "Row 16443 => Predicted: 1\n",
      "Row 16444 => Predicted: 0\n",
      "Row 16445 => Predicted: 0\n",
      "Row 16446 => Predicted: 1\n",
      "Row 16447 => Predicted: 1\n",
      "Row 16448 => Predicted: 0\n",
      "Row 16449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16440 to 16449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16450 => Predicted: 0\n",
      "Row 16451 => Predicted: 0\n",
      "Row 16452 => Predicted: 0\n",
      "Row 16453 => Predicted: 0\n",
      "Row 16454 => Predicted: 1\n",
      "Row 16455 => Predicted: 0\n",
      "Row 16456 => Predicted: 0\n",
      "Row 16457 => Predicted: 1\n",
      "Row 16458 => Predicted: 1\n",
      "Row 16459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16450 to 16459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16460 => Predicted: 1\n",
      "Row 16461 => Predicted: 1\n",
      "Row 16462 => Predicted: 1\n",
      "Row 16463 => Predicted: 1\n",
      "Row 16464 => Predicted: 1\n",
      "Row 16465 => Predicted: 0\n",
      "Row 16466 => Predicted: 0\n",
      "Row 16467 => Predicted: 1\n",
      "Row 16468 => Predicted: 0\n",
      "Row 16469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16460 to 16469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16470 => Predicted: 0\n",
      "Row 16471 => Predicted: 1\n",
      "Row 16472 => Predicted: 1\n",
      "Row 16473 => Predicted: 1\n",
      "Row 16474 => Predicted: 0\n",
      "Row 16475 => Predicted: 1\n",
      "Row 16476 => Predicted: 0\n",
      "Row 16477 => Predicted: 1\n",
      "Row 16478 => Predicted: 1\n",
      "Row 16479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16470 to 16479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16480 => Predicted: 1\n",
      "Row 16481 => Predicted: 1\n",
      "Row 16482 => Predicted: 0\n",
      "Row 16483 => Predicted: 1\n",
      "Row 16484 => Predicted: 0\n",
      "Row 16485 => Predicted: 0\n",
      "Row 16486 => Predicted: 0\n",
      "Row 16487 => Predicted: 0\n",
      "Row 16488 => Predicted: 0\n",
      "Row 16489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16480 to 16489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16490 => Predicted: 1\n",
      "Row 16491 => Predicted: 0\n",
      "Row 16492 => Predicted: 0\n",
      "Row 16493 => Predicted: 0\n",
      "Row 16494 => Predicted: 0\n",
      "Row 16495 => Predicted: 0\n",
      "Row 16496 => Predicted: 0\n",
      "Row 16497 => Predicted: 0\n",
      "Row 16498 => Predicted: 1\n",
      "Row 16499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16490 to 16499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16500 => Predicted: 0\n",
      "Row 16501 => Predicted: 0\n",
      "Row 16502 => Predicted: 0\n",
      "Row 16503 => Predicted: 0\n",
      "Row 16504 => Predicted: 1\n",
      "Row 16505 => Predicted: 0\n",
      "Row 16506 => Predicted: 1\n",
      "Row 16507 => Predicted: 0\n",
      "Row 16508 => Predicted: 1\n",
      "Row 16509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16500 to 16509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16510 => Predicted: 0\n",
      "Row 16511 => Predicted: 0\n",
      "Row 16512 => Predicted: 0\n",
      "Row 16513 => Predicted: 0\n",
      "Row 16514 => Predicted: 1\n",
      "Row 16515 => Predicted: 1\n",
      "Row 16516 => Predicted: 1\n",
      "Row 16517 => Predicted: 0\n",
      "Row 16518 => Predicted: 1\n",
      "Row 16519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16510 to 16519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16520 => Predicted: 0\n",
      "Row 16521 => Predicted: 1\n",
      "Row 16522 => Predicted: 1\n",
      "Row 16523 => Predicted: 1\n",
      "Row 16524 => Predicted: 0\n",
      "Row 16525 => Predicted: 0\n",
      "Row 16526 => Predicted: 1\n",
      "Row 16527 => Predicted: 1\n",
      "Row 16528 => Predicted: 0\n",
      "Row 16529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16520 to 16529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16530 => Predicted: 0\n",
      "Row 16531 => Predicted: 0\n",
      "Row 16532 => Predicted: 0\n",
      "Row 16533 => Predicted: 1\n",
      "Row 16534 => Predicted: 0\n",
      "Row 16535 => Predicted: 0\n",
      "Row 16536 => Predicted: 1\n",
      "Row 16537 => Predicted: 1\n",
      "Row 16538 => Predicted: 1\n",
      "Row 16539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16530 to 16539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16540 => Predicted: 1\n",
      "Row 16541 => Predicted: 1\n",
      "Row 16542 => Predicted: 0\n",
      "Row 16543 => Predicted: 1\n",
      "Row 16544 => Predicted: 0\n",
      "Row 16545 => Predicted: 1\n",
      "Row 16546 => Predicted: 1\n",
      "Row 16547 => Predicted: 0\n",
      "Row 16548 => Predicted: 1\n",
      "Row 16549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16540 to 16549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16550 => Predicted: 1\n",
      "Row 16551 => Predicted: 0\n",
      "Row 16552 => Predicted: 1\n",
      "Row 16553 => Predicted: 1\n",
      "Row 16554 => Predicted: 1\n",
      "Row 16555 => Predicted: 1\n",
      "Row 16556 => Predicted: 1\n",
      "Row 16557 => Predicted: 0\n",
      "Row 16558 => Predicted: 0\n",
      "Row 16559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16550 to 16559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16560 => Predicted: 0\n",
      "Row 16561 => Predicted: 1\n",
      "Row 16562 => Predicted: 0\n",
      "Row 16563 => Predicted: 0\n",
      "Row 16564 => Predicted: 0\n",
      "Row 16565 => Predicted: 0\n",
      "Row 16566 => Predicted: 0\n",
      "Row 16567 => Predicted: 0\n",
      "Row 16568 => Predicted: 0\n",
      "Row 16569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16560 to 16569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16570 => Predicted: 0\n",
      "Row 16571 => Predicted: 1\n",
      "Row 16572 => Predicted: 1\n",
      "Row 16573 => Predicted: 1\n",
      "Row 16574 => Predicted: 0\n",
      "Row 16575 => Predicted: 0\n",
      "Row 16576 => Predicted: 1\n",
      "Row 16577 => Predicted: 0\n",
      "Row 16578 => Predicted: 0\n",
      "Row 16579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16570 to 16579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16580 => Predicted: 0\n",
      "Row 16581 => Predicted: 0\n",
      "Row 16582 => Predicted: 1\n",
      "Row 16583 => Predicted: 0\n",
      "Row 16584 => Predicted: 0\n",
      "Row 16585 => Predicted: 1\n",
      "Row 16586 => Predicted: 1\n",
      "Row 16587 => Predicted: 0\n",
      "Row 16588 => Predicted: 1\n",
      "Row 16589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16580 to 16589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16590 => Predicted: 1\n",
      "Row 16591 => Predicted: 0\n",
      "Row 16592 => Predicted: 1\n",
      "Row 16593 => Predicted: 1\n",
      "Row 16594 => Predicted: 1\n",
      "Row 16595 => Predicted: 0\n",
      "Row 16596 => Predicted: 0\n",
      "Row 16597 => Predicted: 0\n",
      "Row 16598 => Predicted: 0\n",
      "Row 16599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16590 to 16599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16600 => Predicted: 0\n",
      "Row 16601 => Predicted: 0\n",
      "Row 16602 => Predicted: 0\n",
      "Row 16603 => Predicted: 0\n",
      "Row 16604 => Predicted: 1\n",
      "Row 16605 => Predicted: 1\n",
      "Row 16606 => Predicted: 0\n",
      "Row 16607 => Predicted: 0\n",
      "Row 16608 => Predicted: 0\n",
      "Row 16609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16600 to 16609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16610 => Predicted: 1\n",
      "Row 16611 => Predicted: 0\n",
      "Row 16612 => Predicted: 1\n",
      "Row 16613 => Predicted: 0\n",
      "Row 16614 => Predicted: 0\n",
      "Row 16615 => Predicted: 1\n",
      "Row 16616 => Predicted: 1\n",
      "Row 16617 => Predicted: 0\n",
      "Row 16618 => Predicted: 1\n",
      "Row 16619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16610 to 16619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16620 => Predicted: 0\n",
      "Row 16621 => Predicted: 1\n",
      "Row 16622 => Predicted: 1\n",
      "Row 16623 => Predicted: 0\n",
      "Row 16624 => Predicted: 1\n",
      "Row 16625 => Predicted: 0\n",
      "Row 16626 => Predicted: 1\n",
      "Row 16627 => Predicted: 1\n",
      "Row 16628 => Predicted: 0\n",
      "Row 16629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16620 to 16629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16630 => Predicted: 1\n",
      "Row 16631 => Predicted: 1\n",
      "Row 16632 => Predicted: 1\n",
      "Row 16633 => Predicted: 1\n",
      "Row 16634 => Predicted: 0\n",
      "Row 16635 => Predicted: 1\n",
      "Row 16636 => Predicted: 0\n",
      "Row 16637 => Predicted: 0\n",
      "Row 16638 => Predicted: 1\n",
      "Row 16639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16630 to 16639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16640 => Predicted: 1\n",
      "Row 16641 => Predicted: 1\n",
      "Row 16642 => Predicted: 1\n",
      "Row 16643 => Predicted: 1\n",
      "Row 16644 => Predicted: 0\n",
      "Row 16645 => Predicted: 0\n",
      "Row 16646 => Predicted: 1\n",
      "Row 16647 => Predicted: 1\n",
      "Row 16648 => Predicted: 0\n",
      "Row 16649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16640 to 16649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16650 => Predicted: 0\n",
      "Row 16651 => Predicted: 0\n",
      "Row 16652 => Predicted: 1\n",
      "Row 16653 => Predicted: 1\n",
      "Row 16654 => Predicted: 1\n",
      "Row 16655 => Predicted: 1\n",
      "Row 16656 => Predicted: 1\n",
      "Row 16657 => Predicted: 0\n",
      "Row 16658 => Predicted: 0\n",
      "Row 16659 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16650 to 16659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16660 => Predicted: 1\n",
      "Row 16661 => Predicted: 0\n",
      "Row 16662 => Predicted: 0\n",
      "Row 16663 => Predicted: 1\n",
      "Row 16664 => Predicted: 0\n",
      "Row 16665 => Predicted: 0\n",
      "Row 16666 => Predicted: 1\n",
      "Row 16667 => Predicted: 1\n",
      "Row 16668 => Predicted: 1\n",
      "Row 16669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16660 to 16669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16670 => Predicted: 0\n",
      "Row 16671 => Predicted: 1\n",
      "Row 16672 => Predicted: 0\n",
      "Row 16673 => Predicted: 0\n",
      "Row 16674 => Predicted: 1\n",
      "Row 16675 => Predicted: 1\n",
      "Row 16676 => Predicted: 1\n",
      "Row 16677 => Predicted: 1\n",
      "Row 16678 => Predicted: 0\n",
      "Row 16679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16670 to 16679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16680 => Predicted: 0\n",
      "Row 16681 => Predicted: 1\n",
      "Row 16682 => Predicted: 1\n",
      "Row 16683 => Predicted: 1\n",
      "Row 16684 => Predicted: 1\n",
      "Row 16685 => Predicted: 0\n",
      "Row 16686 => Predicted: 1\n",
      "Row 16687 => Predicted: 0\n",
      "Row 16688 => Predicted: 0\n",
      "Row 16689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16680 to 16689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16690 => Predicted: 1\n",
      "Row 16691 => Predicted: 0\n",
      "Row 16692 => Predicted: 0\n",
      "Row 16693 => Predicted: 0\n",
      "Row 16694 => Predicted: 1\n",
      "Row 16695 => Predicted: 0\n",
      "Row 16696 => Predicted: 0\n",
      "Row 16697 => Predicted: 1\n",
      "Row 16698 => Predicted: 1\n",
      "Row 16699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16690 to 16699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16700 => Predicted: 0\n",
      "Row 16701 => Predicted: 0\n",
      "Row 16702 => Predicted: 1\n",
      "Row 16703 => Predicted: 0\n",
      "Row 16704 => Predicted: 0\n",
      "Row 16705 => Predicted: 1\n",
      "Row 16706 => Predicted: 1\n",
      "Row 16707 => Predicted: 0\n",
      "Row 16708 => Predicted: 1\n",
      "Row 16709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16700 to 16709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16710 => Predicted: 0\n",
      "Row 16711 => Predicted: 1\n",
      "Row 16712 => Predicted: 0\n",
      "Row 16713 => Predicted: 1\n",
      "Row 16714 => Predicted: 0\n",
      "Row 16715 => Predicted: 0\n",
      "Row 16716 => Predicted: 0\n",
      "Row 16717 => Predicted: 0\n",
      "Row 16718 => Predicted: 0\n",
      "Row 16719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16710 to 16719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16720 => Predicted: 0\n",
      "Row 16721 => Predicted: 1\n",
      "Row 16722 => Predicted: 0\n",
      "Row 16723 => Predicted: 1\n",
      "Row 16724 => Predicted: 0\n",
      "Row 16725 => Predicted: 0\n",
      "Row 16726 => Predicted: 0\n",
      "Row 16727 => Predicted: 0\n",
      "Row 16728 => Predicted: 0\n",
      "Row 16729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16720 to 16729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16730 => Predicted: 1\n",
      "Row 16731 => Predicted: 1\n",
      "Row 16732 => Predicted: 1\n",
      "Row 16733 => Predicted: 1\n",
      "Row 16734 => Predicted: 1\n",
      "Row 16735 => Predicted: 1\n",
      "Row 16736 => Predicted: 1\n",
      "Row 16737 => Predicted: 1\n",
      "Row 16738 => Predicted: 0\n",
      "Row 16739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16730 to 16739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16740 => Predicted: 0\n",
      "Row 16741 => Predicted: 0\n",
      "Row 16742 => Predicted: 0\n",
      "Row 16743 => Predicted: 0\n",
      "Row 16744 => Predicted: 1\n",
      "Row 16745 => Predicted: 1\n",
      "Row 16746 => Predicted: 1\n",
      "Row 16747 => Predicted: 1\n",
      "Row 16748 => Predicted: 0\n",
      "Row 16749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16740 to 16749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16750 => Predicted: 1\n",
      "Row 16751 => Predicted: 1\n",
      "Row 16752 => Predicted: 0\n",
      "Row 16753 => Predicted: 1\n",
      "Row 16754 => Predicted: 1\n",
      "Row 16755 => Predicted: 0\n",
      "Row 16756 => Predicted: 0\n",
      "Row 16757 => Predicted: 1\n",
      "Row 16758 => Predicted: 1\n",
      "Row 16759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16750 to 16759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16760 => Predicted: 0\n",
      "Row 16761 => Predicted: 0\n",
      "Row 16762 => Predicted: 1\n",
      "Row 16763 => Predicted: 1\n",
      "Row 16764 => Predicted: 1\n",
      "Row 16765 => Predicted: 1\n",
      "Row 16766 => Predicted: 1\n",
      "Row 16767 => Predicted: 0\n",
      "Row 16768 => Predicted: 1\n",
      "Row 16769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16760 to 16769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16770 => Predicted: 1\n",
      "Row 16771 => Predicted: 1\n",
      "Row 16772 => Predicted: 1\n",
      "Row 16773 => Predicted: 0\n",
      "Row 16774 => Predicted: 1\n",
      "Row 16775 => Predicted: 0\n",
      "Row 16776 => Predicted: 1\n",
      "Row 16777 => Predicted: 0\n",
      "Row 16778 => Predicted: 1\n",
      "Row 16779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16770 to 16779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16780 => Predicted: 1\n",
      "Row 16781 => Predicted: 0\n",
      "Row 16782 => Predicted: 0\n",
      "Row 16783 => Predicted: 0\n",
      "Row 16784 => Predicted: 1\n",
      "Row 16785 => Predicted: 0\n",
      "Row 16786 => Predicted: 1\n",
      "Row 16787 => Predicted: 0\n",
      "Row 16788 => Predicted: 0\n",
      "Row 16789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16780 to 16789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16790 => Predicted: 1\n",
      "Row 16791 => Predicted: 0\n",
      "Row 16792 => Predicted: 0\n",
      "Row 16793 => Predicted: 1\n",
      "Row 16794 => Predicted: 0\n",
      "Row 16795 => Predicted: 0\n",
      "Row 16796 => Predicted: 1\n",
      "Row 16797 => Predicted: 0\n",
      "Row 16798 => Predicted: 1\n",
      "Row 16799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16790 to 16799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16800 => Predicted: 1\n",
      "Row 16801 => Predicted: 0\n",
      "Row 16802 => Predicted: 0\n",
      "Row 16803 => Predicted: 1\n",
      "Row 16804 => Predicted: 0\n",
      "Row 16805 => Predicted: 1\n",
      "Row 16806 => Predicted: 1\n",
      "Row 16807 => Predicted: 0\n",
      "Row 16808 => Predicted: 1\n",
      "Row 16809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16800 to 16809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16810 => Predicted: 1\n",
      "Row 16811 => Predicted: 0\n",
      "Row 16812 => Predicted: 1\n",
      "Row 16813 => Predicted: 1\n",
      "Row 16814 => Predicted: 0\n",
      "Row 16815 => Predicted: 0\n",
      "Row 16816 => Predicted: 1\n",
      "Row 16817 => Predicted: 0\n",
      "Row 16818 => Predicted: 0\n",
      "Row 16819 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16810 to 16819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16820 => Predicted: 1\n",
      "Row 16821 => Predicted: 0\n",
      "Row 16822 => Predicted: 1\n",
      "Row 16823 => Predicted: 0\n",
      "Row 16824 => Predicted: 1\n",
      "Row 16825 => Predicted: 0\n",
      "Row 16826 => Predicted: 0\n",
      "Row 16827 => Predicted: 0\n",
      "Row 16828 => Predicted: 1\n",
      "Row 16829 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16820 to 16829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16830 => Predicted: 0\n",
      "Row 16831 => Predicted: 0\n",
      "Row 16832 => Predicted: 0\n",
      "Row 16833 => Predicted: 0\n",
      "Row 16834 => Predicted: 0\n",
      "Row 16835 => Predicted: 1\n",
      "Row 16836 => Predicted: 1\n",
      "Row 16837 => Predicted: 0\n",
      "Row 16838 => Predicted: 0\n",
      "Row 16839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16830 to 16839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16840 => Predicted: 0\n",
      "Row 16841 => Predicted: 1\n",
      "Row 16842 => Predicted: 0\n",
      "Row 16843 => Predicted: 1\n",
      "Row 16844 => Predicted: 0\n",
      "Row 16845 => Predicted: 1\n",
      "Row 16846 => Predicted: 1\n",
      "Row 16847 => Predicted: 0\n",
      "Row 16848 => Predicted: 0\n",
      "Row 16849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16840 to 16849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16850 => Predicted: 1\n",
      "Row 16851 => Predicted: 1\n",
      "Row 16852 => Predicted: 0\n",
      "Row 16853 => Predicted: 1\n",
      "Row 16854 => Predicted: 0\n",
      "Row 16855 => Predicted: 1\n",
      "Row 16856 => Predicted: 1\n",
      "Row 16857 => Predicted: 1\n",
      "Row 16858 => Predicted: 0\n",
      "Row 16859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16850 to 16859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16860 => Predicted: 0\n",
      "Row 16861 => Predicted: 1\n",
      "Row 16862 => Predicted: 0\n",
      "Row 16863 => Predicted: 0\n",
      "Row 16864 => Predicted: 1\n",
      "Row 16865 => Predicted: 0\n",
      "Row 16866 => Predicted: 0\n",
      "Row 16867 => Predicted: 0\n",
      "Row 16868 => Predicted: 0\n",
      "Row 16869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16860 to 16869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16870 => Predicted: 0\n",
      "Row 16871 => Predicted: 1\n",
      "Row 16872 => Predicted: 1\n",
      "Row 16873 => Predicted: 1\n",
      "Row 16874 => Predicted: 0\n",
      "Row 16875 => Predicted: 1\n",
      "Row 16876 => Predicted: 1\n",
      "Row 16877 => Predicted: 1\n",
      "Row 16878 => Predicted: 1\n",
      "Row 16879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16870 to 16879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16880 => Predicted: 0\n",
      "Row 16881 => Predicted: 0\n",
      "Row 16882 => Predicted: 1\n",
      "Row 16883 => Predicted: 0\n",
      "Row 16884 => Predicted: 1\n",
      "Row 16885 => Predicted: 0\n",
      "Row 16886 => Predicted: 0\n",
      "Row 16887 => Predicted: 1\n",
      "Row 16888 => Predicted: 1\n",
      "Row 16889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16880 to 16889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16890 => Predicted: 0\n",
      "Row 16891 => Predicted: 0\n",
      "Row 16892 => Predicted: 0\n",
      "Row 16893 => Predicted: 0\n",
      "Row 16894 => Predicted: 0\n",
      "Row 16895 => Predicted: 1\n",
      "Row 16896 => Predicted: 0\n",
      "Row 16897 => Predicted: 0\n",
      "Row 16898 => Predicted: 1\n",
      "Row 16899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16890 to 16899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16900 => Predicted: 0\n",
      "Row 16901 => Predicted: 1\n",
      "Row 16902 => Predicted: 1\n",
      "Row 16903 => Predicted: 1\n",
      "Row 16904 => Predicted: 0\n",
      "Row 16905 => Predicted: 1\n",
      "Row 16906 => Predicted: 1\n",
      "Row 16907 => Predicted: 0\n",
      "Row 16908 => Predicted: 0\n",
      "Row 16909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16900 to 16909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16910 => Predicted: 1\n",
      "Row 16911 => Predicted: 1\n",
      "Row 16912 => Predicted: 1\n",
      "Row 16913 => Predicted: 0\n",
      "Row 16914 => Predicted: 1\n",
      "Row 16915 => Predicted: 0\n",
      "Row 16916 => Predicted: 0\n",
      "Row 16917 => Predicted: 0\n",
      "Row 16918 => Predicted: 0\n",
      "Row 16919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16910 to 16919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16920 => Predicted: 1\n",
      "Row 16921 => Predicted: 0\n",
      "Row 16922 => Predicted: 0\n",
      "Row 16923 => Predicted: 1\n",
      "Row 16924 => Predicted: 0\n",
      "Row 16925 => Predicted: 1\n",
      "Row 16926 => Predicted: 1\n",
      "Row 16927 => Predicted: 0\n",
      "Row 16928 => Predicted: 0\n",
      "Row 16929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16920 to 16929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16930 => Predicted: 0\n",
      "Row 16931 => Predicted: 0\n",
      "Row 16932 => Predicted: 1\n",
      "Row 16933 => Predicted: 1\n",
      "Row 16934 => Predicted: 0\n",
      "Row 16935 => Predicted: 0\n",
      "Row 16936 => Predicted: 1\n",
      "Row 16937 => Predicted: 0\n",
      "Row 16938 => Predicted: 0\n",
      "Row 16939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16930 to 16939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16940 => Predicted: 0\n",
      "Row 16941 => Predicted: 0\n",
      "Row 16942 => Predicted: 1\n",
      "Row 16943 => Predicted: 0\n",
      "Row 16944 => Predicted: 1\n",
      "Row 16945 => Predicted: 0\n",
      "Row 16946 => Predicted: 0\n",
      "Row 16947 => Predicted: 0\n",
      "Row 16948 => Predicted: 1\n",
      "Row 16949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16940 to 16949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16950 => Predicted: 0\n",
      "Row 16951 => Predicted: 1\n",
      "Row 16952 => Predicted: 1\n",
      "Row 16953 => Predicted: 0\n",
      "Row 16954 => Predicted: 1\n",
      "Row 16955 => Predicted: 0\n",
      "Row 16956 => Predicted: 1\n",
      "Row 16957 => Predicted: 0\n",
      "Row 16958 => Predicted: 1\n",
      "Row 16959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16950 to 16959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16960 => Predicted: 0\n",
      "Row 16961 => Predicted: 1\n",
      "Row 16962 => Predicted: 1\n",
      "Row 16963 => Predicted: 1\n",
      "Row 16964 => Predicted: 0\n",
      "Row 16965 => Predicted: 1\n",
      "Row 16966 => Predicted: 1\n",
      "Row 16967 => Predicted: 1\n",
      "Row 16968 => Predicted: 0\n",
      "Row 16969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16960 to 16969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16970 => Predicted: 0\n",
      "Row 16971 => Predicted: 1\n",
      "Row 16972 => Predicted: 0\n",
      "Row 16973 => Predicted: 0\n",
      "Row 16974 => Predicted: 1\n",
      "Row 16975 => Predicted: 0\n",
      "Row 16976 => Predicted: 1\n",
      "Row 16977 => Predicted: 0\n",
      "Row 16978 => Predicted: 0\n",
      "Row 16979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 16970 to 16979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16980 => Predicted: 1\n",
      "Row 16981 => Predicted: 0\n",
      "Row 16982 => Predicted: 1\n",
      "Row 16983 => Predicted: 0\n",
      "Row 16984 => Predicted: 0\n",
      "Row 16985 => Predicted: 0\n",
      "Row 16986 => Predicted: 1\n",
      "Row 16987 => Predicted: 0\n",
      "Row 16988 => Predicted: 0\n",
      "Row 16989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16980 to 16989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16990 => Predicted: 1\n",
      "Row 16991 => Predicted: 1\n",
      "Row 16992 => Predicted: 1\n",
      "Row 16993 => Predicted: 1\n",
      "Row 16994 => Predicted: 1\n",
      "Row 16995 => Predicted: 1\n",
      "Row 16996 => Predicted: 0\n",
      "Row 16997 => Predicted: 0\n",
      "Row 16998 => Predicted: 0\n",
      "Row 16999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 16990 to 16999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17000 => Predicted: 0\n",
      "Row 17001 => Predicted: 0\n",
      "Row 17002 => Predicted: 0\n",
      "Row 17003 => Predicted: 1\n",
      "Row 17004 => Predicted: 1\n",
      "Row 17005 => Predicted: 1\n",
      "Row 17006 => Predicted: 0\n",
      "Row 17007 => Predicted: 1\n",
      "Row 17008 => Predicted: 1\n",
      "Row 17009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17000 to 17009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17010 => Predicted: 1\n",
      "Row 17011 => Predicted: 0\n",
      "Row 17012 => Predicted: 1\n",
      "Row 17013 => Predicted: 1\n",
      "Row 17014 => Predicted: 0\n",
      "Row 17015 => Predicted: 1\n",
      "Row 17016 => Predicted: 1\n",
      "Row 17017 => Predicted: 1\n",
      "Row 17018 => Predicted: 0\n",
      "Row 17019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17010 to 17019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17020 => Predicted: 0\n",
      "Row 17021 => Predicted: 1\n",
      "Row 17022 => Predicted: 0\n",
      "Row 17023 => Predicted: 0\n",
      "Row 17024 => Predicted: 1\n",
      "Row 17025 => Predicted: 0\n",
      "Row 17026 => Predicted: 1\n",
      "Row 17027 => Predicted: 1\n",
      "Row 17028 => Predicted: 1\n",
      "Row 17029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17020 to 17029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17030 => Predicted: 1\n",
      "Row 17031 => Predicted: 1\n",
      "Row 17032 => Predicted: 1\n",
      "Row 17033 => Predicted: 1\n",
      "Row 17034 => Predicted: 0\n",
      "Row 17035 => Predicted: 1\n",
      "Row 17036 => Predicted: 0\n",
      "Row 17037 => Predicted: 1\n",
      "Row 17038 => Predicted: 0\n",
      "Row 17039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17030 to 17039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17040 => Predicted: 0\n",
      "Row 17041 => Predicted: 0\n",
      "Row 17042 => Predicted: 0\n",
      "Row 17043 => Predicted: 1\n",
      "Row 17044 => Predicted: 0\n",
      "Row 17045 => Predicted: 0\n",
      "Row 17046 => Predicted: 0\n",
      "Row 17047 => Predicted: 0\n",
      "Row 17048 => Predicted: 1\n",
      "Row 17049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17040 to 17049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17050 => Predicted: 1\n",
      "Row 17051 => Predicted: 0\n",
      "Row 17052 => Predicted: 0\n",
      "Row 17053 => Predicted: 0\n",
      "Row 17054 => Predicted: 0\n",
      "Row 17055 => Predicted: 0\n",
      "Row 17056 => Predicted: 0\n",
      "Row 17057 => Predicted: 1\n",
      "Row 17058 => Predicted: 0\n",
      "Row 17059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17050 to 17059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17060 => Predicted: 0\n",
      "Row 17061 => Predicted: 0\n",
      "Row 17062 => Predicted: 1\n",
      "Row 17063 => Predicted: 0\n",
      "Row 17064 => Predicted: 0\n",
      "Row 17065 => Predicted: 1\n",
      "Row 17066 => Predicted: 0\n",
      "Row 17067 => Predicted: 0\n",
      "Row 17068 => Predicted: 1\n",
      "Row 17069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17060 to 17069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17070 => Predicted: 1\n",
      "Row 17071 => Predicted: 0\n",
      "Row 17072 => Predicted: 1\n",
      "Row 17073 => Predicted: 0\n",
      "Row 17074 => Predicted: 1\n",
      "Row 17075 => Predicted: 1\n",
      "Row 17076 => Predicted: 1\n",
      "Row 17077 => Predicted: 1\n",
      "Row 17078 => Predicted: 0\n",
      "Row 17079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17070 to 17079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17080 => Predicted: 1\n",
      "Row 17081 => Predicted: 1\n",
      "Row 17082 => Predicted: 0\n",
      "Row 17083 => Predicted: 1\n",
      "Row 17084 => Predicted: 0\n",
      "Row 17085 => Predicted: 0\n",
      "Row 17086 => Predicted: 0\n",
      "Row 17087 => Predicted: 1\n",
      "Row 17088 => Predicted: 1\n",
      "Row 17089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17080 to 17089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17090 => Predicted: 0\n",
      "Row 17091 => Predicted: 1\n",
      "Row 17092 => Predicted: 1\n",
      "Row 17093 => Predicted: 0\n",
      "Row 17094 => Predicted: 1\n",
      "Row 17095 => Predicted: 1\n",
      "Row 17096 => Predicted: 0\n",
      "Row 17097 => Predicted: 0\n",
      "Row 17098 => Predicted: 0\n",
      "Row 17099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17090 to 17099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17100 => Predicted: 1\n",
      "Row 17101 => Predicted: 0\n",
      "Row 17102 => Predicted: 0\n",
      "Row 17103 => Predicted: 1\n",
      "Row 17104 => Predicted: 1\n",
      "Row 17105 => Predicted: 0\n",
      "Row 17106 => Predicted: 0\n",
      "Row 17107 => Predicted: 1\n",
      "Row 17108 => Predicted: 0\n",
      "Row 17109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17100 to 17109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17110 => Predicted: 0\n",
      "Row 17111 => Predicted: 0\n",
      "Row 17112 => Predicted: 1\n",
      "Row 17113 => Predicted: 1\n",
      "Row 17114 => Predicted: 0\n",
      "Row 17115 => Predicted: 1\n",
      "Row 17116 => Predicted: 1\n",
      "Row 17117 => Predicted: 0\n",
      "Row 17118 => Predicted: 1\n",
      "Row 17119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17110 to 17119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17120 => Predicted: 1\n",
      "Row 17121 => Predicted: 1\n",
      "Row 17122 => Predicted: 0\n",
      "Row 17123 => Predicted: 1\n",
      "Row 17124 => Predicted: 1\n",
      "Row 17125 => Predicted: 0\n",
      "Row 17126 => Predicted: 0\n",
      "Row 17127 => Predicted: 0\n",
      "Row 17128 => Predicted: 0\n",
      "Row 17129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17120 to 17129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17130 => Predicted: 1\n",
      "Row 17131 => Predicted: 0\n",
      "Row 17132 => Predicted: 1\n",
      "Row 17133 => Predicted: 0\n",
      "Row 17134 => Predicted: 1\n",
      "Row 17135 => Predicted: 1\n",
      "Row 17136 => Predicted: 0\n",
      "Row 17137 => Predicted: 1\n",
      "Row 17138 => Predicted: 1\n",
      "Row 17139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17130 to 17139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17140 => Predicted: 0\n",
      "Row 17141 => Predicted: 0\n",
      "Row 17142 => Predicted: 0\n",
      "Row 17143 => Predicted: 0\n",
      "Row 17144 => Predicted: 1\n",
      "Row 17145 => Predicted: 0\n",
      "Row 17146 => Predicted: 1\n",
      "Row 17147 => Predicted: 0\n",
      "Row 17148 => Predicted: 0\n",
      "Row 17149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17140 to 17149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17150 => Predicted: 1\n",
      "Row 17151 => Predicted: 0\n",
      "Row 17152 => Predicted: 0\n",
      "Row 17153 => Predicted: 1\n",
      "Row 17154 => Predicted: 0\n",
      "Row 17155 => Predicted: 0\n",
      "Row 17156 => Predicted: 1\n",
      "Row 17157 => Predicted: 0\n",
      "Row 17158 => Predicted: 0\n",
      "Row 17159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17150 to 17159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17160 => Predicted: 0\n",
      "Row 17161 => Predicted: 1\n",
      "Row 17162 => Predicted: 1\n",
      "Row 17163 => Predicted: 1\n",
      "Row 17164 => Predicted: 0\n",
      "Row 17165 => Predicted: 1\n",
      "Row 17166 => Predicted: 0\n",
      "Row 17167 => Predicted: 1\n",
      "Row 17168 => Predicted: 0\n",
      "Row 17169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17160 to 17169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17170 => Predicted: 1\n",
      "Row 17171 => Predicted: 1\n",
      "Row 17172 => Predicted: 0\n",
      "Row 17173 => Predicted: 0\n",
      "Row 17174 => Predicted: 1\n",
      "Row 17175 => Predicted: 1\n",
      "Row 17176 => Predicted: 0\n",
      "Row 17177 => Predicted: 1\n",
      "Row 17178 => Predicted: 0\n",
      "Row 17179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17170 to 17179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17180 => Predicted: 1\n",
      "Row 17181 => Predicted: 0\n",
      "Row 17182 => Predicted: 0\n",
      "Row 17183 => Predicted: 1\n",
      "Row 17184 => Predicted: 1\n",
      "Row 17185 => Predicted: 0\n",
      "Row 17186 => Predicted: 0\n",
      "Row 17187 => Predicted: 0\n",
      "Row 17188 => Predicted: 0\n",
      "Row 17189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17180 to 17189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17190 => Predicted: 0\n",
      "Row 17191 => Predicted: 0\n",
      "Row 17192 => Predicted: 1\n",
      "Row 17193 => Predicted: 1\n",
      "Row 17194 => Predicted: 1\n",
      "Row 17195 => Predicted: 0\n",
      "Row 17196 => Predicted: 1\n",
      "Row 17197 => Predicted: 1\n",
      "Row 17198 => Predicted: 0\n",
      "Row 17199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17190 to 17199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17200 => Predicted: 0\n",
      "Row 17201 => Predicted: 0\n",
      "Row 17202 => Predicted: 1\n",
      "Row 17203 => Predicted: 0\n",
      "Row 17204 => Predicted: 1\n",
      "Row 17205 => Predicted: 1\n",
      "Row 17206 => Predicted: 1\n",
      "Row 17207 => Predicted: 0\n",
      "Row 17208 => Predicted: 1\n",
      "Row 17209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17200 to 17209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17210 => Predicted: 0\n",
      "Row 17211 => Predicted: 1\n",
      "Row 17212 => Predicted: 1\n",
      "Row 17213 => Predicted: 0\n",
      "Row 17214 => Predicted: 0\n",
      "Row 17215 => Predicted: 1\n",
      "Row 17216 => Predicted: 0\n",
      "Row 17217 => Predicted: 0\n",
      "Row 17218 => Predicted: 1\n",
      "Row 17219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17210 to 17219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17220 => Predicted: 0\n",
      "Row 17221 => Predicted: 0\n",
      "Row 17222 => Predicted: 1\n",
      "Row 17223 => Predicted: 0\n",
      "Row 17224 => Predicted: 0\n",
      "Row 17225 => Predicted: 1\n",
      "Row 17226 => Predicted: 1\n",
      "Row 17227 => Predicted: 0\n",
      "Row 17228 => Predicted: 0\n",
      "Row 17229 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17220 to 17229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17230 => Predicted: 0\n",
      "Row 17231 => Predicted: 0\n",
      "Row 17232 => Predicted: 1\n",
      "Row 17233 => Predicted: 1\n",
      "Row 17234 => Predicted: 0\n",
      "Row 17235 => Predicted: 1\n",
      "Row 17236 => Predicted: 0\n",
      "Row 17237 => Predicted: 0\n",
      "Row 17238 => Predicted: 1\n",
      "Row 17239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17230 to 17239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17240 => Predicted: 0\n",
      "Row 17241 => Predicted: 0\n",
      "Row 17242 => Predicted: 0\n",
      "Row 17243 => Predicted: 1\n",
      "Row 17244 => Predicted: 1\n",
      "Row 17245 => Predicted: 1\n",
      "Row 17246 => Predicted: 1\n",
      "Row 17247 => Predicted: 1\n",
      "Row 17248 => Predicted: 0\n",
      "Row 17249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17240 to 17249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17250 => Predicted: 1\n",
      "Row 17251 => Predicted: 1\n",
      "Row 17252 => Predicted: 0\n",
      "Row 17253 => Predicted: 1\n",
      "Row 17254 => Predicted: 0\n",
      "Row 17255 => Predicted: 1\n",
      "Row 17256 => Predicted: 0\n",
      "Row 17257 => Predicted: 1\n",
      "Row 17258 => Predicted: 1\n",
      "Row 17259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17250 to 17259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17260 => Predicted: 1\n",
      "Row 17261 => Predicted: 1\n",
      "Row 17262 => Predicted: 1\n",
      "Row 17263 => Predicted: 0\n",
      "Row 17264 => Predicted: 1\n",
      "Row 17265 => Predicted: 1\n",
      "Row 17266 => Predicted: 0\n",
      "Row 17267 => Predicted: 1\n",
      "Row 17268 => Predicted: 1\n",
      "Row 17269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17260 to 17269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17270 => Predicted: 1\n",
      "Row 17271 => Predicted: 0\n",
      "Row 17272 => Predicted: 0\n",
      "Row 17273 => Predicted: 1\n",
      "Row 17274 => Predicted: 0\n",
      "Row 17275 => Predicted: 1\n",
      "Row 17276 => Predicted: 1\n",
      "Row 17277 => Predicted: 1\n",
      "Row 17278 => Predicted: 0\n",
      "Row 17279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17270 to 17279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17280 => Predicted: 0\n",
      "Row 17281 => Predicted: 1\n",
      "Row 17282 => Predicted: 0\n",
      "Row 17283 => Predicted: 0\n",
      "Row 17284 => Predicted: 1\n",
      "Row 17285 => Predicted: 0\n",
      "Row 17286 => Predicted: 1\n",
      "Row 17287 => Predicted: 1\n",
      "Row 17288 => Predicted: 1\n",
      "Row 17289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17280 to 17289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17290 => Predicted: 1\n",
      "Row 17291 => Predicted: 1\n",
      "Row 17292 => Predicted: 0\n",
      "Row 17293 => Predicted: 1\n",
      "Row 17294 => Predicted: 1\n",
      "Row 17295 => Predicted: 1\n",
      "Row 17296 => Predicted: 1\n",
      "Row 17297 => Predicted: 1\n",
      "Row 17298 => Predicted: 1\n",
      "Row 17299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17290 to 17299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17300 => Predicted: 0\n",
      "Row 17301 => Predicted: 0\n",
      "Row 17302 => Predicted: 0\n",
      "Row 17303 => Predicted: 0\n",
      "Row 17304 => Predicted: 1\n",
      "Row 17305 => Predicted: 0\n",
      "Row 17306 => Predicted: 0\n",
      "Row 17307 => Predicted: 1\n",
      "Row 17308 => Predicted: 1\n",
      "Row 17309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17300 to 17309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17310 => Predicted: 1\n",
      "Row 17311 => Predicted: 1\n",
      "Row 17312 => Predicted: 0\n",
      "Row 17313 => Predicted: 1\n",
      "Row 17314 => Predicted: 1\n",
      "Row 17315 => Predicted: 0\n",
      "Row 17316 => Predicted: 1\n",
      "Row 17317 => Predicted: 0\n",
      "Row 17318 => Predicted: 0\n",
      "Row 17319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17310 to 17319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17320 => Predicted: 0\n",
      "Row 17321 => Predicted: 1\n",
      "Row 17322 => Predicted: 0\n",
      "Row 17323 => Predicted: 1\n",
      "Row 17324 => Predicted: 1\n",
      "Row 17325 => Predicted: 1\n",
      "Row 17326 => Predicted: 0\n",
      "Row 17327 => Predicted: 0\n",
      "Row 17328 => Predicted: 0\n",
      "Row 17329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17320 to 17329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17330 => Predicted: 1\n",
      "Row 17331 => Predicted: 1\n",
      "Row 17332 => Predicted: 1\n",
      "Row 17333 => Predicted: 0\n",
      "Row 17334 => Predicted: 0\n",
      "Row 17335 => Predicted: 0\n",
      "Row 17336 => Predicted: 1\n",
      "Row 17337 => Predicted: 1\n",
      "Row 17338 => Predicted: 1\n",
      "Row 17339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17330 to 17339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17340 => Predicted: 1\n",
      "Row 17341 => Predicted: 1\n",
      "Row 17342 => Predicted: 0\n",
      "Row 17343 => Predicted: 0\n",
      "Row 17344 => Predicted: 0\n",
      "Row 17345 => Predicted: 0\n",
      "Row 17346 => Predicted: 1\n",
      "Row 17347 => Predicted: 1\n",
      "Row 17348 => Predicted: 1\n",
      "Row 17349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17340 to 17349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17350 => Predicted: 1\n",
      "Row 17351 => Predicted: 1\n",
      "Row 17352 => Predicted: 0\n",
      "Row 17353 => Predicted: 0\n",
      "Row 17354 => Predicted: 1\n",
      "Row 17355 => Predicted: 1\n",
      "Row 17356 => Predicted: 0\n",
      "Row 17357 => Predicted: 1\n",
      "Row 17358 => Predicted: 1\n",
      "Row 17359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17350 to 17359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17360 => Predicted: 1\n",
      "Row 17361 => Predicted: 0\n",
      "Row 17362 => Predicted: 1\n",
      "Row 17363 => Predicted: 0\n",
      "Row 17364 => Predicted: 0\n",
      "Row 17365 => Predicted: 1\n",
      "Row 17366 => Predicted: 1\n",
      "Row 17367 => Predicted: 1\n",
      "Row 17368 => Predicted: 0\n",
      "Row 17369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17360 to 17369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17370 => Predicted: 0\n",
      "Row 17371 => Predicted: 1\n",
      "Row 17372 => Predicted: 1\n",
      "Row 17373 => Predicted: 1\n",
      "Row 17374 => Predicted: 0\n",
      "Row 17375 => Predicted: 1\n",
      "Row 17376 => Predicted: 1\n",
      "Row 17377 => Predicted: 1\n",
      "Row 17378 => Predicted: 1\n",
      "Row 17379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17370 to 17379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17380 => Predicted: 1\n",
      "Row 17381 => Predicted: 0\n",
      "Row 17382 => Predicted: 0\n",
      "Row 17383 => Predicted: 0\n",
      "Row 17384 => Predicted: 0\n",
      "Row 17385 => Predicted: 1\n",
      "Row 17386 => Predicted: 1\n",
      "Row 17387 => Predicted: 0\n",
      "Row 17388 => Predicted: 0\n",
      "Row 17389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17380 to 17389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17390 => Predicted: 0\n",
      "Row 17391 => Predicted: 1\n",
      "Row 17392 => Predicted: 1\n",
      "Row 17393 => Predicted: 0\n",
      "Row 17394 => Predicted: 1\n",
      "Row 17395 => Predicted: 1\n",
      "Row 17396 => Predicted: 1\n",
      "Row 17397 => Predicted: 1\n",
      "Row 17398 => Predicted: 1\n",
      "Row 17399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17390 to 17399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17400 => Predicted: 1\n",
      "Row 17401 => Predicted: 0\n",
      "Row 17402 => Predicted: 1\n",
      "Row 17403 => Predicted: 0\n",
      "Row 17404 => Predicted: 0\n",
      "Row 17405 => Predicted: 1\n",
      "Row 17406 => Predicted: 1\n",
      "Row 17407 => Predicted: 1\n",
      "Row 17408 => Predicted: 1\n",
      "Row 17409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17400 to 17409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17410 => Predicted: 1\n",
      "Row 17411 => Predicted: 1\n",
      "Row 17412 => Predicted: 1\n",
      "Row 17413 => Predicted: 1\n",
      "Row 17414 => Predicted: 0\n",
      "Row 17415 => Predicted: 1\n",
      "Row 17416 => Predicted: 1\n",
      "Row 17417 => Predicted: 0\n",
      "Row 17418 => Predicted: 0\n",
      "Row 17419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17410 to 17419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17420 => Predicted: 1\n",
      "Row 17421 => Predicted: 0\n",
      "Row 17422 => Predicted: 1\n",
      "Row 17423 => Predicted: 0\n",
      "Row 17424 => Predicted: 1\n",
      "Row 17425 => Predicted: 0\n",
      "Row 17426 => Predicted: 0\n",
      "Row 17427 => Predicted: 0\n",
      "Row 17428 => Predicted: 1\n",
      "Row 17429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17420 to 17429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17430 => Predicted: 0\n",
      "Row 17431 => Predicted: 1\n",
      "Row 17432 => Predicted: 0\n",
      "Row 17433 => Predicted: 1\n",
      "Row 17434 => Predicted: 1\n",
      "Row 17435 => Predicted: 1\n",
      "Row 17436 => Predicted: 1\n",
      "Row 17437 => Predicted: 1\n",
      "Row 17438 => Predicted: 0\n",
      "Row 17439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17430 to 17439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17440 => Predicted: 1\n",
      "Row 17441 => Predicted: 1\n",
      "Row 17442 => Predicted: 1\n",
      "Row 17443 => Predicted: 1\n",
      "Row 17444 => Predicted: 0\n",
      "Row 17445 => Predicted: 0\n",
      "Row 17446 => Predicted: 0\n",
      "Row 17447 => Predicted: 0\n",
      "Row 17448 => Predicted: 1\n",
      "Row 17449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17440 to 17449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17450 => Predicted: 1\n",
      "Row 17451 => Predicted: 1\n",
      "Row 17452 => Predicted: 1\n",
      "Row 17453 => Predicted: 0\n",
      "Row 17454 => Predicted: 0\n",
      "Row 17455 => Predicted: 0\n",
      "Row 17456 => Predicted: 1\n",
      "Row 17457 => Predicted: 1\n",
      "Row 17458 => Predicted: 1\n",
      "Row 17459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17450 to 17459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17460 => Predicted: 0\n",
      "Row 17461 => Predicted: 0\n",
      "Row 17462 => Predicted: 1\n",
      "Row 17463 => Predicted: 0\n",
      "Row 17464 => Predicted: 0\n",
      "Row 17465 => Predicted: 0\n",
      "Row 17466 => Predicted: 1\n",
      "Row 17467 => Predicted: 0\n",
      "Row 17468 => Predicted: 1\n",
      "Row 17469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17460 to 17469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17470 => Predicted: 0\n",
      "Row 17471 => Predicted: 1\n",
      "Row 17472 => Predicted: 1\n",
      "Row 17473 => Predicted: 1\n",
      "Row 17474 => Predicted: 1\n",
      "Row 17475 => Predicted: 0\n",
      "Row 17476 => Predicted: 1\n",
      "Row 17477 => Predicted: 1\n",
      "Row 17478 => Predicted: 0\n",
      "Row 17479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17470 to 17479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17480 => Predicted: 0\n",
      "Row 17481 => Predicted: 1\n",
      "Row 17482 => Predicted: 1\n",
      "Row 17483 => Predicted: 0\n",
      "Row 17484 => Predicted: 0\n",
      "Row 17485 => Predicted: 1\n",
      "Row 17486 => Predicted: 0\n",
      "Row 17487 => Predicted: 1\n",
      "Row 17488 => Predicted: 0\n",
      "Row 17489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17480 to 17489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17490 => Predicted: 0\n",
      "Row 17491 => Predicted: 0\n",
      "Row 17492 => Predicted: 1\n",
      "Row 17493 => Predicted: 0\n",
      "Row 17494 => Predicted: 1\n",
      "Row 17495 => Predicted: 1\n",
      "Row 17496 => Predicted: 0\n",
      "Row 17497 => Predicted: 1\n",
      "Row 17498 => Predicted: 0\n",
      "Row 17499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17490 to 17499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17500 => Predicted: 1\n",
      "Row 17501 => Predicted: 0\n",
      "Row 17502 => Predicted: 1\n",
      "Row 17503 => Predicted: 0\n",
      "Row 17504 => Predicted: 0\n",
      "Row 17505 => Predicted: 0\n",
      "Row 17506 => Predicted: 0\n",
      "Row 17507 => Predicted: 0\n",
      "Row 17508 => Predicted: 0\n",
      "Row 17509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17500 to 17509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17510 => Predicted: 1\n",
      "Row 17511 => Predicted: 0\n",
      "Row 17512 => Predicted: 0\n",
      "Row 17513 => Predicted: 1\n",
      "Row 17514 => Predicted: 0\n",
      "Row 17515 => Predicted: 0\n",
      "Row 17516 => Predicted: 1\n",
      "Row 17517 => Predicted: 0\n",
      "Row 17518 => Predicted: 1\n",
      "Row 17519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17510 to 17519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17520 => Predicted: 1\n",
      "Row 17521 => Predicted: 0\n",
      "Row 17522 => Predicted: 1\n",
      "Row 17523 => Predicted: 1\n",
      "Row 17524 => Predicted: 0\n",
      "Row 17525 => Predicted: 1\n",
      "Row 17526 => Predicted: 1\n",
      "Row 17527 => Predicted: 1\n",
      "Row 17528 => Predicted: 1\n",
      "Row 17529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17520 to 17529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17530 => Predicted: 0\n",
      "Row 17531 => Predicted: 0\n",
      "Row 17532 => Predicted: 1\n",
      "Row 17533 => Predicted: 1\n",
      "Row 17534 => Predicted: 0\n",
      "Row 17535 => Predicted: 1\n",
      "Row 17536 => Predicted: 0\n",
      "Row 17537 => Predicted: 0\n",
      "Row 17538 => Predicted: 0\n",
      "Row 17539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17530 to 17539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17540 => Predicted: 0\n",
      "Row 17541 => Predicted: 1\n",
      "Row 17542 => Predicted: 0\n",
      "Row 17543 => Predicted: 1\n",
      "Row 17544 => Predicted: 1\n",
      "Row 17545 => Predicted: 1\n",
      "Row 17546 => Predicted: 1\n",
      "Row 17547 => Predicted: 1\n",
      "Row 17548 => Predicted: 1\n",
      "Row 17549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17540 to 17549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17550 => Predicted: 0\n",
      "Row 17551 => Predicted: 0\n",
      "Row 17552 => Predicted: 1\n",
      "Row 17553 => Predicted: 0\n",
      "Row 17554 => Predicted: 1\n",
      "Row 17555 => Predicted: 1\n",
      "Row 17556 => Predicted: 0\n",
      "Row 17557 => Predicted: 1\n",
      "Row 17558 => Predicted: 0\n",
      "Row 17559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17550 to 17559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17560 => Predicted: 1\n",
      "Row 17561 => Predicted: 0\n",
      "Row 17562 => Predicted: 1\n",
      "Row 17563 => Predicted: 0\n",
      "Row 17564 => Predicted: 1\n",
      "Row 17565 => Predicted: 1\n",
      "Row 17566 => Predicted: 0\n",
      "Row 17567 => Predicted: 0\n",
      "Row 17568 => Predicted: 1\n",
      "Row 17569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17560 to 17569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17570 => Predicted: 1\n",
      "Row 17571 => Predicted: 1\n",
      "Row 17572 => Predicted: 1\n",
      "Row 17573 => Predicted: 0\n",
      "Row 17574 => Predicted: 1\n",
      "Row 17575 => Predicted: 1\n",
      "Row 17576 => Predicted: 0\n",
      "Row 17577 => Predicted: 1\n",
      "Row 17578 => Predicted: 0\n",
      "Row 17579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17570 to 17579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17580 => Predicted: 0\n",
      "Row 17581 => Predicted: 0\n",
      "Row 17582 => Predicted: 1\n",
      "Row 17583 => Predicted: 0\n",
      "Row 17584 => Predicted: 0\n",
      "Row 17585 => Predicted: 1\n",
      "Row 17586 => Predicted: 1\n",
      "Row 17587 => Predicted: 0\n",
      "Row 17588 => Predicted: 1\n",
      "Row 17589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17580 to 17589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17590 => Predicted: 0\n",
      "Row 17591 => Predicted: 0\n",
      "Row 17592 => Predicted: 0\n",
      "Row 17593 => Predicted: 1\n",
      "Row 17594 => Predicted: 1\n",
      "Row 17595 => Predicted: 1\n",
      "Row 17596 => Predicted: 1\n",
      "Row 17597 => Predicted: 1\n",
      "Row 17598 => Predicted: 1\n",
      "Row 17599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17590 to 17599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17600 => Predicted: 1\n",
      "Row 17601 => Predicted: 1\n",
      "Row 17602 => Predicted: 1\n",
      "Row 17603 => Predicted: 1\n",
      "Row 17604 => Predicted: 1\n",
      "Row 17605 => Predicted: 0\n",
      "Row 17606 => Predicted: 1\n",
      "Row 17607 => Predicted: 0\n",
      "Row 17608 => Predicted: 1\n",
      "Row 17609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17600 to 17609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17610 => Predicted: 0\n",
      "Row 17611 => Predicted: 0\n",
      "Row 17612 => Predicted: 0\n",
      "Row 17613 => Predicted: 1\n",
      "Row 17614 => Predicted: 0\n",
      "Row 17615 => Predicted: 1\n",
      "Row 17616 => Predicted: 1\n",
      "Row 17617 => Predicted: 1\n",
      "Row 17618 => Predicted: 1\n",
      "Row 17619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17610 to 17619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17620 => Predicted: 0\n",
      "Row 17621 => Predicted: 0\n",
      "Row 17622 => Predicted: 0\n",
      "Row 17623 => Predicted: 0\n",
      "Row 17624 => Predicted: 0\n",
      "Row 17625 => Predicted: 1\n",
      "Row 17626 => Predicted: 0\n",
      "Row 17627 => Predicted: 0\n",
      "Row 17628 => Predicted: 0\n",
      "Row 17629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17620 to 17629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17630 => Predicted: 1\n",
      "Row 17631 => Predicted: 1\n",
      "Row 17632 => Predicted: 1\n",
      "Row 17633 => Predicted: 1\n",
      "Row 17634 => Predicted: 1\n",
      "Row 17635 => Predicted: 0\n",
      "Row 17636 => Predicted: 0\n",
      "Row 17637 => Predicted: 0\n",
      "Row 17638 => Predicted: 0\n",
      "Row 17639 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17630 to 17639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17640 => Predicted: 0\n",
      "Row 17641 => Predicted: 1\n",
      "Row 17642 => Predicted: 1\n",
      "Row 17643 => Predicted: 1\n",
      "Row 17644 => Predicted: 1\n",
      "Row 17645 => Predicted: 0\n",
      "Row 17646 => Predicted: 1\n",
      "Row 17647 => Predicted: 0\n",
      "Row 17648 => Predicted: 1\n",
      "Row 17649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17640 to 17649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17650 => Predicted: 0\n",
      "Row 17651 => Predicted: 0\n",
      "Row 17652 => Predicted: 1\n",
      "Row 17653 => Predicted: 0\n",
      "Row 17654 => Predicted: 0\n",
      "Row 17655 => Predicted: 1\n",
      "Row 17656 => Predicted: 1\n",
      "Row 17657 => Predicted: 1\n",
      "Row 17658 => Predicted: 0\n",
      "Row 17659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17650 to 17659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17660 => Predicted: 0\n",
      "Row 17661 => Predicted: 0\n",
      "Row 17662 => Predicted: 1\n",
      "Row 17663 => Predicted: 1\n",
      "Row 17664 => Predicted: 1\n",
      "Row 17665 => Predicted: 0\n",
      "Row 17666 => Predicted: 1\n",
      "Row 17667 => Predicted: 0\n",
      "Row 17668 => Predicted: 0\n",
      "Row 17669 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17660 to 17669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17670 => Predicted: 0\n",
      "Row 17671 => Predicted: 0\n",
      "Row 17672 => Predicted: 1\n",
      "Row 17673 => Predicted: 0\n",
      "Row 17674 => Predicted: 0\n",
      "Row 17675 => Predicted: 0\n",
      "Row 17676 => Predicted: 0\n",
      "Row 17677 => Predicted: 1\n",
      "Row 17678 => Predicted: 0\n",
      "Row 17679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17670 to 17679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17680 => Predicted: 0\n",
      "Row 17681 => Predicted: 0\n",
      "Row 17682 => Predicted: 0\n",
      "Row 17683 => Predicted: 0\n",
      "Row 17684 => Predicted: 1\n",
      "Row 17685 => Predicted: 1\n",
      "Row 17686 => Predicted: 0\n",
      "Row 17687 => Predicted: 0\n",
      "Row 17688 => Predicted: 0\n",
      "Row 17689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17680 to 17689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17690 => Predicted: 1\n",
      "Row 17691 => Predicted: 0\n",
      "Row 17692 => Predicted: 0\n",
      "Row 17693 => Predicted: 0\n",
      "Row 17694 => Predicted: 1\n",
      "Row 17695 => Predicted: 0\n",
      "Row 17696 => Predicted: 0\n",
      "Row 17697 => Predicted: 1\n",
      "Row 17698 => Predicted: 1\n",
      "Row 17699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17690 to 17699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17700 => Predicted: 0\n",
      "Row 17701 => Predicted: 0\n",
      "Row 17702 => Predicted: 0\n",
      "Row 17703 => Predicted: 1\n",
      "Row 17704 => Predicted: 1\n",
      "Row 17705 => Predicted: 0\n",
      "Row 17706 => Predicted: 0\n",
      "Row 17707 => Predicted: 0\n",
      "Row 17708 => Predicted: 1\n",
      "Row 17709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17700 to 17709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17710 => Predicted: 0\n",
      "Row 17711 => Predicted: 1\n",
      "Row 17712 => Predicted: 1\n",
      "Row 17713 => Predicted: 0\n",
      "Row 17714 => Predicted: 1\n",
      "Row 17715 => Predicted: 1\n",
      "Row 17716 => Predicted: 0\n",
      "Row 17717 => Predicted: 0\n",
      "Row 17718 => Predicted: 0\n",
      "Row 17719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17710 to 17719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17720 => Predicted: 0\n",
      "Row 17721 => Predicted: 1\n",
      "Row 17722 => Predicted: 1\n",
      "Row 17723 => Predicted: 0\n",
      "Row 17724 => Predicted: 0\n",
      "Row 17725 => Predicted: 0\n",
      "Row 17726 => Predicted: 1\n",
      "Row 17727 => Predicted: 0\n",
      "Row 17728 => Predicted: 1\n",
      "Row 17729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17720 to 17729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17730 => Predicted: 1\n",
      "Row 17731 => Predicted: 0\n",
      "Row 17732 => Predicted: 1\n",
      "Row 17733 => Predicted: 1\n",
      "Row 17734 => Predicted: 0\n",
      "Row 17735 => Predicted: 1\n",
      "Row 17736 => Predicted: 1\n",
      "Row 17737 => Predicted: 0\n",
      "Row 17738 => Predicted: 1\n",
      "Row 17739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17730 to 17739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17740 => Predicted: 1\n",
      "Row 17741 => Predicted: 0\n",
      "Row 17742 => Predicted: 0\n",
      "Row 17743 => Predicted: 0\n",
      "Row 17744 => Predicted: 0\n",
      "Row 17745 => Predicted: 0\n",
      "Row 17746 => Predicted: 0\n",
      "Row 17747 => Predicted: 0\n",
      "Row 17748 => Predicted: 1\n",
      "Row 17749 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17740 to 17749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17750 => Predicted: 1\n",
      "Row 17751 => Predicted: 0\n",
      "Row 17752 => Predicted: 1\n",
      "Row 17753 => Predicted: 0\n",
      "Row 17754 => Predicted: 0\n",
      "Row 17755 => Predicted: 1\n",
      "Row 17756 => Predicted: 1\n",
      "Row 17757 => Predicted: 0\n",
      "Row 17758 => Predicted: 1\n",
      "Row 17759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17750 to 17759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17760 => Predicted: 1\n",
      "Row 17761 => Predicted: 1\n",
      "Row 17762 => Predicted: 1\n",
      "Row 17763 => Predicted: 1\n",
      "Row 17764 => Predicted: 0\n",
      "Row 17765 => Predicted: 0\n",
      "Row 17766 => Predicted: 0\n",
      "Row 17767 => Predicted: 1\n",
      "Row 17768 => Predicted: 0\n",
      "Row 17769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17760 to 17769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17770 => Predicted: 0\n",
      "Row 17771 => Predicted: 1\n",
      "Row 17772 => Predicted: 0\n",
      "Row 17773 => Predicted: 1\n",
      "Row 17774 => Predicted: 1\n",
      "Row 17775 => Predicted: 1\n",
      "Row 17776 => Predicted: 1\n",
      "Row 17777 => Predicted: 1\n",
      "Row 17778 => Predicted: 0\n",
      "Row 17779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17770 to 17779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17780 => Predicted: 0\n",
      "Row 17781 => Predicted: 1\n",
      "Row 17782 => Predicted: 1\n",
      "Row 17783 => Predicted: 0\n",
      "Row 17784 => Predicted: 1\n",
      "Row 17785 => Predicted: 0\n",
      "Row 17786 => Predicted: 1\n",
      "Row 17787 => Predicted: 0\n",
      "Row 17788 => Predicted: 0\n",
      "Row 17789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17780 to 17789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17790 => Predicted: 1\n",
      "Row 17791 => Predicted: 0\n",
      "Row 17792 => Predicted: 0\n",
      "Row 17793 => Predicted: 0\n",
      "Row 17794 => Predicted: 0\n",
      "Row 17795 => Predicted: 0\n",
      "Row 17796 => Predicted: 1\n",
      "Row 17797 => Predicted: 1\n",
      "Row 17798 => Predicted: 0\n",
      "Row 17799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17790 to 17799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17800 => Predicted: 0\n",
      "Row 17801 => Predicted: 0\n",
      "Row 17802 => Predicted: 1\n",
      "Row 17803 => Predicted: 1\n",
      "Row 17804 => Predicted: 0\n",
      "Row 17805 => Predicted: 0\n",
      "Row 17806 => Predicted: 1\n",
      "Row 17807 => Predicted: 1\n",
      "Row 17808 => Predicted: 1\n",
      "Row 17809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17800 to 17809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17810 => Predicted: 1\n",
      "Row 17811 => Predicted: 1\n",
      "Row 17812 => Predicted: 0\n",
      "Row 17813 => Predicted: 0\n",
      "Row 17814 => Predicted: 1\n",
      "Row 17815 => Predicted: 1\n",
      "Row 17816 => Predicted: 1\n",
      "Row 17817 => Predicted: 0\n",
      "Row 17818 => Predicted: 0\n",
      "Row 17819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17810 to 17819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17820 => Predicted: 0\n",
      "Row 17821 => Predicted: 0\n",
      "Row 17822 => Predicted: 0\n",
      "Row 17823 => Predicted: 0\n",
      "Row 17824 => Predicted: 1\n",
      "Row 17825 => Predicted: 0\n",
      "Row 17826 => Predicted: 0\n",
      "Row 17827 => Predicted: 1\n",
      "Row 17828 => Predicted: 1\n",
      "Row 17829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17820 to 17829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17830 => Predicted: 1\n",
      "Row 17831 => Predicted: 1\n",
      "Row 17832 => Predicted: 1\n",
      "Row 17833 => Predicted: 0\n",
      "Row 17834 => Predicted: 0\n",
      "Row 17835 => Predicted: 1\n",
      "Row 17836 => Predicted: 1\n",
      "Row 17837 => Predicted: 1\n",
      "Row 17838 => Predicted: 0\n",
      "Row 17839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17830 to 17839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17840 => Predicted: 1\n",
      "Row 17841 => Predicted: 1\n",
      "Row 17842 => Predicted: 1\n",
      "Row 17843 => Predicted: 1\n",
      "Row 17844 => Predicted: 0\n",
      "Row 17845 => Predicted: 1\n",
      "Row 17846 => Predicted: 1\n",
      "Row 17847 => Predicted: 1\n",
      "Row 17848 => Predicted: 0\n",
      "Row 17849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17840 to 17849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17850 => Predicted: 1\n",
      "Row 17851 => Predicted: 1\n",
      "Row 17852 => Predicted: 0\n",
      "Row 17853 => Predicted: 0\n",
      "Row 17854 => Predicted: 0\n",
      "Row 17855 => Predicted: 1\n",
      "Row 17856 => Predicted: 0\n",
      "Row 17857 => Predicted: 0\n",
      "Row 17858 => Predicted: 0\n",
      "Row 17859 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17850 to 17859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17860 => Predicted: 0\n",
      "Row 17861 => Predicted: 1\n",
      "Row 17862 => Predicted: 0\n",
      "Row 17863 => Predicted: 1\n",
      "Row 17864 => Predicted: 1\n",
      "Row 17865 => Predicted: 0\n",
      "Row 17866 => Predicted: 1\n",
      "Row 17867 => Predicted: 1\n",
      "Row 17868 => Predicted: 1\n",
      "Row 17869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17860 to 17869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17870 => Predicted: 0\n",
      "Row 17871 => Predicted: 0\n",
      "Row 17872 => Predicted: 0\n",
      "Row 17873 => Predicted: 1\n",
      "Row 17874 => Predicted: 0\n",
      "Row 17875 => Predicted: 1\n",
      "Row 17876 => Predicted: 1\n",
      "Row 17877 => Predicted: 1\n",
      "Row 17878 => Predicted: 1\n",
      "Row 17879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17870 to 17879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17880 => Predicted: 1\n",
      "Row 17881 => Predicted: 0\n",
      "Row 17882 => Predicted: 1\n",
      "Row 17883 => Predicted: 0\n",
      "Row 17884 => Predicted: 1\n",
      "Row 17885 => Predicted: 0\n",
      "Row 17886 => Predicted: 1\n",
      "Row 17887 => Predicted: 1\n",
      "Row 17888 => Predicted: 1\n",
      "Row 17889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17880 to 17889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17890 => Predicted: 0\n",
      "Row 17891 => Predicted: 0\n",
      "Row 17892 => Predicted: 0\n",
      "Row 17893 => Predicted: 1\n",
      "Row 17894 => Predicted: 0\n",
      "Row 17895 => Predicted: 1\n",
      "Row 17896 => Predicted: 1\n",
      "Row 17897 => Predicted: 0\n",
      "Row 17898 => Predicted: 0\n",
      "Row 17899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17890 to 17899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17900 => Predicted: 1\n",
      "Row 17901 => Predicted: 1\n",
      "Row 17902 => Predicted: 1\n",
      "Row 17903 => Predicted: 0\n",
      "Row 17904 => Predicted: 0\n",
      "Row 17905 => Predicted: 0\n",
      "Row 17906 => Predicted: 0\n",
      "Row 17907 => Predicted: 1\n",
      "Row 17908 => Predicted: 1\n",
      "Row 17909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17900 to 17909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17910 => Predicted: 1\n",
      "Row 17911 => Predicted: 1\n",
      "Row 17912 => Predicted: 0\n",
      "Row 17913 => Predicted: 1\n",
      "Row 17914 => Predicted: 0\n",
      "Row 17915 => Predicted: 0\n",
      "Row 17916 => Predicted: 1\n",
      "Row 17917 => Predicted: 1\n",
      "Row 17918 => Predicted: 1\n",
      "Row 17919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17910 to 17919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17920 => Predicted: 0\n",
      "Row 17921 => Predicted: 1\n",
      "Row 17922 => Predicted: 0\n",
      "Row 17923 => Predicted: 1\n",
      "Row 17924 => Predicted: 1\n",
      "Row 17925 => Predicted: 0\n",
      "Row 17926 => Predicted: 0\n",
      "Row 17927 => Predicted: 0\n",
      "Row 17928 => Predicted: 0\n",
      "Row 17929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17920 to 17929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17930 => Predicted: 0\n",
      "Row 17931 => Predicted: 1\n",
      "Row 17932 => Predicted: 0\n",
      "Row 17933 => Predicted: 0\n",
      "Row 17934 => Predicted: 0\n",
      "Row 17935 => Predicted: 0\n",
      "Row 17936 => Predicted: 0\n",
      "Row 17937 => Predicted: 1\n",
      "Row 17938 => Predicted: 0\n",
      "Row 17939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17930 to 17939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17940 => Predicted: 0\n",
      "Row 17941 => Predicted: 1\n",
      "Row 17942 => Predicted: 1\n",
      "Row 17943 => Predicted: 1\n",
      "Row 17944 => Predicted: 0\n",
      "Row 17945 => Predicted: 1\n",
      "Row 17946 => Predicted: 0\n",
      "Row 17947 => Predicted: 0\n",
      "Row 17948 => Predicted: 0\n",
      "Row 17949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17940 to 17949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17950 => Predicted: 0\n",
      "Row 17951 => Predicted: 0\n",
      "Row 17952 => Predicted: 1\n",
      "Row 17953 => Predicted: 1\n",
      "Row 17954 => Predicted: 0\n",
      "Row 17955 => Predicted: 0\n",
      "Row 17956 => Predicted: 0\n",
      "Row 17957 => Predicted: 0\n",
      "Row 17958 => Predicted: 1\n",
      "Row 17959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17950 to 17959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17960 => Predicted: 0\n",
      "Row 17961 => Predicted: 1\n",
      "Row 17962 => Predicted: 0\n",
      "Row 17963 => Predicted: 0\n",
      "Row 17964 => Predicted: 0\n",
      "Row 17965 => Predicted: 0\n",
      "Row 17966 => Predicted: 0\n",
      "Row 17967 => Predicted: 0\n",
      "Row 17968 => Predicted: 1\n",
      "Row 17969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17960 to 17969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17970 => Predicted: 0\n",
      "Row 17971 => Predicted: 0\n",
      "Row 17972 => Predicted: 0\n",
      "Row 17973 => Predicted: 0\n",
      "Row 17974 => Predicted: 1\n",
      "Row 17975 => Predicted: 0\n",
      "Row 17976 => Predicted: 1\n",
      "Row 17977 => Predicted: 1\n",
      "Row 17978 => Predicted: 1\n",
      "Row 17979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17970 to 17979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17980 => Predicted: 1\n",
      "Row 17981 => Predicted: 1\n",
      "Row 17982 => Predicted: 1\n",
      "Row 17983 => Predicted: 0\n",
      "Row 17984 => Predicted: 1\n",
      "Row 17985 => Predicted: 0\n",
      "Row 17986 => Predicted: 0\n",
      "Row 17987 => Predicted: 1\n",
      "Row 17988 => Predicted: 1\n",
      "Row 17989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 17980 to 17989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17990 => Predicted: 1\n",
      "Row 17991 => Predicted: 0\n",
      "Row 17992 => Predicted: 1\n",
      "Row 17993 => Predicted: 1\n",
      "Row 17994 => Predicted: 1\n",
      "Row 17995 => Predicted: 0\n",
      "Row 17996 => Predicted: 1\n",
      "Row 17997 => Predicted: 0\n",
      "Row 17998 => Predicted: 1\n",
      "Row 17999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 17990 to 17999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18000 => Predicted: 0\n",
      "Row 18001 => Predicted: 1\n",
      "Row 18002 => Predicted: 0\n",
      "Row 18003 => Predicted: 1\n",
      "Row 18004 => Predicted: 0\n",
      "Row 18005 => Predicted: 1\n",
      "Row 18006 => Predicted: 1\n",
      "Row 18007 => Predicted: 1\n",
      "Row 18008 => Predicted: 1\n",
      "Row 18009 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18000 to 18009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18010 => Predicted: 1\n",
      "Row 18011 => Predicted: 1\n",
      "Row 18012 => Predicted: 1\n",
      "Row 18013 => Predicted: 0\n",
      "Row 18014 => Predicted: 0\n",
      "Row 18015 => Predicted: 0\n",
      "Row 18016 => Predicted: 1\n",
      "Row 18017 => Predicted: 1\n",
      "Row 18018 => Predicted: 1\n",
      "Row 18019 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18010 to 18019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18020 => Predicted: 1\n",
      "Row 18021 => Predicted: 0\n",
      "Row 18022 => Predicted: 1\n",
      "Row 18023 => Predicted: 0\n",
      "Row 18024 => Predicted: 1\n",
      "Row 18025 => Predicted: 0\n",
      "Row 18026 => Predicted: 1\n",
      "Row 18027 => Predicted: 1\n",
      "Row 18028 => Predicted: 0\n",
      "Row 18029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18020 to 18029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18030 => Predicted: 0\n",
      "Row 18031 => Predicted: 0\n",
      "Row 18032 => Predicted: 1\n",
      "Row 18033 => Predicted: 1\n",
      "Row 18034 => Predicted: 1\n",
      "Row 18035 => Predicted: 0\n",
      "Row 18036 => Predicted: 0\n",
      "Row 18037 => Predicted: 0\n",
      "Row 18038 => Predicted: 0\n",
      "Row 18039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18030 to 18039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18040 => Predicted: 0\n",
      "Row 18041 => Predicted: 0\n",
      "Row 18042 => Predicted: 1\n",
      "Row 18043 => Predicted: 0\n",
      "Row 18044 => Predicted: 0\n",
      "Row 18045 => Predicted: 0\n",
      "Row 18046 => Predicted: 0\n",
      "Row 18047 => Predicted: 0\n",
      "Row 18048 => Predicted: 1\n",
      "Row 18049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18040 to 18049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18050 => Predicted: 1\n",
      "Row 18051 => Predicted: 1\n",
      "Row 18052 => Predicted: 1\n",
      "Row 18053 => Predicted: 0\n",
      "Row 18054 => Predicted: 1\n",
      "Row 18055 => Predicted: 0\n",
      "Row 18056 => Predicted: 0\n",
      "Row 18057 => Predicted: 1\n",
      "Row 18058 => Predicted: 0\n",
      "Row 18059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18050 to 18059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18060 => Predicted: 0\n",
      "Row 18061 => Predicted: 1\n",
      "Row 18062 => Predicted: 0\n",
      "Row 18063 => Predicted: 0\n",
      "Row 18064 => Predicted: 1\n",
      "Row 18065 => Predicted: 1\n",
      "Row 18066 => Predicted: 1\n",
      "Row 18067 => Predicted: 0\n",
      "Row 18068 => Predicted: 1\n",
      "Row 18069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18060 to 18069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18070 => Predicted: 1\n",
      "Row 18071 => Predicted: 0\n",
      "Row 18072 => Predicted: 0\n",
      "Row 18073 => Predicted: 0\n",
      "Row 18074 => Predicted: 0\n",
      "Row 18075 => Predicted: 1\n",
      "Row 18076 => Predicted: 0\n",
      "Row 18077 => Predicted: 1\n",
      "Row 18078 => Predicted: 0\n",
      "Row 18079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18070 to 18079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18080 => Predicted: 1\n",
      "Row 18081 => Predicted: 0\n",
      "Row 18082 => Predicted: 0\n",
      "Row 18083 => Predicted: 1\n",
      "Row 18084 => Predicted: 0\n",
      "Row 18085 => Predicted: 0\n",
      "Row 18086 => Predicted: 0\n",
      "Row 18087 => Predicted: 0\n",
      "Row 18088 => Predicted: 1\n",
      "Row 18089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18080 to 18089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18090 => Predicted: 0\n",
      "Row 18091 => Predicted: 0\n",
      "Row 18092 => Predicted: 1\n",
      "Row 18093 => Predicted: 0\n",
      "Row 18094 => Predicted: 1\n",
      "Row 18095 => Predicted: 0\n",
      "Row 18096 => Predicted: 1\n",
      "Row 18097 => Predicted: 0\n",
      "Row 18098 => Predicted: 1\n",
      "Row 18099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18090 to 18099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18100 => Predicted: 0\n",
      "Row 18101 => Predicted: 1\n",
      "Row 18102 => Predicted: 1\n",
      "Row 18103 => Predicted: 1\n",
      "Row 18104 => Predicted: 0\n",
      "Row 18105 => Predicted: 0\n",
      "Row 18106 => Predicted: 0\n",
      "Row 18107 => Predicted: 0\n",
      "Row 18108 => Predicted: 1\n",
      "Row 18109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18100 to 18109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18110 => Predicted: 1\n",
      "Row 18111 => Predicted: 1\n",
      "Row 18112 => Predicted: 1\n",
      "Row 18113 => Predicted: 0\n",
      "Row 18114 => Predicted: 1\n",
      "Row 18115 => Predicted: 1\n",
      "Row 18116 => Predicted: 0\n",
      "Row 18117 => Predicted: 0\n",
      "Row 18118 => Predicted: 1\n",
      "Row 18119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18110 to 18119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18120 => Predicted: 1\n",
      "Row 18121 => Predicted: 0\n",
      "Row 18122 => Predicted: 1\n",
      "Row 18123 => Predicted: 0\n",
      "Row 18124 => Predicted: 1\n",
      "Row 18125 => Predicted: 0\n",
      "Row 18126 => Predicted: 1\n",
      "Row 18127 => Predicted: 0\n",
      "Row 18128 => Predicted: 0\n",
      "Row 18129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18120 to 18129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18130 => Predicted: 1\n",
      "Row 18131 => Predicted: 0\n",
      "Row 18132 => Predicted: 0\n",
      "Row 18133 => Predicted: 1\n",
      "Row 18134 => Predicted: 1\n",
      "Row 18135 => Predicted: 1\n",
      "Row 18136 => Predicted: 1\n",
      "Row 18137 => Predicted: 0\n",
      "Row 18138 => Predicted: 0\n",
      "Row 18139 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18130 to 18139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18140 => Predicted: 1\n",
      "Row 18141 => Predicted: 0\n",
      "Row 18142 => Predicted: 1\n",
      "Row 18143 => Predicted: 1\n",
      "Row 18144 => Predicted: 1\n",
      "Row 18145 => Predicted: 1\n",
      "Row 18146 => Predicted: 0\n",
      "Row 18147 => Predicted: 0\n",
      "Row 18148 => Predicted: 1\n",
      "Row 18149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18140 to 18149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18150 => Predicted: 1\n",
      "Row 18151 => Predicted: 0\n",
      "Row 18152 => Predicted: 1\n",
      "Row 18153 => Predicted: 1\n",
      "Row 18154 => Predicted: 1\n",
      "Row 18155 => Predicted: 0\n",
      "Row 18156 => Predicted: 0\n",
      "Row 18157 => Predicted: 1\n",
      "Row 18158 => Predicted: 0\n",
      "Row 18159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18150 to 18159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18160 => Predicted: 1\n",
      "Row 18161 => Predicted: 0\n",
      "Row 18162 => Predicted: 1\n",
      "Row 18163 => Predicted: 1\n",
      "Row 18164 => Predicted: 1\n",
      "Row 18165 => Predicted: 1\n",
      "Row 18166 => Predicted: 0\n",
      "Row 18167 => Predicted: 0\n",
      "Row 18168 => Predicted: 1\n",
      "Row 18169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18160 to 18169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18170 => Predicted: 0\n",
      "Row 18171 => Predicted: 1\n",
      "Row 18172 => Predicted: 0\n",
      "Row 18173 => Predicted: 1\n",
      "Row 18174 => Predicted: 0\n",
      "Row 18175 => Predicted: 1\n",
      "Row 18176 => Predicted: 0\n",
      "Row 18177 => Predicted: 0\n",
      "Row 18178 => Predicted: 0\n",
      "Row 18179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18170 to 18179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18180 => Predicted: 1\n",
      "Row 18181 => Predicted: 1\n",
      "Row 18182 => Predicted: 0\n",
      "Row 18183 => Predicted: 1\n",
      "Row 18184 => Predicted: 1\n",
      "Row 18185 => Predicted: 1\n",
      "Row 18186 => Predicted: 1\n",
      "Row 18187 => Predicted: 1\n",
      "Row 18188 => Predicted: 0\n",
      "Row 18189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18180 to 18189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18190 => Predicted: 1\n",
      "Row 18191 => Predicted: 1\n",
      "Row 18192 => Predicted: 1\n",
      "Row 18193 => Predicted: 1\n",
      "Row 18194 => Predicted: 1\n",
      "Row 18195 => Predicted: 1\n",
      "Row 18196 => Predicted: 0\n",
      "Row 18197 => Predicted: 1\n",
      "Row 18198 => Predicted: 0\n",
      "Row 18199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18190 to 18199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18200 => Predicted: 1\n",
      "Row 18201 => Predicted: 0\n",
      "Row 18202 => Predicted: 0\n",
      "Row 18203 => Predicted: 0\n",
      "Row 18204 => Predicted: 1\n",
      "Row 18205 => Predicted: 0\n",
      "Row 18206 => Predicted: 1\n",
      "Row 18207 => Predicted: 1\n",
      "Row 18208 => Predicted: 1\n",
      "Row 18209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18200 to 18209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18210 => Predicted: 0\n",
      "Row 18211 => Predicted: 0\n",
      "Row 18212 => Predicted: 0\n",
      "Row 18213 => Predicted: 0\n",
      "Row 18214 => Predicted: 1\n",
      "Row 18215 => Predicted: 1\n",
      "Row 18216 => Predicted: 0\n",
      "Row 18217 => Predicted: 0\n",
      "Row 18218 => Predicted: 0\n",
      "Row 18219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18210 to 18219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18220 => Predicted: 1\n",
      "Row 18221 => Predicted: 0\n",
      "Row 18222 => Predicted: 0\n",
      "Row 18223 => Predicted: 1\n",
      "Row 18224 => Predicted: 1\n",
      "Row 18225 => Predicted: 0\n",
      "Row 18226 => Predicted: 0\n",
      "Row 18227 => Predicted: 0\n",
      "Row 18228 => Predicted: 0\n",
      "Row 18229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18220 to 18229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18230 => Predicted: 1\n",
      "Row 18231 => Predicted: 0\n",
      "Row 18232 => Predicted: 0\n",
      "Row 18233 => Predicted: 0\n",
      "Row 18234 => Predicted: 1\n",
      "Row 18235 => Predicted: 0\n",
      "Row 18236 => Predicted: 1\n",
      "Row 18237 => Predicted: 0\n",
      "Row 18238 => Predicted: 0\n",
      "Row 18239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18230 to 18239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18240 => Predicted: 1\n",
      "Row 18241 => Predicted: 1\n",
      "Row 18242 => Predicted: 0\n",
      "Row 18243 => Predicted: 0\n",
      "Row 18244 => Predicted: 1\n",
      "Row 18245 => Predicted: 0\n",
      "Row 18246 => Predicted: 0\n",
      "Row 18247 => Predicted: 1\n",
      "Row 18248 => Predicted: 1\n",
      "Row 18249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18240 to 18249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18250 => Predicted: 1\n",
      "Row 18251 => Predicted: 0\n",
      "Row 18252 => Predicted: 1\n",
      "Row 18253 => Predicted: 1\n",
      "Row 18254 => Predicted: 0\n",
      "Row 18255 => Predicted: 1\n",
      "Row 18256 => Predicted: 1\n",
      "Row 18257 => Predicted: 1\n",
      "Row 18258 => Predicted: 1\n",
      "Row 18259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18250 to 18259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18260 => Predicted: 0\n",
      "Row 18261 => Predicted: 1\n",
      "Row 18262 => Predicted: 1\n",
      "Row 18263 => Predicted: 0\n",
      "Row 18264 => Predicted: 0\n",
      "Row 18265 => Predicted: 0\n",
      "Row 18266 => Predicted: 1\n",
      "Row 18267 => Predicted: 0\n",
      "Row 18268 => Predicted: 1\n",
      "Row 18269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18260 to 18269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18270 => Predicted: 1\n",
      "Row 18271 => Predicted: 0\n",
      "Row 18272 => Predicted: 1\n",
      "Row 18273 => Predicted: 0\n",
      "Row 18274 => Predicted: 1\n",
      "Row 18275 => Predicted: 0\n",
      "Row 18276 => Predicted: 1\n",
      "Row 18277 => Predicted: 1\n",
      "Row 18278 => Predicted: 1\n",
      "Row 18279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18270 to 18279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18280 => Predicted: 0\n",
      "Row 18281 => Predicted: 0\n",
      "Row 18282 => Predicted: 0\n",
      "Row 18283 => Predicted: 1\n",
      "Row 18284 => Predicted: 0\n",
      "Row 18285 => Predicted: 0\n",
      "Row 18286 => Predicted: 1\n",
      "Row 18287 => Predicted: 0\n",
      "Row 18288 => Predicted: 0\n",
      "Row 18289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18280 to 18289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18290 => Predicted: 0\n",
      "Row 18291 => Predicted: 0\n",
      "Row 18292 => Predicted: 0\n",
      "Row 18293 => Predicted: 0\n",
      "Row 18294 => Predicted: 1\n",
      "Row 18295 => Predicted: 0\n",
      "Row 18296 => Predicted: 0\n",
      "Row 18297 => Predicted: 1\n",
      "Row 18298 => Predicted: 0\n",
      "Row 18299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18290 to 18299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18300 => Predicted: 0\n",
      "Row 18301 => Predicted: 1\n",
      "Row 18302 => Predicted: 1\n",
      "Row 18303 => Predicted: 0\n",
      "Row 18304 => Predicted: 0\n",
      "Row 18305 => Predicted: 1\n",
      "Row 18306 => Predicted: 0\n",
      "Row 18307 => Predicted: 0\n",
      "Row 18308 => Predicted: 1\n",
      "Row 18309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18300 to 18309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18310 => Predicted: 0\n",
      "Row 18311 => Predicted: 0\n",
      "Row 18312 => Predicted: 1\n",
      "Row 18313 => Predicted: 1\n",
      "Row 18314 => Predicted: 0\n",
      "Row 18315 => Predicted: 1\n",
      "Row 18316 => Predicted: 1\n",
      "Row 18317 => Predicted: 0\n",
      "Row 18318 => Predicted: 0\n",
      "Row 18319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18310 to 18319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18320 => Predicted: 1\n",
      "Row 18321 => Predicted: 1\n",
      "Row 18322 => Predicted: 0\n",
      "Row 18323 => Predicted: 0\n",
      "Row 18324 => Predicted: 1\n",
      "Row 18325 => Predicted: 0\n",
      "Row 18326 => Predicted: 1\n",
      "Row 18327 => Predicted: 0\n",
      "Row 18328 => Predicted: 1\n",
      "Row 18329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18320 to 18329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18330 => Predicted: 1\n",
      "Row 18331 => Predicted: 0\n",
      "Row 18332 => Predicted: 1\n",
      "Row 18333 => Predicted: 0\n",
      "Row 18334 => Predicted: 0\n",
      "Row 18335 => Predicted: 1\n",
      "Row 18336 => Predicted: 1\n",
      "Row 18337 => Predicted: 1\n",
      "Row 18338 => Predicted: 0\n",
      "Row 18339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18330 to 18339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18340 => Predicted: 0\n",
      "Row 18341 => Predicted: 1\n",
      "Row 18342 => Predicted: 0\n",
      "Row 18343 => Predicted: 1\n",
      "Row 18344 => Predicted: 1\n",
      "Row 18345 => Predicted: 0\n",
      "Row 18346 => Predicted: 1\n",
      "Row 18347 => Predicted: 0\n",
      "Row 18348 => Predicted: 1\n",
      "Row 18349 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18340 to 18349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18350 => Predicted: 1\n",
      "Row 18351 => Predicted: 0\n",
      "Row 18352 => Predicted: 1\n",
      "Row 18353 => Predicted: 1\n",
      "Row 18354 => Predicted: 0\n",
      "Row 18355 => Predicted: 1\n",
      "Row 18356 => Predicted: 1\n",
      "Row 18357 => Predicted: 0\n",
      "Row 18358 => Predicted: 0\n",
      "Row 18359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18350 to 18359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18360 => Predicted: 1\n",
      "Row 18361 => Predicted: 0\n",
      "Row 18362 => Predicted: 0\n",
      "Row 18363 => Predicted: 0\n",
      "Row 18364 => Predicted: 1\n",
      "Row 18365 => Predicted: 1\n",
      "Row 18366 => Predicted: 1\n",
      "Row 18367 => Predicted: 1\n",
      "Row 18368 => Predicted: 0\n",
      "Row 18369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18360 to 18369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18370 => Predicted: 1\n",
      "Row 18371 => Predicted: 0\n",
      "Row 18372 => Predicted: 0\n",
      "Row 18373 => Predicted: 0\n",
      "Row 18374 => Predicted: 0\n",
      "Row 18375 => Predicted: 1\n",
      "Row 18376 => Predicted: 0\n",
      "Row 18377 => Predicted: 1\n",
      "Row 18378 => Predicted: 1\n",
      "Row 18379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18370 to 18379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18380 => Predicted: 0\n",
      "Row 18381 => Predicted: 0\n",
      "Row 18382 => Predicted: 0\n",
      "Row 18383 => Predicted: 1\n",
      "Row 18384 => Predicted: 1\n",
      "Row 18385 => Predicted: 1\n",
      "Row 18386 => Predicted: 1\n",
      "Row 18387 => Predicted: 0\n",
      "Row 18388 => Predicted: 0\n",
      "Row 18389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18380 to 18389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18390 => Predicted: 1\n",
      "Row 18391 => Predicted: 1\n",
      "Row 18392 => Predicted: 0\n",
      "Row 18393 => Predicted: 0\n",
      "Row 18394 => Predicted: 1\n",
      "Row 18395 => Predicted: 0\n",
      "Row 18396 => Predicted: 1\n",
      "Row 18397 => Predicted: 0\n",
      "Row 18398 => Predicted: 0\n",
      "Row 18399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18390 to 18399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18400 => Predicted: 0\n",
      "Row 18401 => Predicted: 0\n",
      "Row 18402 => Predicted: 0\n",
      "Row 18403 => Predicted: 0\n",
      "Row 18404 => Predicted: 0\n",
      "Row 18405 => Predicted: 1\n",
      "Row 18406 => Predicted: 0\n",
      "Row 18407 => Predicted: 1\n",
      "Row 18408 => Predicted: 0\n",
      "Row 18409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18400 to 18409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18410 => Predicted: 1\n",
      "Row 18411 => Predicted: 0\n",
      "Row 18412 => Predicted: 1\n",
      "Row 18413 => Predicted: 0\n",
      "Row 18414 => Predicted: 1\n",
      "Row 18415 => Predicted: 0\n",
      "Row 18416 => Predicted: 1\n",
      "Row 18417 => Predicted: 1\n",
      "Row 18418 => Predicted: 0\n",
      "Row 18419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18410 to 18419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18420 => Predicted: 0\n",
      "Row 18421 => Predicted: 0\n",
      "Row 18422 => Predicted: 1\n",
      "Row 18423 => Predicted: 0\n",
      "Row 18424 => Predicted: 1\n",
      "Row 18425 => Predicted: 1\n",
      "Row 18426 => Predicted: 1\n",
      "Row 18427 => Predicted: 0\n",
      "Row 18428 => Predicted: 1\n",
      "Row 18429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18420 to 18429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18430 => Predicted: 0\n",
      "Row 18431 => Predicted: 0\n",
      "Row 18432 => Predicted: 0\n",
      "Row 18433 => Predicted: 0\n",
      "Row 18434 => Predicted: 0\n",
      "Row 18435 => Predicted: 1\n",
      "Row 18436 => Predicted: 1\n",
      "Row 18437 => Predicted: 1\n",
      "Row 18438 => Predicted: 1\n",
      "Row 18439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18430 to 18439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18440 => Predicted: 1\n",
      "Row 18441 => Predicted: 1\n",
      "Row 18442 => Predicted: 1\n",
      "Row 18443 => Predicted: 0\n",
      "Row 18444 => Predicted: 1\n",
      "Row 18445 => Predicted: 0\n",
      "Row 18446 => Predicted: 1\n",
      "Row 18447 => Predicted: 1\n",
      "Row 18448 => Predicted: 1\n",
      "Row 18449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18440 to 18449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18450 => Predicted: 0\n",
      "Row 18451 => Predicted: 1\n",
      "Row 18452 => Predicted: 0\n",
      "Row 18453 => Predicted: 1\n",
      "Row 18454 => Predicted: 1\n",
      "Row 18455 => Predicted: 0\n",
      "Row 18456 => Predicted: 0\n",
      "Row 18457 => Predicted: 1\n",
      "Row 18458 => Predicted: 0\n",
      "Row 18459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18450 to 18459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18460 => Predicted: 0\n",
      "Row 18461 => Predicted: 1\n",
      "Row 18462 => Predicted: 1\n",
      "Row 18463 => Predicted: 1\n",
      "Row 18464 => Predicted: 0\n",
      "Row 18465 => Predicted: 1\n",
      "Row 18466 => Predicted: 0\n",
      "Row 18467 => Predicted: 1\n",
      "Row 18468 => Predicted: 1\n",
      "Row 18469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18460 to 18469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18470 => Predicted: 1\n",
      "Row 18471 => Predicted: 0\n",
      "Row 18472 => Predicted: 0\n",
      "Row 18473 => Predicted: 0\n",
      "Row 18474 => Predicted: 0\n",
      "Row 18475 => Predicted: 0\n",
      "Row 18476 => Predicted: 1\n",
      "Row 18477 => Predicted: 0\n",
      "Row 18478 => Predicted: 1\n",
      "Row 18479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18470 to 18479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18480 => Predicted: 0\n",
      "Row 18481 => Predicted: 0\n",
      "Row 18482 => Predicted: 1\n",
      "Row 18483 => Predicted: 1\n",
      "Row 18484 => Predicted: 0\n",
      "Row 18485 => Predicted: 1\n",
      "Row 18486 => Predicted: 0\n",
      "Row 18487 => Predicted: 0\n",
      "Row 18488 => Predicted: 1\n",
      "Row 18489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18480 to 18489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18490 => Predicted: 0\n",
      "Row 18491 => Predicted: 0\n",
      "Row 18492 => Predicted: 0\n",
      "Row 18493 => Predicted: 0\n",
      "Row 18494 => Predicted: 1\n",
      "Row 18495 => Predicted: 1\n",
      "Row 18496 => Predicted: 0\n",
      "Row 18497 => Predicted: 0\n",
      "Row 18498 => Predicted: 0\n",
      "Row 18499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18490 to 18499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18500 => Predicted: 0\n",
      "Row 18501 => Predicted: 1\n",
      "Row 18502 => Predicted: 1\n",
      "Row 18503 => Predicted: 1\n",
      "Row 18504 => Predicted: 1\n",
      "Row 18505 => Predicted: 0\n",
      "Row 18506 => Predicted: 1\n",
      "Row 18507 => Predicted: 1\n",
      "Row 18508 => Predicted: 1\n",
      "Row 18509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18500 to 18509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18510 => Predicted: 1\n",
      "Row 18511 => Predicted: 1\n",
      "Row 18512 => Predicted: 1\n",
      "Row 18513 => Predicted: 1\n",
      "Row 18514 => Predicted: 1\n",
      "Row 18515 => Predicted: 1\n",
      "Row 18516 => Predicted: 1\n",
      "Row 18517 => Predicted: 1\n",
      "Row 18518 => Predicted: 0\n",
      "Row 18519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18510 to 18519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18520 => Predicted: 1\n",
      "Row 18521 => Predicted: 1\n",
      "Row 18522 => Predicted: 1\n",
      "Row 18523 => Predicted: 1\n",
      "Row 18524 => Predicted: 1\n",
      "Row 18525 => Predicted: 0\n",
      "Row 18526 => Predicted: 1\n",
      "Row 18527 => Predicted: 1\n",
      "Row 18528 => Predicted: 0\n",
      "Row 18529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18520 to 18529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18530 => Predicted: 0\n",
      "Row 18531 => Predicted: 1\n",
      "Row 18532 => Predicted: 0\n",
      "Row 18533 => Predicted: 0\n",
      "Row 18534 => Predicted: 0\n",
      "Row 18535 => Predicted: 0\n",
      "Row 18536 => Predicted: 0\n",
      "Row 18537 => Predicted: 1\n",
      "Row 18538 => Predicted: 1\n",
      "Row 18539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18530 to 18539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18540 => Predicted: 0\n",
      "Row 18541 => Predicted: 1\n",
      "Row 18542 => Predicted: 1\n",
      "Row 18543 => Predicted: 0\n",
      "Row 18544 => Predicted: 1\n",
      "Row 18545 => Predicted: 1\n",
      "Row 18546 => Predicted: 1\n",
      "Row 18547 => Predicted: 1\n",
      "Row 18548 => Predicted: 1\n",
      "Row 18549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18540 to 18549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18550 => Predicted: 0\n",
      "Row 18551 => Predicted: 0\n",
      "Row 18552 => Predicted: 1\n",
      "Row 18553 => Predicted: 0\n",
      "Row 18554 => Predicted: 0\n",
      "Row 18555 => Predicted: 1\n",
      "Row 18556 => Predicted: 0\n",
      "Row 18557 => Predicted: 1\n",
      "Row 18558 => Predicted: 1\n",
      "Row 18559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18550 to 18559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18560 => Predicted: 1\n",
      "Row 18561 => Predicted: 0\n",
      "Row 18562 => Predicted: 0\n",
      "Row 18563 => Predicted: 0\n",
      "Row 18564 => Predicted: 1\n",
      "Row 18565 => Predicted: 1\n",
      "Row 18566 => Predicted: 1\n",
      "Row 18567 => Predicted: 1\n",
      "Row 18568 => Predicted: 0\n",
      "Row 18569 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18560 to 18569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18570 => Predicted: 1\n",
      "Row 18571 => Predicted: 0\n",
      "Row 18572 => Predicted: 1\n",
      "Row 18573 => Predicted: 0\n",
      "Row 18574 => Predicted: 0\n",
      "Row 18575 => Predicted: 0\n",
      "Row 18576 => Predicted: 0\n",
      "Row 18577 => Predicted: 1\n",
      "Row 18578 => Predicted: 0\n",
      "Row 18579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18570 to 18579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18580 => Predicted: 1\n",
      "Row 18581 => Predicted: 1\n",
      "Row 18582 => Predicted: 1\n",
      "Row 18583 => Predicted: 0\n",
      "Row 18584 => Predicted: 0\n",
      "Row 18585 => Predicted: 1\n",
      "Row 18586 => Predicted: 1\n",
      "Row 18587 => Predicted: 1\n",
      "Row 18588 => Predicted: 1\n",
      "Row 18589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18580 to 18589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18590 => Predicted: 0\n",
      "Row 18591 => Predicted: 1\n",
      "Row 18592 => Predicted: 1\n",
      "Row 18593 => Predicted: 1\n",
      "Row 18594 => Predicted: 1\n",
      "Row 18595 => Predicted: 0\n",
      "Row 18596 => Predicted: 1\n",
      "Row 18597 => Predicted: 1\n",
      "Row 18598 => Predicted: 1\n",
      "Row 18599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18590 to 18599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18600 => Predicted: 0\n",
      "Row 18601 => Predicted: 0\n",
      "Row 18602 => Predicted: 0\n",
      "Row 18603 => Predicted: 1\n",
      "Row 18604 => Predicted: 1\n",
      "Row 18605 => Predicted: 1\n",
      "Row 18606 => Predicted: 0\n",
      "Row 18607 => Predicted: 1\n",
      "Row 18608 => Predicted: 0\n",
      "Row 18609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18600 to 18609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18610 => Predicted: 1\n",
      "Row 18611 => Predicted: 0\n",
      "Row 18612 => Predicted: 0\n",
      "Row 18613 => Predicted: 0\n",
      "Row 18614 => Predicted: 1\n",
      "Row 18615 => Predicted: 0\n",
      "Row 18616 => Predicted: 0\n",
      "Row 18617 => Predicted: 0\n",
      "Row 18618 => Predicted: 1\n",
      "Row 18619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18610 to 18619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18620 => Predicted: 0\n",
      "Row 18621 => Predicted: 0\n",
      "Row 18622 => Predicted: 0\n",
      "Row 18623 => Predicted: 0\n",
      "Row 18624 => Predicted: 1\n",
      "Row 18625 => Predicted: 0\n",
      "Row 18626 => Predicted: 1\n",
      "Row 18627 => Predicted: 0\n",
      "Row 18628 => Predicted: 0\n",
      "Row 18629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18620 to 18629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18630 => Predicted: 1\n",
      "Row 18631 => Predicted: 1\n",
      "Row 18632 => Predicted: 0\n",
      "Row 18633 => Predicted: 0\n",
      "Row 18634 => Predicted: 0\n",
      "Row 18635 => Predicted: 0\n",
      "Row 18636 => Predicted: 1\n",
      "Row 18637 => Predicted: 1\n",
      "Row 18638 => Predicted: 1\n",
      "Row 18639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18630 to 18639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18640 => Predicted: 0\n",
      "Row 18641 => Predicted: 1\n",
      "Row 18642 => Predicted: 0\n",
      "Row 18643 => Predicted: 0\n",
      "Row 18644 => Predicted: 0\n",
      "Row 18645 => Predicted: 0\n",
      "Row 18646 => Predicted: 0\n",
      "Row 18647 => Predicted: 0\n",
      "Row 18648 => Predicted: 0\n",
      "Row 18649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18640 to 18649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18650 => Predicted: 1\n",
      "Row 18651 => Predicted: 1\n",
      "Row 18652 => Predicted: 0\n",
      "Row 18653 => Predicted: 0\n",
      "Row 18654 => Predicted: 1\n",
      "Row 18655 => Predicted: 1\n",
      "Row 18656 => Predicted: 0\n",
      "Row 18657 => Predicted: 1\n",
      "Row 18658 => Predicted: 0\n",
      "Row 18659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18650 to 18659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18660 => Predicted: 0\n",
      "Row 18661 => Predicted: 1\n",
      "Row 18662 => Predicted: 0\n",
      "Row 18663 => Predicted: 0\n",
      "Row 18664 => Predicted: 0\n",
      "Row 18665 => Predicted: 1\n",
      "Row 18666 => Predicted: 1\n",
      "Row 18667 => Predicted: 0\n",
      "Row 18668 => Predicted: 1\n",
      "Row 18669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18660 to 18669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18670 => Predicted: 1\n",
      "Row 18671 => Predicted: 1\n",
      "Row 18672 => Predicted: 1\n",
      "Row 18673 => Predicted: 1\n",
      "Row 18674 => Predicted: 1\n",
      "Row 18675 => Predicted: 1\n",
      "Row 18676 => Predicted: 0\n",
      "Row 18677 => Predicted: 0\n",
      "Row 18678 => Predicted: 0\n",
      "Row 18679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18670 to 18679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18680 => Predicted: 1\n",
      "Row 18681 => Predicted: 1\n",
      "Row 18682 => Predicted: 1\n",
      "Row 18683 => Predicted: 0\n",
      "Row 18684 => Predicted: 1\n",
      "Row 18685 => Predicted: 0\n",
      "Row 18686 => Predicted: 0\n",
      "Row 18687 => Predicted: 0\n",
      "Row 18688 => Predicted: 1\n",
      "Row 18689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18680 to 18689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18690 => Predicted: 1\n",
      "Row 18691 => Predicted: 0\n",
      "Row 18692 => Predicted: 0\n",
      "Row 18693 => Predicted: 0\n",
      "Row 18694 => Predicted: 0\n",
      "Row 18695 => Predicted: 1\n",
      "Row 18696 => Predicted: 1\n",
      "Row 18697 => Predicted: 0\n",
      "Row 18698 => Predicted: 0\n",
      "Row 18699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18690 to 18699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18700 => Predicted: 1\n",
      "Row 18701 => Predicted: 0\n",
      "Row 18702 => Predicted: 0\n",
      "Row 18703 => Predicted: 1\n",
      "Row 18704 => Predicted: 1\n",
      "Row 18705 => Predicted: 1\n",
      "Row 18706 => Predicted: 1\n",
      "Row 18707 => Predicted: 1\n",
      "Row 18708 => Predicted: 0\n",
      "Row 18709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18700 to 18709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18710 => Predicted: 0\n",
      "Row 18711 => Predicted: 1\n",
      "Row 18712 => Predicted: 0\n",
      "Row 18713 => Predicted: 0\n",
      "Row 18714 => Predicted: 0\n",
      "Row 18715 => Predicted: 0\n",
      "Row 18716 => Predicted: 0\n",
      "Row 18717 => Predicted: 0\n",
      "Row 18718 => Predicted: 0\n",
      "Row 18719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18710 to 18719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18720 => Predicted: 0\n",
      "Row 18721 => Predicted: 0\n",
      "Row 18722 => Predicted: 0\n",
      "Row 18723 => Predicted: 1\n",
      "Row 18724 => Predicted: 1\n",
      "Row 18725 => Predicted: 1\n",
      "Row 18726 => Predicted: 1\n",
      "Row 18727 => Predicted: 0\n",
      "Row 18728 => Predicted: 1\n",
      "Row 18729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18720 to 18729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18730 => Predicted: 0\n",
      "Row 18731 => Predicted: 0\n",
      "Row 18732 => Predicted: 1\n",
      "Row 18733 => Predicted: 0\n",
      "Row 18734 => Predicted: 0\n",
      "Row 18735 => Predicted: 1\n",
      "Row 18736 => Predicted: 0\n",
      "Row 18737 => Predicted: 0\n",
      "Row 18738 => Predicted: 0\n",
      "Row 18739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18730 to 18739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18740 => Predicted: 1\n",
      "Row 18741 => Predicted: 0\n",
      "Row 18742 => Predicted: 1\n",
      "Row 18743 => Predicted: 1\n",
      "Row 18744 => Predicted: 0\n",
      "Row 18745 => Predicted: 1\n",
      "Row 18746 => Predicted: 1\n",
      "Row 18747 => Predicted: 1\n",
      "Row 18748 => Predicted: 1\n",
      "Row 18749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18740 to 18749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18750 => Predicted: 0\n",
      "Row 18751 => Predicted: 1\n",
      "Row 18752 => Predicted: 0\n",
      "Row 18753 => Predicted: 0\n",
      "Row 18754 => Predicted: 0\n",
      "Row 18755 => Predicted: 1\n",
      "Row 18756 => Predicted: 0\n",
      "Row 18757 => Predicted: 0\n",
      "Row 18758 => Predicted: 1\n",
      "Row 18759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18750 to 18759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18760 => Predicted: 1\n",
      "Row 18761 => Predicted: 1\n",
      "Row 18762 => Predicted: 0\n",
      "Row 18763 => Predicted: 1\n",
      "Row 18764 => Predicted: 1\n",
      "Row 18765 => Predicted: 0\n",
      "Row 18766 => Predicted: 0\n",
      "Row 18767 => Predicted: 1\n",
      "Row 18768 => Predicted: 0\n",
      "Row 18769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18760 to 18769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18770 => Predicted: 1\n",
      "Row 18771 => Predicted: 1\n",
      "Row 18772 => Predicted: 0\n",
      "Row 18773 => Predicted: 1\n",
      "Row 18774 => Predicted: 0\n",
      "Row 18775 => Predicted: 1\n",
      "Row 18776 => Predicted: 1\n",
      "Row 18777 => Predicted: 0\n",
      "Row 18778 => Predicted: 0\n",
      "Row 18779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18770 to 18779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18780 => Predicted: 1\n",
      "Row 18781 => Predicted: 1\n",
      "Row 18782 => Predicted: 0\n",
      "Row 18783 => Predicted: 1\n",
      "Row 18784 => Predicted: 1\n",
      "Row 18785 => Predicted: 1\n",
      "Row 18786 => Predicted: 0\n",
      "Row 18787 => Predicted: 1\n",
      "Row 18788 => Predicted: 1\n",
      "Row 18789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18780 to 18789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18790 => Predicted: 1\n",
      "Row 18791 => Predicted: 0\n",
      "Row 18792 => Predicted: 1\n",
      "Row 18793 => Predicted: 0\n",
      "Row 18794 => Predicted: 1\n",
      "Row 18795 => Predicted: 1\n",
      "Row 18796 => Predicted: 0\n",
      "Row 18797 => Predicted: 1\n",
      "Row 18798 => Predicted: 0\n",
      "Row 18799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18790 to 18799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18800 => Predicted: 0\n",
      "Row 18801 => Predicted: 1\n",
      "Row 18802 => Predicted: 1\n",
      "Row 18803 => Predicted: 0\n",
      "Row 18804 => Predicted: 0\n",
      "Row 18805 => Predicted: 1\n",
      "Row 18806 => Predicted: 0\n",
      "Row 18807 => Predicted: 1\n",
      "Row 18808 => Predicted: 1\n",
      "Row 18809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18800 to 18809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18810 => Predicted: 0\n",
      "Row 18811 => Predicted: 0\n",
      "Row 18812 => Predicted: 0\n",
      "Row 18813 => Predicted: 0\n",
      "Row 18814 => Predicted: 1\n",
      "Row 18815 => Predicted: 0\n",
      "Row 18816 => Predicted: 1\n",
      "Row 18817 => Predicted: 1\n",
      "Row 18818 => Predicted: 1\n",
      "Row 18819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18810 to 18819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18820 => Predicted: 0\n",
      "Row 18821 => Predicted: 1\n",
      "Row 18822 => Predicted: 1\n",
      "Row 18823 => Predicted: 1\n",
      "Row 18824 => Predicted: 0\n",
      "Row 18825 => Predicted: 0\n",
      "Row 18826 => Predicted: 0\n",
      "Row 18827 => Predicted: 0\n",
      "Row 18828 => Predicted: 1\n",
      "Row 18829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18820 to 18829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18830 => Predicted: 0\n",
      "Row 18831 => Predicted: 0\n",
      "Row 18832 => Predicted: 0\n",
      "Row 18833 => Predicted: 1\n",
      "Row 18834 => Predicted: 0\n",
      "Row 18835 => Predicted: 0\n",
      "Row 18836 => Predicted: 1\n",
      "Row 18837 => Predicted: 1\n",
      "Row 18838 => Predicted: 1\n",
      "Row 18839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18830 to 18839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18840 => Predicted: 0\n",
      "Row 18841 => Predicted: 1\n",
      "Row 18842 => Predicted: 0\n",
      "Row 18843 => Predicted: 1\n",
      "Row 18844 => Predicted: 1\n",
      "Row 18845 => Predicted: 1\n",
      "Row 18846 => Predicted: 1\n",
      "Row 18847 => Predicted: 0\n",
      "Row 18848 => Predicted: 1\n",
      "Row 18849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18840 to 18849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18850 => Predicted: 1\n",
      "Row 18851 => Predicted: 0\n",
      "Row 18852 => Predicted: 0\n",
      "Row 18853 => Predicted: 1\n",
      "Row 18854 => Predicted: 1\n",
      "Row 18855 => Predicted: 0\n",
      "Row 18856 => Predicted: 0\n",
      "Row 18857 => Predicted: 0\n",
      "Row 18858 => Predicted: 0\n",
      "Row 18859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18850 to 18859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18860 => Predicted: 0\n",
      "Row 18861 => Predicted: 1\n",
      "Row 18862 => Predicted: 0\n",
      "Row 18863 => Predicted: 0\n",
      "Row 18864 => Predicted: 0\n",
      "Row 18865 => Predicted: 1\n",
      "Row 18866 => Predicted: 1\n",
      "Row 18867 => Predicted: 1\n",
      "Row 18868 => Predicted: 0\n",
      "Row 18869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18860 to 18869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18870 => Predicted: 1\n",
      "Row 18871 => Predicted: 0\n",
      "Row 18872 => Predicted: 0\n",
      "Row 18873 => Predicted: 0\n",
      "Row 18874 => Predicted: 1\n",
      "Row 18875 => Predicted: 0\n",
      "Row 18876 => Predicted: 1\n",
      "Row 18877 => Predicted: 1\n",
      "Row 18878 => Predicted: 1\n",
      "Row 18879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18870 to 18879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18880 => Predicted: 1\n",
      "Row 18881 => Predicted: 0\n",
      "Row 18882 => Predicted: 1\n",
      "Row 18883 => Predicted: 0\n",
      "Row 18884 => Predicted: 1\n",
      "Row 18885 => Predicted: 1\n",
      "Row 18886 => Predicted: 1\n",
      "Row 18887 => Predicted: 0\n",
      "Row 18888 => Predicted: 0\n",
      "Row 18889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18880 to 18889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18890 => Predicted: 0\n",
      "Row 18891 => Predicted: 0\n",
      "Row 18892 => Predicted: 1\n",
      "Row 18893 => Predicted: 0\n",
      "Row 18894 => Predicted: 0\n",
      "Row 18895 => Predicted: 0\n",
      "Row 18896 => Predicted: 0\n",
      "Row 18897 => Predicted: 1\n",
      "Row 18898 => Predicted: 1\n",
      "Row 18899 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18890 to 18899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18900 => Predicted: 1\n",
      "Row 18901 => Predicted: 1\n",
      "Row 18902 => Predicted: 0\n",
      "Row 18903 => Predicted: 1\n",
      "Row 18904 => Predicted: 0\n",
      "Row 18905 => Predicted: 1\n",
      "Row 18906 => Predicted: 1\n",
      "Row 18907 => Predicted: 0\n",
      "Row 18908 => Predicted: 0\n",
      "Row 18909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18900 to 18909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18910 => Predicted: 1\n",
      "Row 18911 => Predicted: 1\n",
      "Row 18912 => Predicted: 0\n",
      "Row 18913 => Predicted: 0\n",
      "Row 18914 => Predicted: 1\n",
      "Row 18915 => Predicted: 0\n",
      "Row 18916 => Predicted: 1\n",
      "Row 18917 => Predicted: 0\n",
      "Row 18918 => Predicted: 0\n",
      "Row 18919 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18910 to 18919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18920 => Predicted: 1\n",
      "Row 18921 => Predicted: 1\n",
      "Row 18922 => Predicted: 1\n",
      "Row 18923 => Predicted: 1\n",
      "Row 18924 => Predicted: 1\n",
      "Row 18925 => Predicted: 1\n",
      "Row 18926 => Predicted: 0\n",
      "Row 18927 => Predicted: 1\n",
      "Row 18928 => Predicted: 0\n",
      "Row 18929 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18920 to 18929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18930 => Predicted: 0\n",
      "Row 18931 => Predicted: 1\n",
      "Row 18932 => Predicted: 1\n",
      "Row 18933 => Predicted: 1\n",
      "Row 18934 => Predicted: 0\n",
      "Row 18935 => Predicted: 0\n",
      "Row 18936 => Predicted: 0\n",
      "Row 18937 => Predicted: 0\n",
      "Row 18938 => Predicted: 0\n",
      "Row 18939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18930 to 18939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18940 => Predicted: 0\n",
      "Row 18941 => Predicted: 1\n",
      "Row 18942 => Predicted: 0\n",
      "Row 18943 => Predicted: 1\n",
      "Row 18944 => Predicted: 0\n",
      "Row 18945 => Predicted: 0\n",
      "Row 18946 => Predicted: 0\n",
      "Row 18947 => Predicted: 1\n",
      "Row 18948 => Predicted: 1\n",
      "Row 18949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18940 to 18949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18950 => Predicted: 1\n",
      "Row 18951 => Predicted: 0\n",
      "Row 18952 => Predicted: 0\n",
      "Row 18953 => Predicted: 1\n",
      "Row 18954 => Predicted: 1\n",
      "Row 18955 => Predicted: 1\n",
      "Row 18956 => Predicted: 1\n",
      "Row 18957 => Predicted: 1\n",
      "Row 18958 => Predicted: 0\n",
      "Row 18959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18950 to 18959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18960 => Predicted: 1\n",
      "Row 18961 => Predicted: 1\n",
      "Row 18962 => Predicted: 0\n",
      "Row 18963 => Predicted: 1\n",
      "Row 18964 => Predicted: 1\n",
      "Row 18965 => Predicted: 0\n",
      "Row 18966 => Predicted: 1\n",
      "Row 18967 => Predicted: 0\n",
      "Row 18968 => Predicted: 1\n",
      "Row 18969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18960 to 18969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18970 => Predicted: 0\n",
      "Row 18971 => Predicted: 0\n",
      "Row 18972 => Predicted: 0\n",
      "Row 18973 => Predicted: 1\n",
      "Row 18974 => Predicted: 0\n",
      "Row 18975 => Predicted: 0\n",
      "Row 18976 => Predicted: 0\n",
      "Row 18977 => Predicted: 0\n",
      "Row 18978 => Predicted: 1\n",
      "Row 18979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 18970 to 18979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18980 => Predicted: 0\n",
      "Row 18981 => Predicted: 1\n",
      "Row 18982 => Predicted: 1\n",
      "Row 18983 => Predicted: 1\n",
      "Row 18984 => Predicted: 0\n",
      "Row 18985 => Predicted: 1\n",
      "Row 18986 => Predicted: 1\n",
      "Row 18987 => Predicted: 1\n",
      "Row 18988 => Predicted: 1\n",
      "Row 18989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18980 to 18989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18990 => Predicted: 1\n",
      "Row 18991 => Predicted: 1\n",
      "Row 18992 => Predicted: 0\n",
      "Row 18993 => Predicted: 1\n",
      "Row 18994 => Predicted: 0\n",
      "Row 18995 => Predicted: 1\n",
      "Row 18996 => Predicted: 1\n",
      "Row 18997 => Predicted: 0\n",
      "Row 18998 => Predicted: 1\n",
      "Row 18999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 18990 to 18999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19000 => Predicted: 0\n",
      "Row 19001 => Predicted: 1\n",
      "Row 19002 => Predicted: 0\n",
      "Row 19003 => Predicted: 0\n",
      "Row 19004 => Predicted: 0\n",
      "Row 19005 => Predicted: 0\n",
      "Row 19006 => Predicted: 0\n",
      "Row 19007 => Predicted: 1\n",
      "Row 19008 => Predicted: 1\n",
      "Row 19009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19000 to 19009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19010 => Predicted: 1\n",
      "Row 19011 => Predicted: 1\n",
      "Row 19012 => Predicted: 1\n",
      "Row 19013 => Predicted: 0\n",
      "Row 19014 => Predicted: 0\n",
      "Row 19015 => Predicted: 1\n",
      "Row 19016 => Predicted: 1\n",
      "Row 19017 => Predicted: 1\n",
      "Row 19018 => Predicted: 1\n",
      "Row 19019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19010 to 19019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19020 => Predicted: 1\n",
      "Row 19021 => Predicted: 0\n",
      "Row 19022 => Predicted: 0\n",
      "Row 19023 => Predicted: 1\n",
      "Row 19024 => Predicted: 0\n",
      "Row 19025 => Predicted: 0\n",
      "Row 19026 => Predicted: 0\n",
      "Row 19027 => Predicted: 1\n",
      "Row 19028 => Predicted: 1\n",
      "Row 19029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19020 to 19029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19030 => Predicted: 0\n",
      "Row 19031 => Predicted: 1\n",
      "Row 19032 => Predicted: 1\n",
      "Row 19033 => Predicted: 0\n",
      "Row 19034 => Predicted: 0\n",
      "Row 19035 => Predicted: 1\n",
      "Row 19036 => Predicted: 0\n",
      "Row 19037 => Predicted: 1\n",
      "Row 19038 => Predicted: 1\n",
      "Row 19039 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19030 to 19039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19040 => Predicted: 0\n",
      "Row 19041 => Predicted: 0\n",
      "Row 19042 => Predicted: 1\n",
      "Row 19043 => Predicted: 1\n",
      "Row 19044 => Predicted: 1\n",
      "Row 19045 => Predicted: 1\n",
      "Row 19046 => Predicted: 1\n",
      "Row 19047 => Predicted: 0\n",
      "Row 19048 => Predicted: 0\n",
      "Row 19049 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19040 to 19049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19050 => Predicted: 0\n",
      "Row 19051 => Predicted: 0\n",
      "Row 19052 => Predicted: 0\n",
      "Row 19053 => Predicted: 1\n",
      "Row 19054 => Predicted: 0\n",
      "Row 19055 => Predicted: 0\n",
      "Row 19056 => Predicted: 1\n",
      "Row 19057 => Predicted: 1\n",
      "Row 19058 => Predicted: 1\n",
      "Row 19059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19050 to 19059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19060 => Predicted: 0\n",
      "Row 19061 => Predicted: 0\n",
      "Row 19062 => Predicted: 0\n",
      "Row 19063 => Predicted: 0\n",
      "Row 19064 => Predicted: 0\n",
      "Row 19065 => Predicted: 0\n",
      "Row 19066 => Predicted: 1\n",
      "Row 19067 => Predicted: 1\n",
      "Row 19068 => Predicted: 0\n",
      "Row 19069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19060 to 19069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19070 => Predicted: 0\n",
      "Row 19071 => Predicted: 1\n",
      "Row 19072 => Predicted: 0\n",
      "Row 19073 => Predicted: 0\n",
      "Row 19074 => Predicted: 0\n",
      "Row 19075 => Predicted: 1\n",
      "Row 19076 => Predicted: 1\n",
      "Row 19077 => Predicted: 0\n",
      "Row 19078 => Predicted: 0\n",
      "Row 19079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19070 to 19079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19080 => Predicted: 0\n",
      "Row 19081 => Predicted: 1\n",
      "Row 19082 => Predicted: 1\n",
      "Row 19083 => Predicted: 1\n",
      "Row 19084 => Predicted: 1\n",
      "Row 19085 => Predicted: 1\n",
      "Row 19086 => Predicted: 0\n",
      "Row 19087 => Predicted: 0\n",
      "Row 19088 => Predicted: 0\n",
      "Row 19089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19080 to 19089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19090 => Predicted: 1\n",
      "Row 19091 => Predicted: 0\n",
      "Row 19092 => Predicted: 1\n",
      "Row 19093 => Predicted: 0\n",
      "Row 19094 => Predicted: 1\n",
      "Row 19095 => Predicted: 0\n",
      "Row 19096 => Predicted: 1\n",
      "Row 19097 => Predicted: 0\n",
      "Row 19098 => Predicted: 0\n",
      "Row 19099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19090 to 19099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19100 => Predicted: 0\n",
      "Row 19101 => Predicted: 0\n",
      "Row 19102 => Predicted: 0\n",
      "Row 19103 => Predicted: 1\n",
      "Row 19104 => Predicted: 0\n",
      "Row 19105 => Predicted: 1\n",
      "Row 19106 => Predicted: 0\n",
      "Row 19107 => Predicted: 1\n",
      "Row 19108 => Predicted: 1\n",
      "Row 19109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19100 to 19109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19110 => Predicted: 0\n",
      "Row 19111 => Predicted: 1\n",
      "Row 19112 => Predicted: 1\n",
      "Row 19113 => Predicted: 0\n",
      "Row 19114 => Predicted: 0\n",
      "Row 19115 => Predicted: 1\n",
      "Row 19116 => Predicted: 1\n",
      "Row 19117 => Predicted: 0\n",
      "Row 19118 => Predicted: 0\n",
      "Row 19119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19110 to 19119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19120 => Predicted: 1\n",
      "Row 19121 => Predicted: 1\n",
      "Row 19122 => Predicted: 1\n",
      "Row 19123 => Predicted: 0\n",
      "Row 19124 => Predicted: 1\n",
      "Row 19125 => Predicted: 1\n",
      "Row 19126 => Predicted: 1\n",
      "Row 19127 => Predicted: 0\n",
      "Row 19128 => Predicted: 1\n",
      "Row 19129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19120 to 19129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19130 => Predicted: 0\n",
      "Row 19131 => Predicted: 1\n",
      "Row 19132 => Predicted: 0\n",
      "Row 19133 => Predicted: 1\n",
      "Row 19134 => Predicted: 0\n",
      "Row 19135 => Predicted: 1\n",
      "Row 19136 => Predicted: 1\n",
      "Row 19137 => Predicted: 1\n",
      "Row 19138 => Predicted: 1\n",
      "Row 19139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19130 to 19139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19140 => Predicted: 1\n",
      "Row 19141 => Predicted: 1\n",
      "Row 19142 => Predicted: 0\n",
      "Row 19143 => Predicted: 1\n",
      "Row 19144 => Predicted: 1\n",
      "Row 19145 => Predicted: 0\n",
      "Row 19146 => Predicted: 1\n",
      "Row 19147 => Predicted: 1\n",
      "Row 19148 => Predicted: 1\n",
      "Row 19149 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19140 to 19149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19150 => Predicted: 1\n",
      "Row 19151 => Predicted: 0\n",
      "Row 19152 => Predicted: 0\n",
      "Row 19153 => Predicted: 1\n",
      "Row 19154 => Predicted: 0\n",
      "Row 19155 => Predicted: 0\n",
      "Row 19156 => Predicted: 1\n",
      "Row 19157 => Predicted: 1\n",
      "Row 19158 => Predicted: 1\n",
      "Row 19159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19150 to 19159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19160 => Predicted: 0\n",
      "Row 19161 => Predicted: 1\n",
      "Row 19162 => Predicted: 1\n",
      "Row 19163 => Predicted: 1\n",
      "Row 19164 => Predicted: 1\n",
      "Row 19165 => Predicted: 0\n",
      "Row 19166 => Predicted: 1\n",
      "Row 19167 => Predicted: 1\n",
      "Row 19168 => Predicted: 1\n",
      "Row 19169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19160 to 19169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19170 => Predicted: 1\n",
      "Row 19171 => Predicted: 1\n",
      "Row 19172 => Predicted: 0\n",
      "Row 19173 => Predicted: 0\n",
      "Row 19174 => Predicted: 0\n",
      "Row 19175 => Predicted: 0\n",
      "Row 19176 => Predicted: 1\n",
      "Row 19177 => Predicted: 0\n",
      "Row 19178 => Predicted: 1\n",
      "Row 19179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19170 to 19179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19180 => Predicted: 1\n",
      "Row 19181 => Predicted: 0\n",
      "Row 19182 => Predicted: 0\n",
      "Row 19183 => Predicted: 1\n",
      "Row 19184 => Predicted: 1\n",
      "Row 19185 => Predicted: 1\n",
      "Row 19186 => Predicted: 0\n",
      "Row 19187 => Predicted: 1\n",
      "Row 19188 => Predicted: 0\n",
      "Row 19189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19180 to 19189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19190 => Predicted: 0\n",
      "Row 19191 => Predicted: 1\n",
      "Row 19192 => Predicted: 0\n",
      "Row 19193 => Predicted: 0\n",
      "Row 19194 => Predicted: 0\n",
      "Row 19195 => Predicted: 1\n",
      "Row 19196 => Predicted: 0\n",
      "Row 19197 => Predicted: 1\n",
      "Row 19198 => Predicted: 0\n",
      "Row 19199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19190 to 19199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19200 => Predicted: 0\n",
      "Row 19201 => Predicted: 1\n",
      "Row 19202 => Predicted: 0\n",
      "Row 19203 => Predicted: 1\n",
      "Row 19204 => Predicted: 1\n",
      "Row 19205 => Predicted: 1\n",
      "Row 19206 => Predicted: 0\n",
      "Row 19207 => Predicted: 1\n",
      "Row 19208 => Predicted: 1\n",
      "Row 19209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19200 to 19209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19210 => Predicted: 0\n",
      "Row 19211 => Predicted: 1\n",
      "Row 19212 => Predicted: 1\n",
      "Row 19213 => Predicted: 1\n",
      "Row 19214 => Predicted: 0\n",
      "Row 19215 => Predicted: 0\n",
      "Row 19216 => Predicted: 0\n",
      "Row 19217 => Predicted: 0\n",
      "Row 19218 => Predicted: 0\n",
      "Row 19219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19210 to 19219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19220 => Predicted: 1\n",
      "Row 19221 => Predicted: 1\n",
      "Row 19222 => Predicted: 0\n",
      "Row 19223 => Predicted: 1\n",
      "Row 19224 => Predicted: 0\n",
      "Row 19225 => Predicted: 1\n",
      "Row 19226 => Predicted: 0\n",
      "Row 19227 => Predicted: 0\n",
      "Row 19228 => Predicted: 1\n",
      "Row 19229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19220 to 19229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19230 => Predicted: 0\n",
      "Row 19231 => Predicted: 0\n",
      "Row 19232 => Predicted: 1\n",
      "Row 19233 => Predicted: 0\n",
      "Row 19234 => Predicted: 1\n",
      "Row 19235 => Predicted: 1\n",
      "Row 19236 => Predicted: 0\n",
      "Row 19237 => Predicted: 1\n",
      "Row 19238 => Predicted: 0\n",
      "Row 19239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19230 to 19239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19240 => Predicted: 0\n",
      "Row 19241 => Predicted: 0\n",
      "Row 19242 => Predicted: 1\n",
      "Row 19243 => Predicted: 1\n",
      "Row 19244 => Predicted: 0\n",
      "Row 19245 => Predicted: 1\n",
      "Row 19246 => Predicted: 1\n",
      "Row 19247 => Predicted: 0\n",
      "Row 19248 => Predicted: 0\n",
      "Row 19249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19240 to 19249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19250 => Predicted: 1\n",
      "Row 19251 => Predicted: 0\n",
      "Row 19252 => Predicted: 0\n",
      "Row 19253 => Predicted: 1\n",
      "Row 19254 => Predicted: 1\n",
      "Row 19255 => Predicted: 1\n",
      "Row 19256 => Predicted: 0\n",
      "Row 19257 => Predicted: 0\n",
      "Row 19258 => Predicted: 1\n",
      "Row 19259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19250 to 19259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19260 => Predicted: 1\n",
      "Row 19261 => Predicted: 1\n",
      "Row 19262 => Predicted: 0\n",
      "Row 19263 => Predicted: 0\n",
      "Row 19264 => Predicted: 0\n",
      "Row 19265 => Predicted: 0\n",
      "Row 19266 => Predicted: 0\n",
      "Row 19267 => Predicted: 1\n",
      "Row 19268 => Predicted: 1\n",
      "Row 19269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19260 to 19269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19270 => Predicted: 0\n",
      "Row 19271 => Predicted: 1\n",
      "Row 19272 => Predicted: 0\n",
      "Row 19273 => Predicted: 1\n",
      "Row 19274 => Predicted: 1\n",
      "Row 19275 => Predicted: 1\n",
      "Row 19276 => Predicted: 0\n",
      "Row 19277 => Predicted: 1\n",
      "Row 19278 => Predicted: 1\n",
      "Row 19279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19270 to 19279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19280 => Predicted: 0\n",
      "Row 19281 => Predicted: 1\n",
      "Row 19282 => Predicted: 0\n",
      "Row 19283 => Predicted: 1\n",
      "Row 19284 => Predicted: 0\n",
      "Row 19285 => Predicted: 1\n",
      "Row 19286 => Predicted: 1\n",
      "Row 19287 => Predicted: 1\n",
      "Row 19288 => Predicted: 0\n",
      "Row 19289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19280 to 19289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19290 => Predicted: 0\n",
      "Row 19291 => Predicted: 0\n",
      "Row 19292 => Predicted: 0\n",
      "Row 19293 => Predicted: 1\n",
      "Row 19294 => Predicted: 1\n",
      "Row 19295 => Predicted: 0\n",
      "Row 19296 => Predicted: 0\n",
      "Row 19297 => Predicted: 0\n",
      "Row 19298 => Predicted: 0\n",
      "Row 19299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19290 to 19299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19300 => Predicted: 0\n",
      "Row 19301 => Predicted: 1\n",
      "Row 19302 => Predicted: 0\n",
      "Row 19303 => Predicted: 0\n",
      "Row 19304 => Predicted: 1\n",
      "Row 19305 => Predicted: 0\n",
      "Row 19306 => Predicted: 1\n",
      "Row 19307 => Predicted: 0\n",
      "Row 19308 => Predicted: 1\n",
      "Row 19309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19300 to 19309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19310 => Predicted: 1\n",
      "Row 19311 => Predicted: 0\n",
      "Row 19312 => Predicted: 1\n",
      "Row 19313 => Predicted: 0\n",
      "Row 19314 => Predicted: 1\n",
      "Row 19315 => Predicted: 0\n",
      "Row 19316 => Predicted: 0\n",
      "Row 19317 => Predicted: 0\n",
      "Row 19318 => Predicted: 1\n",
      "Row 19319 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19310 to 19319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19320 => Predicted: 0\n",
      "Row 19321 => Predicted: 1\n",
      "Row 19322 => Predicted: 1\n",
      "Row 19323 => Predicted: 0\n",
      "Row 19324 => Predicted: 0\n",
      "Row 19325 => Predicted: 1\n",
      "Row 19326 => Predicted: 0\n",
      "Row 19327 => Predicted: 1\n",
      "Row 19328 => Predicted: 1\n",
      "Row 19329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19320 to 19329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19330 => Predicted: 0\n",
      "Row 19331 => Predicted: 0\n",
      "Row 19332 => Predicted: 1\n",
      "Row 19333 => Predicted: 0\n",
      "Row 19334 => Predicted: 0\n",
      "Row 19335 => Predicted: 0\n",
      "Row 19336 => Predicted: 1\n",
      "Row 19337 => Predicted: 1\n",
      "Row 19338 => Predicted: 1\n",
      "Row 19339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19330 to 19339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19340 => Predicted: 0\n",
      "Row 19341 => Predicted: 1\n",
      "Row 19342 => Predicted: 0\n",
      "Row 19343 => Predicted: 1\n",
      "Row 19344 => Predicted: 1\n",
      "Row 19345 => Predicted: 0\n",
      "Row 19346 => Predicted: 0\n",
      "Row 19347 => Predicted: 1\n",
      "Row 19348 => Predicted: 0\n",
      "Row 19349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19340 to 19349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19350 => Predicted: 0\n",
      "Row 19351 => Predicted: 0\n",
      "Row 19352 => Predicted: 1\n",
      "Row 19353 => Predicted: 0\n",
      "Row 19354 => Predicted: 0\n",
      "Row 19355 => Predicted: 0\n",
      "Row 19356 => Predicted: 0\n",
      "Row 19357 => Predicted: 1\n",
      "Row 19358 => Predicted: 0\n",
      "Row 19359 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19350 to 19359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19360 => Predicted: 1\n",
      "Row 19361 => Predicted: 0\n",
      "Row 19362 => Predicted: 0\n",
      "Row 19363 => Predicted: 1\n",
      "Row 19364 => Predicted: 1\n",
      "Row 19365 => Predicted: 1\n",
      "Row 19366 => Predicted: 1\n",
      "Row 19367 => Predicted: 1\n",
      "Row 19368 => Predicted: 1\n",
      "Row 19369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19360 to 19369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19370 => Predicted: 0\n",
      "Row 19371 => Predicted: 0\n",
      "Row 19372 => Predicted: 0\n",
      "Row 19373 => Predicted: 0\n",
      "Row 19374 => Predicted: 1\n",
      "Row 19375 => Predicted: 0\n",
      "Row 19376 => Predicted: 0\n",
      "Row 19377 => Predicted: 1\n",
      "Row 19378 => Predicted: 0\n",
      "Row 19379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19370 to 19379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19380 => Predicted: 0\n",
      "Row 19381 => Predicted: 1\n",
      "Row 19382 => Predicted: 0\n",
      "Row 19383 => Predicted: 1\n",
      "Row 19384 => Predicted: 0\n",
      "Row 19385 => Predicted: 1\n",
      "Row 19386 => Predicted: 0\n",
      "Row 19387 => Predicted: 1\n",
      "Row 19388 => Predicted: 1\n",
      "Row 19389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19380 to 19389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19390 => Predicted: 1\n",
      "Row 19391 => Predicted: 0\n",
      "Row 19392 => Predicted: 1\n",
      "Row 19393 => Predicted: 0\n",
      "Row 19394 => Predicted: 0\n",
      "Row 19395 => Predicted: 0\n",
      "Row 19396 => Predicted: 1\n",
      "Row 19397 => Predicted: 1\n",
      "Row 19398 => Predicted: 0\n",
      "Row 19399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19390 to 19399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19400 => Predicted: 1\n",
      "Row 19401 => Predicted: 1\n",
      "Row 19402 => Predicted: 0\n",
      "Row 19403 => Predicted: 0\n",
      "Row 19404 => Predicted: 1\n",
      "Row 19405 => Predicted: 0\n",
      "Row 19406 => Predicted: 0\n",
      "Row 19407 => Predicted: 0\n",
      "Row 19408 => Predicted: 0\n",
      "Row 19409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19400 to 19409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19410 => Predicted: 1\n",
      "Row 19411 => Predicted: 1\n",
      "Row 19412 => Predicted: 1\n",
      "Row 19413 => Predicted: 0\n",
      "Row 19414 => Predicted: 0\n",
      "Row 19415 => Predicted: 1\n",
      "Row 19416 => Predicted: 1\n",
      "Row 19417 => Predicted: 1\n",
      "Row 19418 => Predicted: 1\n",
      "Row 19419 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19410 to 19419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19420 => Predicted: 0\n",
      "Row 19421 => Predicted: 1\n",
      "Row 19422 => Predicted: 1\n",
      "Row 19423 => Predicted: 1\n",
      "Row 19424 => Predicted: 0\n",
      "Row 19425 => Predicted: 1\n",
      "Row 19426 => Predicted: 0\n",
      "Row 19427 => Predicted: 0\n",
      "Row 19428 => Predicted: 1\n",
      "Row 19429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19420 to 19429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19430 => Predicted: 0\n",
      "Row 19431 => Predicted: 1\n",
      "Row 19432 => Predicted: 1\n",
      "Row 19433 => Predicted: 1\n",
      "Row 19434 => Predicted: 0\n",
      "Row 19435 => Predicted: 0\n",
      "Row 19436 => Predicted: 0\n",
      "Row 19437 => Predicted: 1\n",
      "Row 19438 => Predicted: 1\n",
      "Row 19439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19430 to 19439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19440 => Predicted: 0\n",
      "Row 19441 => Predicted: 0\n",
      "Row 19442 => Predicted: 0\n",
      "Row 19443 => Predicted: 1\n",
      "Row 19444 => Predicted: 0\n",
      "Row 19445 => Predicted: 0\n",
      "Row 19446 => Predicted: 1\n",
      "Row 19447 => Predicted: 0\n",
      "Row 19448 => Predicted: 1\n",
      "Row 19449 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19440 to 19449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19450 => Predicted: 1\n",
      "Row 19451 => Predicted: 0\n",
      "Row 19452 => Predicted: 0\n",
      "Row 19453 => Predicted: 0\n",
      "Row 19454 => Predicted: 1\n",
      "Row 19455 => Predicted: 0\n",
      "Row 19456 => Predicted: 0\n",
      "Row 19457 => Predicted: 0\n",
      "Row 19458 => Predicted: 1\n",
      "Row 19459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19450 to 19459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19460 => Predicted: 1\n",
      "Row 19461 => Predicted: 0\n",
      "Row 19462 => Predicted: 1\n",
      "Row 19463 => Predicted: 0\n",
      "Row 19464 => Predicted: 0\n",
      "Row 19465 => Predicted: 0\n",
      "Row 19466 => Predicted: 1\n",
      "Row 19467 => Predicted: 1\n",
      "Row 19468 => Predicted: 0\n",
      "Row 19469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19460 to 19469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19470 => Predicted: 0\n",
      "Row 19471 => Predicted: 0\n",
      "Row 19472 => Predicted: 1\n",
      "Row 19473 => Predicted: 1\n",
      "Row 19474 => Predicted: 0\n",
      "Row 19475 => Predicted: 0\n",
      "Row 19476 => Predicted: 0\n",
      "Row 19477 => Predicted: 0\n",
      "Row 19478 => Predicted: 1\n",
      "Row 19479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19470 to 19479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19480 => Predicted: 1\n",
      "Row 19481 => Predicted: 1\n",
      "Row 19482 => Predicted: 0\n",
      "Row 19483 => Predicted: 1\n",
      "Row 19484 => Predicted: 0\n",
      "Row 19485 => Predicted: 0\n",
      "Row 19486 => Predicted: 0\n",
      "Row 19487 => Predicted: 0\n",
      "Row 19488 => Predicted: 1\n",
      "Row 19489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19480 to 19489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19490 => Predicted: 1\n",
      "Row 19491 => Predicted: 1\n",
      "Row 19492 => Predicted: 1\n",
      "Row 19493 => Predicted: 0\n",
      "Row 19494 => Predicted: 1\n",
      "Row 19495 => Predicted: 0\n",
      "Row 19496 => Predicted: 1\n",
      "Row 19497 => Predicted: 0\n",
      "Row 19498 => Predicted: 1\n",
      "Row 19499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19490 to 19499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19500 => Predicted: 0\n",
      "Row 19501 => Predicted: 1\n",
      "Row 19502 => Predicted: 1\n",
      "Row 19503 => Predicted: 1\n",
      "Row 19504 => Predicted: 0\n",
      "Row 19505 => Predicted: 1\n",
      "Row 19506 => Predicted: 1\n",
      "Row 19507 => Predicted: 0\n",
      "Row 19508 => Predicted: 1\n",
      "Row 19509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19500 to 19509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19510 => Predicted: 1\n",
      "Row 19511 => Predicted: 1\n",
      "Row 19512 => Predicted: 0\n",
      "Row 19513 => Predicted: 0\n",
      "Row 19514 => Predicted: 0\n",
      "Row 19515 => Predicted: 1\n",
      "Row 19516 => Predicted: 0\n",
      "Row 19517 => Predicted: 1\n",
      "Row 19518 => Predicted: 0\n",
      "Row 19519 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19510 to 19519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19520 => Predicted: 0\n",
      "Row 19521 => Predicted: 0\n",
      "Row 19522 => Predicted: 0\n",
      "Row 19523 => Predicted: 1\n",
      "Row 19524 => Predicted: 1\n",
      "Row 19525 => Predicted: 1\n",
      "Row 19526 => Predicted: 1\n",
      "Row 19527 => Predicted: 0\n",
      "Row 19528 => Predicted: 1\n",
      "Row 19529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19520 to 19529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19530 => Predicted: 0\n",
      "Row 19531 => Predicted: 1\n",
      "Row 19532 => Predicted: 1\n",
      "Row 19533 => Predicted: 1\n",
      "Row 19534 => Predicted: 0\n",
      "Row 19535 => Predicted: 0\n",
      "Row 19536 => Predicted: 1\n",
      "Row 19537 => Predicted: 1\n",
      "Row 19538 => Predicted: 0\n",
      "Row 19539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19530 to 19539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19540 => Predicted: 1\n",
      "Row 19541 => Predicted: 1\n",
      "Row 19542 => Predicted: 0\n",
      "Row 19543 => Predicted: 1\n",
      "Row 19544 => Predicted: 0\n",
      "Row 19545 => Predicted: 1\n",
      "Row 19546 => Predicted: 1\n",
      "Row 19547 => Predicted: 1\n",
      "Row 19548 => Predicted: 1\n",
      "Row 19549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19540 to 19549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19550 => Predicted: 0\n",
      "Row 19551 => Predicted: 0\n",
      "Row 19552 => Predicted: 1\n",
      "Row 19553 => Predicted: 1\n",
      "Row 19554 => Predicted: 1\n",
      "Row 19555 => Predicted: 0\n",
      "Row 19556 => Predicted: 0\n",
      "Row 19557 => Predicted: 0\n",
      "Row 19558 => Predicted: 0\n",
      "Row 19559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19550 to 19559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19560 => Predicted: 1\n",
      "Row 19561 => Predicted: 0\n",
      "Row 19562 => Predicted: 1\n",
      "Row 19563 => Predicted: 1\n",
      "Row 19564 => Predicted: 0\n",
      "Row 19565 => Predicted: 0\n",
      "Row 19566 => Predicted: 0\n",
      "Row 19567 => Predicted: 0\n",
      "Row 19568 => Predicted: 1\n",
      "Row 19569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19560 to 19569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19570 => Predicted: 0\n",
      "Row 19571 => Predicted: 1\n",
      "Row 19572 => Predicted: 0\n",
      "Row 19573 => Predicted: 1\n",
      "Row 19574 => Predicted: 0\n",
      "Row 19575 => Predicted: 0\n",
      "Row 19576 => Predicted: 1\n",
      "Row 19577 => Predicted: 1\n",
      "Row 19578 => Predicted: 0\n",
      "Row 19579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19570 to 19579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19580 => Predicted: 0\n",
      "Row 19581 => Predicted: 1\n",
      "Row 19582 => Predicted: 0\n",
      "Row 19583 => Predicted: 1\n",
      "Row 19584 => Predicted: 1\n",
      "Row 19585 => Predicted: 1\n",
      "Row 19586 => Predicted: 0\n",
      "Row 19587 => Predicted: 0\n",
      "Row 19588 => Predicted: 1\n",
      "Row 19589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19580 to 19589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19590 => Predicted: 0\n",
      "Row 19591 => Predicted: 0\n",
      "Row 19592 => Predicted: 0\n",
      "Row 19593 => Predicted: 0\n",
      "Row 19594 => Predicted: 0\n",
      "Row 19595 => Predicted: 1\n",
      "Row 19596 => Predicted: 1\n",
      "Row 19597 => Predicted: 0\n",
      "Row 19598 => Predicted: 1\n",
      "Row 19599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19590 to 19599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19600 => Predicted: 1\n",
      "Row 19601 => Predicted: 1\n",
      "Row 19602 => Predicted: 1\n",
      "Row 19603 => Predicted: 0\n",
      "Row 19604 => Predicted: 1\n",
      "Row 19605 => Predicted: 1\n",
      "Row 19606 => Predicted: 1\n",
      "Row 19607 => Predicted: 0\n",
      "Row 19608 => Predicted: 1\n",
      "Row 19609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19600 to 19609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19610 => Predicted: 1\n",
      "Row 19611 => Predicted: 0\n",
      "Row 19612 => Predicted: 0\n",
      "Row 19613 => Predicted: 0\n",
      "Row 19614 => Predicted: 1\n",
      "Row 19615 => Predicted: 1\n",
      "Row 19616 => Predicted: 0\n",
      "Row 19617 => Predicted: 0\n",
      "Row 19618 => Predicted: 1\n",
      "Row 19619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19610 to 19619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19620 => Predicted: 0\n",
      "Row 19621 => Predicted: 0\n",
      "Row 19622 => Predicted: 1\n",
      "Row 19623 => Predicted: 1\n",
      "Row 19624 => Predicted: 1\n",
      "Row 19625 => Predicted: 0\n",
      "Row 19626 => Predicted: 0\n",
      "Row 19627 => Predicted: 0\n",
      "Row 19628 => Predicted: 0\n",
      "Row 19629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19620 to 19629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19630 => Predicted: 0\n",
      "Row 19631 => Predicted: 1\n",
      "Row 19632 => Predicted: 1\n",
      "Row 19633 => Predicted: 0\n",
      "Row 19634 => Predicted: 0\n",
      "Row 19635 => Predicted: 1\n",
      "Row 19636 => Predicted: 1\n",
      "Row 19637 => Predicted: 1\n",
      "Row 19638 => Predicted: 1\n",
      "Row 19639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19630 to 19639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19640 => Predicted: 1\n",
      "Row 19641 => Predicted: 0\n",
      "Row 19642 => Predicted: 0\n",
      "Row 19643 => Predicted: 0\n",
      "Row 19644 => Predicted: 1\n",
      "Row 19645 => Predicted: 1\n",
      "Row 19646 => Predicted: 1\n",
      "Row 19647 => Predicted: 1\n",
      "Row 19648 => Predicted: 0\n",
      "Row 19649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19640 to 19649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19650 => Predicted: 1\n",
      "Row 19651 => Predicted: 1\n",
      "Row 19652 => Predicted: 1\n",
      "Row 19653 => Predicted: 1\n",
      "Row 19654 => Predicted: 1\n",
      "Row 19655 => Predicted: 1\n",
      "Row 19656 => Predicted: 0\n",
      "Row 19657 => Predicted: 1\n",
      "Row 19658 => Predicted: 0\n",
      "Row 19659 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19650 to 19659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19660 => Predicted: 1\n",
      "Row 19661 => Predicted: 1\n",
      "Row 19662 => Predicted: 0\n",
      "Row 19663 => Predicted: 1\n",
      "Row 19664 => Predicted: 1\n",
      "Row 19665 => Predicted: 0\n",
      "Row 19666 => Predicted: 0\n",
      "Row 19667 => Predicted: 1\n",
      "Row 19668 => Predicted: 0\n",
      "Row 19669 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19660 to 19669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19670 => Predicted: 0\n",
      "Row 19671 => Predicted: 0\n",
      "Row 19672 => Predicted: 0\n",
      "Row 19673 => Predicted: 0\n",
      "Row 19674 => Predicted: 0\n",
      "Row 19675 => Predicted: 0\n",
      "Row 19676 => Predicted: 1\n",
      "Row 19677 => Predicted: 0\n",
      "Row 19678 => Predicted: 1\n",
      "Row 19679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19670 to 19679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19680 => Predicted: 1\n",
      "Row 19681 => Predicted: 1\n",
      "Row 19682 => Predicted: 1\n",
      "Row 19683 => Predicted: 0\n",
      "Row 19684 => Predicted: 0\n",
      "Row 19685 => Predicted: 0\n",
      "Row 19686 => Predicted: 1\n",
      "Row 19687 => Predicted: 1\n",
      "Row 19688 => Predicted: 1\n",
      "Row 19689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19680 to 19689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19690 => Predicted: 0\n",
      "Row 19691 => Predicted: 0\n",
      "Row 19692 => Predicted: 0\n",
      "Row 19693 => Predicted: 1\n",
      "Row 19694 => Predicted: 1\n",
      "Row 19695 => Predicted: 1\n",
      "Row 19696 => Predicted: 1\n",
      "Row 19697 => Predicted: 1\n",
      "Row 19698 => Predicted: 1\n",
      "Row 19699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19690 to 19699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19700 => Predicted: 1\n",
      "Row 19701 => Predicted: 1\n",
      "Row 19702 => Predicted: 1\n",
      "Row 19703 => Predicted: 0\n",
      "Row 19704 => Predicted: 0\n",
      "Row 19705 => Predicted: 0\n",
      "Row 19706 => Predicted: 1\n",
      "Row 19707 => Predicted: 1\n",
      "Row 19708 => Predicted: 1\n",
      "Row 19709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19700 to 19709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19710 => Predicted: 0\n",
      "Row 19711 => Predicted: 0\n",
      "Row 19712 => Predicted: 1\n",
      "Row 19713 => Predicted: 1\n",
      "Row 19714 => Predicted: 1\n",
      "Row 19715 => Predicted: 0\n",
      "Row 19716 => Predicted: 1\n",
      "Row 19717 => Predicted: 0\n",
      "Row 19718 => Predicted: 0\n",
      "Row 19719 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19710 to 19719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19720 => Predicted: 0\n",
      "Row 19721 => Predicted: 1\n",
      "Row 19722 => Predicted: 0\n",
      "Row 19723 => Predicted: 0\n",
      "Row 19724 => Predicted: 0\n",
      "Row 19725 => Predicted: 1\n",
      "Row 19726 => Predicted: 1\n",
      "Row 19727 => Predicted: 1\n",
      "Row 19728 => Predicted: 0\n",
      "Row 19729 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19720 to 19729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19730 => Predicted: 1\n",
      "Row 19731 => Predicted: 0\n",
      "Row 19732 => Predicted: 1\n",
      "Row 19733 => Predicted: 0\n",
      "Row 19734 => Predicted: 1\n",
      "Row 19735 => Predicted: 0\n",
      "Row 19736 => Predicted: 1\n",
      "Row 19737 => Predicted: 1\n",
      "Row 19738 => Predicted: 0\n",
      "Row 19739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19730 to 19739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19740 => Predicted: 0\n",
      "Row 19741 => Predicted: 1\n",
      "Row 19742 => Predicted: 0\n",
      "Row 19743 => Predicted: 1\n",
      "Row 19744 => Predicted: 0\n",
      "Row 19745 => Predicted: 0\n",
      "Row 19746 => Predicted: 0\n",
      "Row 19747 => Predicted: 0\n",
      "Row 19748 => Predicted: 0\n",
      "Row 19749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19740 to 19749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19750 => Predicted: 0\n",
      "Row 19751 => Predicted: 1\n",
      "Row 19752 => Predicted: 1\n",
      "Row 19753 => Predicted: 0\n",
      "Row 19754 => Predicted: 1\n",
      "Row 19755 => Predicted: 1\n",
      "Row 19756 => Predicted: 0\n",
      "Row 19757 => Predicted: 0\n",
      "Row 19758 => Predicted: 0\n",
      "Row 19759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19750 to 19759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19760 => Predicted: 0\n",
      "Row 19761 => Predicted: 0\n",
      "Row 19762 => Predicted: 1\n",
      "Row 19763 => Predicted: 1\n",
      "Row 19764 => Predicted: 0\n",
      "Row 19765 => Predicted: 1\n",
      "Row 19766 => Predicted: 1\n",
      "Row 19767 => Predicted: 1\n",
      "Row 19768 => Predicted: 1\n",
      "Row 19769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19760 to 19769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19770 => Predicted: 1\n",
      "Row 19771 => Predicted: 1\n",
      "Row 19772 => Predicted: 1\n",
      "Row 19773 => Predicted: 0\n",
      "Row 19774 => Predicted: 1\n",
      "Row 19775 => Predicted: 1\n",
      "Row 19776 => Predicted: 1\n",
      "Row 19777 => Predicted: 1\n",
      "Row 19778 => Predicted: 0\n",
      "Row 19779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19770 to 19779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19780 => Predicted: 0\n",
      "Row 19781 => Predicted: 0\n",
      "Row 19782 => Predicted: 0\n",
      "Row 19783 => Predicted: 0\n",
      "Row 19784 => Predicted: 0\n",
      "Row 19785 => Predicted: 1\n",
      "Row 19786 => Predicted: 1\n",
      "Row 19787 => Predicted: 1\n",
      "Row 19788 => Predicted: 0\n",
      "Row 19789 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19780 to 19789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19790 => Predicted: 1\n",
      "Row 19791 => Predicted: 0\n",
      "Row 19792 => Predicted: 1\n",
      "Row 19793 => Predicted: 0\n",
      "Row 19794 => Predicted: 1\n",
      "Row 19795 => Predicted: 1\n",
      "Row 19796 => Predicted: 1\n",
      "Row 19797 => Predicted: 0\n",
      "Row 19798 => Predicted: 1\n",
      "Row 19799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19790 to 19799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19800 => Predicted: 0\n",
      "Row 19801 => Predicted: 1\n",
      "Row 19802 => Predicted: 1\n",
      "Row 19803 => Predicted: 1\n",
      "Row 19804 => Predicted: 0\n",
      "Row 19805 => Predicted: 0\n",
      "Row 19806 => Predicted: 1\n",
      "Row 19807 => Predicted: 1\n",
      "Row 19808 => Predicted: 1\n",
      "Row 19809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19800 to 19809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19810 => Predicted: 1\n",
      "Row 19811 => Predicted: 0\n",
      "Row 19812 => Predicted: 0\n",
      "Row 19813 => Predicted: 1\n",
      "Row 19814 => Predicted: 0\n",
      "Row 19815 => Predicted: 0\n",
      "Row 19816 => Predicted: 1\n",
      "Row 19817 => Predicted: 0\n",
      "Row 19818 => Predicted: 0\n",
      "Row 19819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19810 to 19819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19820 => Predicted: 1\n",
      "Row 19821 => Predicted: 1\n",
      "Row 19822 => Predicted: 0\n",
      "Row 19823 => Predicted: 0\n",
      "Row 19824 => Predicted: 1\n",
      "Row 19825 => Predicted: 1\n",
      "Row 19826 => Predicted: 1\n",
      "Row 19827 => Predicted: 1\n",
      "Row 19828 => Predicted: 1\n",
      "Row 19829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19820 to 19829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19830 => Predicted: 1\n",
      "Row 19831 => Predicted: 0\n",
      "Row 19832 => Predicted: 1\n",
      "Row 19833 => Predicted: 1\n",
      "Row 19834 => Predicted: 0\n",
      "Row 19835 => Predicted: 1\n",
      "Row 19836 => Predicted: 1\n",
      "Row 19837 => Predicted: 1\n",
      "Row 19838 => Predicted: 1\n",
      "Row 19839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19830 to 19839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19840 => Predicted: 1\n",
      "Row 19841 => Predicted: 0\n",
      "Row 19842 => Predicted: 1\n",
      "Row 19843 => Predicted: 1\n",
      "Row 19844 => Predicted: 1\n",
      "Row 19845 => Predicted: 0\n",
      "Row 19846 => Predicted: 0\n",
      "Row 19847 => Predicted: 0\n",
      "Row 19848 => Predicted: 1\n",
      "Row 19849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19840 to 19849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19850 => Predicted: 0\n",
      "Row 19851 => Predicted: 1\n",
      "Row 19852 => Predicted: 0\n",
      "Row 19853 => Predicted: 0\n",
      "Row 19854 => Predicted: 0\n",
      "Row 19855 => Predicted: 1\n",
      "Row 19856 => Predicted: 1\n",
      "Row 19857 => Predicted: 0\n",
      "Row 19858 => Predicted: 0\n",
      "Row 19859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19850 to 19859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19860 => Predicted: 1\n",
      "Row 19861 => Predicted: 0\n",
      "Row 19862 => Predicted: 1\n",
      "Row 19863 => Predicted: 1\n",
      "Row 19864 => Predicted: 0\n",
      "Row 19865 => Predicted: 0\n",
      "Row 19866 => Predicted: 1\n",
      "Row 19867 => Predicted: 1\n",
      "Row 19868 => Predicted: 0\n",
      "Row 19869 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19860 to 19869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19870 => Predicted: 0\n",
      "Row 19871 => Predicted: 0\n",
      "Row 19872 => Predicted: 1\n",
      "Row 19873 => Predicted: 0\n",
      "Row 19874 => Predicted: 0\n",
      "Row 19875 => Predicted: 1\n",
      "Row 19876 => Predicted: 1\n",
      "Row 19877 => Predicted: 1\n",
      "Row 19878 => Predicted: 1\n",
      "Row 19879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19870 to 19879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19880 => Predicted: 0\n",
      "Row 19881 => Predicted: 0\n",
      "Row 19882 => Predicted: 1\n",
      "Row 19883 => Predicted: 0\n",
      "Row 19884 => Predicted: 1\n",
      "Row 19885 => Predicted: 0\n",
      "Row 19886 => Predicted: 0\n",
      "Row 19887 => Predicted: 0\n",
      "Row 19888 => Predicted: 1\n",
      "Row 19889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19880 to 19889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19890 => Predicted: 0\n",
      "Row 19891 => Predicted: 0\n",
      "Row 19892 => Predicted: 0\n",
      "Row 19893 => Predicted: 1\n",
      "Row 19894 => Predicted: 1\n",
      "Row 19895 => Predicted: 1\n",
      "Row 19896 => Predicted: 0\n",
      "Row 19897 => Predicted: 0\n",
      "Row 19898 => Predicted: 0\n",
      "Row 19899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19890 to 19899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19900 => Predicted: 1\n",
      "Row 19901 => Predicted: 1\n",
      "Row 19902 => Predicted: 1\n",
      "Row 19903 => Predicted: 0\n",
      "Row 19904 => Predicted: 0\n",
      "Row 19905 => Predicted: 1\n",
      "Row 19906 => Predicted: 1\n",
      "Row 19907 => Predicted: 1\n",
      "Row 19908 => Predicted: 0\n",
      "Row 19909 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19900 to 19909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19910 => Predicted: 0\n",
      "Row 19911 => Predicted: 1\n",
      "Row 19912 => Predicted: 1\n",
      "Row 19913 => Predicted: 1\n",
      "Row 19914 => Predicted: 1\n",
      "Row 19915 => Predicted: 0\n",
      "Row 19916 => Predicted: 0\n",
      "Row 19917 => Predicted: 0\n",
      "Row 19918 => Predicted: 0\n",
      "Row 19919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19910 to 19919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19920 => Predicted: 1\n",
      "Row 19921 => Predicted: 1\n",
      "Row 19922 => Predicted: 0\n",
      "Row 19923 => Predicted: 1\n",
      "Row 19924 => Predicted: 1\n",
      "Row 19925 => Predicted: 1\n",
      "Row 19926 => Predicted: 1\n",
      "Row 19927 => Predicted: 0\n",
      "Row 19928 => Predicted: 1\n",
      "Row 19929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19920 to 19929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19930 => Predicted: 0\n",
      "Row 19931 => Predicted: 1\n",
      "Row 19932 => Predicted: 1\n",
      "Row 19933 => Predicted: 1\n",
      "Row 19934 => Predicted: 1\n",
      "Row 19935 => Predicted: 1\n",
      "Row 19936 => Predicted: 1\n",
      "Row 19937 => Predicted: 0\n",
      "Row 19938 => Predicted: 0\n",
      "Row 19939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19930 to 19939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19940 => Predicted: 1\n",
      "Row 19941 => Predicted: 0\n",
      "Row 19942 => Predicted: 0\n",
      "Row 19943 => Predicted: 1\n",
      "Row 19944 => Predicted: 0\n",
      "Row 19945 => Predicted: 0\n",
      "Row 19946 => Predicted: 1\n",
      "Row 19947 => Predicted: 1\n",
      "Row 19948 => Predicted: 0\n",
      "Row 19949 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19940 to 19949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19950 => Predicted: 0\n",
      "Row 19951 => Predicted: 0\n",
      "Row 19952 => Predicted: 0\n",
      "Row 19953 => Predicted: 0\n",
      "Row 19954 => Predicted: 1\n",
      "Row 19955 => Predicted: 0\n",
      "Row 19956 => Predicted: 0\n",
      "Row 19957 => Predicted: 1\n",
      "Row 19958 => Predicted: 0\n",
      "Row 19959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19950 to 19959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19960 => Predicted: 1\n",
      "Row 19961 => Predicted: 0\n",
      "Row 19962 => Predicted: 0\n",
      "Row 19963 => Predicted: 0\n",
      "Row 19964 => Predicted: 0\n",
      "Row 19965 => Predicted: 0\n",
      "Row 19966 => Predicted: 1\n",
      "Row 19967 => Predicted: 0\n",
      "Row 19968 => Predicted: 1\n",
      "Row 19969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19960 to 19969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19970 => Predicted: 0\n",
      "Row 19971 => Predicted: 1\n",
      "Row 19972 => Predicted: 1\n",
      "Row 19973 => Predicted: 0\n",
      "Row 19974 => Predicted: 1\n",
      "Row 19975 => Predicted: 0\n",
      "Row 19976 => Predicted: 1\n",
      "Row 19977 => Predicted: 0\n",
      "Row 19978 => Predicted: 1\n",
      "Row 19979 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19970 to 19979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19980 => Predicted: 1\n",
      "Row 19981 => Predicted: 1\n",
      "Row 19982 => Predicted: 1\n",
      "Row 19983 => Predicted: 1\n",
      "Row 19984 => Predicted: 0\n",
      "Row 19985 => Predicted: 1\n",
      "Row 19986 => Predicted: 1\n",
      "Row 19987 => Predicted: 0\n",
      "Row 19988 => Predicted: 0\n",
      "Row 19989 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 19980 to 19989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19990 => Predicted: 1\n",
      "Row 19991 => Predicted: 0\n",
      "Row 19992 => Predicted: 1\n",
      "Row 19993 => Predicted: 0\n",
      "Row 19994 => Predicted: 1\n",
      "Row 19995 => Predicted: 0\n",
      "Row 19996 => Predicted: 1\n",
      "Row 19997 => Predicted: 0\n",
      "Row 19998 => Predicted: 0\n",
      "Row 19999 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 19990 to 19999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20000 => Predicted: 1\n",
      "Row 20001 => Predicted: 0\n",
      "Row 20002 => Predicted: 1\n",
      "Row 20003 => Predicted: 1\n",
      "Row 20004 => Predicted: 0\n",
      "Row 20005 => Predicted: 0\n",
      "Row 20006 => Predicted: 1\n",
      "Row 20007 => Predicted: 1\n",
      "Row 20008 => Predicted: 0\n",
      "Row 20009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20000 to 20009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20010 => Predicted: 0\n",
      "Row 20011 => Predicted: 1\n",
      "Row 20012 => Predicted: 0\n",
      "Row 20013 => Predicted: 1\n",
      "Row 20014 => Predicted: 0\n",
      "Row 20015 => Predicted: 0\n",
      "Row 20016 => Predicted: 0\n",
      "Row 20017 => Predicted: 1\n",
      "Row 20018 => Predicted: 1\n",
      "Row 20019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20010 to 20019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20020 => Predicted: 1\n",
      "Row 20021 => Predicted: 1\n",
      "Row 20022 => Predicted: 0\n",
      "Row 20023 => Predicted: 1\n",
      "Row 20024 => Predicted: 1\n",
      "Row 20025 => Predicted: 1\n",
      "Row 20026 => Predicted: 1\n",
      "Row 20027 => Predicted: 0\n",
      "Row 20028 => Predicted: 1\n",
      "Row 20029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20020 to 20029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20030 => Predicted: 1\n",
      "Row 20031 => Predicted: 0\n",
      "Row 20032 => Predicted: 0\n",
      "Row 20033 => Predicted: 1\n",
      "Row 20034 => Predicted: 0\n",
      "Row 20035 => Predicted: 0\n",
      "Row 20036 => Predicted: 0\n",
      "Row 20037 => Predicted: 1\n",
      "Row 20038 => Predicted: 0\n",
      "Row 20039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20030 to 20039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20040 => Predicted: 1\n",
      "Row 20041 => Predicted: 0\n",
      "Row 20042 => Predicted: 1\n",
      "Row 20043 => Predicted: 1\n",
      "Row 20044 => Predicted: 1\n",
      "Row 20045 => Predicted: 1\n",
      "Row 20046 => Predicted: 1\n",
      "Row 20047 => Predicted: 0\n",
      "Row 20048 => Predicted: 1\n",
      "Row 20049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20040 to 20049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20050 => Predicted: 1\n",
      "Row 20051 => Predicted: 0\n",
      "Row 20052 => Predicted: 0\n",
      "Row 20053 => Predicted: 1\n",
      "Row 20054 => Predicted: 0\n",
      "Row 20055 => Predicted: 1\n",
      "Row 20056 => Predicted: 1\n",
      "Row 20057 => Predicted: 1\n",
      "Row 20058 => Predicted: 0\n",
      "Row 20059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20050 to 20059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20060 => Predicted: 1\n",
      "Row 20061 => Predicted: 0\n",
      "Row 20062 => Predicted: 0\n",
      "Row 20063 => Predicted: 0\n",
      "Row 20064 => Predicted: 0\n",
      "Row 20065 => Predicted: 0\n",
      "Row 20066 => Predicted: 0\n",
      "Row 20067 => Predicted: 0\n",
      "Row 20068 => Predicted: 0\n",
      "Row 20069 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20060 to 20069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20070 => Predicted: 1\n",
      "Row 20071 => Predicted: 0\n",
      "Row 20072 => Predicted: 1\n",
      "Row 20073 => Predicted: 1\n",
      "Row 20074 => Predicted: 0\n",
      "Row 20075 => Predicted: 0\n",
      "Row 20076 => Predicted: 1\n",
      "Row 20077 => Predicted: 1\n",
      "Row 20078 => Predicted: 0\n",
      "Row 20079 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20070 to 20079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20080 => Predicted: 1\n",
      "Row 20081 => Predicted: 0\n",
      "Row 20082 => Predicted: 1\n",
      "Row 20083 => Predicted: 0\n",
      "Row 20084 => Predicted: 0\n",
      "Row 20085 => Predicted: 1\n",
      "Row 20086 => Predicted: 0\n",
      "Row 20087 => Predicted: 1\n",
      "Row 20088 => Predicted: 1\n",
      "Row 20089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20080 to 20089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20090 => Predicted: 0\n",
      "Row 20091 => Predicted: 1\n",
      "Row 20092 => Predicted: 1\n",
      "Row 20093 => Predicted: 0\n",
      "Row 20094 => Predicted: 1\n",
      "Row 20095 => Predicted: 0\n",
      "Row 20096 => Predicted: 1\n",
      "Row 20097 => Predicted: 0\n",
      "Row 20098 => Predicted: 1\n",
      "Row 20099 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20090 to 20099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20100 => Predicted: 0\n",
      "Row 20101 => Predicted: 0\n",
      "Row 20102 => Predicted: 0\n",
      "Row 20103 => Predicted: 1\n",
      "Row 20104 => Predicted: 1\n",
      "Row 20105 => Predicted: 0\n",
      "Row 20106 => Predicted: 1\n",
      "Row 20107 => Predicted: 0\n",
      "Row 20108 => Predicted: 1\n",
      "Row 20109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20100 to 20109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20110 => Predicted: 1\n",
      "Row 20111 => Predicted: 1\n",
      "Row 20112 => Predicted: 0\n",
      "Row 20113 => Predicted: 1\n",
      "Row 20114 => Predicted: 0\n",
      "Row 20115 => Predicted: 0\n",
      "Row 20116 => Predicted: 1\n",
      "Row 20117 => Predicted: 0\n",
      "Row 20118 => Predicted: 1\n",
      "Row 20119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20110 to 20119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20120 => Predicted: 0\n",
      "Row 20121 => Predicted: 0\n",
      "Row 20122 => Predicted: 0\n",
      "Row 20123 => Predicted: 1\n",
      "Row 20124 => Predicted: 1\n",
      "Row 20125 => Predicted: 0\n",
      "Row 20126 => Predicted: 1\n",
      "Row 20127 => Predicted: 1\n",
      "Row 20128 => Predicted: 1\n",
      "Row 20129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20120 to 20129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20130 => Predicted: 1\n",
      "Row 20131 => Predicted: 1\n",
      "Row 20132 => Predicted: 1\n",
      "Row 20133 => Predicted: 0\n",
      "Row 20134 => Predicted: 0\n",
      "Row 20135 => Predicted: 1\n",
      "Row 20136 => Predicted: 1\n",
      "Row 20137 => Predicted: 0\n",
      "Row 20138 => Predicted: 1\n",
      "Row 20139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20130 to 20139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20140 => Predicted: 1\n",
      "Row 20141 => Predicted: 1\n",
      "Row 20142 => Predicted: 0\n",
      "Row 20143 => Predicted: 0\n",
      "Row 20144 => Predicted: 0\n",
      "Row 20145 => Predicted: 1\n",
      "Row 20146 => Predicted: 1\n",
      "Row 20147 => Predicted: 0\n",
      "Row 20148 => Predicted: 0\n",
      "Row 20149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20140 to 20149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20150 => Predicted: 1\n",
      "Row 20151 => Predicted: 1\n",
      "Row 20152 => Predicted: 0\n",
      "Row 20153 => Predicted: 1\n",
      "Row 20154 => Predicted: 0\n",
      "Row 20155 => Predicted: 1\n",
      "Row 20156 => Predicted: 0\n",
      "Row 20157 => Predicted: 1\n",
      "Row 20158 => Predicted: 0\n",
      "Row 20159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20150 to 20159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20160 => Predicted: 0\n",
      "Row 20161 => Predicted: 0\n",
      "Row 20162 => Predicted: 0\n",
      "Row 20163 => Predicted: 0\n",
      "Row 20164 => Predicted: 0\n",
      "Row 20165 => Predicted: 1\n",
      "Row 20166 => Predicted: 0\n",
      "Row 20167 => Predicted: 1\n",
      "Row 20168 => Predicted: 1\n",
      "Row 20169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20160 to 20169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20170 => Predicted: 1\n",
      "Row 20171 => Predicted: 1\n",
      "Row 20172 => Predicted: 1\n",
      "Row 20173 => Predicted: 0\n",
      "Row 20174 => Predicted: 1\n",
      "Row 20175 => Predicted: 1\n",
      "Row 20176 => Predicted: 1\n",
      "Row 20177 => Predicted: 1\n",
      "Row 20178 => Predicted: 0\n",
      "Row 20179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20170 to 20179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20180 => Predicted: 0\n",
      "Row 20181 => Predicted: 1\n",
      "Row 20182 => Predicted: 1\n",
      "Row 20183 => Predicted: 1\n",
      "Row 20184 => Predicted: 1\n",
      "Row 20185 => Predicted: 1\n",
      "Row 20186 => Predicted: 0\n",
      "Row 20187 => Predicted: 0\n",
      "Row 20188 => Predicted: 1\n",
      "Row 20189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20180 to 20189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20190 => Predicted: 0\n",
      "Row 20191 => Predicted: 0\n",
      "Row 20192 => Predicted: 0\n",
      "Row 20193 => Predicted: 0\n",
      "Row 20194 => Predicted: 1\n",
      "Row 20195 => Predicted: 1\n",
      "Row 20196 => Predicted: 0\n",
      "Row 20197 => Predicted: 1\n",
      "Row 20198 => Predicted: 0\n",
      "Row 20199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20190 to 20199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20200 => Predicted: 1\n",
      "Row 20201 => Predicted: 1\n",
      "Row 20202 => Predicted: 1\n",
      "Row 20203 => Predicted: 1\n",
      "Row 20204 => Predicted: 0\n",
      "Row 20205 => Predicted: 0\n",
      "Row 20206 => Predicted: 0\n",
      "Row 20207 => Predicted: 1\n",
      "Row 20208 => Predicted: 1\n",
      "Row 20209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20200 to 20209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20210 => Predicted: 0\n",
      "Row 20211 => Predicted: 0\n",
      "Row 20212 => Predicted: 0\n",
      "Row 20213 => Predicted: 0\n",
      "Row 20214 => Predicted: 0\n",
      "Row 20215 => Predicted: 0\n",
      "Row 20216 => Predicted: 1\n",
      "Row 20217 => Predicted: 1\n",
      "Row 20218 => Predicted: 1\n",
      "Row 20219 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20210 to 20219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20220 => Predicted: 1\n",
      "Row 20221 => Predicted: 1\n",
      "Row 20222 => Predicted: 1\n",
      "Row 20223 => Predicted: 1\n",
      "Row 20224 => Predicted: 0\n",
      "Row 20225 => Predicted: 0\n",
      "Row 20226 => Predicted: 1\n",
      "Row 20227 => Predicted: 1\n",
      "Row 20228 => Predicted: 0\n",
      "Row 20229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20220 to 20229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20230 => Predicted: 0\n",
      "Row 20231 => Predicted: 1\n",
      "Row 20232 => Predicted: 1\n",
      "Row 20233 => Predicted: 1\n",
      "Row 20234 => Predicted: 0\n",
      "Row 20235 => Predicted: 0\n",
      "Row 20236 => Predicted: 0\n",
      "Row 20237 => Predicted: 0\n",
      "Row 20238 => Predicted: 1\n",
      "Row 20239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20230 to 20239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20240 => Predicted: 1\n",
      "Row 20241 => Predicted: 1\n",
      "Row 20242 => Predicted: 1\n",
      "Row 20243 => Predicted: 0\n",
      "Row 20244 => Predicted: 1\n",
      "Row 20245 => Predicted: 0\n",
      "Row 20246 => Predicted: 1\n",
      "Row 20247 => Predicted: 1\n",
      "Row 20248 => Predicted: 1\n",
      "Row 20249 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20240 to 20249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20250 => Predicted: 1\n",
      "Row 20251 => Predicted: 0\n",
      "Row 20252 => Predicted: 1\n",
      "Row 20253 => Predicted: 0\n",
      "Row 20254 => Predicted: 1\n",
      "Row 20255 => Predicted: 1\n",
      "Row 20256 => Predicted: 0\n",
      "Row 20257 => Predicted: 0\n",
      "Row 20258 => Predicted: 0\n",
      "Row 20259 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20250 to 20259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20260 => Predicted: 1\n",
      "Row 20261 => Predicted: 0\n",
      "Row 20262 => Predicted: 1\n",
      "Row 20263 => Predicted: 1\n",
      "Row 20264 => Predicted: 1\n",
      "Row 20265 => Predicted: 0\n",
      "Row 20266 => Predicted: 0\n",
      "Row 20267 => Predicted: 1\n",
      "Row 20268 => Predicted: 0\n",
      "Row 20269 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20260 to 20269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20270 => Predicted: 1\n",
      "Row 20271 => Predicted: 1\n",
      "Row 20272 => Predicted: 0\n",
      "Row 20273 => Predicted: 1\n",
      "Row 20274 => Predicted: 1\n",
      "Row 20275 => Predicted: 0\n",
      "Row 20276 => Predicted: 1\n",
      "Row 20277 => Predicted: 1\n",
      "Row 20278 => Predicted: 0\n",
      "Row 20279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20270 to 20279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20280 => Predicted: 0\n",
      "Row 20281 => Predicted: 1\n",
      "Row 20282 => Predicted: 0\n",
      "Row 20283 => Predicted: 1\n",
      "Row 20284 => Predicted: 1\n",
      "Row 20285 => Predicted: 0\n",
      "Row 20286 => Predicted: 0\n",
      "Row 20287 => Predicted: 0\n",
      "Row 20288 => Predicted: 1\n",
      "Row 20289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20280 to 20289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20290 => Predicted: 0\n",
      "Row 20291 => Predicted: 0\n",
      "Row 20292 => Predicted: 0\n",
      "Row 20293 => Predicted: 1\n",
      "Row 20294 => Predicted: 1\n",
      "Row 20295 => Predicted: 0\n",
      "Row 20296 => Predicted: 0\n",
      "Row 20297 => Predicted: 0\n",
      "Row 20298 => Predicted: 0\n",
      "Row 20299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20290 to 20299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20300 => Predicted: 0\n",
      "Row 20301 => Predicted: 0\n",
      "Row 20302 => Predicted: 0\n",
      "Row 20303 => Predicted: 0\n",
      "Row 20304 => Predicted: 0\n",
      "Row 20305 => Predicted: 1\n",
      "Row 20306 => Predicted: 1\n",
      "Row 20307 => Predicted: 0\n",
      "Row 20308 => Predicted: 1\n",
      "Row 20309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20300 to 20309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20310 => Predicted: 1\n",
      "Row 20311 => Predicted: 0\n",
      "Row 20312 => Predicted: 1\n",
      "Row 20313 => Predicted: 1\n",
      "Row 20314 => Predicted: 1\n",
      "Row 20315 => Predicted: 0\n",
      "Row 20316 => Predicted: 0\n",
      "Row 20317 => Predicted: 1\n",
      "Row 20318 => Predicted: 0\n",
      "Row 20319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20310 to 20319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20320 => Predicted: 0\n",
      "Row 20321 => Predicted: 1\n",
      "Row 20322 => Predicted: 0\n",
      "Row 20323 => Predicted: 1\n",
      "Row 20324 => Predicted: 0\n",
      "Row 20325 => Predicted: 0\n",
      "Row 20326 => Predicted: 1\n",
      "Row 20327 => Predicted: 1\n",
      "Row 20328 => Predicted: 1\n",
      "Row 20329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20320 to 20329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20330 => Predicted: 1\n",
      "Row 20331 => Predicted: 0\n",
      "Row 20332 => Predicted: 1\n",
      "Row 20333 => Predicted: 1\n",
      "Row 20334 => Predicted: 1\n",
      "Row 20335 => Predicted: 0\n",
      "Row 20336 => Predicted: 1\n",
      "Row 20337 => Predicted: 1\n",
      "Row 20338 => Predicted: 0\n",
      "Row 20339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20330 to 20339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20340 => Predicted: 1\n",
      "Row 20341 => Predicted: 0\n",
      "Row 20342 => Predicted: 0\n",
      "Row 20343 => Predicted: 0\n",
      "Row 20344 => Predicted: 0\n",
      "Row 20345 => Predicted: 0\n",
      "Row 20346 => Predicted: 0\n",
      "Row 20347 => Predicted: 1\n",
      "Row 20348 => Predicted: 1\n",
      "Row 20349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20340 to 20349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20350 => Predicted: 1\n",
      "Row 20351 => Predicted: 1\n",
      "Row 20352 => Predicted: 1\n",
      "Row 20353 => Predicted: 1\n",
      "Row 20354 => Predicted: 1\n",
      "Row 20355 => Predicted: 1\n",
      "Row 20356 => Predicted: 0\n",
      "Row 20357 => Predicted: 1\n",
      "Row 20358 => Predicted: 0\n",
      "Row 20359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20350 to 20359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20360 => Predicted: 1\n",
      "Row 20361 => Predicted: 1\n",
      "Row 20362 => Predicted: 1\n",
      "Row 20363 => Predicted: 0\n",
      "Row 20364 => Predicted: 0\n",
      "Row 20365 => Predicted: 1\n",
      "Row 20366 => Predicted: 1\n",
      "Row 20367 => Predicted: 1\n",
      "Row 20368 => Predicted: 1\n",
      "Row 20369 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20360 to 20369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20370 => Predicted: 0\n",
      "Row 20371 => Predicted: 0\n",
      "Row 20372 => Predicted: 0\n",
      "Row 20373 => Predicted: 0\n",
      "Row 20374 => Predicted: 0\n",
      "Row 20375 => Predicted: 0\n",
      "Row 20376 => Predicted: 0\n",
      "Row 20377 => Predicted: 1\n",
      "Row 20378 => Predicted: 1\n",
      "Row 20379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20370 to 20379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20380 => Predicted: 0\n",
      "Row 20381 => Predicted: 1\n",
      "Row 20382 => Predicted: 1\n",
      "Row 20383 => Predicted: 0\n",
      "Row 20384 => Predicted: 0\n",
      "Row 20385 => Predicted: 0\n",
      "Row 20386 => Predicted: 0\n",
      "Row 20387 => Predicted: 0\n",
      "Row 20388 => Predicted: 0\n",
      "Row 20389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20380 to 20389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20390 => Predicted: 0\n",
      "Row 20391 => Predicted: 0\n",
      "Row 20392 => Predicted: 0\n",
      "Row 20393 => Predicted: 0\n",
      "Row 20394 => Predicted: 0\n",
      "Row 20395 => Predicted: 1\n",
      "Row 20396 => Predicted: 0\n",
      "Row 20397 => Predicted: 1\n",
      "Row 20398 => Predicted: 1\n",
      "Row 20399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20390 to 20399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20400 => Predicted: 0\n",
      "Row 20401 => Predicted: 1\n",
      "Row 20402 => Predicted: 0\n",
      "Row 20403 => Predicted: 0\n",
      "Row 20404 => Predicted: 1\n",
      "Row 20405 => Predicted: 0\n",
      "Row 20406 => Predicted: 1\n",
      "Row 20407 => Predicted: 1\n",
      "Row 20408 => Predicted: 0\n",
      "Row 20409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20400 to 20409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20410 => Predicted: 0\n",
      "Row 20411 => Predicted: 1\n",
      "Row 20412 => Predicted: 1\n",
      "Row 20413 => Predicted: 1\n",
      "Row 20414 => Predicted: 1\n",
      "Row 20415 => Predicted: 1\n",
      "Row 20416 => Predicted: 0\n",
      "Row 20417 => Predicted: 0\n",
      "Row 20418 => Predicted: 1\n",
      "Row 20419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20410 to 20419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20420 => Predicted: 0\n",
      "Row 20421 => Predicted: 0\n",
      "Row 20422 => Predicted: 0\n",
      "Row 20423 => Predicted: 0\n",
      "Row 20424 => Predicted: 1\n",
      "Row 20425 => Predicted: 0\n",
      "Row 20426 => Predicted: 1\n",
      "Row 20427 => Predicted: 1\n",
      "Row 20428 => Predicted: 1\n",
      "Row 20429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20420 to 20429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20430 => Predicted: 0\n",
      "Row 20431 => Predicted: 1\n",
      "Row 20432 => Predicted: 1\n",
      "Row 20433 => Predicted: 0\n",
      "Row 20434 => Predicted: 1\n",
      "Row 20435 => Predicted: 1\n",
      "Row 20436 => Predicted: 0\n",
      "Row 20437 => Predicted: 0\n",
      "Row 20438 => Predicted: 0\n",
      "Row 20439 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20430 to 20439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20440 => Predicted: 1\n",
      "Row 20441 => Predicted: 1\n",
      "Row 20442 => Predicted: 1\n",
      "Row 20443 => Predicted: 1\n",
      "Row 20444 => Predicted: 1\n",
      "Row 20445 => Predicted: 0\n",
      "Row 20446 => Predicted: 1\n",
      "Row 20447 => Predicted: 0\n",
      "Row 20448 => Predicted: 1\n",
      "Row 20449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20440 to 20449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20450 => Predicted: 1\n",
      "Row 20451 => Predicted: 0\n",
      "Row 20452 => Predicted: 1\n",
      "Row 20453 => Predicted: 1\n",
      "Row 20454 => Predicted: 1\n",
      "Row 20455 => Predicted: 1\n",
      "Row 20456 => Predicted: 0\n",
      "Row 20457 => Predicted: 1\n",
      "Row 20458 => Predicted: 1\n",
      "Row 20459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20450 to 20459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20460 => Predicted: 0\n",
      "Row 20461 => Predicted: 1\n",
      "Row 20462 => Predicted: 0\n",
      "Row 20463 => Predicted: 0\n",
      "Row 20464 => Predicted: 0\n",
      "Row 20465 => Predicted: 0\n",
      "Row 20466 => Predicted: 1\n",
      "Row 20467 => Predicted: 0\n",
      "Row 20468 => Predicted: 1\n",
      "Row 20469 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20460 to 20469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20470 => Predicted: 0\n",
      "Row 20471 => Predicted: 0\n",
      "Row 20472 => Predicted: 0\n",
      "Row 20473 => Predicted: 0\n",
      "Row 20474 => Predicted: 1\n",
      "Row 20475 => Predicted: 1\n",
      "Row 20476 => Predicted: 1\n",
      "Row 20477 => Predicted: 0\n",
      "Row 20478 => Predicted: 0\n",
      "Row 20479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20470 to 20479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20480 => Predicted: 0\n",
      "Row 20481 => Predicted: 1\n",
      "Row 20482 => Predicted: 0\n",
      "Row 20483 => Predicted: 0\n",
      "Row 20484 => Predicted: 0\n",
      "Row 20485 => Predicted: 1\n",
      "Row 20486 => Predicted: 0\n",
      "Row 20487 => Predicted: 0\n",
      "Row 20488 => Predicted: 0\n",
      "Row 20489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20480 to 20489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20490 => Predicted: 1\n",
      "Row 20491 => Predicted: 1\n",
      "Row 20492 => Predicted: 1\n",
      "Row 20493 => Predicted: 0\n",
      "Row 20494 => Predicted: 1\n",
      "Row 20495 => Predicted: 0\n",
      "Row 20496 => Predicted: 0\n",
      "Row 20497 => Predicted: 1\n",
      "Row 20498 => Predicted: 1\n",
      "Row 20499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20490 to 20499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20500 => Predicted: 1\n",
      "Row 20501 => Predicted: 0\n",
      "Row 20502 => Predicted: 0\n",
      "Row 20503 => Predicted: 0\n",
      "Row 20504 => Predicted: 1\n",
      "Row 20505 => Predicted: 1\n",
      "Row 20506 => Predicted: 1\n",
      "Row 20507 => Predicted: 0\n",
      "Row 20508 => Predicted: 0\n",
      "Row 20509 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20500 to 20509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20510 => Predicted: 0\n",
      "Row 20511 => Predicted: 1\n",
      "Row 20512 => Predicted: 1\n",
      "Row 20513 => Predicted: 1\n",
      "Row 20514 => Predicted: 0\n",
      "Row 20515 => Predicted: 1\n",
      "Row 20516 => Predicted: 1\n",
      "Row 20517 => Predicted: 0\n",
      "Row 20518 => Predicted: 1\n",
      "Row 20519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20510 to 20519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20520 => Predicted: 1\n",
      "Row 20521 => Predicted: 1\n",
      "Row 20522 => Predicted: 1\n",
      "Row 20523 => Predicted: 0\n",
      "Row 20524 => Predicted: 0\n",
      "Row 20525 => Predicted: 0\n",
      "Row 20526 => Predicted: 1\n",
      "Row 20527 => Predicted: 0\n",
      "Row 20528 => Predicted: 1\n",
      "Row 20529 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20520 to 20529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20530 => Predicted: 0\n",
      "Row 20531 => Predicted: 1\n",
      "Row 20532 => Predicted: 0\n",
      "Row 20533 => Predicted: 0\n",
      "Row 20534 => Predicted: 0\n",
      "Row 20535 => Predicted: 0\n",
      "Row 20536 => Predicted: 1\n",
      "Row 20537 => Predicted: 0\n",
      "Row 20538 => Predicted: 0\n",
      "Row 20539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20530 to 20539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20540 => Predicted: 1\n",
      "Row 20541 => Predicted: 1\n",
      "Row 20542 => Predicted: 1\n",
      "Row 20543 => Predicted: 1\n",
      "Row 20544 => Predicted: 0\n",
      "Row 20545 => Predicted: 0\n",
      "Row 20546 => Predicted: 0\n",
      "Row 20547 => Predicted: 1\n",
      "Row 20548 => Predicted: 1\n",
      "Row 20549 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20540 to 20549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20550 => Predicted: 0\n",
      "Row 20551 => Predicted: 0\n",
      "Row 20552 => Predicted: 0\n",
      "Row 20553 => Predicted: 0\n",
      "Row 20554 => Predicted: 1\n",
      "Row 20555 => Predicted: 1\n",
      "Row 20556 => Predicted: 1\n",
      "Row 20557 => Predicted: 0\n",
      "Row 20558 => Predicted: 0\n",
      "Row 20559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20550 to 20559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20560 => Predicted: 0\n",
      "Row 20561 => Predicted: 0\n",
      "Row 20562 => Predicted: 0\n",
      "Row 20563 => Predicted: 1\n",
      "Row 20564 => Predicted: 0\n",
      "Row 20565 => Predicted: 1\n",
      "Row 20566 => Predicted: 0\n",
      "Row 20567 => Predicted: 0\n",
      "Row 20568 => Predicted: 0\n",
      "Row 20569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20560 to 20569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20570 => Predicted: 1\n",
      "Row 20571 => Predicted: 1\n",
      "Row 20572 => Predicted: 1\n",
      "Row 20573 => Predicted: 1\n",
      "Row 20574 => Predicted: 0\n",
      "Row 20575 => Predicted: 0\n",
      "Row 20576 => Predicted: 1\n",
      "Row 20577 => Predicted: 1\n",
      "Row 20578 => Predicted: 1\n",
      "Row 20579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20570 to 20579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20580 => Predicted: 0\n",
      "Row 20581 => Predicted: 1\n",
      "Row 20582 => Predicted: 1\n",
      "Row 20583 => Predicted: 1\n",
      "Row 20584 => Predicted: 0\n",
      "Row 20585 => Predicted: 1\n",
      "Row 20586 => Predicted: 1\n",
      "Row 20587 => Predicted: 0\n",
      "Row 20588 => Predicted: 1\n",
      "Row 20589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20580 to 20589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20590 => Predicted: 0\n",
      "Row 20591 => Predicted: 1\n",
      "Row 20592 => Predicted: 0\n",
      "Row 20593 => Predicted: 1\n",
      "Row 20594 => Predicted: 0\n",
      "Row 20595 => Predicted: 1\n",
      "Row 20596 => Predicted: 0\n",
      "Row 20597 => Predicted: 1\n",
      "Row 20598 => Predicted: 1\n",
      "Row 20599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20590 to 20599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20600 => Predicted: 0\n",
      "Row 20601 => Predicted: 1\n",
      "Row 20602 => Predicted: 0\n",
      "Row 20603 => Predicted: 0\n",
      "Row 20604 => Predicted: 1\n",
      "Row 20605 => Predicted: 1\n",
      "Row 20606 => Predicted: 0\n",
      "Row 20607 => Predicted: 1\n",
      "Row 20608 => Predicted: 0\n",
      "Row 20609 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20600 to 20609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20610 => Predicted: 0\n",
      "Row 20611 => Predicted: 1\n",
      "Row 20612 => Predicted: 1\n",
      "Row 20613 => Predicted: 1\n",
      "Row 20614 => Predicted: 0\n",
      "Row 20615 => Predicted: 1\n",
      "Row 20616 => Predicted: 0\n",
      "Row 20617 => Predicted: 0\n",
      "Row 20618 => Predicted: 1\n",
      "Row 20619 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20610 to 20619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20620 => Predicted: 0\n",
      "Row 20621 => Predicted: 1\n",
      "Row 20622 => Predicted: 1\n",
      "Row 20623 => Predicted: 0\n",
      "Row 20624 => Predicted: 1\n",
      "Row 20625 => Predicted: 0\n",
      "Row 20626 => Predicted: 0\n",
      "Row 20627 => Predicted: 0\n",
      "Row 20628 => Predicted: 1\n",
      "Row 20629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20620 to 20629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20630 => Predicted: 0\n",
      "Row 20631 => Predicted: 0\n",
      "Row 20632 => Predicted: 0\n",
      "Row 20633 => Predicted: 1\n",
      "Row 20634 => Predicted: 1\n",
      "Row 20635 => Predicted: 0\n",
      "Row 20636 => Predicted: 1\n",
      "Row 20637 => Predicted: 0\n",
      "Row 20638 => Predicted: 1\n",
      "Row 20639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20630 to 20639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20640 => Predicted: 1\n",
      "Row 20641 => Predicted: 1\n",
      "Row 20642 => Predicted: 0\n",
      "Row 20643 => Predicted: 1\n",
      "Row 20644 => Predicted: 1\n",
      "Row 20645 => Predicted: 0\n",
      "Row 20646 => Predicted: 0\n",
      "Row 20647 => Predicted: 1\n",
      "Row 20648 => Predicted: 0\n",
      "Row 20649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20640 to 20649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20650 => Predicted: 0\n",
      "Row 20651 => Predicted: 1\n",
      "Row 20652 => Predicted: 1\n",
      "Row 20653 => Predicted: 1\n",
      "Row 20654 => Predicted: 1\n",
      "Row 20655 => Predicted: 1\n",
      "Row 20656 => Predicted: 1\n",
      "Row 20657 => Predicted: 0\n",
      "Row 20658 => Predicted: 0\n",
      "Row 20659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20650 to 20659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20660 => Predicted: 0\n",
      "Row 20661 => Predicted: 0\n",
      "Row 20662 => Predicted: 1\n",
      "Row 20663 => Predicted: 1\n",
      "Row 20664 => Predicted: 1\n",
      "Row 20665 => Predicted: 0\n",
      "Row 20666 => Predicted: 0\n",
      "Row 20667 => Predicted: 1\n",
      "Row 20668 => Predicted: 0\n",
      "Row 20669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20660 to 20669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20670 => Predicted: 0\n",
      "Row 20671 => Predicted: 0\n",
      "Row 20672 => Predicted: 0\n",
      "Row 20673 => Predicted: 0\n",
      "Row 20674 => Predicted: 1\n",
      "Row 20675 => Predicted: 1\n",
      "Row 20676 => Predicted: 1\n",
      "Row 20677 => Predicted: 0\n",
      "Row 20678 => Predicted: 1\n",
      "Row 20679 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20670 to 20679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20680 => Predicted: 1\n",
      "Row 20681 => Predicted: 0\n",
      "Row 20682 => Predicted: 0\n",
      "Row 20683 => Predicted: 0\n",
      "Row 20684 => Predicted: 0\n",
      "Row 20685 => Predicted: 1\n",
      "Row 20686 => Predicted: 0\n",
      "Row 20687 => Predicted: 0\n",
      "Row 20688 => Predicted: 1\n",
      "Row 20689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20680 to 20689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20690 => Predicted: 1\n",
      "Row 20691 => Predicted: 0\n",
      "Row 20692 => Predicted: 0\n",
      "Row 20693 => Predicted: 1\n",
      "Row 20694 => Predicted: 1\n",
      "Row 20695 => Predicted: 0\n",
      "Row 20696 => Predicted: 0\n",
      "Row 20697 => Predicted: 1\n",
      "Row 20698 => Predicted: 0\n",
      "Row 20699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20690 to 20699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20700 => Predicted: 0\n",
      "Row 20701 => Predicted: 1\n",
      "Row 20702 => Predicted: 0\n",
      "Row 20703 => Predicted: 1\n",
      "Row 20704 => Predicted: 1\n",
      "Row 20705 => Predicted: 0\n",
      "Row 20706 => Predicted: 1\n",
      "Row 20707 => Predicted: 0\n",
      "Row 20708 => Predicted: 1\n",
      "Row 20709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20700 to 20709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20710 => Predicted: 0\n",
      "Row 20711 => Predicted: 0\n",
      "Row 20712 => Predicted: 0\n",
      "Row 20713 => Predicted: 0\n",
      "Row 20714 => Predicted: 0\n",
      "Row 20715 => Predicted: 1\n",
      "Row 20716 => Predicted: 0\n",
      "Row 20717 => Predicted: 0\n",
      "Row 20718 => Predicted: 0\n",
      "Row 20719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20710 to 20719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20720 => Predicted: 0\n",
      "Row 20721 => Predicted: 0\n",
      "Row 20722 => Predicted: 0\n",
      "Row 20723 => Predicted: 0\n",
      "Row 20724 => Predicted: 0\n",
      "Row 20725 => Predicted: 1\n",
      "Row 20726 => Predicted: 1\n",
      "Row 20727 => Predicted: 1\n",
      "Row 20728 => Predicted: 1\n",
      "Row 20729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20720 to 20729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20730 => Predicted: 0\n",
      "Row 20731 => Predicted: 0\n",
      "Row 20732 => Predicted: 0\n",
      "Row 20733 => Predicted: 1\n",
      "Row 20734 => Predicted: 0\n",
      "Row 20735 => Predicted: 0\n",
      "Row 20736 => Predicted: 0\n",
      "Row 20737 => Predicted: 0\n",
      "Row 20738 => Predicted: 1\n",
      "Row 20739 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20730 to 20739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20740 => Predicted: 1\n",
      "Row 20741 => Predicted: 1\n",
      "Row 20742 => Predicted: 1\n",
      "Row 20743 => Predicted: 0\n",
      "Row 20744 => Predicted: 0\n",
      "Row 20745 => Predicted: 1\n",
      "Row 20746 => Predicted: 1\n",
      "Row 20747 => Predicted: 0\n",
      "Row 20748 => Predicted: 1\n",
      "Row 20749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20740 to 20749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20750 => Predicted: 0\n",
      "Row 20751 => Predicted: 0\n",
      "Row 20752 => Predicted: 0\n",
      "Row 20753 => Predicted: 1\n",
      "Row 20754 => Predicted: 0\n",
      "Row 20755 => Predicted: 0\n",
      "Row 20756 => Predicted: 1\n",
      "Row 20757 => Predicted: 0\n",
      "Row 20758 => Predicted: 1\n",
      "Row 20759 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20750 to 20759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20760 => Predicted: 0\n",
      "Row 20761 => Predicted: 0\n",
      "Row 20762 => Predicted: 0\n",
      "Row 20763 => Predicted: 1\n",
      "Row 20764 => Predicted: 0\n",
      "Row 20765 => Predicted: 0\n",
      "Row 20766 => Predicted: 1\n",
      "Row 20767 => Predicted: 0\n",
      "Row 20768 => Predicted: 1\n",
      "Row 20769 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20760 to 20769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20770 => Predicted: 1\n",
      "Row 20771 => Predicted: 0\n",
      "Row 20772 => Predicted: 0\n",
      "Row 20773 => Predicted: 1\n",
      "Row 20774 => Predicted: 0\n",
      "Row 20775 => Predicted: 1\n",
      "Row 20776 => Predicted: 1\n",
      "Row 20777 => Predicted: 1\n",
      "Row 20778 => Predicted: 0\n",
      "Row 20779 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20770 to 20779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20780 => Predicted: 1\n",
      "Row 20781 => Predicted: 1\n",
      "Row 20782 => Predicted: 0\n",
      "Row 20783 => Predicted: 1\n",
      "Row 20784 => Predicted: 0\n",
      "Row 20785 => Predicted: 1\n",
      "Row 20786 => Predicted: 0\n",
      "Row 20787 => Predicted: 0\n",
      "Row 20788 => Predicted: 1\n",
      "Row 20789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20780 to 20789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20790 => Predicted: 1\n",
      "Row 20791 => Predicted: 0\n",
      "Row 20792 => Predicted: 0\n",
      "Row 20793 => Predicted: 0\n",
      "Row 20794 => Predicted: 0\n",
      "Row 20795 => Predicted: 1\n",
      "Row 20796 => Predicted: 1\n",
      "Row 20797 => Predicted: 0\n",
      "Row 20798 => Predicted: 0\n",
      "Row 20799 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20790 to 20799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20800 => Predicted: 1\n",
      "Row 20801 => Predicted: 0\n",
      "Row 20802 => Predicted: 1\n",
      "Row 20803 => Predicted: 0\n",
      "Row 20804 => Predicted: 0\n",
      "Row 20805 => Predicted: 0\n",
      "Row 20806 => Predicted: 0\n",
      "Row 20807 => Predicted: 1\n",
      "Row 20808 => Predicted: 1\n",
      "Row 20809 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20800 to 20809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20810 => Predicted: 1\n",
      "Row 20811 => Predicted: 1\n",
      "Row 20812 => Predicted: 1\n",
      "Row 20813 => Predicted: 1\n",
      "Row 20814 => Predicted: 1\n",
      "Row 20815 => Predicted: 1\n",
      "Row 20816 => Predicted: 0\n",
      "Row 20817 => Predicted: 0\n",
      "Row 20818 => Predicted: 1\n",
      "Row 20819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20810 to 20819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20820 => Predicted: 0\n",
      "Row 20821 => Predicted: 1\n",
      "Row 20822 => Predicted: 1\n",
      "Row 20823 => Predicted: 1\n",
      "Row 20824 => Predicted: 1\n",
      "Row 20825 => Predicted: 1\n",
      "Row 20826 => Predicted: 1\n",
      "Row 20827 => Predicted: 1\n",
      "Row 20828 => Predicted: 0\n",
      "Row 20829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20820 to 20829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20830 => Predicted: 1\n",
      "Row 20831 => Predicted: 1\n",
      "Row 20832 => Predicted: 0\n",
      "Row 20833 => Predicted: 0\n",
      "Row 20834 => Predicted: 0\n",
      "Row 20835 => Predicted: 0\n",
      "Row 20836 => Predicted: 1\n",
      "Row 20837 => Predicted: 0\n",
      "Row 20838 => Predicted: 0\n",
      "Row 20839 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20830 to 20839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20840 => Predicted: 1\n",
      "Row 20841 => Predicted: 0\n",
      "Row 20842 => Predicted: 0\n",
      "Row 20843 => Predicted: 1\n",
      "Row 20844 => Predicted: 0\n",
      "Row 20845 => Predicted: 0\n",
      "Row 20846 => Predicted: 0\n",
      "Row 20847 => Predicted: 1\n",
      "Row 20848 => Predicted: 1\n",
      "Row 20849 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20840 to 20849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20850 => Predicted: 0\n",
      "Row 20851 => Predicted: 1\n",
      "Row 20852 => Predicted: 0\n",
      "Row 20853 => Predicted: 0\n",
      "Row 20854 => Predicted: 0\n",
      "Row 20855 => Predicted: 1\n",
      "Row 20856 => Predicted: 1\n",
      "Row 20857 => Predicted: 1\n",
      "Row 20858 => Predicted: 0\n",
      "Row 20859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20850 to 20859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20860 => Predicted: 1\n",
      "Row 20861 => Predicted: 1\n",
      "Row 20862 => Predicted: 0\n",
      "Row 20863 => Predicted: 0\n",
      "Row 20864 => Predicted: 1\n",
      "Row 20865 => Predicted: 0\n",
      "Row 20866 => Predicted: 0\n",
      "Row 20867 => Predicted: 1\n",
      "Row 20868 => Predicted: 0\n",
      "Row 20869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20860 to 20869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20870 => Predicted: 1\n",
      "Row 20871 => Predicted: 1\n",
      "Row 20872 => Predicted: 1\n",
      "Row 20873 => Predicted: 1\n",
      "Row 20874 => Predicted: 1\n",
      "Row 20875 => Predicted: 1\n",
      "Row 20876 => Predicted: 1\n",
      "Row 20877 => Predicted: 0\n",
      "Row 20878 => Predicted: 1\n",
      "Row 20879 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20870 to 20879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20880 => Predicted: 1\n",
      "Row 20881 => Predicted: 0\n",
      "Row 20882 => Predicted: 1\n",
      "Row 20883 => Predicted: 1\n",
      "Row 20884 => Predicted: 0\n",
      "Row 20885 => Predicted: 0\n",
      "Row 20886 => Predicted: 0\n",
      "Row 20887 => Predicted: 0\n",
      "Row 20888 => Predicted: 1\n",
      "Row 20889 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20880 to 20889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20890 => Predicted: 1\n",
      "Row 20891 => Predicted: 1\n",
      "Row 20892 => Predicted: 1\n",
      "Row 20893 => Predicted: 0\n",
      "Row 20894 => Predicted: 1\n",
      "Row 20895 => Predicted: 1\n",
      "Row 20896 => Predicted: 1\n",
      "Row 20897 => Predicted: 1\n",
      "Row 20898 => Predicted: 1\n",
      "Row 20899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20890 to 20899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20900 => Predicted: 0\n",
      "Row 20901 => Predicted: 0\n",
      "Row 20902 => Predicted: 0\n",
      "Row 20903 => Predicted: 1\n",
      "Row 20904 => Predicted: 0\n",
      "Row 20905 => Predicted: 1\n",
      "Row 20906 => Predicted: 1\n",
      "Row 20907 => Predicted: 1\n",
      "Row 20908 => Predicted: 1\n",
      "Row 20909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20900 to 20909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20910 => Predicted: 1\n",
      "Row 20911 => Predicted: 1\n",
      "Row 20912 => Predicted: 1\n",
      "Row 20913 => Predicted: 1\n",
      "Row 20914 => Predicted: 0\n",
      "Row 20915 => Predicted: 0\n",
      "Row 20916 => Predicted: 1\n",
      "Row 20917 => Predicted: 0\n",
      "Row 20918 => Predicted: 1\n",
      "Row 20919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20910 to 20919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20920 => Predicted: 1\n",
      "Row 20921 => Predicted: 0\n",
      "Row 20922 => Predicted: 1\n",
      "Row 20923 => Predicted: 1\n",
      "Row 20924 => Predicted: 0\n",
      "Row 20925 => Predicted: 0\n",
      "Row 20926 => Predicted: 1\n",
      "Row 20927 => Predicted: 1\n",
      "Row 20928 => Predicted: 1\n",
      "Row 20929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20920 to 20929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20930 => Predicted: 0\n",
      "Row 20931 => Predicted: 1\n",
      "Row 20932 => Predicted: 0\n",
      "Row 20933 => Predicted: 1\n",
      "Row 20934 => Predicted: 0\n",
      "Row 20935 => Predicted: 0\n",
      "Row 20936 => Predicted: 1\n",
      "Row 20937 => Predicted: 1\n",
      "Row 20938 => Predicted: 1\n",
      "Row 20939 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20930 to 20939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20940 => Predicted: 0\n",
      "Row 20941 => Predicted: 1\n",
      "Row 20942 => Predicted: 1\n",
      "Row 20943 => Predicted: 1\n",
      "Row 20944 => Predicted: 1\n",
      "Row 20945 => Predicted: 0\n",
      "Row 20946 => Predicted: 1\n",
      "Row 20947 => Predicted: 0\n",
      "Row 20948 => Predicted: 0\n",
      "Row 20949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20940 to 20949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20950 => Predicted: 1\n",
      "Row 20951 => Predicted: 1\n",
      "Row 20952 => Predicted: 1\n",
      "Row 20953 => Predicted: 0\n",
      "Row 20954 => Predicted: 0\n",
      "Row 20955 => Predicted: 0\n",
      "Row 20956 => Predicted: 1\n",
      "Row 20957 => Predicted: 1\n",
      "Row 20958 => Predicted: 1\n",
      "Row 20959 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20950 to 20959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20960 => Predicted: 1\n",
      "Row 20961 => Predicted: 1\n",
      "Row 20962 => Predicted: 1\n",
      "Row 20963 => Predicted: 1\n",
      "Row 20964 => Predicted: 0\n",
      "Row 20965 => Predicted: 1\n",
      "Row 20966 => Predicted: 0\n",
      "Row 20967 => Predicted: 0\n",
      "Row 20968 => Predicted: 0\n",
      "Row 20969 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20960 to 20969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20970 => Predicted: 0\n",
      "Row 20971 => Predicted: 0\n",
      "Row 20972 => Predicted: 0\n",
      "Row 20973 => Predicted: 0\n",
      "Row 20974 => Predicted: 0\n",
      "Row 20975 => Predicted: 1\n",
      "Row 20976 => Predicted: 1\n",
      "Row 20977 => Predicted: 0\n",
      "Row 20978 => Predicted: 1\n",
      "Row 20979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20970 to 20979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20980 => Predicted: 1\n",
      "Row 20981 => Predicted: 1\n",
      "Row 20982 => Predicted: 1\n",
      "Row 20983 => Predicted: 1\n",
      "Row 20984 => Predicted: 1\n",
      "Row 20985 => Predicted: 1\n",
      "Row 20986 => Predicted: 0\n",
      "Row 20987 => Predicted: 1\n",
      "Row 20988 => Predicted: 0\n",
      "Row 20989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 20980 to 20989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20990 => Predicted: 1\n",
      "Row 20991 => Predicted: 0\n",
      "Row 20992 => Predicted: 1\n",
      "Row 20993 => Predicted: 0\n",
      "Row 20994 => Predicted: 1\n",
      "Row 20995 => Predicted: 1\n",
      "Row 20996 => Predicted: 1\n",
      "Row 20997 => Predicted: 0\n",
      "Row 20998 => Predicted: 0\n",
      "Row 20999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 20990 to 20999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21000 => Predicted: 1\n",
      "Row 21001 => Predicted: 1\n",
      "Row 21002 => Predicted: 1\n",
      "Row 21003 => Predicted: 0\n",
      "Row 21004 => Predicted: 1\n",
      "Row 21005 => Predicted: 0\n",
      "Row 21006 => Predicted: 0\n",
      "Row 21007 => Predicted: 0\n",
      "Row 21008 => Predicted: 1\n",
      "Row 21009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21000 to 21009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21010 => Predicted: 1\n",
      "Row 21011 => Predicted: 1\n",
      "Row 21012 => Predicted: 1\n",
      "Row 21013 => Predicted: 0\n",
      "Row 21014 => Predicted: 0\n",
      "Row 21015 => Predicted: 0\n",
      "Row 21016 => Predicted: 0\n",
      "Row 21017 => Predicted: 0\n",
      "Row 21018 => Predicted: 0\n",
      "Row 21019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21010 to 21019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21020 => Predicted: 0\n",
      "Row 21021 => Predicted: 1\n",
      "Row 21022 => Predicted: 1\n",
      "Row 21023 => Predicted: 0\n",
      "Row 21024 => Predicted: 1\n",
      "Row 21025 => Predicted: 0\n",
      "Row 21026 => Predicted: 0\n",
      "Row 21027 => Predicted: 0\n",
      "Row 21028 => Predicted: 0\n",
      "Row 21029 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21020 to 21029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21030 => Predicted: 0\n",
      "Row 21031 => Predicted: 0\n",
      "Row 21032 => Predicted: 0\n",
      "Row 21033 => Predicted: 0\n",
      "Row 21034 => Predicted: 1\n",
      "Row 21035 => Predicted: 0\n",
      "Row 21036 => Predicted: 1\n",
      "Row 21037 => Predicted: 1\n",
      "Row 21038 => Predicted: 1\n",
      "Row 21039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21030 to 21039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21040 => Predicted: 1\n",
      "Row 21041 => Predicted: 1\n",
      "Row 21042 => Predicted: 1\n",
      "Row 21043 => Predicted: 0\n",
      "Row 21044 => Predicted: 0\n",
      "Row 21045 => Predicted: 1\n",
      "Row 21046 => Predicted: 1\n",
      "Row 21047 => Predicted: 1\n",
      "Row 21048 => Predicted: 1\n",
      "Row 21049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21040 to 21049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21050 => Predicted: 0\n",
      "Row 21051 => Predicted: 0\n",
      "Row 21052 => Predicted: 1\n",
      "Row 21053 => Predicted: 1\n",
      "Row 21054 => Predicted: 0\n",
      "Row 21055 => Predicted: 1\n",
      "Row 21056 => Predicted: 0\n",
      "Row 21057 => Predicted: 1\n",
      "Row 21058 => Predicted: 1\n",
      "Row 21059 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21050 to 21059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21060 => Predicted: 1\n",
      "Row 21061 => Predicted: 0\n",
      "Row 21062 => Predicted: 1\n",
      "Row 21063 => Predicted: 0\n",
      "Row 21064 => Predicted: 1\n",
      "Row 21065 => Predicted: 0\n",
      "Row 21066 => Predicted: 1\n",
      "Row 21067 => Predicted: 0\n",
      "Row 21068 => Predicted: 1\n",
      "Row 21069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21060 to 21069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21070 => Predicted: 1\n",
      "Row 21071 => Predicted: 1\n",
      "Row 21072 => Predicted: 0\n",
      "Row 21073 => Predicted: 0\n",
      "Row 21074 => Predicted: 0\n",
      "Row 21075 => Predicted: 1\n",
      "Row 21076 => Predicted: 0\n",
      "Row 21077 => Predicted: 0\n",
      "Row 21078 => Predicted: 0\n",
      "Row 21079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21070 to 21079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21080 => Predicted: 0\n",
      "Row 21081 => Predicted: 1\n",
      "Row 21082 => Predicted: 1\n",
      "Row 21083 => Predicted: 0\n",
      "Row 21084 => Predicted: 0\n",
      "Row 21085 => Predicted: 1\n",
      "Row 21086 => Predicted: 0\n",
      "Row 21087 => Predicted: 1\n",
      "Row 21088 => Predicted: 0\n",
      "Row 21089 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21080 to 21089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21090 => Predicted: 1\n",
      "Row 21091 => Predicted: 1\n",
      "Row 21092 => Predicted: 1\n",
      "Row 21093 => Predicted: 1\n",
      "Row 21094 => Predicted: 0\n",
      "Row 21095 => Predicted: 0\n",
      "Row 21096 => Predicted: 0\n",
      "Row 21097 => Predicted: 0\n",
      "Row 21098 => Predicted: 0\n",
      "Row 21099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21090 to 21099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21100 => Predicted: 0\n",
      "Row 21101 => Predicted: 1\n",
      "Row 21102 => Predicted: 1\n",
      "Row 21103 => Predicted: 0\n",
      "Row 21104 => Predicted: 0\n",
      "Row 21105 => Predicted: 0\n",
      "Row 21106 => Predicted: 0\n",
      "Row 21107 => Predicted: 1\n",
      "Row 21108 => Predicted: 1\n",
      "Row 21109 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21100 to 21109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21110 => Predicted: 0\n",
      "Row 21111 => Predicted: 1\n",
      "Row 21112 => Predicted: 1\n",
      "Row 21113 => Predicted: 0\n",
      "Row 21114 => Predicted: 0\n",
      "Row 21115 => Predicted: 1\n",
      "Row 21116 => Predicted: 0\n",
      "Row 21117 => Predicted: 0\n",
      "Row 21118 => Predicted: 0\n",
      "Row 21119 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21110 to 21119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21120 => Predicted: 0\n",
      "Row 21121 => Predicted: 1\n",
      "Row 21122 => Predicted: 1\n",
      "Row 21123 => Predicted: 1\n",
      "Row 21124 => Predicted: 1\n",
      "Row 21125 => Predicted: 0\n",
      "Row 21126 => Predicted: 1\n",
      "Row 21127 => Predicted: 1\n",
      "Row 21128 => Predicted: 1\n",
      "Row 21129 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21120 to 21129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21130 => Predicted: 0\n",
      "Row 21131 => Predicted: 1\n",
      "Row 21132 => Predicted: 1\n",
      "Row 21133 => Predicted: 1\n",
      "Row 21134 => Predicted: 0\n",
      "Row 21135 => Predicted: 1\n",
      "Row 21136 => Predicted: 0\n",
      "Row 21137 => Predicted: 1\n",
      "Row 21138 => Predicted: 0\n",
      "Row 21139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21130 to 21139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21140 => Predicted: 0\n",
      "Row 21141 => Predicted: 0\n",
      "Row 21142 => Predicted: 0\n",
      "Row 21143 => Predicted: 1\n",
      "Row 21144 => Predicted: 1\n",
      "Row 21145 => Predicted: 1\n",
      "Row 21146 => Predicted: 0\n",
      "Row 21147 => Predicted: 1\n",
      "Row 21148 => Predicted: 0\n",
      "Row 21149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21140 to 21149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21150 => Predicted: 0\n",
      "Row 21151 => Predicted: 0\n",
      "Row 21152 => Predicted: 1\n",
      "Row 21153 => Predicted: 1\n",
      "Row 21154 => Predicted: 0\n",
      "Row 21155 => Predicted: 1\n",
      "Row 21156 => Predicted: 0\n",
      "Row 21157 => Predicted: 0\n",
      "Row 21158 => Predicted: 0\n",
      "Row 21159 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21150 to 21159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21160 => Predicted: 0\n",
      "Row 21161 => Predicted: 1\n",
      "Row 21162 => Predicted: 1\n",
      "Row 21163 => Predicted: 1\n",
      "Row 21164 => Predicted: 1\n",
      "Row 21165 => Predicted: 1\n",
      "Row 21166 => Predicted: 1\n",
      "Row 21167 => Predicted: 0\n",
      "Row 21168 => Predicted: 1\n",
      "Row 21169 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21160 to 21169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21170 => Predicted: 0\n",
      "Row 21171 => Predicted: 1\n",
      "Row 21172 => Predicted: 0\n",
      "Row 21173 => Predicted: 0\n",
      "Row 21174 => Predicted: 0\n",
      "Row 21175 => Predicted: 0\n",
      "Row 21176 => Predicted: 0\n",
      "Row 21177 => Predicted: 0\n",
      "Row 21178 => Predicted: 1\n",
      "Row 21179 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21170 to 21179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21180 => Predicted: 1\n",
      "Row 21181 => Predicted: 1\n",
      "Row 21182 => Predicted: 1\n",
      "Row 21183 => Predicted: 1\n",
      "Row 21184 => Predicted: 0\n",
      "Row 21185 => Predicted: 1\n",
      "Row 21186 => Predicted: 0\n",
      "Row 21187 => Predicted: 0\n",
      "Row 21188 => Predicted: 0\n",
      "Row 21189 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21180 to 21189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21190 => Predicted: 0\n",
      "Row 21191 => Predicted: 0\n",
      "Row 21192 => Predicted: 1\n",
      "Row 21193 => Predicted: 0\n",
      "Row 21194 => Predicted: 1\n",
      "Row 21195 => Predicted: 0\n",
      "Row 21196 => Predicted: 0\n",
      "Row 21197 => Predicted: 1\n",
      "Row 21198 => Predicted: 1\n",
      "Row 21199 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21190 to 21199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21200 => Predicted: 1\n",
      "Row 21201 => Predicted: 1\n",
      "Row 21202 => Predicted: 1\n",
      "Row 21203 => Predicted: 1\n",
      "Row 21204 => Predicted: 1\n",
      "Row 21205 => Predicted: 0\n",
      "Row 21206 => Predicted: 0\n",
      "Row 21207 => Predicted: 0\n",
      "Row 21208 => Predicted: 1\n",
      "Row 21209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21200 to 21209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21210 => Predicted: 0\n",
      "Row 21211 => Predicted: 1\n",
      "Row 21212 => Predicted: 0\n",
      "Row 21213 => Predicted: 1\n",
      "Row 21214 => Predicted: 0\n",
      "Row 21215 => Predicted: 1\n",
      "Row 21216 => Predicted: 1\n",
      "Row 21217 => Predicted: 1\n",
      "Row 21218 => Predicted: 1\n",
      "Row 21219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21210 to 21219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21220 => Predicted: 0\n",
      "Row 21221 => Predicted: 1\n",
      "Row 21222 => Predicted: 0\n",
      "Row 21223 => Predicted: 0\n",
      "Row 21224 => Predicted: 1\n",
      "Row 21225 => Predicted: 0\n",
      "Row 21226 => Predicted: 0\n",
      "Row 21227 => Predicted: 1\n",
      "Row 21228 => Predicted: 1\n",
      "Row 21229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21220 to 21229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21230 => Predicted: 0\n",
      "Row 21231 => Predicted: 1\n",
      "Row 21232 => Predicted: 1\n",
      "Row 21233 => Predicted: 0\n",
      "Row 21234 => Predicted: 0\n",
      "Row 21235 => Predicted: 0\n",
      "Row 21236 => Predicted: 1\n",
      "Row 21237 => Predicted: 0\n",
      "Row 21238 => Predicted: 1\n",
      "Row 21239 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21230 to 21239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21240 => Predicted: 1\n",
      "Row 21241 => Predicted: 1\n",
      "Row 21242 => Predicted: 1\n",
      "Row 21243 => Predicted: 0\n",
      "Row 21244 => Predicted: 0\n",
      "Row 21245 => Predicted: 1\n",
      "Row 21246 => Predicted: 1\n",
      "Row 21247 => Predicted: 0\n",
      "Row 21248 => Predicted: 1\n",
      "Row 21249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21240 to 21249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21250 => Predicted: 0\n",
      "Row 21251 => Predicted: 1\n",
      "Row 21252 => Predicted: 0\n",
      "Row 21253 => Predicted: 0\n",
      "Row 21254 => Predicted: 1\n",
      "Row 21255 => Predicted: 0\n",
      "Row 21256 => Predicted: 0\n",
      "Row 21257 => Predicted: 1\n",
      "Row 21258 => Predicted: 1\n",
      "Row 21259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21250 to 21259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21260 => Predicted: 1\n",
      "Row 21261 => Predicted: 0\n",
      "Row 21262 => Predicted: 1\n",
      "Row 21263 => Predicted: 1\n",
      "Row 21264 => Predicted: 0\n",
      "Row 21265 => Predicted: 0\n",
      "Row 21266 => Predicted: 1\n",
      "Row 21267 => Predicted: 1\n",
      "Row 21268 => Predicted: 1\n",
      "Row 21269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21260 to 21269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21270 => Predicted: 1\n",
      "Row 21271 => Predicted: 1\n",
      "Row 21272 => Predicted: 1\n",
      "Row 21273 => Predicted: 1\n",
      "Row 21274 => Predicted: 1\n",
      "Row 21275 => Predicted: 1\n",
      "Row 21276 => Predicted: 1\n",
      "Row 21277 => Predicted: 0\n",
      "Row 21278 => Predicted: 1\n",
      "Row 21279 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21270 to 21279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21280 => Predicted: 1\n",
      "Row 21281 => Predicted: 0\n",
      "Row 21282 => Predicted: 0\n",
      "Row 21283 => Predicted: 1\n",
      "Row 21284 => Predicted: 1\n",
      "Row 21285 => Predicted: 1\n",
      "Row 21286 => Predicted: 0\n",
      "Row 21287 => Predicted: 0\n",
      "Row 21288 => Predicted: 0\n",
      "Row 21289 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21280 to 21289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21290 => Predicted: 1\n",
      "Row 21291 => Predicted: 0\n",
      "Row 21292 => Predicted: 0\n",
      "Row 21293 => Predicted: 0\n",
      "Row 21294 => Predicted: 0\n",
      "Row 21295 => Predicted: 1\n",
      "Row 21296 => Predicted: 0\n",
      "Row 21297 => Predicted: 1\n",
      "Row 21298 => Predicted: 1\n",
      "Row 21299 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21290 to 21299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21300 => Predicted: 0\n",
      "Row 21301 => Predicted: 0\n",
      "Row 21302 => Predicted: 1\n",
      "Row 21303 => Predicted: 1\n",
      "Row 21304 => Predicted: 0\n",
      "Row 21305 => Predicted: 0\n",
      "Row 21306 => Predicted: 0\n",
      "Row 21307 => Predicted: 1\n",
      "Row 21308 => Predicted: 1\n",
      "Row 21309 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21300 to 21309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21310 => Predicted: 1\n",
      "Row 21311 => Predicted: 0\n",
      "Row 21312 => Predicted: 1\n",
      "Row 21313 => Predicted: 1\n",
      "Row 21314 => Predicted: 0\n",
      "Row 21315 => Predicted: 1\n",
      "Row 21316 => Predicted: 1\n",
      "Row 21317 => Predicted: 0\n",
      "Row 21318 => Predicted: 0\n",
      "Row 21319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21310 to 21319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21320 => Predicted: 0\n",
      "Row 21321 => Predicted: 0\n",
      "Row 21322 => Predicted: 1\n",
      "Row 21323 => Predicted: 1\n",
      "Row 21324 => Predicted: 1\n",
      "Row 21325 => Predicted: 0\n",
      "Row 21326 => Predicted: 1\n",
      "Row 21327 => Predicted: 1\n",
      "Row 21328 => Predicted: 0\n",
      "Row 21329 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21320 to 21329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21330 => Predicted: 1\n",
      "Row 21331 => Predicted: 1\n",
      "Row 21332 => Predicted: 1\n",
      "Row 21333 => Predicted: 0\n",
      "Row 21334 => Predicted: 0\n",
      "Row 21335 => Predicted: 1\n",
      "Row 21336 => Predicted: 0\n",
      "Row 21337 => Predicted: 0\n",
      "Row 21338 => Predicted: 0\n",
      "Row 21339 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21330 to 21339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21340 => Predicted: 0\n",
      "Row 21341 => Predicted: 1\n",
      "Row 21342 => Predicted: 1\n",
      "Row 21343 => Predicted: 1\n",
      "Row 21344 => Predicted: 0\n",
      "Row 21345 => Predicted: 0\n",
      "Row 21346 => Predicted: 0\n",
      "Row 21347 => Predicted: 1\n",
      "Row 21348 => Predicted: 0\n",
      "Row 21349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21340 to 21349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21350 => Predicted: 1\n",
      "Row 21351 => Predicted: 0\n",
      "Row 21352 => Predicted: 1\n",
      "Row 21353 => Predicted: 0\n",
      "Row 21354 => Predicted: 1\n",
      "Row 21355 => Predicted: 0\n",
      "Row 21356 => Predicted: 1\n",
      "Row 21357 => Predicted: 1\n",
      "Row 21358 => Predicted: 0\n",
      "Row 21359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21350 to 21359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21360 => Predicted: 0\n",
      "Row 21361 => Predicted: 0\n",
      "Row 21362 => Predicted: 0\n",
      "Row 21363 => Predicted: 1\n",
      "Row 21364 => Predicted: 0\n",
      "Row 21365 => Predicted: 1\n",
      "Row 21366 => Predicted: 1\n",
      "Row 21367 => Predicted: 1\n",
      "Row 21368 => Predicted: 1\n",
      "Row 21369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21360 to 21369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21370 => Predicted: 1\n",
      "Row 21371 => Predicted: 0\n",
      "Row 21372 => Predicted: 1\n",
      "Row 21373 => Predicted: 1\n",
      "Row 21374 => Predicted: 1\n",
      "Row 21375 => Predicted: 1\n",
      "Row 21376 => Predicted: 1\n",
      "Row 21377 => Predicted: 1\n",
      "Row 21378 => Predicted: 1\n",
      "Row 21379 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21370 to 21379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21380 => Predicted: 1\n",
      "Row 21381 => Predicted: 1\n",
      "Row 21382 => Predicted: 0\n",
      "Row 21383 => Predicted: 0\n",
      "Row 21384 => Predicted: 0\n",
      "Row 21385 => Predicted: 0\n",
      "Row 21386 => Predicted: 0\n",
      "Row 21387 => Predicted: 1\n",
      "Row 21388 => Predicted: 1\n",
      "Row 21389 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21380 to 21389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21390 => Predicted: 0\n",
      "Row 21391 => Predicted: 0\n",
      "Row 21392 => Predicted: 1\n",
      "Row 21393 => Predicted: 0\n",
      "Row 21394 => Predicted: 0\n",
      "Row 21395 => Predicted: 1\n",
      "Row 21396 => Predicted: 0\n",
      "Row 21397 => Predicted: 1\n",
      "Row 21398 => Predicted: 1\n",
      "Row 21399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21390 to 21399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21400 => Predicted: 1\n",
      "Row 21401 => Predicted: 0\n",
      "Row 21402 => Predicted: 1\n",
      "Row 21403 => Predicted: 0\n",
      "Row 21404 => Predicted: 1\n",
      "Row 21405 => Predicted: 0\n",
      "Row 21406 => Predicted: 1\n",
      "Row 21407 => Predicted: 0\n",
      "Row 21408 => Predicted: 0\n",
      "Row 21409 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21400 to 21409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21410 => Predicted: 0\n",
      "Row 21411 => Predicted: 1\n",
      "Row 21412 => Predicted: 1\n",
      "Row 21413 => Predicted: 1\n",
      "Row 21414 => Predicted: 1\n",
      "Row 21415 => Predicted: 1\n",
      "Row 21416 => Predicted: 0\n",
      "Row 21417 => Predicted: 0\n",
      "Row 21418 => Predicted: 1\n",
      "Row 21419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21410 to 21419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21420 => Predicted: 0\n",
      "Row 21421 => Predicted: 0\n",
      "Row 21422 => Predicted: 0\n",
      "Row 21423 => Predicted: 0\n",
      "Row 21424 => Predicted: 0\n",
      "Row 21425 => Predicted: 1\n",
      "Row 21426 => Predicted: 0\n",
      "Row 21427 => Predicted: 1\n",
      "Row 21428 => Predicted: 0\n",
      "Row 21429 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21420 to 21429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21430 => Predicted: 1\n",
      "Row 21431 => Predicted: 0\n",
      "Row 21432 => Predicted: 0\n",
      "Row 21433 => Predicted: 0\n",
      "Row 21434 => Predicted: 0\n",
      "Row 21435 => Predicted: 0\n",
      "Row 21436 => Predicted: 1\n",
      "Row 21437 => Predicted: 1\n",
      "Row 21438 => Predicted: 0\n",
      "Row 21439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21430 to 21439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21440 => Predicted: 0\n",
      "Row 21441 => Predicted: 0\n",
      "Row 21442 => Predicted: 0\n",
      "Row 21443 => Predicted: 1\n",
      "Row 21444 => Predicted: 0\n",
      "Row 21445 => Predicted: 1\n",
      "Row 21446 => Predicted: 0\n",
      "Row 21447 => Predicted: 0\n",
      "Row 21448 => Predicted: 0\n",
      "Row 21449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21440 to 21449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21450 => Predicted: 1\n",
      "Row 21451 => Predicted: 1\n",
      "Row 21452 => Predicted: 0\n",
      "Row 21453 => Predicted: 1\n",
      "Row 21454 => Predicted: 0\n",
      "Row 21455 => Predicted: 0\n",
      "Row 21456 => Predicted: 1\n",
      "Row 21457 => Predicted: 1\n",
      "Row 21458 => Predicted: 0\n",
      "Row 21459 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21450 to 21459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21460 => Predicted: 1\n",
      "Row 21461 => Predicted: 0\n",
      "Row 21462 => Predicted: 1\n",
      "Row 21463 => Predicted: 0\n",
      "Row 21464 => Predicted: 0\n",
      "Row 21465 => Predicted: 1\n",
      "Row 21466 => Predicted: 1\n",
      "Row 21467 => Predicted: 0\n",
      "Row 21468 => Predicted: 1\n",
      "Row 21469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21460 to 21469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21470 => Predicted: 1\n",
      "Row 21471 => Predicted: 0\n",
      "Row 21472 => Predicted: 0\n",
      "Row 21473 => Predicted: 0\n",
      "Row 21474 => Predicted: 1\n",
      "Row 21475 => Predicted: 0\n",
      "Row 21476 => Predicted: 0\n",
      "Row 21477 => Predicted: 0\n",
      "Row 21478 => Predicted: 0\n",
      "Row 21479 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21470 to 21479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21480 => Predicted: 1\n",
      "Row 21481 => Predicted: 1\n",
      "Row 21482 => Predicted: 1\n",
      "Row 21483 => Predicted: 0\n",
      "Row 21484 => Predicted: 0\n",
      "Row 21485 => Predicted: 0\n",
      "Row 21486 => Predicted: 0\n",
      "Row 21487 => Predicted: 1\n",
      "Row 21488 => Predicted: 0\n",
      "Row 21489 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21480 to 21489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21490 => Predicted: 1\n",
      "Row 21491 => Predicted: 0\n",
      "Row 21492 => Predicted: 1\n",
      "Row 21493 => Predicted: 1\n",
      "Row 21494 => Predicted: 1\n",
      "Row 21495 => Predicted: 1\n",
      "Row 21496 => Predicted: 0\n",
      "Row 21497 => Predicted: 0\n",
      "Row 21498 => Predicted: 1\n",
      "Row 21499 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21490 to 21499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21500 => Predicted: 1\n",
      "Row 21501 => Predicted: 1\n",
      "Row 21502 => Predicted: 0\n",
      "Row 21503 => Predicted: 1\n",
      "Row 21504 => Predicted: 1\n",
      "Row 21505 => Predicted: 0\n",
      "Row 21506 => Predicted: 0\n",
      "Row 21507 => Predicted: 0\n",
      "Row 21508 => Predicted: 0\n",
      "Row 21509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21500 to 21509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21510 => Predicted: 1\n",
      "Row 21511 => Predicted: 1\n",
      "Row 21512 => Predicted: 1\n",
      "Row 21513 => Predicted: 0\n",
      "Row 21514 => Predicted: 0\n",
      "Row 21515 => Predicted: 0\n",
      "Row 21516 => Predicted: 1\n",
      "Row 21517 => Predicted: 1\n",
      "Row 21518 => Predicted: 0\n",
      "Row 21519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21510 to 21519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21520 => Predicted: 0\n",
      "Row 21521 => Predicted: 0\n",
      "Row 21522 => Predicted: 1\n",
      "Row 21523 => Predicted: 1\n",
      "Row 21524 => Predicted: 1\n",
      "Row 21525 => Predicted: 0\n",
      "Row 21526 => Predicted: 1\n",
      "Row 21527 => Predicted: 0\n",
      "Row 21528 => Predicted: 0\n",
      "Row 21529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21520 to 21529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21530 => Predicted: 0\n",
      "Row 21531 => Predicted: 1\n",
      "Row 21532 => Predicted: 1\n",
      "Row 21533 => Predicted: 0\n",
      "Row 21534 => Predicted: 0\n",
      "Row 21535 => Predicted: 0\n",
      "Row 21536 => Predicted: 1\n",
      "Row 21537 => Predicted: 1\n",
      "Row 21538 => Predicted: 0\n",
      "Row 21539 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21530 to 21539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21540 => Predicted: 0\n",
      "Row 21541 => Predicted: 0\n",
      "Row 21542 => Predicted: 1\n",
      "Row 21543 => Predicted: 1\n",
      "Row 21544 => Predicted: 0\n",
      "Row 21545 => Predicted: 1\n",
      "Row 21546 => Predicted: 0\n",
      "Row 21547 => Predicted: 0\n",
      "Row 21548 => Predicted: 1\n",
      "Row 21549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21540 to 21549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21550 => Predicted: 0\n",
      "Row 21551 => Predicted: 1\n",
      "Row 21552 => Predicted: 1\n",
      "Row 21553 => Predicted: 0\n",
      "Row 21554 => Predicted: 0\n",
      "Row 21555 => Predicted: 1\n",
      "Row 21556 => Predicted: 1\n",
      "Row 21557 => Predicted: 1\n",
      "Row 21558 => Predicted: 1\n",
      "Row 21559 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21550 to 21559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21560 => Predicted: 1\n",
      "Row 21561 => Predicted: 0\n",
      "Row 21562 => Predicted: 0\n",
      "Row 21563 => Predicted: 1\n",
      "Row 21564 => Predicted: 0\n",
      "Row 21565 => Predicted: 1\n",
      "Row 21566 => Predicted: 1\n",
      "Row 21567 => Predicted: 0\n",
      "Row 21568 => Predicted: 1\n",
      "Row 21569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21560 to 21569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21570 => Predicted: 0\n",
      "Row 21571 => Predicted: 1\n",
      "Row 21572 => Predicted: 1\n",
      "Row 21573 => Predicted: 1\n",
      "Row 21574 => Predicted: 1\n",
      "Row 21575 => Predicted: 0\n",
      "Row 21576 => Predicted: 0\n",
      "Row 21577 => Predicted: 1\n",
      "Row 21578 => Predicted: 0\n",
      "Row 21579 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21570 to 21579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21580 => Predicted: 0\n",
      "Row 21581 => Predicted: 1\n",
      "Row 21582 => Predicted: 0\n",
      "Row 21583 => Predicted: 0\n",
      "Row 21584 => Predicted: 0\n",
      "Row 21585 => Predicted: 1\n",
      "Row 21586 => Predicted: 0\n",
      "Row 21587 => Predicted: 1\n",
      "Row 21588 => Predicted: 1\n",
      "Row 21589 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21580 to 21589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21590 => Predicted: 1\n",
      "Row 21591 => Predicted: 0\n",
      "Row 21592 => Predicted: 0\n",
      "Row 21593 => Predicted: 0\n",
      "Row 21594 => Predicted: 1\n",
      "Row 21595 => Predicted: 1\n",
      "Row 21596 => Predicted: 0\n",
      "Row 21597 => Predicted: 0\n",
      "Row 21598 => Predicted: 1\n",
      "Row 21599 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21590 to 21599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21600 => Predicted: 0\n",
      "Row 21601 => Predicted: 0\n",
      "Row 21602 => Predicted: 0\n",
      "Row 21603 => Predicted: 1\n",
      "Row 21604 => Predicted: 1\n",
      "Row 21605 => Predicted: 1\n",
      "Row 21606 => Predicted: 1\n",
      "Row 21607 => Predicted: 1\n",
      "Row 21608 => Predicted: 0\n",
      "Row 21609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21600 to 21609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21610 => Predicted: 1\n",
      "Row 21611 => Predicted: 1\n",
      "Row 21612 => Predicted: 1\n",
      "Row 21613 => Predicted: 1\n",
      "Row 21614 => Predicted: 1\n",
      "Row 21615 => Predicted: 0\n",
      "Row 21616 => Predicted: 1\n",
      "Row 21617 => Predicted: 1\n",
      "Row 21618 => Predicted: 1\n",
      "Row 21619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21610 to 21619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21620 => Predicted: 1\n",
      "Row 21621 => Predicted: 1\n",
      "Row 21622 => Predicted: 1\n",
      "Row 21623 => Predicted: 1\n",
      "Row 21624 => Predicted: 1\n",
      "Row 21625 => Predicted: 0\n",
      "Row 21626 => Predicted: 1\n",
      "Row 21627 => Predicted: 1\n",
      "Row 21628 => Predicted: 0\n",
      "Row 21629 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21620 to 21629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21630 => Predicted: 0\n",
      "Row 21631 => Predicted: 1\n",
      "Row 21632 => Predicted: 0\n",
      "Row 21633 => Predicted: 1\n",
      "Row 21634 => Predicted: 0\n",
      "Row 21635 => Predicted: 0\n",
      "Row 21636 => Predicted: 0\n",
      "Row 21637 => Predicted: 1\n",
      "Row 21638 => Predicted: 0\n",
      "Row 21639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21630 to 21639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21640 => Predicted: 0\n",
      "Row 21641 => Predicted: 0\n",
      "Row 21642 => Predicted: 1\n",
      "Row 21643 => Predicted: 1\n",
      "Row 21644 => Predicted: 1\n",
      "Row 21645 => Predicted: 1\n",
      "Row 21646 => Predicted: 0\n",
      "Row 21647 => Predicted: 1\n",
      "Row 21648 => Predicted: 1\n",
      "Row 21649 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21640 to 21649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21650 => Predicted: 0\n",
      "Row 21651 => Predicted: 1\n",
      "Row 21652 => Predicted: 1\n",
      "Row 21653 => Predicted: 1\n",
      "Row 21654 => Predicted: 1\n",
      "Row 21655 => Predicted: 1\n",
      "Row 21656 => Predicted: 0\n",
      "Row 21657 => Predicted: 1\n",
      "Row 21658 => Predicted: 0\n",
      "Row 21659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21650 to 21659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21660 => Predicted: 0\n",
      "Row 21661 => Predicted: 1\n",
      "Row 21662 => Predicted: 1\n",
      "Row 21663 => Predicted: 0\n",
      "Row 21664 => Predicted: 1\n",
      "Row 21665 => Predicted: 0\n",
      "Row 21666 => Predicted: 1\n",
      "Row 21667 => Predicted: 1\n",
      "Row 21668 => Predicted: 1\n",
      "Row 21669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21660 to 21669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21670 => Predicted: 1\n",
      "Row 21671 => Predicted: 1\n",
      "Row 21672 => Predicted: 0\n",
      "Row 21673 => Predicted: 0\n",
      "Row 21674 => Predicted: 1\n",
      "Row 21675 => Predicted: 0\n",
      "Row 21676 => Predicted: 1\n",
      "Row 21677 => Predicted: 0\n",
      "Row 21678 => Predicted: 1\n",
      "Row 21679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21670 to 21679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21680 => Predicted: 1\n",
      "Row 21681 => Predicted: 0\n",
      "Row 21682 => Predicted: 0\n",
      "Row 21683 => Predicted: 1\n",
      "Row 21684 => Predicted: 0\n",
      "Row 21685 => Predicted: 0\n",
      "Row 21686 => Predicted: 0\n",
      "Row 21687 => Predicted: 1\n",
      "Row 21688 => Predicted: 1\n",
      "Row 21689 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21680 to 21689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21690 => Predicted: 0\n",
      "Row 21691 => Predicted: 1\n",
      "Row 21692 => Predicted: 1\n",
      "Row 21693 => Predicted: 0\n",
      "Row 21694 => Predicted: 1\n",
      "Row 21695 => Predicted: 1\n",
      "Row 21696 => Predicted: 1\n",
      "Row 21697 => Predicted: 1\n",
      "Row 21698 => Predicted: 0\n",
      "Row 21699 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21690 to 21699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21700 => Predicted: 0\n",
      "Row 21701 => Predicted: 1\n",
      "Row 21702 => Predicted: 1\n",
      "Row 21703 => Predicted: 1\n",
      "Row 21704 => Predicted: 1\n",
      "Row 21705 => Predicted: 1\n",
      "Row 21706 => Predicted: 0\n",
      "Row 21707 => Predicted: 0\n",
      "Row 21708 => Predicted: 0\n",
      "Row 21709 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21700 to 21709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21710 => Predicted: 1\n",
      "Row 21711 => Predicted: 1\n",
      "Row 21712 => Predicted: 0\n",
      "Row 21713 => Predicted: 0\n",
      "Row 21714 => Predicted: 0\n",
      "Row 21715 => Predicted: 1\n",
      "Row 21716 => Predicted: 1\n",
      "Row 21717 => Predicted: 0\n",
      "Row 21718 => Predicted: 0\n",
      "Row 21719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21710 to 21719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21720 => Predicted: 0\n",
      "Row 21721 => Predicted: 0\n",
      "Row 21722 => Predicted: 1\n",
      "Row 21723 => Predicted: 1\n",
      "Row 21724 => Predicted: 1\n",
      "Row 21725 => Predicted: 0\n",
      "Row 21726 => Predicted: 1\n",
      "Row 21727 => Predicted: 1\n",
      "Row 21728 => Predicted: 0\n",
      "Row 21729 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21720 to 21729...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21730 => Predicted: 0\n",
      "Row 21731 => Predicted: 1\n",
      "Row 21732 => Predicted: 0\n",
      "Row 21733 => Predicted: 1\n",
      "Row 21734 => Predicted: 1\n",
      "Row 21735 => Predicted: 0\n",
      "Row 21736 => Predicted: 0\n",
      "Row 21737 => Predicted: 0\n",
      "Row 21738 => Predicted: 1\n",
      "Row 21739 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21730 to 21739...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21740 => Predicted: 0\n",
      "Row 21741 => Predicted: 0\n",
      "Row 21742 => Predicted: 0\n",
      "Row 21743 => Predicted: 0\n",
      "Row 21744 => Predicted: 0\n",
      "Row 21745 => Predicted: 1\n",
      "Row 21746 => Predicted: 0\n",
      "Row 21747 => Predicted: 0\n",
      "Row 21748 => Predicted: 1\n",
      "Row 21749 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21740 to 21749...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21750 => Predicted: 0\n",
      "Row 21751 => Predicted: 1\n",
      "Row 21752 => Predicted: 1\n",
      "Row 21753 => Predicted: 1\n",
      "Row 21754 => Predicted: 0\n",
      "Row 21755 => Predicted: 0\n",
      "Row 21756 => Predicted: 0\n",
      "Row 21757 => Predicted: 1\n",
      "Row 21758 => Predicted: 0\n",
      "Row 21759 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21750 to 21759...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21760 => Predicted: 1\n",
      "Row 21761 => Predicted: 0\n",
      "Row 21762 => Predicted: 0\n",
      "Row 21763 => Predicted: 0\n",
      "Row 21764 => Predicted: 1\n",
      "Row 21765 => Predicted: 0\n",
      "Row 21766 => Predicted: 1\n",
      "Row 21767 => Predicted: 1\n",
      "Row 21768 => Predicted: 1\n",
      "Row 21769 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21760 to 21769...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21770 => Predicted: 0\n",
      "Row 21771 => Predicted: 1\n",
      "Row 21772 => Predicted: 0\n",
      "Row 21773 => Predicted: 1\n",
      "Row 21774 => Predicted: 0\n",
      "Row 21775 => Predicted: 0\n",
      "Row 21776 => Predicted: 1\n",
      "Row 21777 => Predicted: 0\n",
      "Row 21778 => Predicted: 0\n",
      "Row 21779 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21770 to 21779...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21780 => Predicted: 1\n",
      "Row 21781 => Predicted: 1\n",
      "Row 21782 => Predicted: 1\n",
      "Row 21783 => Predicted: 0\n",
      "Row 21784 => Predicted: 1\n",
      "Row 21785 => Predicted: 0\n",
      "Row 21786 => Predicted: 0\n",
      "Row 21787 => Predicted: 1\n",
      "Row 21788 => Predicted: 1\n",
      "Row 21789 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21780 to 21789...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21790 => Predicted: 0\n",
      "Row 21791 => Predicted: 1\n",
      "Row 21792 => Predicted: 1\n",
      "Row 21793 => Predicted: 0\n",
      "Row 21794 => Predicted: 1\n",
      "Row 21795 => Predicted: 1\n",
      "Row 21796 => Predicted: 1\n",
      "Row 21797 => Predicted: 1\n",
      "Row 21798 => Predicted: 1\n",
      "Row 21799 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21790 to 21799...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21800 => Predicted: 1\n",
      "Row 21801 => Predicted: 0\n",
      "Row 21802 => Predicted: 1\n",
      "Row 21803 => Predicted: 1\n",
      "Row 21804 => Predicted: 1\n",
      "Row 21805 => Predicted: 1\n",
      "Row 21806 => Predicted: 0\n",
      "Row 21807 => Predicted: 1\n",
      "Row 21808 => Predicted: 1\n",
      "Row 21809 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21800 to 21809...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21810 => Predicted: 0\n",
      "Row 21811 => Predicted: 0\n",
      "Row 21812 => Predicted: 1\n",
      "Row 21813 => Predicted: 1\n",
      "Row 21814 => Predicted: 0\n",
      "Row 21815 => Predicted: 0\n",
      "Row 21816 => Predicted: 0\n",
      "Row 21817 => Predicted: 1\n",
      "Row 21818 => Predicted: 0\n",
      "Row 21819 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21810 to 21819...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21820 => Predicted: 1\n",
      "Row 21821 => Predicted: 1\n",
      "Row 21822 => Predicted: 1\n",
      "Row 21823 => Predicted: 0\n",
      "Row 21824 => Predicted: 0\n",
      "Row 21825 => Predicted: 0\n",
      "Row 21826 => Predicted: 0\n",
      "Row 21827 => Predicted: 0\n",
      "Row 21828 => Predicted: 1\n",
      "Row 21829 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21820 to 21829...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21830 => Predicted: 0\n",
      "Row 21831 => Predicted: 1\n",
      "Row 21832 => Predicted: 1\n",
      "Row 21833 => Predicted: 0\n",
      "Row 21834 => Predicted: 0\n",
      "Row 21835 => Predicted: 1\n",
      "Row 21836 => Predicted: 0\n",
      "Row 21837 => Predicted: 1\n",
      "Row 21838 => Predicted: 1\n",
      "Row 21839 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21830 to 21839...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21840 => Predicted: 0\n",
      "Row 21841 => Predicted: 1\n",
      "Row 21842 => Predicted: 1\n",
      "Row 21843 => Predicted: 1\n",
      "Row 21844 => Predicted: 0\n",
      "Row 21845 => Predicted: 1\n",
      "Row 21846 => Predicted: 0\n",
      "Row 21847 => Predicted: 0\n",
      "Row 21848 => Predicted: 0\n",
      "Row 21849 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21840 to 21849...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21850 => Predicted: 1\n",
      "Row 21851 => Predicted: 0\n",
      "Row 21852 => Predicted: 0\n",
      "Row 21853 => Predicted: 1\n",
      "Row 21854 => Predicted: 1\n",
      "Row 21855 => Predicted: 1\n",
      "Row 21856 => Predicted: 0\n",
      "Row 21857 => Predicted: 0\n",
      "Row 21858 => Predicted: 0\n",
      "Row 21859 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21850 to 21859...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21860 => Predicted: 1\n",
      "Row 21861 => Predicted: 1\n",
      "Row 21862 => Predicted: 0\n",
      "Row 21863 => Predicted: 1\n",
      "Row 21864 => Predicted: 0\n",
      "Row 21865 => Predicted: 0\n",
      "Row 21866 => Predicted: 1\n",
      "Row 21867 => Predicted: 1\n",
      "Row 21868 => Predicted: 1\n",
      "Row 21869 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21860 to 21869...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21870 => Predicted: 1\n",
      "Row 21871 => Predicted: 1\n",
      "Row 21872 => Predicted: 1\n",
      "Row 21873 => Predicted: 0\n",
      "Row 21874 => Predicted: 0\n",
      "Row 21875 => Predicted: 1\n",
      "Row 21876 => Predicted: 0\n",
      "Row 21877 => Predicted: 0\n",
      "Row 21878 => Predicted: 0\n",
      "Row 21879 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21870 to 21879...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21880 => Predicted: 1\n",
      "Row 21881 => Predicted: 1\n",
      "Row 21882 => Predicted: 0\n",
      "Row 21883 => Predicted: 0\n",
      "Row 21884 => Predicted: 1\n",
      "Row 21885 => Predicted: 0\n",
      "Row 21886 => Predicted: 1\n",
      "Row 21887 => Predicted: 1\n",
      "Row 21888 => Predicted: 0\n",
      "Row 21889 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21880 to 21889...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21890 => Predicted: 1\n",
      "Row 21891 => Predicted: 1\n",
      "Row 21892 => Predicted: 1\n",
      "Row 21893 => Predicted: 1\n",
      "Row 21894 => Predicted: 0\n",
      "Row 21895 => Predicted: 0\n",
      "Row 21896 => Predicted: 1\n",
      "Row 21897 => Predicted: 0\n",
      "Row 21898 => Predicted: 1\n",
      "Row 21899 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21890 to 21899...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21900 => Predicted: 0\n",
      "Row 21901 => Predicted: 1\n",
      "Row 21902 => Predicted: 1\n",
      "Row 21903 => Predicted: 0\n",
      "Row 21904 => Predicted: 1\n",
      "Row 21905 => Predicted: 0\n",
      "Row 21906 => Predicted: 0\n",
      "Row 21907 => Predicted: 0\n",
      "Row 21908 => Predicted: 0\n",
      "Row 21909 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21900 to 21909...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21910 => Predicted: 1\n",
      "Row 21911 => Predicted: 1\n",
      "Row 21912 => Predicted: 0\n",
      "Row 21913 => Predicted: 0\n",
      "Row 21914 => Predicted: 0\n",
      "Row 21915 => Predicted: 1\n",
      "Row 21916 => Predicted: 1\n",
      "Row 21917 => Predicted: 0\n",
      "Row 21918 => Predicted: 1\n",
      "Row 21919 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21910 to 21919...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21920 => Predicted: 0\n",
      "Row 21921 => Predicted: 0\n",
      "Row 21922 => Predicted: 1\n",
      "Row 21923 => Predicted: 1\n",
      "Row 21924 => Predicted: 0\n",
      "Row 21925 => Predicted: 1\n",
      "Row 21926 => Predicted: 0\n",
      "Row 21927 => Predicted: 0\n",
      "Row 21928 => Predicted: 1\n",
      "Row 21929 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21920 to 21929...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21930 => Predicted: 0\n",
      "Row 21931 => Predicted: 1\n",
      "Row 21932 => Predicted: 0\n",
      "Row 21933 => Predicted: 1\n",
      "Row 21934 => Predicted: 1\n",
      "Row 21935 => Predicted: 0\n",
      "Row 21936 => Predicted: 1\n",
      "Row 21937 => Predicted: 1\n",
      "Row 21938 => Predicted: 1\n",
      "Row 21939 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21930 to 21939...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21940 => Predicted: 1\n",
      "Row 21941 => Predicted: 0\n",
      "Row 21942 => Predicted: 1\n",
      "Row 21943 => Predicted: 0\n",
      "Row 21944 => Predicted: 0\n",
      "Row 21945 => Predicted: 1\n",
      "Row 21946 => Predicted: 1\n",
      "Row 21947 => Predicted: 1\n",
      "Row 21948 => Predicted: 1\n",
      "Row 21949 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21940 to 21949...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21950 => Predicted: 0\n",
      "Row 21951 => Predicted: 1\n",
      "Row 21952 => Predicted: 1\n",
      "Row 21953 => Predicted: 1\n",
      "Row 21954 => Predicted: 0\n",
      "Row 21955 => Predicted: 0\n",
      "Row 21956 => Predicted: 0\n",
      "Row 21957 => Predicted: 1\n",
      "Row 21958 => Predicted: 0\n",
      "Row 21959 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21950 to 21959...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21960 => Predicted: 1\n",
      "Row 21961 => Predicted: 1\n",
      "Row 21962 => Predicted: 1\n",
      "Row 21963 => Predicted: 0\n",
      "Row 21964 => Predicted: 0\n",
      "Row 21965 => Predicted: 0\n",
      "Row 21966 => Predicted: 0\n",
      "Row 21967 => Predicted: 1\n",
      "Row 21968 => Predicted: 1\n",
      "Row 21969 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21960 to 21969...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21970 => Predicted: 1\n",
      "Row 21971 => Predicted: 1\n",
      "Row 21972 => Predicted: 1\n",
      "Row 21973 => Predicted: 1\n",
      "Row 21974 => Predicted: 1\n",
      "Row 21975 => Predicted: 0\n",
      "Row 21976 => Predicted: 0\n",
      "Row 21977 => Predicted: 1\n",
      "Row 21978 => Predicted: 1\n",
      "Row 21979 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21970 to 21979...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21980 => Predicted: 1\n",
      "Row 21981 => Predicted: 0\n",
      "Row 21982 => Predicted: 1\n",
      "Row 21983 => Predicted: 0\n",
      "Row 21984 => Predicted: 0\n",
      "Row 21985 => Predicted: 0\n",
      "Row 21986 => Predicted: 1\n",
      "Row 21987 => Predicted: 1\n",
      "Row 21988 => Predicted: 0\n",
      "Row 21989 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 21980 to 21989...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21990 => Predicted: 1\n",
      "Row 21991 => Predicted: 1\n",
      "Row 21992 => Predicted: 0\n",
      "Row 21993 => Predicted: 1\n",
      "Row 21994 => Predicted: 0\n",
      "Row 21995 => Predicted: 0\n",
      "Row 21996 => Predicted: 0\n",
      "Row 21997 => Predicted: 1\n",
      "Row 21998 => Predicted: 0\n",
      "Row 21999 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 21990 to 21999...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22000 => Predicted: 1\n",
      "Row 22001 => Predicted: 0\n",
      "Row 22002 => Predicted: 1\n",
      "Row 22003 => Predicted: 1\n",
      "Row 22004 => Predicted: 1\n",
      "Row 22005 => Predicted: 1\n",
      "Row 22006 => Predicted: 0\n",
      "Row 22007 => Predicted: 1\n",
      "Row 22008 => Predicted: 1\n",
      "Row 22009 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22000 to 22009...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22010 => Predicted: 0\n",
      "Row 22011 => Predicted: 0\n",
      "Row 22012 => Predicted: 1\n",
      "Row 22013 => Predicted: 0\n",
      "Row 22014 => Predicted: 1\n",
      "Row 22015 => Predicted: 0\n",
      "Row 22016 => Predicted: 0\n",
      "Row 22017 => Predicted: 1\n",
      "Row 22018 => Predicted: 0\n",
      "Row 22019 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22010 to 22019...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22020 => Predicted: 0\n",
      "Row 22021 => Predicted: 1\n",
      "Row 22022 => Predicted: 0\n",
      "Row 22023 => Predicted: 0\n",
      "Row 22024 => Predicted: 0\n",
      "Row 22025 => Predicted: 1\n",
      "Row 22026 => Predicted: 1\n",
      "Row 22027 => Predicted: 1\n",
      "Row 22028 => Predicted: 0\n",
      "Row 22029 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22020 to 22029...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22030 => Predicted: 1\n",
      "Row 22031 => Predicted: 1\n",
      "Row 22032 => Predicted: 1\n",
      "Row 22033 => Predicted: 1\n",
      "Row 22034 => Predicted: 0\n",
      "Row 22035 => Predicted: 0\n",
      "Row 22036 => Predicted: 1\n",
      "Row 22037 => Predicted: 1\n",
      "Row 22038 => Predicted: 0\n",
      "Row 22039 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22030 to 22039...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22040 => Predicted: 0\n",
      "Row 22041 => Predicted: 0\n",
      "Row 22042 => Predicted: 1\n",
      "Row 22043 => Predicted: 1\n",
      "Row 22044 => Predicted: 1\n",
      "Row 22045 => Predicted: 1\n",
      "Row 22046 => Predicted: 1\n",
      "Row 22047 => Predicted: 0\n",
      "Row 22048 => Predicted: 0\n",
      "Row 22049 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22040 to 22049...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22050 => Predicted: 0\n",
      "Row 22051 => Predicted: 0\n",
      "Row 22052 => Predicted: 1\n",
      "Row 22053 => Predicted: 1\n",
      "Row 22054 => Predicted: 1\n",
      "Row 22055 => Predicted: 0\n",
      "Row 22056 => Predicted: 0\n",
      "Row 22057 => Predicted: 0\n",
      "Row 22058 => Predicted: 0\n",
      "Row 22059 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22050 to 22059...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22060 => Predicted: 1\n",
      "Row 22061 => Predicted: 1\n",
      "Row 22062 => Predicted: 0\n",
      "Row 22063 => Predicted: 1\n",
      "Row 22064 => Predicted: 1\n",
      "Row 22065 => Predicted: 1\n",
      "Row 22066 => Predicted: 0\n",
      "Row 22067 => Predicted: 0\n",
      "Row 22068 => Predicted: 0\n",
      "Row 22069 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22060 to 22069...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22070 => Predicted: 0\n",
      "Row 22071 => Predicted: 0\n",
      "Row 22072 => Predicted: 0\n",
      "Row 22073 => Predicted: 1\n",
      "Row 22074 => Predicted: 0\n",
      "Row 22075 => Predicted: 1\n",
      "Row 22076 => Predicted: 0\n",
      "Row 22077 => Predicted: 1\n",
      "Row 22078 => Predicted: 0\n",
      "Row 22079 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22070 to 22079...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22080 => Predicted: 0\n",
      "Row 22081 => Predicted: 0\n",
      "Row 22082 => Predicted: 0\n",
      "Row 22083 => Predicted: 1\n",
      "Row 22084 => Predicted: 0\n",
      "Row 22085 => Predicted: 1\n",
      "Row 22086 => Predicted: 0\n",
      "Row 22087 => Predicted: 1\n",
      "Row 22088 => Predicted: 0\n",
      "Row 22089 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22080 to 22089...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22090 => Predicted: 0\n",
      "Row 22091 => Predicted: 0\n",
      "Row 22092 => Predicted: 1\n",
      "Row 22093 => Predicted: 1\n",
      "Row 22094 => Predicted: 1\n",
      "Row 22095 => Predicted: 0\n",
      "Row 22096 => Predicted: 1\n",
      "Row 22097 => Predicted: 1\n",
      "Row 22098 => Predicted: 1\n",
      "Row 22099 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22090 to 22099...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22100 => Predicted: 0\n",
      "Row 22101 => Predicted: 1\n",
      "Row 22102 => Predicted: 1\n",
      "Row 22103 => Predicted: 1\n",
      "Row 22104 => Predicted: 1\n",
      "Row 22105 => Predicted: 0\n",
      "Row 22106 => Predicted: 1\n",
      "Row 22107 => Predicted: 0\n",
      "Row 22108 => Predicted: 1\n",
      "Row 22109 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22100 to 22109...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22110 => Predicted: 1\n",
      "Row 22111 => Predicted: 0\n",
      "Row 22112 => Predicted: 0\n",
      "Row 22113 => Predicted: 0\n",
      "Row 22114 => Predicted: 0\n",
      "Row 22115 => Predicted: 1\n",
      "Row 22116 => Predicted: 0\n",
      "Row 22117 => Predicted: 0\n",
      "Row 22118 => Predicted: 1\n",
      "Row 22119 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22110 to 22119...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22120 => Predicted: 0\n",
      "Row 22121 => Predicted: 0\n",
      "Row 22122 => Predicted: 0\n",
      "Row 22123 => Predicted: 0\n",
      "Row 22124 => Predicted: 1\n",
      "Row 22125 => Predicted: 0\n",
      "Row 22126 => Predicted: 1\n",
      "Row 22127 => Predicted: 0\n",
      "Row 22128 => Predicted: 1\n",
      "Row 22129 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22120 to 22129...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22130 => Predicted: 1\n",
      "Row 22131 => Predicted: 0\n",
      "Row 22132 => Predicted: 0\n",
      "Row 22133 => Predicted: 0\n",
      "Row 22134 => Predicted: 1\n",
      "Row 22135 => Predicted: 0\n",
      "Row 22136 => Predicted: 1\n",
      "Row 22137 => Predicted: 0\n",
      "Row 22138 => Predicted: 1\n",
      "Row 22139 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22130 to 22139...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22140 => Predicted: 1\n",
      "Row 22141 => Predicted: 0\n",
      "Row 22142 => Predicted: 0\n",
      "Row 22143 => Predicted: 0\n",
      "Row 22144 => Predicted: 1\n",
      "Row 22145 => Predicted: 0\n",
      "Row 22146 => Predicted: 0\n",
      "Row 22147 => Predicted: 0\n",
      "Row 22148 => Predicted: 1\n",
      "Row 22149 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22140 to 22149...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22150 => Predicted: 1\n",
      "Row 22151 => Predicted: 0\n",
      "Row 22152 => Predicted: 0\n",
      "Row 22153 => Predicted: 0\n",
      "Row 22154 => Predicted: 0\n",
      "Row 22155 => Predicted: 1\n",
      "Row 22156 => Predicted: 1\n",
      "Row 22157 => Predicted: 1\n",
      "Row 22158 => Predicted: 1\n",
      "Row 22159 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22150 to 22159...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22160 => Predicted: 1\n",
      "Row 22161 => Predicted: 1\n",
      "Row 22162 => Predicted: 1\n",
      "Row 22163 => Predicted: 1\n",
      "Row 22164 => Predicted: 0\n",
      "Row 22165 => Predicted: 1\n",
      "Row 22166 => Predicted: 0\n",
      "Row 22167 => Predicted: 1\n",
      "Row 22168 => Predicted: 1\n",
      "Row 22169 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22160 to 22169...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22170 => Predicted: 1\n",
      "Row 22171 => Predicted: 1\n",
      "Row 22172 => Predicted: 0\n",
      "Row 22173 => Predicted: 1\n",
      "Row 22174 => Predicted: 1\n",
      "Row 22175 => Predicted: 0\n",
      "Row 22176 => Predicted: 0\n",
      "Row 22177 => Predicted: 1\n",
      "Row 22178 => Predicted: 1\n",
      "Row 22179 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22170 to 22179...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22180 => Predicted: 1\n",
      "Row 22181 => Predicted: 0\n",
      "Row 22182 => Predicted: 0\n",
      "Row 22183 => Predicted: 1\n",
      "Row 22184 => Predicted: 0\n",
      "Row 22185 => Predicted: 1\n",
      "Row 22186 => Predicted: 0\n",
      "Row 22187 => Predicted: 0\n",
      "Row 22188 => Predicted: 0\n",
      "Row 22189 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22180 to 22189...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22190 => Predicted: 1\n",
      "Row 22191 => Predicted: 0\n",
      "Row 22192 => Predicted: 1\n",
      "Row 22193 => Predicted: 0\n",
      "Row 22194 => Predicted: 1\n",
      "Row 22195 => Predicted: 0\n",
      "Row 22196 => Predicted: 0\n",
      "Row 22197 => Predicted: 1\n",
      "Row 22198 => Predicted: 0\n",
      "Row 22199 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22190 to 22199...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22200 => Predicted: 1\n",
      "Row 22201 => Predicted: 1\n",
      "Row 22202 => Predicted: 1\n",
      "Row 22203 => Predicted: 0\n",
      "Row 22204 => Predicted: 1\n",
      "Row 22205 => Predicted: 0\n",
      "Row 22206 => Predicted: 1\n",
      "Row 22207 => Predicted: 0\n",
      "Row 22208 => Predicted: 1\n",
      "Row 22209 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22200 to 22209...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22210 => Predicted: 0\n",
      "Row 22211 => Predicted: 1\n",
      "Row 22212 => Predicted: 0\n",
      "Row 22213 => Predicted: 1\n",
      "Row 22214 => Predicted: 0\n",
      "Row 22215 => Predicted: 0\n",
      "Row 22216 => Predicted: 0\n",
      "Row 22217 => Predicted: 0\n",
      "Row 22218 => Predicted: 1\n",
      "Row 22219 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22210 to 22219...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22220 => Predicted: 1\n",
      "Row 22221 => Predicted: 1\n",
      "Row 22222 => Predicted: 1\n",
      "Row 22223 => Predicted: 0\n",
      "Row 22224 => Predicted: 0\n",
      "Row 22225 => Predicted: 0\n",
      "Row 22226 => Predicted: 1\n",
      "Row 22227 => Predicted: 1\n",
      "Row 22228 => Predicted: 1\n",
      "Row 22229 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22220 to 22229...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22230 => Predicted: 0\n",
      "Row 22231 => Predicted: 1\n",
      "Row 22232 => Predicted: 0\n",
      "Row 22233 => Predicted: 0\n",
      "Row 22234 => Predicted: 0\n",
      "Row 22235 => Predicted: 0\n",
      "Row 22236 => Predicted: 0\n",
      "Row 22237 => Predicted: 0\n",
      "Row 22238 => Predicted: 0\n",
      "Row 22239 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22230 to 22239...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22240 => Predicted: 0\n",
      "Row 22241 => Predicted: 0\n",
      "Row 22242 => Predicted: 1\n",
      "Row 22243 => Predicted: 0\n",
      "Row 22244 => Predicted: 0\n",
      "Row 22245 => Predicted: 0\n",
      "Row 22246 => Predicted: 1\n",
      "Row 22247 => Predicted: 1\n",
      "Row 22248 => Predicted: 1\n",
      "Row 22249 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22240 to 22249...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22250 => Predicted: 1\n",
      "Row 22251 => Predicted: 1\n",
      "Row 22252 => Predicted: 0\n",
      "Row 22253 => Predicted: 0\n",
      "Row 22254 => Predicted: 0\n",
      "Row 22255 => Predicted: 0\n",
      "Row 22256 => Predicted: 0\n",
      "Row 22257 => Predicted: 0\n",
      "Row 22258 => Predicted: 0\n",
      "Row 22259 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22250 to 22259...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22260 => Predicted: 0\n",
      "Row 22261 => Predicted: 1\n",
      "Row 22262 => Predicted: 1\n",
      "Row 22263 => Predicted: 0\n",
      "Row 22264 => Predicted: 0\n",
      "Row 22265 => Predicted: 1\n",
      "Row 22266 => Predicted: 0\n",
      "Row 22267 => Predicted: 0\n",
      "Row 22268 => Predicted: 0\n",
      "Row 22269 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22260 to 22269...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22270 => Predicted: 1\n",
      "Row 22271 => Predicted: 1\n",
      "Row 22272 => Predicted: 1\n",
      "Row 22273 => Predicted: 1\n",
      "Row 22274 => Predicted: 1\n",
      "Row 22275 => Predicted: 0\n",
      "Row 22276 => Predicted: 1\n",
      "Row 22277 => Predicted: 0\n",
      "Row 22278 => Predicted: 1\n",
      "Row 22279 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22270 to 22279...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22280 => Predicted: 1\n",
      "Row 22281 => Predicted: 1\n",
      "Row 22282 => Predicted: 0\n",
      "Row 22283 => Predicted: 1\n",
      "Row 22284 => Predicted: 1\n",
      "Row 22285 => Predicted: 1\n",
      "Row 22286 => Predicted: 1\n",
      "Row 22287 => Predicted: 1\n",
      "Row 22288 => Predicted: 1\n",
      "Row 22289 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22280 to 22289...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22290 => Predicted: 1\n",
      "Row 22291 => Predicted: 1\n",
      "Row 22292 => Predicted: 0\n",
      "Row 22293 => Predicted: 1\n",
      "Row 22294 => Predicted: 1\n",
      "Row 22295 => Predicted: 0\n",
      "Row 22296 => Predicted: 1\n",
      "Row 22297 => Predicted: 0\n",
      "Row 22298 => Predicted: 0\n",
      "Row 22299 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22290 to 22299...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22300 => Predicted: 1\n",
      "Row 22301 => Predicted: 0\n",
      "Row 22302 => Predicted: 0\n",
      "Row 22303 => Predicted: 0\n",
      "Row 22304 => Predicted: 0\n",
      "Row 22305 => Predicted: 1\n",
      "Row 22306 => Predicted: 1\n",
      "Row 22307 => Predicted: 0\n",
      "Row 22308 => Predicted: 1\n",
      "Row 22309 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22300 to 22309...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22310 => Predicted: 0\n",
      "Row 22311 => Predicted: 0\n",
      "Row 22312 => Predicted: 1\n",
      "Row 22313 => Predicted: 0\n",
      "Row 22314 => Predicted: 1\n",
      "Row 22315 => Predicted: 1\n",
      "Row 22316 => Predicted: 1\n",
      "Row 22317 => Predicted: 0\n",
      "Row 22318 => Predicted: 0\n",
      "Row 22319 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22310 to 22319...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22320 => Predicted: 0\n",
      "Row 22321 => Predicted: 1\n",
      "Row 22322 => Predicted: 0\n",
      "Row 22323 => Predicted: 1\n",
      "Row 22324 => Predicted: 1\n",
      "Row 22325 => Predicted: 0\n",
      "Row 22326 => Predicted: 1\n",
      "Row 22327 => Predicted: 1\n",
      "Row 22328 => Predicted: 0\n",
      "Row 22329 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22320 to 22329...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22330 => Predicted: 1\n",
      "Row 22331 => Predicted: 1\n",
      "Row 22332 => Predicted: 1\n",
      "Row 22333 => Predicted: 1\n",
      "Row 22334 => Predicted: 1\n",
      "Row 22335 => Predicted: 0\n",
      "Row 22336 => Predicted: 0\n",
      "Row 22337 => Predicted: 1\n",
      "Row 22338 => Predicted: 0\n",
      "Row 22339 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22330 to 22339...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22340 => Predicted: 1\n",
      "Row 22341 => Predicted: 0\n",
      "Row 22342 => Predicted: 0\n",
      "Row 22343 => Predicted: 1\n",
      "Row 22344 => Predicted: 1\n",
      "Row 22345 => Predicted: 0\n",
      "Row 22346 => Predicted: 1\n",
      "Row 22347 => Predicted: 0\n",
      "Row 22348 => Predicted: 1\n",
      "Row 22349 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22340 to 22349...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22350 => Predicted: 0\n",
      "Row 22351 => Predicted: 0\n",
      "Row 22352 => Predicted: 1\n",
      "Row 22353 => Predicted: 0\n",
      "Row 22354 => Predicted: 0\n",
      "Row 22355 => Predicted: 1\n",
      "Row 22356 => Predicted: 0\n",
      "Row 22357 => Predicted: 1\n",
      "Row 22358 => Predicted: 0\n",
      "Row 22359 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22350 to 22359...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22360 => Predicted: 1\n",
      "Row 22361 => Predicted: 1\n",
      "Row 22362 => Predicted: 1\n",
      "Row 22363 => Predicted: 1\n",
      "Row 22364 => Predicted: 0\n",
      "Row 22365 => Predicted: 0\n",
      "Row 22366 => Predicted: 1\n",
      "Row 22367 => Predicted: 0\n",
      "Row 22368 => Predicted: 0\n",
      "Row 22369 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22360 to 22369...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22370 => Predicted: 0\n",
      "Row 22371 => Predicted: 0\n",
      "Row 22372 => Predicted: 0\n",
      "Row 22373 => Predicted: 1\n",
      "Row 22374 => Predicted: 1\n",
      "Row 22375 => Predicted: 1\n",
      "Row 22376 => Predicted: 1\n",
      "Row 22377 => Predicted: 1\n",
      "Row 22378 => Predicted: 0\n",
      "Row 22379 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22370 to 22379...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22380 => Predicted: 1\n",
      "Row 22381 => Predicted: 0\n",
      "Row 22382 => Predicted: 1\n",
      "Row 22383 => Predicted: 1\n",
      "Row 22384 => Predicted: 0\n",
      "Row 22385 => Predicted: 0\n",
      "Row 22386 => Predicted: 1\n",
      "Row 22387 => Predicted: 0\n",
      "Row 22388 => Predicted: 1\n",
      "Row 22389 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22380 to 22389...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22390 => Predicted: 1\n",
      "Row 22391 => Predicted: 0\n",
      "Row 22392 => Predicted: 0\n",
      "Row 22393 => Predicted: 0\n",
      "Row 22394 => Predicted: 1\n",
      "Row 22395 => Predicted: 1\n",
      "Row 22396 => Predicted: 0\n",
      "Row 22397 => Predicted: 0\n",
      "Row 22398 => Predicted: 0\n",
      "Row 22399 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22390 to 22399...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22400 => Predicted: 0\n",
      "Row 22401 => Predicted: 1\n",
      "Row 22402 => Predicted: 0\n",
      "Row 22403 => Predicted: 1\n",
      "Row 22404 => Predicted: 1\n",
      "Row 22405 => Predicted: 0\n",
      "Row 22406 => Predicted: 0\n",
      "Row 22407 => Predicted: 0\n",
      "Row 22408 => Predicted: 1\n",
      "Row 22409 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22400 to 22409...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22410 => Predicted: 1\n",
      "Row 22411 => Predicted: 0\n",
      "Row 22412 => Predicted: 0\n",
      "Row 22413 => Predicted: 1\n",
      "Row 22414 => Predicted: 0\n",
      "Row 22415 => Predicted: 0\n",
      "Row 22416 => Predicted: 1\n",
      "Row 22417 => Predicted: 1\n",
      "Row 22418 => Predicted: 0\n",
      "Row 22419 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22410 to 22419...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22420 => Predicted: 0\n",
      "Row 22421 => Predicted: 0\n",
      "Row 22422 => Predicted: 1\n",
      "Row 22423 => Predicted: 1\n",
      "Row 22424 => Predicted: 1\n",
      "Row 22425 => Predicted: 1\n",
      "Row 22426 => Predicted: 1\n",
      "Row 22427 => Predicted: 0\n",
      "Row 22428 => Predicted: 1\n",
      "Row 22429 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22420 to 22429...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22430 => Predicted: 0\n",
      "Row 22431 => Predicted: 0\n",
      "Row 22432 => Predicted: 1\n",
      "Row 22433 => Predicted: 0\n",
      "Row 22434 => Predicted: 0\n",
      "Row 22435 => Predicted: 1\n",
      "Row 22436 => Predicted: 1\n",
      "Row 22437 => Predicted: 1\n",
      "Row 22438 => Predicted: 0\n",
      "Row 22439 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22430 to 22439...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22440 => Predicted: 1\n",
      "Row 22441 => Predicted: 1\n",
      "Row 22442 => Predicted: 1\n",
      "Row 22443 => Predicted: 1\n",
      "Row 22444 => Predicted: 1\n",
      "Row 22445 => Predicted: 0\n",
      "Row 22446 => Predicted: 1\n",
      "Row 22447 => Predicted: 1\n",
      "Row 22448 => Predicted: 0\n",
      "Row 22449 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22440 to 22449...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22450 => Predicted: 1\n",
      "Row 22451 => Predicted: 0\n",
      "Row 22452 => Predicted: 1\n",
      "Row 22453 => Predicted: 1\n",
      "Row 22454 => Predicted: 0\n",
      "Row 22455 => Predicted: 1\n",
      "Row 22456 => Predicted: 1\n",
      "Row 22457 => Predicted: 1\n",
      "Row 22458 => Predicted: 0\n",
      "Row 22459 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22450 to 22459...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22460 => Predicted: 0\n",
      "Row 22461 => Predicted: 0\n",
      "Row 22462 => Predicted: 0\n",
      "Row 22463 => Predicted: 0\n",
      "Row 22464 => Predicted: 1\n",
      "Row 22465 => Predicted: 0\n",
      "Row 22466 => Predicted: 0\n",
      "Row 22467 => Predicted: 0\n",
      "Row 22468 => Predicted: 0\n",
      "Row 22469 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22460 to 22469...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22470 => Predicted: 0\n",
      "Row 22471 => Predicted: 1\n",
      "Row 22472 => Predicted: 0\n",
      "Row 22473 => Predicted: 1\n",
      "Row 22474 => Predicted: 0\n",
      "Row 22475 => Predicted: 1\n",
      "Row 22476 => Predicted: 1\n",
      "Row 22477 => Predicted: 0\n",
      "Row 22478 => Predicted: 1\n",
      "Row 22479 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22470 to 22479...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22480 => Predicted: 1\n",
      "Row 22481 => Predicted: 0\n",
      "Row 22482 => Predicted: 0\n",
      "Row 22483 => Predicted: 0\n",
      "Row 22484 => Predicted: 0\n",
      "Row 22485 => Predicted: 1\n",
      "Row 22486 => Predicted: 0\n",
      "Row 22487 => Predicted: 1\n",
      "Row 22488 => Predicted: 1\n",
      "Row 22489 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22480 to 22489...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22490 => Predicted: 0\n",
      "Row 22491 => Predicted: 1\n",
      "Row 22492 => Predicted: 1\n",
      "Row 22493 => Predicted: 0\n",
      "Row 22494 => Predicted: 0\n",
      "Row 22495 => Predicted: 0\n",
      "Row 22496 => Predicted: 1\n",
      "Row 22497 => Predicted: 1\n",
      "Row 22498 => Predicted: 1\n",
      "Row 22499 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22490 to 22499...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22500 => Predicted: 1\n",
      "Row 22501 => Predicted: 1\n",
      "Row 22502 => Predicted: 0\n",
      "Row 22503 => Predicted: 0\n",
      "Row 22504 => Predicted: 1\n",
      "Row 22505 => Predicted: 1\n",
      "Row 22506 => Predicted: 0\n",
      "Row 22507 => Predicted: 0\n",
      "Row 22508 => Predicted: 1\n",
      "Row 22509 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22500 to 22509...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22510 => Predicted: 1\n",
      "Row 22511 => Predicted: 1\n",
      "Row 22512 => Predicted: 0\n",
      "Row 22513 => Predicted: 1\n",
      "Row 22514 => Predicted: 1\n",
      "Row 22515 => Predicted: 0\n",
      "Row 22516 => Predicted: 1\n",
      "Row 22517 => Predicted: 1\n",
      "Row 22518 => Predicted: 1\n",
      "Row 22519 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22510 to 22519...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22520 => Predicted: 1\n",
      "Row 22521 => Predicted: 1\n",
      "Row 22522 => Predicted: 1\n",
      "Row 22523 => Predicted: 0\n",
      "Row 22524 => Predicted: 1\n",
      "Row 22525 => Predicted: 0\n",
      "Row 22526 => Predicted: 1\n",
      "Row 22527 => Predicted: 1\n",
      "Row 22528 => Predicted: 1\n",
      "Row 22529 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22520 to 22529...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22530 => Predicted: 1\n",
      "Row 22531 => Predicted: 1\n",
      "Row 22532 => Predicted: 0\n",
      "Row 22533 => Predicted: 1\n",
      "Row 22534 => Predicted: 0\n",
      "Row 22535 => Predicted: 0\n",
      "Row 22536 => Predicted: 0\n",
      "Row 22537 => Predicted: 1\n",
      "Row 22538 => Predicted: 1\n",
      "Row 22539 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22530 to 22539...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22540 => Predicted: 0\n",
      "Row 22541 => Predicted: 0\n",
      "Row 22542 => Predicted: 1\n",
      "Row 22543 => Predicted: 0\n",
      "Row 22544 => Predicted: 0\n",
      "Row 22545 => Predicted: 1\n",
      "Row 22546 => Predicted: 0\n",
      "Row 22547 => Predicted: 1\n",
      "Row 22548 => Predicted: 0\n",
      "Row 22549 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22540 to 22549...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22550 => Predicted: 1\n",
      "Row 22551 => Predicted: 0\n",
      "Row 22552 => Predicted: 0\n",
      "Row 22553 => Predicted: 0\n",
      "Row 22554 => Predicted: 1\n",
      "Row 22555 => Predicted: 1\n",
      "Row 22556 => Predicted: 1\n",
      "Row 22557 => Predicted: 0\n",
      "Row 22558 => Predicted: 0\n",
      "Row 22559 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22550 to 22559...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22560 => Predicted: 0\n",
      "Row 22561 => Predicted: 0\n",
      "Row 22562 => Predicted: 0\n",
      "Row 22563 => Predicted: 1\n",
      "Row 22564 => Predicted: 0\n",
      "Row 22565 => Predicted: 1\n",
      "Row 22566 => Predicted: 0\n",
      "Row 22567 => Predicted: 1\n",
      "Row 22568 => Predicted: 1\n",
      "Row 22569 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22560 to 22569...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22570 => Predicted: 1\n",
      "Row 22571 => Predicted: 0\n",
      "Row 22572 => Predicted: 1\n",
      "Row 22573 => Predicted: 1\n",
      "Row 22574 => Predicted: 0\n",
      "Row 22575 => Predicted: 1\n",
      "Row 22576 => Predicted: 0\n",
      "Row 22577 => Predicted: 0\n",
      "Row 22578 => Predicted: 1\n",
      "Row 22579 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22570 to 22579...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22580 => Predicted: 0\n",
      "Row 22581 => Predicted: 1\n",
      "Row 22582 => Predicted: 0\n",
      "Row 22583 => Predicted: 1\n",
      "Row 22584 => Predicted: 1\n",
      "Row 22585 => Predicted: 0\n",
      "Row 22586 => Predicted: 1\n",
      "Row 22587 => Predicted: 1\n",
      "Row 22588 => Predicted: 1\n",
      "Row 22589 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22580 to 22589...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22590 => Predicted: 1\n",
      "Row 22591 => Predicted: 0\n",
      "Row 22592 => Predicted: 1\n",
      "Row 22593 => Predicted: 1\n",
      "Row 22594 => Predicted: 0\n",
      "Row 22595 => Predicted: 1\n",
      "Row 22596 => Predicted: 1\n",
      "Row 22597 => Predicted: 0\n",
      "Row 22598 => Predicted: 0\n",
      "Row 22599 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22590 to 22599...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22600 => Predicted: 1\n",
      "Row 22601 => Predicted: 1\n",
      "Row 22602 => Predicted: 0\n",
      "Row 22603 => Predicted: 1\n",
      "Row 22604 => Predicted: 1\n",
      "Row 22605 => Predicted: 1\n",
      "Row 22606 => Predicted: 0\n",
      "Row 22607 => Predicted: 1\n",
      "Row 22608 => Predicted: 0\n",
      "Row 22609 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22600 to 22609...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22610 => Predicted: 1\n",
      "Row 22611 => Predicted: 1\n",
      "Row 22612 => Predicted: 1\n",
      "Row 22613 => Predicted: 1\n",
      "Row 22614 => Predicted: 1\n",
      "Row 22615 => Predicted: 0\n",
      "Row 22616 => Predicted: 0\n",
      "Row 22617 => Predicted: 1\n",
      "Row 22618 => Predicted: 1\n",
      "Row 22619 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22610 to 22619...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22620 => Predicted: 0\n",
      "Row 22621 => Predicted: 1\n",
      "Row 22622 => Predicted: 1\n",
      "Row 22623 => Predicted: 1\n",
      "Row 22624 => Predicted: 0\n",
      "Row 22625 => Predicted: 0\n",
      "Row 22626 => Predicted: 0\n",
      "Row 22627 => Predicted: 0\n",
      "Row 22628 => Predicted: 1\n",
      "Row 22629 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22620 to 22629...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22630 => Predicted: 1\n",
      "Row 22631 => Predicted: 1\n",
      "Row 22632 => Predicted: 0\n",
      "Row 22633 => Predicted: 0\n",
      "Row 22634 => Predicted: 1\n",
      "Row 22635 => Predicted: 1\n",
      "Row 22636 => Predicted: 1\n",
      "Row 22637 => Predicted: 0\n",
      "Row 22638 => Predicted: 1\n",
      "Row 22639 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22630 to 22639...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22640 => Predicted: 0\n",
      "Row 22641 => Predicted: 0\n",
      "Row 22642 => Predicted: 1\n",
      "Row 22643 => Predicted: 1\n",
      "Row 22644 => Predicted: 0\n",
      "Row 22645 => Predicted: 1\n",
      "Row 22646 => Predicted: 0\n",
      "Row 22647 => Predicted: 1\n",
      "Row 22648 => Predicted: 0\n",
      "Row 22649 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22640 to 22649...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22650 => Predicted: 0\n",
      "Row 22651 => Predicted: 1\n",
      "Row 22652 => Predicted: 1\n",
      "Row 22653 => Predicted: 1\n",
      "Row 22654 => Predicted: 1\n",
      "Row 22655 => Predicted: 1\n",
      "Row 22656 => Predicted: 1\n",
      "Row 22657 => Predicted: 0\n",
      "Row 22658 => Predicted: 0\n",
      "Row 22659 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22650 to 22659...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22660 => Predicted: 1\n",
      "Row 22661 => Predicted: 1\n",
      "Row 22662 => Predicted: 0\n",
      "Row 22663 => Predicted: 1\n",
      "Row 22664 => Predicted: 0\n",
      "Row 22665 => Predicted: 0\n",
      "Row 22666 => Predicted: 0\n",
      "Row 22667 => Predicted: 0\n",
      "Row 22668 => Predicted: 0\n",
      "Row 22669 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22660 to 22669...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22670 => Predicted: 0\n",
      "Row 22671 => Predicted: 0\n",
      "Row 22672 => Predicted: 0\n",
      "Row 22673 => Predicted: 0\n",
      "Row 22674 => Predicted: 0\n",
      "Row 22675 => Predicted: 1\n",
      "Row 22676 => Predicted: 1\n",
      "Row 22677 => Predicted: 0\n",
      "Row 22678 => Predicted: 1\n",
      "Row 22679 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22670 to 22679...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22680 => Predicted: 0\n",
      "Row 22681 => Predicted: 0\n",
      "Row 22682 => Predicted: 1\n",
      "Row 22683 => Predicted: 1\n",
      "Row 22684 => Predicted: 1\n",
      "Row 22685 => Predicted: 1\n",
      "Row 22686 => Predicted: 1\n",
      "Row 22687 => Predicted: 1\n",
      "Row 22688 => Predicted: 1\n",
      "Row 22689 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22680 to 22689...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22690 => Predicted: 0\n",
      "Row 22691 => Predicted: 0\n",
      "Row 22692 => Predicted: 0\n",
      "Row 22693 => Predicted: 0\n",
      "Row 22694 => Predicted: 0\n",
      "Row 22695 => Predicted: 1\n",
      "Row 22696 => Predicted: 1\n",
      "Row 22697 => Predicted: 1\n",
      "Row 22698 => Predicted: 0\n",
      "Row 22699 => Predicted: 0\n",
      "\n",
      "Terminating Ollama server after rows 22690 to 22699...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22700 => Predicted: 0\n",
      "Row 22701 => Predicted: 1\n",
      "Row 22702 => Predicted: 1\n",
      "Row 22703 => Predicted: 1\n",
      "Row 22704 => Predicted: 0\n",
      "Row 22705 => Predicted: 0\n",
      "Row 22706 => Predicted: 1\n",
      "Row 22707 => Predicted: 1\n",
      "Row 22708 => Predicted: 1\n",
      "Row 22709 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22700 to 22709...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22710 => Predicted: 1\n",
      "Row 22711 => Predicted: 1\n",
      "Row 22712 => Predicted: 0\n",
      "Row 22713 => Predicted: 0\n",
      "Row 22714 => Predicted: 1\n",
      "Row 22715 => Predicted: 1\n",
      "Row 22716 => Predicted: 0\n",
      "Row 22717 => Predicted: 0\n",
      "Row 22718 => Predicted: 0\n",
      "Row 22719 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22710 to 22719...\n",
      "Server stopped.\n",
      "\n",
      "Starting Ollama server (default port 11434)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22720 => Predicted: 1\n",
      "Row 22721 => Predicted: 1\n",
      "Row 22722 => Predicted: 0\n",
      "Row 22723 => Predicted: 0\n",
      "Row 22724 => Predicted: 0\n",
      "Row 22725 => Predicted: 0\n",
      "Row 22726 => Predicted: 1\n",
      "\n",
      "Terminating Ollama server after rows 22720 to 22726...\n",
      "Server stopped.\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10145  1156]\n",
      " [  875 10551]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91     11301\n",
      "    positive       0.90      0.92      0.91     11426\n",
      "\n",
      "    accuracy                           0.91     22727\n",
      "   macro avg       0.91      0.91      0.91     22727\n",
      "weighted avg       0.91      0.91      0.91     22727\n",
      "\n",
      "Saved predictions to ollama_reviews_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load dataset\n",
    "    csv_path = f\"{base_dir}/filtered_test_sen.csv\"   \n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Batch setup\n",
    "    chunk_size = 10   # 10 rows per batch\n",
    "    model_name = \"llama3.2\"\n",
    "    predictions = [None] * len(df)  \n",
    "\n",
    "    # Loop through DataFrame in batches\n",
    "    for start_idx in range(0, len(df), chunk_size):\n",
    "        end_idx = min(start_idx + chunk_size, len(df))\n",
    "        batch_rows = range(start_idx, end_idx)\n",
    "\n",
    "        # Start Ollama server \n",
    "        server_process, logs = start_ollama_server()\n",
    "        time.sleep(3)  \n",
    "\n",
    "        # For every row in each batch, review text is extracted and returns sentiment label\n",
    "        for idx in batch_rows:\n",
    "            text = df.at[idx, \"Text\"]\n",
    "            pred = classify_sentiment(text, model_name=model_name, timeout=60)\n",
    "            predictions[idx] = pred\n",
    "            print(f\"Row {idx} => Predicted: {pred}\")\n",
    "\n",
    "        # Stop Ollama server \n",
    "        print(f\"\\nTerminating Ollama server after rows {start_idx} to {end_idx-1}...\")\n",
    "        server_process.terminate()\n",
    "        server_process.wait()\n",
    "        print(\"Server stopped.\\n\")\n",
    "\n",
    "    # Predictions added to new column\n",
    "    df[\"prediction\"] = predictions\n",
    "\n",
    "    # Evaluation using confusion matrix and classification report\n",
    "    if \"Sentiment\" in df.columns:\n",
    "        y_true = df[\"Sentiment\"]\n",
    "        y_pred = df[\"prediction\"]\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        report = classification_report(y_true, y_pred, target_names=[\"negative\", \"positive\"])\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "\n",
    "    # Save results as separate file\n",
    "    output_path = \"ollama_reviews_with_predictions.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved predictions to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.90      0.91     11301\n",
      "    Positive       0.90      0.92      0.91     11426\n",
      "\n",
      "    accuracy                           0.91     22727\n",
      "   macro avg       0.91      0.91      0.91     22727\n",
      "weighted avg       0.91      0.91      0.91     22727\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{base_dir}/ollama_reviews_with_predictions.csv\")\n",
    "y_true = df[\"Sentiment\"]       \n",
    "y_pred = df[\"prediction\"]  \n",
    "numeric_labels = [0, 1]          \n",
    "class_names = [\"Negative\", \"Positive\"]  \n",
    "cm = confusion_matrix(y_true, y_pred, labels=numeric_labels)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix: Amazon Fine Food Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Comparing DistilBERT and Llama 3.2 Predictions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distil = pd.read_csv(\"test_with_distilbert_predictions.csv\")\n",
    "df_llama = pd.read_csv(\"ollama_reviews_with_predictions.csv\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_distil[['Text', 'Sentiment', 'distilbert_prediction']],  \n",
    "    df_llama[['Text', 'prediction']],                     \n",
    "    on='Text',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "df_merged.rename(columns={\n",
    "    'Sentiment': 'ground_truth', \n",
    "    'distilbert_prediction': 'distilbert_pred',\n",
    "    'prediction': 'llama_pred'\n",
    "}, inplace=True)\n",
    "\n",
    "final_columns = ['Text', 'ground_truth', 'distilbert_pred', 'llama_pred']\n",
    "df_final = df_merged[final_columns]\n",
    "\n",
    "df_final.to_csv(\"comparison_distil_llama.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3.2 performs better than DistilBERT:  629\n",
      "DistilBERT performs better than Llama 3.2:  1565\n",
      "Both fail:  466\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"comparison_distil_llama.csv\")\n",
    "distil_correct = df[\"distilbert_pred\"] == df[\"ground_truth\"]\n",
    "llama_correct = df[\"llama_pred\"] == df[\"ground_truth\"]\n",
    "\n",
    "# Cases where Llama 3.2 is correct and DistilBERT is not\n",
    "df_llama_better = df[llama_correct & (~distil_correct)]\n",
    "\n",
    "# Cases where DistilBERT is correct and Llama 3.2 is not\n",
    "df_distil_better = df[distil_correct & (~llama_correct)]\n",
    "\n",
    "# Cases where both fail the ground truth\n",
    "df_both_fail = df[(~llama_correct) & (~distil_correct)]\n",
    "\n",
    "print(\"Llama 3.2 performs better than DistilBERT: \", len(df_llama_better))\n",
    "print(\"DistilBERT performs better than Llama 3.2: \", len(df_distil_better))\n",
    "print(\"Both fail: \", len(df_both_fail))\n",
    "\n",
    "df_llama_better.to_csv(\"llama_performs_better.csv\", index=False)\n",
    "df_distil_better.to_csv(\"distil_performs_better.csv\", index=False)\n",
    "df_both_fail.to_csv(\"both_fail.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
